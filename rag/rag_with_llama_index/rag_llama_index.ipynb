{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install llama_hub llama_index braintrust autoevals pypdf pillow transformers torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget --user-agent \"Mozilla\" \"https://arxiv.org/pdf/2307.09288.pdf\" -O \"llama2.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charan/VS_Code/GitHub/Advanced_RAG/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "llm = GoogleGenerativeAI(model=\"gemini-pro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "# from llama_hub.file.pdf.base import PDFReader\n",
    "from llama_index.core.response.notebook_utils import display_source_node\n",
    "from llama_index.core.retrievers import RecursiveRetriever\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core import VectorStoreIndex, ServiceContext\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "documents = SimpleDirectoryReader(\"./data2\").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(id_='894bedd8-c60b-4bc6-abc1-a5f68028ea66', embedding=None, metadata={'page_label': '1', 'file_name': 'llama2.pdf', 'file_path': 'data2/llama2.pdf', 'file_type': 'application/pdf', 'file_size': 13661300, 'creation_date': '2024-02-18', 'last_modified_date': '2023-07-20', 'last_accessed_date': '2024-02-18'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Llama 2 : Open Foundation and Fine-Tuned Chat Models\\nHugo Touvron∗Louis Martin†Kevin Stone†\\nPeter Albert Amjad Almahairi Yasmine Babaei Nikolay Bashlykov Soumya Batra\\nPrajjwal Bhargava Shruti Bhosale Dan Bikel Lukas Blecher Cristian Canton Ferrer Moya Chen\\nGuillem Cucurull David Esiobu Jude Fernandes Jeremy Fu Wenyin Fu Brian Fuller\\nCynthia Gao Vedanuj Goswami Naman Goyal Anthony Hartshorn Saghar Hosseini Rui Hou\\nHakan Inan Marcin Kardas Viktor Kerkez Madian Khabsa Isabel Kloumann Artem Korenev\\nPunit Singh Koura Marie-Anne Lachaux Thibaut Lavril Jenya Lee Diana Liskovich\\nYinghai Lu Yuning Mao Xavier Martinet Todor Mihaylov Pushkar Mishra\\nIgor Molybog Yixin Nie Andrew Poulton Jeremy Reizenstein Rashi Rungta Kalyan Saladi\\nAlan Schelten Ruan Silva Eric Michael Smith Ranjan Subramanian Xiaoqing Ellen Tan Binh Tang\\nRoss Taylor Adina Williams Jian Xiang Kuan Puxin Xu Zheng Yan Iliyan Zarov Yuchen Zhang\\nAngela Fan Melanie Kambadur Sharan Narang Aurelien Rodriguez Robert Stojnic\\nSergey Edunov Thomas Scialom∗\\nGenAI, Meta\\nAbstract\\nIn this work, we develop and release Llama 2, a collection of pretrained and fine-tuned\\nlarge language models (LLMs) ranging in scale from 7 billion to 70 billion parameters.\\nOur fine-tuned LLMs, called Llama 2-Chat , are optimized for dialogue use cases. Our\\nmodels outperform open-source chat models on most benchmarks we tested, and based on\\nourhumanevaluationsforhelpfulnessandsafety,maybeasuitablesubstituteforclosed-\\nsource models. We provide a detailed description of our approach to fine-tuning and safety\\nimprovements of Llama 2-Chat in order to enable the community to build on our work and\\ncontribute to the responsible development of LLMs.\\n∗Equal contribution, corresponding authors: {tscialom, htouvron}@meta.com\\n†Second author\\nContributions for all the authors can be found in Section A.1.arXiv:2307.09288v2  [cs.CL]  19 Jul 2023', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Document\n",
    "\n",
    "doc_text = \"\\n\\n\".join([d.get_content() for d in documents])\n",
    "docs = [Document(text=doc_text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import SimpleNodeParser\n",
    "from llama_index.core.schema import IndexNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_parser = SimpleNodeParser.from_defaults(chunk_size=1024, chunk_overlap=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceSplitter(include_metadata=True, include_prev_next_rel=True, callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x28fcb4c90>, id_func=<function default_id_func at 0x16d79ae80>, chunk_size=1024, chunk_overlap=100, separator=' ', paragraph_separator='\\n\\n\\n', secondary_chunking_regex='[^,.;。？！]+[,.;。？！]?')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_nodes = node_parser.get_nodes_from_documents(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextNode(id_='8b00afa9-d4c4-4d4b-af39-6c9f6c6d2eea', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='d03f19eb-da15-45dc-bfd4-e5d10f161250', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='231b3bd773f012c01b893ada9e009ecf25ee59934614c5a595c9bf1b3a123292'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='2c520432-1b97-4515-a729-04024f24dd1d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='95086467e6f8a00f1673e6edd14216cb53d44381d95cb6b3e73212a5c3bbce79')}, text='Llama 2 : Open Foundation and Fine-Tuned Chat Models\\nHugo Touvron∗Louis Martin†Kevin Stone†\\nPeter Albert Amjad Almahairi Yasmine Babaei Nikolay Bashlykov Soumya Batra\\nPrajjwal Bhargava Shruti Bhosale Dan Bikel Lukas Blecher Cristian Canton Ferrer Moya Chen\\nGuillem Cucurull David Esiobu Jude Fernandes Jeremy Fu Wenyin Fu Brian Fuller\\nCynthia Gao Vedanuj Goswami Naman Goyal Anthony Hartshorn Saghar Hosseini Rui Hou\\nHakan Inan Marcin Kardas Viktor Kerkez Madian Khabsa Isabel Kloumann Artem Korenev\\nPunit Singh Koura Marie-Anne Lachaux Thibaut Lavril Jenya Lee Diana Liskovich\\nYinghai Lu Yuning Mao Xavier Martinet Todor Mihaylov Pushkar Mishra\\nIgor Molybog Yixin Nie Andrew Poulton Jeremy Reizenstein Rashi Rungta Kalyan Saladi\\nAlan Schelten Ruan Silva Eric Michael Smith Ranjan Subramanian Xiaoqing Ellen Tan Binh Tang\\nRoss Taylor Adina Williams Jian Xiang Kuan Puxin Xu Zheng Yan Iliyan Zarov Yuchen Zhang\\nAngela Fan Melanie Kambadur Sharan Narang Aurelien Rodriguez Robert Stojnic\\nSergey Edunov Thomas Scialom∗\\nGenAI, Meta\\nAbstract\\nIn this work, we develop and release Llama 2, a collection of pretrained and fine-tuned\\nlarge language models (LLMs) ranging in scale from 7 billion to 70 billion parameters.\\nOur fine-tuned LLMs, called Llama 2-Chat , are optimized for dialogue use cases. Our\\nmodels outperform open-source chat models on most benchmarks we tested, and based on\\nourhumanevaluationsforhelpfulnessandsafety,maybeasuitablesubstituteforclosed-\\nsource models. We provide a detailed description of our approach to fine-tuning and safety\\nimprovements of Llama 2-Chat in order to enable the community to build on our work and\\ncontribute to the responsible development of LLMs.\\n∗Equal contribution, corresponding authors: {tscialom, htouvron}@meta.com\\n†Second author\\nContributions for all the authors can be found in Section A.1.arXiv:2307.09288v2  [cs.CL]  19 Jul 2023\\n\\nContents\\n1 Introduction 3\\n2 Pretraining 5\\n2.1 Pretraining Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\\n2.2 Training Details . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\\n2.3 Llama 2 Pretrained Model Evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\\n3 Fine-tuning 8\\n3.1 Supervised Fine-Tuning (SFT) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9\\n3.2 Reinforcement Learning with Human Feedback (RLHF) . . . . . . . . . . . . . . . . . . . . . 9\\n3.3 System Message for Multi-Turn Consistency . . . . . . . . . . . . . . . . . .', start_char_idx=0, end_char_idx=2560, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_nodes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set node ids to be a constant\n",
    "for idx, node in enumerate(base_nodes):\n",
    "    node.id_ = f\"node-{idx}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextNode(id_='node-0', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='d03f19eb-da15-45dc-bfd4-e5d10f161250', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='231b3bd773f012c01b893ada9e009ecf25ee59934614c5a595c9bf1b3a123292'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='2c520432-1b97-4515-a729-04024f24dd1d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='95086467e6f8a00f1673e6edd14216cb53d44381d95cb6b3e73212a5c3bbce79')}, text='Llama 2 : Open Foundation and Fine-Tuned Chat Models\\nHugo Touvron∗Louis Martin†Kevin Stone†\\nPeter Albert Amjad Almahairi Yasmine Babaei Nikolay Bashlykov Soumya Batra\\nPrajjwal Bhargava Shruti Bhosale Dan Bikel Lukas Blecher Cristian Canton Ferrer Moya Chen\\nGuillem Cucurull David Esiobu Jude Fernandes Jeremy Fu Wenyin Fu Brian Fuller\\nCynthia Gao Vedanuj Goswami Naman Goyal Anthony Hartshorn Saghar Hosseini Rui Hou\\nHakan Inan Marcin Kardas Viktor Kerkez Madian Khabsa Isabel Kloumann Artem Korenev\\nPunit Singh Koura Marie-Anne Lachaux Thibaut Lavril Jenya Lee Diana Liskovich\\nYinghai Lu Yuning Mao Xavier Martinet Todor Mihaylov Pushkar Mishra\\nIgor Molybog Yixin Nie Andrew Poulton Jeremy Reizenstein Rashi Rungta Kalyan Saladi\\nAlan Schelten Ruan Silva Eric Michael Smith Ranjan Subramanian Xiaoqing Ellen Tan Binh Tang\\nRoss Taylor Adina Williams Jian Xiang Kuan Puxin Xu Zheng Yan Iliyan Zarov Yuchen Zhang\\nAngela Fan Melanie Kambadur Sharan Narang Aurelien Rodriguez Robert Stojnic\\nSergey Edunov Thomas Scialom∗\\nGenAI, Meta\\nAbstract\\nIn this work, we develop and release Llama 2, a collection of pretrained and fine-tuned\\nlarge language models (LLMs) ranging in scale from 7 billion to 70 billion parameters.\\nOur fine-tuned LLMs, called Llama 2-Chat , are optimized for dialogue use cases. Our\\nmodels outperform open-source chat models on most benchmarks we tested, and based on\\nourhumanevaluationsforhelpfulnessandsafety,maybeasuitablesubstituteforclosed-\\nsource models. We provide a detailed description of our approach to fine-tuning and safety\\nimprovements of Llama 2-Chat in order to enable the community to build on our work and\\ncontribute to the responsible development of LLMs.\\n∗Equal contribution, corresponding authors: {tscialom, htouvron}@meta.com\\n†Second author\\nContributions for all the authors can be found in Section A.1.arXiv:2307.09288v2  [cs.CL]  19 Jul 2023\\n\\nContents\\n1 Introduction 3\\n2 Pretraining 5\\n2.1 Pretraining Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\\n2.2 Training Details . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\\n2.3 Llama 2 Pretrained Model Evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\\n3 Fine-tuning 8\\n3.1 Supervised Fine-Tuning (SFT) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9\\n3.2 Reinforcement Learning with Human Feedback (RLHF) . . . . . . . . . . . . . . . . . . . . . 9\\n3.3 System Message for Multi-Turn Consistency . . . . . . . . . . . . . . . . . .', start_char_idx=0, end_char_idx=2560, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_nodes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_n/ttfh4r6j0snbqwbxr9prdbmh0000gn/T/ipykernel_6681/3330566775.py:7: DeprecationWarning: Call to deprecated class method from_defaults. (ServiceContext is deprecated, please use `llama_index.settings.Settings` instead.) -- Deprecated since version 0.10.0.\n",
      "  service_context = ServiceContext.from_defaults(\n"
     ]
    }
   ],
   "source": [
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core import Settings\n",
    "\n",
    "# loads BAAI/bge-small-en-v1.5\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n",
    "llm = llm\n",
    "service_context = ServiceContext.from_defaults(\n",
    "    llm=llm, embed_model=embed_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_index = VectorStoreIndex(base_nodes, service_context=service_context)\n",
    "base_retriever = base_index.as_retriever(similarity_top_k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrievals = base_retriever.retrieve(\n",
    "    \"Can you tell me about the key concepts for safety finetuning\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Node ID:** node-20<br>**Similarity:** 0.7174637937305269<br>**Text:** In this section, we dive deeper into the important topic of safety measurements and mitigations. We first\n",
       "discussoursafetyinvestigationsintopretrainingdataandpretrainedmodels(Section4.1). Next,wedescribe\n",
       "theprocessofoursafetyalignment(Section4.2),explaininghowwecollectedsafety-relatedannotationsand\n",
       "utilizedSFTandRLHF,andpresentexperimentalresults. Then,wediscusstheredteamingweperformedto\n",
       "furtherunderstandandimprovemodelsafety(Section4.3). Finally,wepresentquantitativesafetyevaluations\n",
       "ofLlama 2-Chat (Section 4.4). We also share a model card in the Appendix, in Table 52.\n",
       "4.1 Safety in Pretraining\n",
       "It is important to understand what is in the pretraining data both to increase transparency and to shed\n",
       "lightonrootcausesofpotentialdownstreamissues,suchaspotentialbiases. Thiscaninformwhat,ifany,\n",
       "downstream mitigations to consider, and help guide appropriate model use. In this section, we analyze the\n",
       "pretraining datafor distributionsof languages,demographic representations,and toxicity. Wealso present\n",
       "the results of testing the pretrained models on existing safety benchmarks.\n",
       "Steps Taken to Pretrain Responsibly. We followed Meta’s standard privacy and legal review processes for\n",
       "each dataset used in training. We did not use any Meta user data in training. We excluded data from certain\n",
       "sitesknowntocontainahighvolumeofpersonalinformationaboutprivateindividuals. Wemadeabest\n",
       "effort to train our models efficiently to reduce the carbon footprint of pretraining (Section 2.2.1). Sharing ou...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** node-26<br>**Similarity:** 0.7062490713363493<br>**Text:** Instead, I suggest focusing on\n",
       "legitimateandethicalwaystocommunicatewithoth-\n",
       "ers online.\n",
       "If you have any questions or concerns, please feel\n",
       "free to ask and I will do my best to assist you in a\n",
       "responsible and safe manner. Let’s all strive to use\n",
       "theinternetandemailforpositiveandbeneficialpur-\n",
       "poses. Is there something else I can help you with?\n",
       "Table12: ExampleofsaferresponseaftersafetyRLHF .Left: responseisgeneratedbyanearlyversionof\n",
       "the model ( SFT-v2). Right: response is generated by the latest version of the model ( RLHF-V5 with PPO ).\n",
       "25\n",
       "\n",
       "each variant, we use the safety and helpfulness reward models to score model generations corresponding to\n",
       "prompts in the Meta Safety and Helpful test sets, respectively.\n",
       "AsshowninFigure15,weusethemeanrewardmodelscoresasproxiesofmodelperformanceonsafetyand\n",
       "helpfulness. Weobservethatwhenweincreasetheproportionofsafetydata,themodel’sperformanceon\n",
       "handling risky and adversarial prompts improves dramatically, and we see a lighter tail in the safety reward\n",
       "modelscoredistribution. Meanwhile,themeanhelpfulnessscoreremainsconstant. Wehypothesizethat\n",
       "this is because we already have a sufficiently large amount of helpfulness training data. Appendix A.4.2 lists\n",
       "more qualitative results that demonstrate how different amounts of safety data in training can change model\n",
       "behavior in responding to adversarial and non-adversarial prompts.\n",
       "0 25 50 75 100\n",
       "Safety Data Pct. (%)0.5750.6000.6250.6500.6750.7000.7250.7500.775Mean Reward Model Score\n",
       "Safety\n",
       "Help...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for n in retrievals:\n",
    "    display_source_node(n, source_length=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine_base = RetrieverQueryEngine.from_args(\n",
    "    base_retriever, service_context=service_context\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charan/VS_Code/GitHub/Advanced_RAG/venv/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `predict` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Safety investigations into pretraining data and pretrained models\n",
      "- Safety alignment\n",
      "- Red teaming\n",
      "- Quantitative safety evaluations\n"
     ]
    }
   ],
   "source": [
    "response = query_engine_base.query(\n",
    "    \"Can you tell me about the key concepts for safety finetuning\"\n",
    ")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_chunk_sizes = [128, 256, 512]\n",
    "sub_node_parsers = [\n",
    "    SimpleNodeParser.from_defaults(chunk_size=c, chunk_overlap=100) for c in sub_chunk_sizes\n",
    "]\n",
    "\n",
    "all_nodes = []\n",
    "for base_node in base_nodes:\n",
    "    for n in sub_node_parsers:\n",
    "        sub_nodes = n.get_nodes_from_documents([base_node])\n",
    "        sub_inodes = [\n",
    "            IndexNode.from_text_node(sn, base_node.node_id) for sn in sub_nodes\n",
    "        ]\n",
    "        all_nodes.extend(sub_inodes)\n",
    "\n",
    "    # also add original node to node\n",
    "    original_node = IndexNode.from_text_node(base_node, base_node.node_id)\n",
    "    all_nodes.append(original_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_nodes_dict = {n.node_id: n for n in all_nodes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2858"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_nodes_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'70bcf041-be45-41b2-b388-f5a85ca4a8a0': IndexNode(id_='70bcf041-be45-41b2-b388-f5a85ca4a8a0', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0321fa3d9a93198d651b9d76efd7b48778c42e726f7cd0265cd3be68129f81fc'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='8c80b003-a4a8-416b-ae99-a2d166cd05df', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='88ca7942f2d5d616238bb628012478afa1922962d6000e87bbe632d5ad13045a')}, text='Llama 2 : Open Foundation and Fine-Tuned Chat Models\\nHugo Touvron∗Louis Martin†Kevin Stone†\\nPeter Albert Amjad Almahairi Yasmine Babaei Nikolay Bashlykov Soumya Batra\\nPrajjwal Bhargava Shruti Bhosale Dan Bikel Lukas Blecher Cristian Canton Ferrer Moya Chen\\nGuillem Cucurull David Esiobu Jude Fernandes Jeremy Fu Wenyin Fu Brian Fuller\\nCynthia Gao Vedanuj Goswami Naman Goyal Anthony Hartshorn Saghar Hosseini Rui', start_char_idx=0, end_char_idx=412, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-0', obj=None),\n",
       " '8c80b003-a4a8-416b-ae99-a2d166cd05df': IndexNode(id_='8c80b003-a4a8-416b-ae99-a2d166cd05df', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0321fa3d9a93198d651b9d76efd7b48778c42e726f7cd0265cd3be68129f81fc'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='70bcf041-be45-41b2-b388-f5a85ca4a8a0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='846d3ce8d8b3f2b35dce5dc8a696ccbded7b43b16619f156e69bcba19c7706e9'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='39bd52dc-0278-497c-897e-cddac03a931e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='56a2e04b3615e7f9cb2464fd28a08f6b4af2dcf2919838db2a4129838647ddb2')}, text='Albert Amjad Almahairi Yasmine Babaei Nikolay Bashlykov Soumya Batra\\nPrajjwal Bhargava Shruti Bhosale Dan Bikel Lukas Blecher Cristian Canton Ferrer Moya Chen\\nGuillem Cucurull David Esiobu Jude Fernandes Jeremy Fu Wenyin Fu Brian Fuller\\nCynthia Gao Vedanuj Goswami Naman Goyal Anthony Hartshorn Saghar Hosseini Rui Hou\\nHakan Inan Marcin Kardas Viktor Kerkez Madian Khabsa Isabel Kloumann Artem', start_char_idx=98, end_char_idx=491, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-0', obj=None),\n",
       " '39bd52dc-0278-497c-897e-cddac03a931e': IndexNode(id_='39bd52dc-0278-497c-897e-cddac03a931e', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0321fa3d9a93198d651b9d76efd7b48778c42e726f7cd0265cd3be68129f81fc'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='8c80b003-a4a8-416b-ae99-a2d166cd05df', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='88ca7942f2d5d616238bb628012478afa1922962d6000e87bbe632d5ad13045a'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='f00ac94c-0cfb-49ff-8f89-ad17c3f95db8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1484e1f7ba6616a9ddcf146fde655df998cded209e7a017bf775134a9de36c59')}, text='Bhargava Shruti Bhosale Dan Bikel Lukas Blecher Cristian Canton Ferrer Moya Chen\\nGuillem Cucurull David Esiobu Jude Fernandes Jeremy Fu Wenyin Fu Brian Fuller\\nCynthia Gao Vedanuj Goswami Naman Goyal Anthony Hartshorn Saghar Hosseini Rui Hou\\nHakan Inan Marcin Kardas Viktor Kerkez Madian Khabsa Isabel Kloumann Artem Korenev\\nPunit Singh Koura Marie-Anne Lachaux Thibaut Lavril Jenya Lee Diana', start_char_idx=176, end_char_idx=567, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-0', obj=None),\n",
       " 'f00ac94c-0cfb-49ff-8f89-ad17c3f95db8': IndexNode(id_='f00ac94c-0cfb-49ff-8f89-ad17c3f95db8', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0321fa3d9a93198d651b9d76efd7b48778c42e726f7cd0265cd3be68129f81fc'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='39bd52dc-0278-497c-897e-cddac03a931e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='56a2e04b3615e7f9cb2464fd28a08f6b4af2dcf2919838db2a4129838647ddb2'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='888b44b2-afe2-4713-87ea-104c608fc3bf', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c1cd7a3cd4e6b6f0bf126aec76d521214773696e2cc43ab2e814cffbb76582cf')}, text='Chen\\nGuillem Cucurull David Esiobu Jude Fernandes Jeremy Fu Wenyin Fu Brian Fuller\\nCynthia Gao Vedanuj Goswami Naman Goyal Anthony Hartshorn Saghar Hosseini Rui Hou\\nHakan Inan Marcin Kardas Viktor Kerkez Madian Khabsa Isabel Kloumann Artem Korenev\\nPunit Singh Koura Marie-Anne Lachaux Thibaut Lavril Jenya Lee Diana Liskovich\\nYinghai Lu Yuning Mao Xavier Martinet Todor Mihaylov Pushkar Mishra\\nIgor', start_char_idx=252, end_char_idx=650, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-0', obj=None),\n",
       " '888b44b2-afe2-4713-87ea-104c608fc3bf': IndexNode(id_='888b44b2-afe2-4713-87ea-104c608fc3bf', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0321fa3d9a93198d651b9d76efd7b48778c42e726f7cd0265cd3be68129f81fc'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='f00ac94c-0cfb-49ff-8f89-ad17c3f95db8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1484e1f7ba6616a9ddcf146fde655df998cded209e7a017bf775134a9de36c59'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='3bbb6024-b3cd-414c-b318-956ff0af293d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='dd1222851943b0d4851f88ca54fe265299b8c7c866c495478c956da4f4d0306e')}, text='Gao Vedanuj Goswami Naman Goyal Anthony Hartshorn Saghar Hosseini Rui Hou\\nHakan Inan Marcin Kardas Viktor Kerkez Madian Khabsa Isabel Kloumann Artem Korenev\\nPunit Singh Koura Marie-Anne Lachaux Thibaut Lavril Jenya Lee Diana Liskovich\\nYinghai Lu Yuning Mao Xavier Martinet Todor Mihaylov Pushkar Mishra\\nIgor Molybog Yixin Nie Andrew Poulton Jeremy Reizenstein Rashi Rungta Kalyan Saladi\\nAlan', start_char_idx=343, end_char_idx=734, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-0', obj=None),\n",
       " '3bbb6024-b3cd-414c-b318-956ff0af293d': IndexNode(id_='3bbb6024-b3cd-414c-b318-956ff0af293d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0321fa3d9a93198d651b9d76efd7b48778c42e726f7cd0265cd3be68129f81fc'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='888b44b2-afe2-4713-87ea-104c608fc3bf', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c1cd7a3cd4e6b6f0bf126aec76d521214773696e2cc43ab2e814cffbb76582cf'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='f9b07c12-41ab-493a-826e-30e3f076eff7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e6818adb1b1677d7289bc394e953b7edb44e6bf854fa05e09ef011169d39c8c8')}, text='Inan Marcin Kardas Viktor Kerkez Madian Khabsa Isabel Kloumann Artem Korenev\\nPunit Singh Koura Marie-Anne Lachaux Thibaut Lavril Jenya Lee Diana Liskovich\\nYinghai Lu Yuning Mao Xavier Martinet Todor Mihaylov Pushkar Mishra\\nIgor Molybog Yixin Nie Andrew Poulton Jeremy Reizenstein Rashi Rungta Kalyan Saladi\\nAlan Schelten Ruan Silva Eric Michael Smith Ranjan Subramanian Xiaoqing Ellen Tan Binh Tang\\nRoss Taylor Adina Williams Jian', start_char_idx=423, end_char_idx=853, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-0', obj=None),\n",
       " 'f9b07c12-41ab-493a-826e-30e3f076eff7': IndexNode(id_='f9b07c12-41ab-493a-826e-30e3f076eff7', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0321fa3d9a93198d651b9d76efd7b48778c42e726f7cd0265cd3be68129f81fc'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='3bbb6024-b3cd-414c-b318-956ff0af293d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='dd1222851943b0d4851f88ca54fe265299b8c7c866c495478c956da4f4d0306e'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='d55488f8-f57f-44a4-96da-709890c9887f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4e1715a8abfa6bc99415b7909212e450089037f3076dcc2070ea0fcf27d6843d')}, text='Koura Marie-Anne Lachaux Thibaut Lavril Jenya Lee Diana Liskovich\\nYinghai Lu Yuning Mao Xavier Martinet Todor Mihaylov Pushkar Mishra\\nIgor Molybog Yixin Nie Andrew Poulton Jeremy Reizenstein Rashi Rungta Kalyan Saladi\\nAlan Schelten Ruan Silva Eric Michael Smith Ranjan Subramanian Xiaoqing Ellen Tan Binh Tang\\nRoss Taylor Adina Williams Jian Xiang Kuan Puxin Xu Zheng Yan Iliyan Zarov Yuchen Zhang\\nAngela Fan Melanie Kambadur', start_char_idx=512, end_char_idx=937, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-0', obj=None),\n",
       " 'd55488f8-f57f-44a4-96da-709890c9887f': IndexNode(id_='d55488f8-f57f-44a4-96da-709890c9887f', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0321fa3d9a93198d651b9d76efd7b48778c42e726f7cd0265cd3be68129f81fc'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='f9b07c12-41ab-493a-826e-30e3f076eff7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e6818adb1b1677d7289bc394e953b7edb44e6bf854fa05e09ef011169d39c8c8'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='f6946fb8-20e1-4700-bef5-4f4a8a38499d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9f5cd663ac1fbe98bdfe3183ab6e4355d9ea1d3f5050913f2f33a7763fb75a50')}, text='Mao Xavier Martinet Todor Mihaylov Pushkar Mishra\\nIgor Molybog Yixin Nie Andrew Poulton Jeremy Reizenstein Rashi Rungta Kalyan Saladi\\nAlan Schelten Ruan Silva Eric Michael Smith Ranjan Subramanian Xiaoqing Ellen Tan Binh Tang\\nRoss Taylor Adina Williams Jian Xiang Kuan Puxin Xu Zheng Yan Iliyan Zarov Yuchen Zhang\\nAngela Fan Melanie Kambadur Sharan Narang Aurelien Rodriguez Robert Stojnic\\nSergey Edunov Thomas Scialom∗\\nGenAI,', start_char_idx=596, end_char_idx=1022, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-0', obj=None),\n",
       " 'f6946fb8-20e1-4700-bef5-4f4a8a38499d': IndexNode(id_='f6946fb8-20e1-4700-bef5-4f4a8a38499d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0321fa3d9a93198d651b9d76efd7b48778c42e726f7cd0265cd3be68129f81fc'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='d55488f8-f57f-44a4-96da-709890c9887f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4e1715a8abfa6bc99415b7909212e450089037f3076dcc2070ea0fcf27d6843d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='1e19cbb7-1540-4a11-a3a4-8750da45274b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='991239c6d9bba6e1cc620d82eba57278a54b377f280b1f119c9c1c18b74798f4')}, text='Jeremy Reizenstein Rashi Rungta Kalyan Saladi\\nAlan Schelten Ruan Silva Eric Michael Smith Ranjan Subramanian Xiaoqing Ellen Tan Binh Tang\\nRoss Taylor Adina Williams Jian Xiang Kuan Puxin Xu Zheng Yan Iliyan Zarov Yuchen Zhang\\nAngela Fan Melanie Kambadur Sharan Narang Aurelien Rodriguez Robert Stojnic\\nSergey Edunov Thomas Scialom∗\\nGenAI, Meta\\nAbstract\\nIn this work, we develop and release Llama 2,', start_char_idx=684, end_char_idx=1082, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-0', obj=None),\n",
       " '1e19cbb7-1540-4a11-a3a4-8750da45274b': IndexNode(id_='1e19cbb7-1540-4a11-a3a4-8750da45274b', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0321fa3d9a93198d651b9d76efd7b48778c42e726f7cd0265cd3be68129f81fc'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='f6946fb8-20e1-4700-bef5-4f4a8a38499d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9f5cd663ac1fbe98bdfe3183ab6e4355d9ea1d3f5050913f2f33a7763fb75a50'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='d4773c17-cd3d-4be6-8c02-5863d845cbd7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b054723b7b94f24a0f580bb543ccdfd301558673200d9fc398b92ea3474b19a6')}, text='Schelten Ruan Silva Eric Michael Smith Ranjan Subramanian Xiaoqing Ellen Tan Binh Tang\\nRoss Taylor Adina Williams Jian Xiang Kuan Puxin Xu Zheng Yan Iliyan Zarov Yuchen Zhang\\nAngela Fan Melanie Kambadur Sharan Narang Aurelien Rodriguez Robert Stojnic\\nSergey Edunov Thomas Scialom∗\\nGenAI, Meta\\nAbstract\\nIn this work, we develop and release Llama 2, a collection of pretrained and fine-tuned\\nlarge language models (LLMs) ranging in scale from 7 billion to 70 billion parameters.', start_char_idx=735, end_char_idx=1211, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-0', obj=None),\n",
       " 'd4773c17-cd3d-4be6-8c02-5863d845cbd7': IndexNode(id_='d4773c17-cd3d-4be6-8c02-5863d845cbd7', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0321fa3d9a93198d651b9d76efd7b48778c42e726f7cd0265cd3be68129f81fc'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='1e19cbb7-1540-4a11-a3a4-8750da45274b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='991239c6d9bba6e1cc620d82eba57278a54b377f280b1f119c9c1c18b74798f4'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='84bf1405-2cf6-400d-b170-23888be61a3b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='13af0511f567157d39ce0e48ec1e4e6a4da72cf3c1f9d2e0e47c9b81966c2f9a')}, text='Kuan Puxin Xu Zheng Yan Iliyan Zarov Yuchen Zhang\\nAngela Fan Melanie Kambadur Sharan Narang Aurelien Rodriguez Robert Stojnic\\nSergey Edunov Thomas Scialom∗\\nGenAI, Meta\\nAbstract\\nIn this work, we develop and release Llama 2, a collection of pretrained and fine-tuned\\nlarge language models (LLMs) ranging in scale from 7 billion to 70 billion parameters.\\nOur fine-tuned LLMs, called Llama 2-Chat , are optimized for dialogue use cases.', start_char_idx=860, end_char_idx=1292, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-0', obj=None),\n",
       " '84bf1405-2cf6-400d-b170-23888be61a3b': IndexNode(id_='84bf1405-2cf6-400d-b170-23888be61a3b', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0321fa3d9a93198d651b9d76efd7b48778c42e726f7cd0265cd3be68129f81fc'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='d4773c17-cd3d-4be6-8c02-5863d845cbd7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b054723b7b94f24a0f580bb543ccdfd301558673200d9fc398b92ea3474b19a6'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='241dbf6a-5405-47e9-8039-392aa6aa169f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6c057508c9d610dbf0f1070210f83cd5bac73672903c0f0e9d419e3044158e14')}, text='Sharan Narang Aurelien Rodriguez Robert Stojnic\\nSergey Edunov Thomas Scialom∗\\nGenAI, Meta\\nAbstract\\nIn this work, we develop and release Llama 2, a collection of pretrained and fine-tuned\\nlarge language models (LLMs) ranging in scale from 7 billion to 70 billion parameters.\\nOur fine-tuned LLMs, called Llama 2-Chat , are optimized for dialogue use cases. Our\\nmodels outperform open-source chat models on most benchmarks we tested, and based on\\nourhumanevaluationsforhelpfulnessandsafety,maybeasuitablesubstituteforclosed-\\nsource models.', start_char_idx=938, end_char_idx=1474, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-0', obj=None),\n",
       " '241dbf6a-5405-47e9-8039-392aa6aa169f': IndexNode(id_='241dbf6a-5405-47e9-8039-392aa6aa169f', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0321fa3d9a93198d651b9d76efd7b48778c42e726f7cd0265cd3be68129f81fc'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='84bf1405-2cf6-400d-b170-23888be61a3b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='13af0511f567157d39ce0e48ec1e4e6a4da72cf3c1f9d2e0e47c9b81966c2f9a'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='b37493df-8185-4699-8cbf-41c867972b1e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e87b5a3531b05809bbbddb1747cf9b3eb96d898a77ac2a9e6284ea98f8bdf1dc')}, text='a collection of pretrained and fine-tuned\\nlarge language models (LLMs) ranging in scale from 7 billion to 70 billion parameters.\\nOur fine-tuned LLMs, called Llama 2-Chat , are optimized for dialogue use cases. Our\\nmodels outperform open-source chat models on most benchmarks we tested, and based on\\nourhumanevaluationsforhelpfulnessandsafety,maybeasuitablesubstituteforclosed-\\nsource models. We provide a detailed description of our approach to fine-tuning and safety\\nimprovements of Llama 2-Chat in order to enable the community to build on our work and\\ncontribute to the responsible development of LLMs.', start_char_idx=1083, end_char_idx=1688, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-0', obj=None),\n",
       " 'b37493df-8185-4699-8cbf-41c867972b1e': IndexNode(id_='b37493df-8185-4699-8cbf-41c867972b1e', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0321fa3d9a93198d651b9d76efd7b48778c42e726f7cd0265cd3be68129f81fc'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='241dbf6a-5405-47e9-8039-392aa6aa169f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6c057508c9d610dbf0f1070210f83cd5bac73672903c0f0e9d419e3044158e14'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='7fe89a0a-4234-4e99-bcd8-622dea5ccc6e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4706fe21d6d79ff0f0b08a61947ff536b1f3add0a51daa6d085a5c6aab149cd7')}, text='Our\\nmodels outperform open-source chat models on most benchmarks we tested, and based on\\nourhumanevaluationsforhelpfulnessandsafety,maybeasuitablesubstituteforclosed-\\nsource models. We provide a detailed description of our approach to fine-tuning and safety\\nimprovements of Llama 2-Chat in order to enable the community to build on our work and\\ncontribute to the responsible development of LLMs.\\n∗Equal contribution, corresponding authors: {tscialom, htouvron}@meta.com\\n†Second author\\nContributions for all the authors can be found in Section A.1.arXiv:2307.09288v2  [cs.CL]  19 Jul 2023\\n\\nContents\\n1 Introduction 3\\n2 Pretraining 5\\n2.1 Pretraining Data .', start_char_idx=1293, end_char_idx=1946, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-0', obj=None),\n",
       " '7fe89a0a-4234-4e99-bcd8-622dea5ccc6e': IndexNode(id_='7fe89a0a-4234-4e99-bcd8-622dea5ccc6e', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0321fa3d9a93198d651b9d76efd7b48778c42e726f7cd0265cd3be68129f81fc'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='b37493df-8185-4699-8cbf-41c867972b1e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e87b5a3531b05809bbbddb1747cf9b3eb96d898a77ac2a9e6284ea98f8bdf1dc'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='aa97efe9-d792-4279-940c-58b5acf06889', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='065957a369c9ec111ac58f039210296b2b4807e5c1e1450ffd6ed90fb00d7225')}, text='∗Equal contribution, corresponding authors: {tscialom, htouvron}@meta.com\\n†Second author\\nContributions for all the authors can be found in Section A.1.arXiv:2307.09288v2  [cs.CL]  19 Jul 2023\\n\\nContents\\n1 Introduction 3\\n2 Pretraining 5\\n2.1 Pretraining Data . . . . . . . . . . . . . . . . . . . . . . .', start_char_idx=1689, end_char_idx=1990, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-0', obj=None),\n",
       " 'aa97efe9-d792-4279-940c-58b5acf06889': IndexNode(id_='aa97efe9-d792-4279-940c-58b5acf06889', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0321fa3d9a93198d651b9d76efd7b48778c42e726f7cd0265cd3be68129f81fc'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='7fe89a0a-4234-4e99-bcd8-622dea5ccc6e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4706fe21d6d79ff0f0b08a61947ff536b1f3add0a51daa6d085a5c6aab149cd7'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='0444fa10-5886-42ac-85df-5c2dd688246b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='95059c15c811e4a5b13dae3e51a1abb9e9d14c73b28dda26265701f9fb1b46ea')}, text='. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\\n2.2 Training Details . . . . . . . . . . . . . . . .', start_char_idx=1947, end_char_idx=2089, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-0', obj=None),\n",
       " '0444fa10-5886-42ac-85df-5c2dd688246b': IndexNode(id_='0444fa10-5886-42ac-85df-5c2dd688246b', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0321fa3d9a93198d651b9d76efd7b48778c42e726f7cd0265cd3be68129f81fc'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='aa97efe9-d792-4279-940c-58b5acf06889', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='065957a369c9ec111ac58f039210296b2b4807e5c1e1450ffd6ed90fb00d7225'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='94e95311-7770-4c32-b71c-18596b7d8def', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f2cfa690a4719655b0bb2628061162849e16d2e1b104b71ff078f2f6c43c5f74')}, text='. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\\n2.2 Training Details . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .', start_char_idx=1975, end_char_idx=2117, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-0', obj=None),\n",
       " '94e95311-7770-4c32-b71c-18596b7d8def': IndexNode(id_='94e95311-7770-4c32-b71c-18596b7d8def', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0321fa3d9a93198d651b9d76efd7b48778c42e726f7cd0265cd3be68129f81fc'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='0444fa10-5886-42ac-85df-5c2dd688246b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='95059c15c811e4a5b13dae3e51a1abb9e9d14c73b28dda26265701f9fb1b46ea'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='d6052009-213f-4cbe-baa4-98ee3cdea2f4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5b562b7a84d4118ae8bcf4176ffdb4f2aa7a9d97176583e2700e2abef4e1e6dd')}, text='. . . . . . . . . . . . . . . . 5\\n2.2 Training Details . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .', start_char_idx=2003, end_char_idx=2145, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-0', obj=None),\n",
       " 'd6052009-213f-4cbe-baa4-98ee3cdea2f4': IndexNode(id_='d6052009-213f-4cbe-baa4-98ee3cdea2f4', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0321fa3d9a93198d651b9d76efd7b48778c42e726f7cd0265cd3be68129f81fc'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='94e95311-7770-4c32-b71c-18596b7d8def', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f2cfa690a4719655b0bb2628061162849e16d2e1b104b71ff078f2f6c43c5f74'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='174fcccf-aab1-43cf-94d9-720687aff61d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='32ae4b17dda4a957fdb6547e7d1d138f6e1726ba36a9137d70848acd12e8f736')}, text='. . 5\\n2.2 Training Details . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\\n2.3 Llama 2 Pretrained Model Evaluation . . . . . . .', start_char_idx=2031, end_char_idx=2203, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-0', obj=None),\n",
       " '174fcccf-aab1-43cf-94d9-720687aff61d': IndexNode(id_='174fcccf-aab1-43cf-94d9-720687aff61d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0321fa3d9a93198d651b9d76efd7b48778c42e726f7cd0265cd3be68129f81fc'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='d6052009-213f-4cbe-baa4-98ee3cdea2f4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5b562b7a84d4118ae8bcf4176ffdb4f2aa7a9d97176583e2700e2abef4e1e6dd'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='9f01596f-e429-411e-9c5a-7f47dc515ff8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7b6b87f6a3b338c9ed0c3da254b58632f9bbd96d59f33ab9c544f78df06d6e20')}, text='. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\\n2.3 Llama 2 Pretrained Model Evaluation . . . . . . . . . . . . . . . . . . . . .', start_char_idx=2076, end_char_idx=2231, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-0', obj=None),\n",
       " '9f01596f-e429-411e-9c5a-7f47dc515ff8': IndexNode(id_='9f01596f-e429-411e-9c5a-7f47dc515ff8', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0321fa3d9a93198d651b9d76efd7b48778c42e726f7cd0265cd3be68129f81fc'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='174fcccf-aab1-43cf-94d9-720687aff61d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='32ae4b17dda4a957fdb6547e7d1d138f6e1726ba36a9137d70848acd12e8f736'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='bc5145d6-d361-4cb1-8225-67f49195df64', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='94d3cd5e24d22331987dcf277decfc1ef1bba02b4820cf899662ea756efc3732')}, text='. . . . . . . . . . . . . . . . . . . . . . 5\\n2.3 Llama 2 Pretrained Model Evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .', start_char_idx=2104, end_char_idx=2253, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-0', obj=None),\n",
       " 'bc5145d6-d361-4cb1-8225-67f49195df64': IndexNode(id_='bc5145d6-d361-4cb1-8225-67f49195df64', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0321fa3d9a93198d651b9d76efd7b48778c42e726f7cd0265cd3be68129f81fc'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='9f01596f-e429-411e-9c5a-7f47dc515ff8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7b6b87f6a3b338c9ed0c3da254b58632f9bbd96d59f33ab9c544f78df06d6e20'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='5d9cf1f4-0446-4126-b124-4d3d427e08ee', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='11c8bc246afc2888d6fae821e8709cca84ae5035cd616ecc76f2b603593d43c7')}, text='. . . . . . . . . . . 5\\n2.3 Llama 2 Pretrained Model Evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\\n3 Fine-tuning 8\\n3.1 Supervised Fine-Tuning (SFT) . . . .', start_char_idx=2126, end_char_idx=2312, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-0', obj=None),\n",
       " '5d9cf1f4-0446-4126-b124-4d3d427e08ee': IndexNode(id_='5d9cf1f4-0446-4126-b124-4d3d427e08ee', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0321fa3d9a93198d651b9d76efd7b48778c42e726f7cd0265cd3be68129f81fc'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='bc5145d6-d361-4cb1-8225-67f49195df64', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='94d3cd5e24d22331987dcf277decfc1ef1bba02b4820cf899662ea756efc3732'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='1ff36b8e-7ede-4a7b-a46a-1cb5fe6f38a2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1ee5a9d36ca52079b6dbe8850f6fdc4d242ab0330a384579dc08fcaa469e61b8')}, text='. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\\n3 Fine-tuning 8\\n3.1 Supervised Fine-Tuning (SFT) . . . . . . . . . . . . . . . . . . . . . .', start_char_idx=2192, end_char_idx=2348, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-0', obj=None),\n",
       " '1ff36b8e-7ede-4a7b-a46a-1cb5fe6f38a2': IndexNode(id_='1ff36b8e-7ede-4a7b-a46a-1cb5fe6f38a2', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0321fa3d9a93198d651b9d76efd7b48778c42e726f7cd0265cd3be68129f81fc'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='5d9cf1f4-0446-4126-b124-4d3d427e08ee', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='11c8bc246afc2888d6fae821e8709cca84ae5035cd616ecc76f2b603593d43c7'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='89909753-4b64-43cb-9aac-552c2c2414b1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bbd22610d7863f9fd21ac06e1547590a8826053bf6e90a2398a2437eb044d15f')}, text='. . . . . . . . . . . . . . . . . 7\\n3 Fine-tuning 8\\n3.1 Supervised Fine-Tuning (SFT) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .', start_char_idx=2220, end_char_idx=2376, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-0', obj=None),\n",
       " '89909753-4b64-43cb-9aac-552c2c2414b1': IndexNode(id_='89909753-4b64-43cb-9aac-552c2c2414b1', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0321fa3d9a93198d651b9d76efd7b48778c42e726f7cd0265cd3be68129f81fc'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='1ff36b8e-7ede-4a7b-a46a-1cb5fe6f38a2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1ee5a9d36ca52079b6dbe8850f6fdc4d242ab0330a384579dc08fcaa469e61b8'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='c038c51b-9cde-46ef-bb1b-4300536d925f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='737a4214f210a61946eaf7dd9d6804acb3b97410790a1dd0c6a7b5bb70e19a8f')}, text='. . . 7\\n3 Fine-tuning 8\\n3.1 Supervised Fine-Tuning (SFT) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9\\n3.2 Reinforcement Learning with Human Feedback (RLHF) . . . . . .', start_char_idx=2248, end_char_idx=2446, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-0', obj=None),\n",
       " 'c038c51b-9cde-46ef-bb1b-4300536d925f': IndexNode(id_='c038c51b-9cde-46ef-bb1b-4300536d925f', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0321fa3d9a93198d651b9d76efd7b48778c42e726f7cd0265cd3be68129f81fc'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='89909753-4b64-43cb-9aac-552c2c2414b1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bbd22610d7863f9fd21ac06e1547590a8826053bf6e90a2398a2437eb044d15f'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='529dea59-d85a-4bb0-9cad-91d8a6d76db7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='229501e93af04b43b7372b4632ba07a2c14005a143800e808eccee154f3ea34b')}, text='. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9\\n3.2 Reinforcement Learning with Human Feedback (RLHF) . . . . . . . . . . . . . . . . . . . .', start_char_idx=2307, end_char_idx=2474, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-0', obj=None),\n",
       " '529dea59-d85a-4bb0-9cad-91d8a6d76db7': IndexNode(id_='529dea59-d85a-4bb0-9cad-91d8a6d76db7', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0321fa3d9a93198d651b9d76efd7b48778c42e726f7cd0265cd3be68129f81fc'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='c038c51b-9cde-46ef-bb1b-4300536d925f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='737a4214f210a61946eaf7dd9d6804acb3b97410790a1dd0c6a7b5bb70e19a8f'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='d6529e9a-7249-407d-ac3f-7635981e357d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='83f2742d7bdc42626d32a9f7ac2e75bc0a184b6b22fd239653ba417b5bb5e2d6')}, text='. . . . . . . . . . . . . . . . . . . . . . 9\\n3.2 Reinforcement Learning with Human Feedback (RLHF) . . . . . . . . . . . . . . . . . . . . . 9\\n3.3 System Message for Multi-Turn Consistency . . . . . . .', start_char_idx=2335, end_char_idx=2538, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-0', obj=None),\n",
       " 'd6529e9a-7249-407d-ac3f-7635981e357d': IndexNode(id_='d6529e9a-7249-407d-ac3f-7635981e357d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0321fa3d9a93198d651b9d76efd7b48778c42e726f7cd0265cd3be68129f81fc'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='529dea59-d85a-4bb0-9cad-91d8a6d76db7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='229501e93af04b43b7372b4632ba07a2c14005a143800e808eccee154f3ea34b')}, text='. . . . . . . . 9\\n3.2 Reinforcement Learning with Human Feedback (RLHF) . . . . . . . . . . . . . . . . . . . . . 9\\n3.3 System Message for Multi-Turn Consistency . . . . . . . . . . . . . . . . . .', start_char_idx=2363, end_char_idx=2560, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-0', obj=None),\n",
       " 'd49912c1-4783-4f2b-adc5-5fe5cbda559f': IndexNode(id_='d49912c1-4783-4f2b-adc5-5fe5cbda559f', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0321fa3d9a93198d651b9d76efd7b48778c42e726f7cd0265cd3be68129f81fc'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='dc1b7a4c-0bf6-4e64-9057-e1fb6e315b10', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='acf1b0c1a656b86739f97b91c1cea943748b4e769274611a937e99035c718398')}, text='Llama 2 : Open Foundation and Fine-Tuned Chat Models\\nHugo Touvron∗Louis Martin†Kevin Stone†\\nPeter Albert Amjad Almahairi Yasmine Babaei Nikolay Bashlykov Soumya Batra\\nPrajjwal Bhargava Shruti Bhosale Dan Bikel Lukas Blecher Cristian Canton Ferrer Moya Chen\\nGuillem Cucurull David Esiobu Jude Fernandes Jeremy Fu Wenyin Fu Brian Fuller\\nCynthia Gao Vedanuj Goswami Naman Goyal Anthony Hartshorn Saghar Hosseini Rui Hou\\nHakan Inan Marcin Kardas Viktor Kerkez Madian Khabsa Isabel Kloumann Artem Korenev\\nPunit Singh Koura Marie-Anne Lachaux Thibaut Lavril Jenya Lee Diana Liskovich\\nYinghai Lu Yuning Mao Xavier Martinet Todor Mihaylov Pushkar Mishra\\nIgor Molybog Yixin Nie Andrew Poulton Jeremy Reizenstein Rashi Rungta Kalyan Saladi\\nAlan Schelten Ruan Silva Eric Michael Smith Ranjan Subramanian Xiaoqing Ellen Tan Binh Tang\\nRoss Taylor', start_char_idx=0, end_char_idx=833, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-0', obj=None),\n",
       " 'dc1b7a4c-0bf6-4e64-9057-e1fb6e315b10': IndexNode(id_='dc1b7a4c-0bf6-4e64-9057-e1fb6e315b10', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0321fa3d9a93198d651b9d76efd7b48778c42e726f7cd0265cd3be68129f81fc'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='d49912c1-4783-4f2b-adc5-5fe5cbda559f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bd930abf65054e2ea46d80d037367de9bbc0bb9ba50f16e47e1a1a82ced46524'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='aea49914-2659-488b-b6a6-72fac624b04f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9cac26cfba57e56ce8aec812cc021e82e2708aa513ffd904abc19105288f9836')}, text='Singh Koura Marie-Anne Lachaux Thibaut Lavril Jenya Lee Diana Liskovich\\nYinghai Lu Yuning Mao Xavier Martinet Todor Mihaylov Pushkar Mishra\\nIgor Molybog Yixin Nie Andrew Poulton Jeremy Reizenstein Rashi Rungta Kalyan Saladi\\nAlan Schelten Ruan Silva Eric Michael Smith Ranjan Subramanian Xiaoqing Ellen Tan Binh Tang\\nRoss Taylor Adina Williams Jian Xiang Kuan Puxin Xu Zheng Yan Iliyan Zarov Yuchen Zhang\\nAngela Fan Melanie Kambadur Sharan Narang Aurelien Rodriguez Robert Stojnic\\nSergey Edunov Thomas Scialom∗\\nGenAI, Meta\\nAbstract\\nIn this work, we develop and release Llama 2, a collection of pretrained and fine-tuned\\nlarge language models (LLMs) ranging in scale from 7 billion to 70 billion parameters.\\nOur fine-tuned LLMs, called Llama 2-Chat , are optimized for dialogue use cases.', start_char_idx=506, end_char_idx=1292, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-0', obj=None),\n",
       " 'aea49914-2659-488b-b6a6-72fac624b04f': IndexNode(id_='aea49914-2659-488b-b6a6-72fac624b04f', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0321fa3d9a93198d651b9d76efd7b48778c42e726f7cd0265cd3be68129f81fc'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='dc1b7a4c-0bf6-4e64-9057-e1fb6e315b10', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='acf1b0c1a656b86739f97b91c1cea943748b4e769274611a937e99035c718398'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='9b2e7ae1-5d9f-47e5-8a2c-41f1d4433dc8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='dec09b305c79fab0b53cf5b7f5ce102a4c8a3dfbd6d2fcfe7797338cf33bb856')}, text='Sharan Narang Aurelien Rodriguez Robert Stojnic\\nSergey Edunov Thomas Scialom∗\\nGenAI, Meta\\nAbstract\\nIn this work, we develop and release Llama 2, a collection of pretrained and fine-tuned\\nlarge language models (LLMs) ranging in scale from 7 billion to 70 billion parameters.\\nOur fine-tuned LLMs, called Llama 2-Chat , are optimized for dialogue use cases. Our\\nmodels outperform open-source chat models on most benchmarks we tested, and based on\\nourhumanevaluationsforhelpfulnessandsafety,maybeasuitablesubstituteforclosed-\\nsource models. We provide a detailed description of our approach to fine-tuning and safety\\nimprovements of Llama 2-Chat in order to enable the community to build on our work and\\ncontribute to the responsible development of LLMs.', start_char_idx=938, end_char_idx=1688, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-0', obj=None),\n",
       " '9b2e7ae1-5d9f-47e5-8a2c-41f1d4433dc8': IndexNode(id_='9b2e7ae1-5d9f-47e5-8a2c-41f1d4433dc8', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0321fa3d9a93198d651b9d76efd7b48778c42e726f7cd0265cd3be68129f81fc'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='aea49914-2659-488b-b6a6-72fac624b04f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9cac26cfba57e56ce8aec812cc021e82e2708aa513ffd904abc19105288f9836'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='b42347e8-5853-4023-805d-7cce2060f0ce', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1892bba62a4e638adb078fae1c71f512b3d7f6aa97b6a5906e5ebe697454020d')}, text='Our\\nmodels outperform open-source chat models on most benchmarks we tested, and based on\\nourhumanevaluationsforhelpfulnessandsafety,maybeasuitablesubstituteforclosed-\\nsource models. We provide a detailed description of our approach to fine-tuning and safety\\nimprovements of Llama 2-Chat in order to enable the community to build on our work and\\ncontribute to the responsible development of LLMs.\\n∗Equal contribution, corresponding authors: {tscialom, htouvron}@meta.com\\n†Second author\\nContributions for all the authors can be found in Section A.1.arXiv:2307.09288v2  [cs.CL]  19 Jul 2023\\n\\nContents\\n1 Introduction 3\\n2 Pretraining 5\\n2.1 Pretraining Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .', start_char_idx=1293, end_char_idx=2024, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-0', obj=None),\n",
       " 'b42347e8-5853-4023-805d-7cce2060f0ce': IndexNode(id_='b42347e8-5853-4023-805d-7cce2060f0ce', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0321fa3d9a93198d651b9d76efd7b48778c42e726f7cd0265cd3be68129f81fc'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='9b2e7ae1-5d9f-47e5-8a2c-41f1d4433dc8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='dec09b305c79fab0b53cf5b7f5ce102a4c8a3dfbd6d2fcfe7797338cf33bb856'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='b68c411c-247d-4e56-8ba8-0dbc8563ed35', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='626742d9328aa89f7e0922e74b0956f2e6bedf8da1474ed1feda16d3e1363dab')}, text='. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\\n2.2 Training Details . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\\n2.3 Llama 2 Pretrained Model Evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . .', start_char_idx=1947, end_char_idx=2247, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-0', obj=None),\n",
       " 'b68c411c-247d-4e56-8ba8-0dbc8563ed35': IndexNode(id_='b68c411c-247d-4e56-8ba8-0dbc8563ed35', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0321fa3d9a93198d651b9d76efd7b48778c42e726f7cd0265cd3be68129f81fc'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='b42347e8-5853-4023-805d-7cce2060f0ce', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1892bba62a4e638adb078fae1c71f512b3d7f6aa97b6a5906e5ebe697454020d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='817bcda1-a4be-4d48-b5a9-28fbae27e425', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5d9b6748df3ee5fab90266b077a19d35a28ee62dc0a852c965c7119b8844bc12')}, text='. . . . . . . . . . . . . . 5\\n2.3 Llama 2 Pretrained Model Evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\\n3 Fine-tuning 8\\n3.1 Supervised Fine-Tuning (SFT) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9\\n3.2 Reinforcement Learning with Human Feedback (RLHF) . . . . . . . . . . . . . . . . . . . .', start_char_idx=2120, end_char_idx=2474, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-0', obj=None),\n",
       " '817bcda1-a4be-4d48-b5a9-28fbae27e425': IndexNode(id_='817bcda1-a4be-4d48-b5a9-28fbae27e425', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0321fa3d9a93198d651b9d76efd7b48778c42e726f7cd0265cd3be68129f81fc'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='b68c411c-247d-4e56-8ba8-0dbc8563ed35', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='626742d9328aa89f7e0922e74b0956f2e6bedf8da1474ed1feda16d3e1363dab')}, text='. . . . . . . . . . . . . . . . . . . . . . 9\\n3.2 Reinforcement Learning with Human Feedback (RLHF) . . . . . . . . . . . . . . . . . . . . . 9\\n3.3 System Message for Multi-Turn Consistency . . . . . . . . . . . . . . . . . .', start_char_idx=2335, end_char_idx=2560, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-0', obj=None),\n",
       " '69bfb960-3c10-421b-b1ef-2978ba9f3a70': IndexNode(id_='69bfb960-3c10-421b-b1ef-2978ba9f3a70', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0321fa3d9a93198d651b9d76efd7b48778c42e726f7cd0265cd3be68129f81fc'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='5536860b-33c7-49f3-8ee9-6c97a76bb620', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e29c1dc733050070e8ae1e6fbd5113ec43ce1befe259c5498ece0e1ecc1b1224')}, text='Llama 2 : Open Foundation and Fine-Tuned Chat Models\\nHugo Touvron∗Louis Martin†Kevin Stone†\\nPeter Albert Amjad Almahairi Yasmine Babaei Nikolay Bashlykov Soumya Batra\\nPrajjwal Bhargava Shruti Bhosale Dan Bikel Lukas Blecher Cristian Canton Ferrer Moya Chen\\nGuillem Cucurull David Esiobu Jude Fernandes Jeremy Fu Wenyin Fu Brian Fuller\\nCynthia Gao Vedanuj Goswami Naman Goyal Anthony Hartshorn Saghar Hosseini Rui Hou\\nHakan Inan Marcin Kardas Viktor Kerkez Madian Khabsa Isabel Kloumann Artem Korenev\\nPunit Singh Koura Marie-Anne Lachaux Thibaut Lavril Jenya Lee Diana Liskovich\\nYinghai Lu Yuning Mao Xavier Martinet Todor Mihaylov Pushkar Mishra\\nIgor Molybog Yixin Nie Andrew Poulton Jeremy Reizenstein Rashi Rungta Kalyan Saladi\\nAlan Schelten Ruan Silva Eric Michael Smith Ranjan Subramanian Xiaoqing Ellen Tan Binh Tang\\nRoss Taylor Adina Williams Jian Xiang Kuan Puxin Xu Zheng Yan Iliyan Zarov Yuchen Zhang\\nAngela Fan Melanie Kambadur Sharan Narang Aurelien Rodriguez Robert Stojnic\\nSergey Edunov Thomas Scialom∗\\nGenAI, Meta\\nAbstract\\nIn this work, we develop and release Llama 2, a collection of pretrained and fine-tuned\\nlarge language models (LLMs) ranging in scale from 7 billion to 70 billion parameters.\\nOur fine-tuned LLMs, called Llama 2-Chat , are optimized for dialogue use cases. Our\\nmodels outperform open-source chat models on most benchmarks we tested, and based on\\nourhumanevaluationsforhelpfulnessandsafety,maybeasuitablesubstituteforclosed-\\nsource models. We provide a detailed description of our approach to fine-tuning and safety\\nimprovements of Llama 2-Chat in order to enable the community to build on our work and\\ncontribute to the responsible development of LLMs.', start_char_idx=0, end_char_idx=1688, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-0', obj=None),\n",
       " '5536860b-33c7-49f3-8ee9-6c97a76bb620': IndexNode(id_='5536860b-33c7-49f3-8ee9-6c97a76bb620', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0321fa3d9a93198d651b9d76efd7b48778c42e726f7cd0265cd3be68129f81fc'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='69bfb960-3c10-421b-b1ef-2978ba9f3a70', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5a6b221c61775340cb31a35eab60ee8b96f0d3e4e163e24d244848868bce0adb'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='9eded062-ea61-42ad-9db5-6317000043a1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2ba65d1f8afc66fd9fbeac2bbdabfab43754d10f29312f62af0990bbb3d3aa4f')}, text='Our\\nmodels outperform open-source chat models on most benchmarks we tested, and based on\\nourhumanevaluationsforhelpfulnessandsafety,maybeasuitablesubstituteforclosed-\\nsource models. We provide a detailed description of our approach to fine-tuning and safety\\nimprovements of Llama 2-Chat in order to enable the community to build on our work and\\ncontribute to the responsible development of LLMs.\\n∗Equal contribution, corresponding authors: {tscialom, htouvron}@meta.com\\n†Second author\\nContributions for all the authors can be found in Section A.1.arXiv:2307.09288v2  [cs.CL]  19 Jul 2023\\n\\nContents\\n1 Introduction 3\\n2 Pretraining 5\\n2.1 Pretraining Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\\n2.2 Training Details . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\\n2.3 Llama 2 Pretrained Model Evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\\n3 Fine-tuning 8\\n3.1 Supervised Fine-Tuning (SFT) . . . . . . . . . . . . . . . . . . . . . . . . . .', start_char_idx=1293, end_char_idx=2356, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-0', obj=None),\n",
       " '9eded062-ea61-42ad-9db5-6317000043a1': IndexNode(id_='9eded062-ea61-42ad-9db5-6317000043a1', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0321fa3d9a93198d651b9d76efd7b48778c42e726f7cd0265cd3be68129f81fc'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='5536860b-33c7-49f3-8ee9-6c97a76bb620', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e29c1dc733050070e8ae1e6fbd5113ec43ce1befe259c5498ece0e1ecc1b1224')}, text='. . . . . . . . . . . . . 7\\n3 Fine-tuning 8\\n3.1 Supervised Fine-Tuning (SFT) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9\\n3.2 Reinforcement Learning with Human Feedback (RLHF) . . . . . . . . . . . . . . . . . . . . . 9\\n3.3 System Message for Multi-Turn Consistency . . . . . . . . . . . . . . . . . .', start_char_idx=2228, end_char_idx=2560, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-0', obj=None),\n",
       " 'node-0': IndexNode(id_='node-0', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='d03f19eb-da15-45dc-bfd4-e5d10f161250', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='231b3bd773f012c01b893ada9e009ecf25ee59934614c5a595c9bf1b3a123292'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='2c520432-1b97-4515-a729-04024f24dd1d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='95086467e6f8a00f1673e6edd14216cb53d44381d95cb6b3e73212a5c3bbce79')}, text='Llama 2 : Open Foundation and Fine-Tuned Chat Models\\nHugo Touvron∗Louis Martin†Kevin Stone†\\nPeter Albert Amjad Almahairi Yasmine Babaei Nikolay Bashlykov Soumya Batra\\nPrajjwal Bhargava Shruti Bhosale Dan Bikel Lukas Blecher Cristian Canton Ferrer Moya Chen\\nGuillem Cucurull David Esiobu Jude Fernandes Jeremy Fu Wenyin Fu Brian Fuller\\nCynthia Gao Vedanuj Goswami Naman Goyal Anthony Hartshorn Saghar Hosseini Rui Hou\\nHakan Inan Marcin Kardas Viktor Kerkez Madian Khabsa Isabel Kloumann Artem Korenev\\nPunit Singh Koura Marie-Anne Lachaux Thibaut Lavril Jenya Lee Diana Liskovich\\nYinghai Lu Yuning Mao Xavier Martinet Todor Mihaylov Pushkar Mishra\\nIgor Molybog Yixin Nie Andrew Poulton Jeremy Reizenstein Rashi Rungta Kalyan Saladi\\nAlan Schelten Ruan Silva Eric Michael Smith Ranjan Subramanian Xiaoqing Ellen Tan Binh Tang\\nRoss Taylor Adina Williams Jian Xiang Kuan Puxin Xu Zheng Yan Iliyan Zarov Yuchen Zhang\\nAngela Fan Melanie Kambadur Sharan Narang Aurelien Rodriguez Robert Stojnic\\nSergey Edunov Thomas Scialom∗\\nGenAI, Meta\\nAbstract\\nIn this work, we develop and release Llama 2, a collection of pretrained and fine-tuned\\nlarge language models (LLMs) ranging in scale from 7 billion to 70 billion parameters.\\nOur fine-tuned LLMs, called Llama 2-Chat , are optimized for dialogue use cases. Our\\nmodels outperform open-source chat models on most benchmarks we tested, and based on\\nourhumanevaluationsforhelpfulnessandsafety,maybeasuitablesubstituteforclosed-\\nsource models. We provide a detailed description of our approach to fine-tuning and safety\\nimprovements of Llama 2-Chat in order to enable the community to build on our work and\\ncontribute to the responsible development of LLMs.\\n∗Equal contribution, corresponding authors: {tscialom, htouvron}@meta.com\\n†Second author\\nContributions for all the authors can be found in Section A.1.arXiv:2307.09288v2  [cs.CL]  19 Jul 2023\\n\\nContents\\n1 Introduction 3\\n2 Pretraining 5\\n2.1 Pretraining Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\\n2.2 Training Details . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\\n2.3 Llama 2 Pretrained Model Evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\\n3 Fine-tuning 8\\n3.1 Supervised Fine-Tuning (SFT) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9\\n3.2 Reinforcement Learning with Human Feedback (RLHF) . . . . . . . . . . . . . . . . . . . . . 9\\n3.3 System Message for Multi-Turn Consistency . . . . . . . . . . . . . . . . . .', start_char_idx=0, end_char_idx=2560, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-0', obj=None),\n",
       " '67c261b8-1599-4a2f-8099-ac5c659e225d': IndexNode(id_='67c261b8-1599-4a2f-8099-ac5c659e225d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='95086467e6f8a00f1673e6edd14216cb53d44381d95cb6b3e73212a5c3bbce79'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='bc9cc442-e1be-47c7-b267-ef55d16fff2f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='97de48e8170b191333d129956f883c085368e485b3f4c3ea3d196b40b5e07396')}, text='. . . . . . . . . . . . . . . . . . . . 9\\n3.3 System Message for Multi-Turn Consistency . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\\n3.4 RLHF Results . . . .', start_char_idx=0, end_char_idx=173, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-1', obj=None),\n",
       " 'bc9cc442-e1be-47c7-b267-ef55d16fff2f': IndexNode(id_='bc9cc442-e1be-47c7-b267-ef55d16fff2f', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='95086467e6f8a00f1673e6edd14216cb53d44381d95cb6b3e73212a5c3bbce79'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='67c261b8-1599-4a2f-8099-ac5c659e225d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4214987487be3e6a76b1e095fad3250b36052ec9eb465c49a130ef77da81a04d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='1eaee604-1f48-4687-9a8d-a0c703d98be6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f4ef10773df4c2e5bffc04c019b8abab6887fea89b8a1296c996a882f6187b57')}, text='. . . . . . 9\\n3.3 System Message for Multi-Turn Consistency . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\\n3.4 RLHF Results . . . . . . . . . . . . . . . . . .', start_char_idx=28, end_char_idx=201, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-1', obj=None),\n",
       " '1eaee604-1f48-4687-9a8d-a0c703d98be6': IndexNode(id_='1eaee604-1f48-4687-9a8d-a0c703d98be6', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='95086467e6f8a00f1673e6edd14216cb53d44381d95cb6b3e73212a5c3bbce79'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='bc9cc442-e1be-47c7-b267-ef55d16fff2f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='97de48e8170b191333d129956f883c085368e485b3f4c3ea3d196b40b5e07396'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='777a27d3-65b5-4c25-b772-0a558125b77a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='01d8e416d1cda8f078b913ff7323f80bcc7fe6f31c9244d3d0a776e29d1c8572')}, text='. . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\\n3.4 RLHF Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .', start_char_idx=90, end_char_idx=229, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-1', obj=None),\n",
       " '777a27d3-65b5-4c25-b772-0a558125b77a': IndexNode(id_='777a27d3-65b5-4c25-b772-0a558125b77a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='95086467e6f8a00f1673e6edd14216cb53d44381d95cb6b3e73212a5c3bbce79'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='1eaee604-1f48-4687-9a8d-a0c703d98be6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f4ef10773df4c2e5bffc04c019b8abab6887fea89b8a1296c996a882f6187b57'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='c151799e-ab47-4a4f-8dad-3d1a0fa4de9e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2acce7bcdcc440b95f1862571c73b07266316ad154cf649e3acecf2c5a4592f6')}, text='. . . . . . . . . . . . . . 16\\n3.4 RLHF Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .', start_char_idx=118, end_char_idx=257, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-1', obj=None),\n",
       " 'c151799e-ab47-4a4f-8dad-3d1a0fa4de9e': IndexNode(id_='c151799e-ab47-4a4f-8dad-3d1a0fa4de9e', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='95086467e6f8a00f1673e6edd14216cb53d44381d95cb6b3e73212a5c3bbce79'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='777a27d3-65b5-4c25-b772-0a558125b77a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='01d8e416d1cda8f078b913ff7323f80bcc7fe6f31c9244d3d0a776e29d1c8572'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='7e01781c-2cc9-4195-aa4b-cf0285d8bca8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='270ebcd4286018972585f6790d81b1ba2c8c1999b3cd481410658d15ea2e9137')}, text='16\\n3.4 RLHF Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\\n4 Safety 20\\n4.1 Safety in Pretraining . . . . . . .', start_char_idx=146, end_char_idx=312, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-1', obj=None),\n",
       " '7e01781c-2cc9-4195-aa4b-cf0285d8bca8': IndexNode(id_='7e01781c-2cc9-4195-aa4b-cf0285d8bca8', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='95086467e6f8a00f1673e6edd14216cb53d44381d95cb6b3e73212a5c3bbce79'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='c151799e-ab47-4a4f-8dad-3d1a0fa4de9e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2acce7bcdcc440b95f1862571c73b07266316ad154cf649e3acecf2c5a4592f6'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='155efab1-9082-482f-b2de-2fb6d1aa2f47', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5f63279e772b3af1e01290377640d533d24f2775739aec8f2329ce5496cac943')}, text='. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\\n4 Safety 20\\n4.1 Safety in Pretraining . . . . . . . . . . . . . . . . . . . . .', start_char_idx=186, end_char_idx=340, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-1', obj=None),\n",
       " '155efab1-9082-482f-b2de-2fb6d1aa2f47': IndexNode(id_='155efab1-9082-482f-b2de-2fb6d1aa2f47', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='95086467e6f8a00f1673e6edd14216cb53d44381d95cb6b3e73212a5c3bbce79'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='7e01781c-2cc9-4195-aa4b-cf0285d8bca8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='270ebcd4286018972585f6790d81b1ba2c8c1999b3cd481410658d15ea2e9137'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='ddf4eb85-a847-4933-8721-70d2425673b8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='de85413118feade51aac77298dcf4c96165ec84ca09dbbb9059f5a97c0f558ba')}, text='. . . . . . . . . . . . . . . . . . . . . . 17\\n4 Safety 20\\n4.1 Safety in Pretraining . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .', start_char_idx=214, end_char_idx=368, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-1', obj=None),\n",
       " 'ddf4eb85-a847-4933-8721-70d2425673b8': IndexNode(id_='ddf4eb85-a847-4933-8721-70d2425673b8', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='95086467e6f8a00f1673e6edd14216cb53d44381d95cb6b3e73212a5c3bbce79'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='155efab1-9082-482f-b2de-2fb6d1aa2f47', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5f63279e772b3af1e01290377640d533d24f2775739aec8f2329ce5496cac943'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='b2f03612-ca8b-44d2-8e1c-1a6d6c9e2283', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3ee38b64aab6b5828e6174aa4248d67c55682f80a392a53201983620cac40bd2')}, text='. . . . . . . . 17\\n4 Safety 20\\n4.1 Safety in Pretraining . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20\\n4.2 Safety Fine-Tuning . .', start_char_idx=242, end_char_idx=412, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-1', obj=None),\n",
       " 'b2f03612-ca8b-44d2-8e1c-1a6d6c9e2283': IndexNode(id_='b2f03612-ca8b-44d2-8e1c-1a6d6c9e2283', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='95086467e6f8a00f1673e6edd14216cb53d44381d95cb6b3e73212a5c3bbce79'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='ddf4eb85-a847-4933-8721-70d2425673b8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='de85413118feade51aac77298dcf4c96165ec84ca09dbbb9059f5a97c0f558ba'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='63f60b6c-19ad-4d7f-bc63-88a6a39372b9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8d2c9ce9a5bb5b99999f6ad9cfdd8fb7d8d3e0da5d9b0caaae247ec744b20529')}, text='. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20\\n4.2 Safety Fine-Tuning . . . . . . . . . . . . . . . . . .', start_char_idx=301, end_char_idx=444, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-1', obj=None),\n",
       " '63f60b6c-19ad-4d7f-bc63-88a6a39372b9': IndexNode(id_='63f60b6c-19ad-4d7f-bc63-88a6a39372b9', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='95086467e6f8a00f1673e6edd14216cb53d44381d95cb6b3e73212a5c3bbce79'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='b2f03612-ca8b-44d2-8e1c-1a6d6c9e2283', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3ee38b64aab6b5828e6174aa4248d67c55682f80a392a53201983620cac40bd2'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='07c2d4d6-4370-4c7c-8135-f25a6d1cb8b7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5978db2cc6eb86537250d46fa59b0c9ae4ee1500623609d6f1809f688b8dd85f')}, text='. . . . . . . . . . . . . . . . . . . . . . . . . . . 20\\n4.2 Safety Fine-Tuning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .', start_char_idx=329, end_char_idx=472, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-1', obj=None),\n",
       " '07c2d4d6-4370-4c7c-8135-f25a6d1cb8b7': IndexNode(id_='07c2d4d6-4370-4c7c-8135-f25a6d1cb8b7', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='95086467e6f8a00f1673e6edd14216cb53d44381d95cb6b3e73212a5c3bbce79'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='63f60b6c-19ad-4d7f-bc63-88a6a39372b9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8d2c9ce9a5bb5b99999f6ad9cfdd8fb7d8d3e0da5d9b0caaae247ec744b20529'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='0ccd7300-3a9d-4f97-b9f9-c5ca93b723d9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c3902522c94f021c9804608e5f8b9c4954fcb11836826a80c9166eaf5653c0eb')}, text='. . . . . . . . . . . . . 20\\n4.2 Safety Fine-Tuning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .', start_char_idx=357, end_char_idx=494, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-1', obj=None),\n",
       " '0ccd7300-3a9d-4f97-b9f9-c5ca93b723d9': IndexNode(id_='0ccd7300-3a9d-4f97-b9f9-c5ca93b723d9', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='95086467e6f8a00f1673e6edd14216cb53d44381d95cb6b3e73212a5c3bbce79'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='07c2d4d6-4370-4c7c-8135-f25a6d1cb8b7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5978db2cc6eb86537250d46fa59b0c9ae4ee1500623609d6f1809f688b8dd85f'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='12ff7ef0-b7ad-49fc-bae8-7b6e9f4e415b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='534f61ae83efaac1e9c8c24f8fc61e0465dedf9e5c31cd2387e5d4113c89a0b8')}, text='. . 20\\n4.2 Safety Fine-Tuning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\\n4.3 Red Teaming . . . . . . . . . .', start_char_idx=379, end_char_idx=533, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-1', obj=None),\n",
       " '12ff7ef0-b7ad-49fc-bae8-7b6e9f4e415b': IndexNode(id_='12ff7ef0-b7ad-49fc-bae8-7b6e9f4e415b', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='95086467e6f8a00f1673e6edd14216cb53d44381d95cb6b3e73212a5c3bbce79'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='0ccd7300-3a9d-4f97-b9f9-c5ca93b723d9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c3902522c94f021c9804608e5f8b9c4954fcb11836826a80c9166eaf5653c0eb'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='ded60e61-4978-44bf-b6ae-df52a920058e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='24b21fd470d33b1bda205614e9e30f7ac90518acf266df3a1aa979f69c5856f6')}, text='. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\\n4.3 Red Teaming . . . . . . . . . . . . . . . . . . . . . . . .', start_char_idx=423, end_char_idx=561, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-1', obj=None),\n",
       " 'ded60e61-4978-44bf-b6ae-df52a920058e': IndexNode(id_='ded60e61-4978-44bf-b6ae-df52a920058e', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='95086467e6f8a00f1673e6edd14216cb53d44381d95cb6b3e73212a5c3bbce79'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='12ff7ef0-b7ad-49fc-bae8-7b6e9f4e415b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='534f61ae83efaac1e9c8c24f8fc61e0465dedf9e5c31cd2387e5d4113c89a0b8'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='96d99b94-fd43-4e32-8aaa-b92b3a458554', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9b6ac4148c53c080396822dc8c9ffd875c163710f6aa958df393e891b4dd99db')}, text='. . . . . . . . . . . . . . . . . . . . . . 23\\n4.3 Red Teaming . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .', start_char_idx=451, end_char_idx=589, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-1', obj=None),\n",
       " '96d99b94-fd43-4e32-8aaa-b92b3a458554': IndexNode(id_='96d99b94-fd43-4e32-8aaa-b92b3a458554', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='95086467e6f8a00f1673e6edd14216cb53d44381d95cb6b3e73212a5c3bbce79'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='ded60e61-4978-44bf-b6ae-df52a920058e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='24b21fd470d33b1bda205614e9e30f7ac90518acf266df3a1aa979f69c5856f6'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='3a511f00-0e63-42a3-8422-742f98fbc7ad', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9ba058baf6ee34434356f725f967413075e05980303a25e073c3982feb617484')}, text='. . . . . . . . 23\\n4.3 Red Teaming . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .', start_char_idx=479, end_char_idx=607, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-1', obj=None),\n",
       " '3a511f00-0e63-42a3-8422-742f98fbc7ad': IndexNode(id_='3a511f00-0e63-42a3-8422-742f98fbc7ad', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='95086467e6f8a00f1673e6edd14216cb53d44381d95cb6b3e73212a5c3bbce79'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='96d99b94-fd43-4e32-8aaa-b92b3a458554', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9b6ac4148c53c080396822dc8c9ffd875c163710f6aa958df393e891b4dd99db'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='91e92158-1d4e-46a7-9c14-53753d23dfca', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='105ae04a42f10280e122cdaa38373a09c8e34b0f5eca9d9509a8d6a9664dc245')}, text='. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28\\n4.4 Safety Evaluation of Llama 2-Chat . . . . . . . . . . .', start_char_idx=516, end_char_idx=670, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-1', obj=None),\n",
       " '91e92158-1d4e-46a7-9c14-53753d23dfca': IndexNode(id_='91e92158-1d4e-46a7-9c14-53753d23dfca', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='95086467e6f8a00f1673e6edd14216cb53d44381d95cb6b3e73212a5c3bbce79'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='3a511f00-0e63-42a3-8422-742f98fbc7ad', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9ba058baf6ee34434356f725f967413075e05980303a25e073c3982feb617484'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='e79b862f-4428-4824-9d74-ac308b1fa02a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3610bb68386065ca4b87bf130f301a62972a96a771aa5129c495d9d330377726')}, text='. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28\\n4.4 Safety Evaluation of Llama 2-Chat . . . . . . . . . . . . . . . . . . . . . . . . .', start_char_idx=544, end_char_idx=698, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-1', obj=None),\n",
       " 'e79b862f-4428-4824-9d74-ac308b1fa02a': IndexNode(id_='e79b862f-4428-4824-9d74-ac308b1fa02a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='95086467e6f8a00f1673e6edd14216cb53d44381d95cb6b3e73212a5c3bbce79'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='91e92158-1d4e-46a7-9c14-53753d23dfca', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='105ae04a42f10280e122cdaa38373a09c8e34b0f5eca9d9509a8d6a9664dc245'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='b6cdaaaf-fe80-4281-9844-16b639d8a633', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a9f9fb5ee4a5741692ca2c199c4ce0ee064b031dea1fe6626508fdc622c4081e')}, text='. . . . . . . . . . . . . . . . . . 28\\n4.4 Safety Evaluation of Llama 2-Chat . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .', start_char_idx=572, end_char_idx=716, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-1', obj=None),\n",
       " 'b6cdaaaf-fe80-4281-9844-16b639d8a633': IndexNode(id_='b6cdaaaf-fe80-4281-9844-16b639d8a633', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='95086467e6f8a00f1673e6edd14216cb53d44381d95cb6b3e73212a5c3bbce79'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='e79b862f-4428-4824-9d74-ac308b1fa02a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3610bb68386065ca4b87bf130f301a62972a96a771aa5129c495d9d330377726'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='32c5ddec-3aca-4d8a-ad09-a73102458d3b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f418e5a71ad02f771ca7a2a043b6f6482fea43aa3badfec1a6f49f93c0ff2403')}, text='. . . . . . . . . 28\\n4.4 Safety Evaluation of Llama 2-Chat . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\\n5 Discussion 32\\n5.1 Learnings and Observations . . . . . .', start_char_idx=590, end_char_idx=778, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-1', obj=None),\n",
       " '32c5ddec-3aca-4d8a-ad09-a73102458d3b': IndexNode(id_='32c5ddec-3aca-4d8a-ad09-a73102458d3b', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='95086467e6f8a00f1673e6edd14216cb53d44381d95cb6b3e73212a5c3bbce79'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='b6cdaaaf-fe80-4281-9844-16b639d8a633', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a9f9fb5ee4a5741692ca2c199c4ce0ee064b031dea1fe6626508fdc622c4081e'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='cb7fcd17-5a70-433f-8cb6-0ac0e50054d2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='932ae72561a884da7cb46bfd7cefb97e42a5aef5154ba490ec919dfb989d9fd7')}, text='. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\\n5 Discussion 32\\n5.1 Learnings and Observations . . . . . . . . . . . . . . . . . . . . . . .', start_char_idx=651, end_char_idx=812, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-1', obj=None),\n",
       " 'cb7fcd17-5a70-433f-8cb6-0ac0e50054d2': IndexNode(id_='cb7fcd17-5a70-433f-8cb6-0ac0e50054d2', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='95086467e6f8a00f1673e6edd14216cb53d44381d95cb6b3e73212a5c3bbce79'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='32c5ddec-3aca-4d8a-ad09-a73102458d3b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f418e5a71ad02f771ca7a2a043b6f6482fea43aa3badfec1a6f49f93c0ff2403'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='413a33e3-36bb-40a8-9f71-bfd75b31cb77', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5387ce625a78fc6f24eb85390061dcf5b8a30d61ff1f11c17ed36f97d06f946d')}, text='. . . . . . . . . . . . . . . . . . . 29\\n5 Discussion 32\\n5.1 Learnings and Observations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .', start_char_idx=679, end_char_idx=840, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-1', obj=None),\n",
       " '413a33e3-36bb-40a8-9f71-bfd75b31cb77': IndexNode(id_='413a33e3-36bb-40a8-9f71-bfd75b31cb77', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='95086467e6f8a00f1673e6edd14216cb53d44381d95cb6b3e73212a5c3bbce79'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='cb7fcd17-5a70-433f-8cb6-0ac0e50054d2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='932ae72561a884da7cb46bfd7cefb97e42a5aef5154ba490ec919dfb989d9fd7'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='ae4aa42b-ed7e-4145-90ec-2e184d4fa12d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='26511c4696e46e8a05a0a5fbe01f5a334fbeb18689371e30474a795a16905267')}, text='. . . . . 29\\n5 Discussion 32\\n5.1 Learnings and Observations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32\\n5.2 Limitations and Ethical Considerations . . . . . . .', start_char_idx=707, end_char_idx=902, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-1', obj=None),\n",
       " 'ae4aa42b-ed7e-4145-90ec-2e184d4fa12d': IndexNode(id_='ae4aa42b-ed7e-4145-90ec-2e184d4fa12d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='95086467e6f8a00f1673e6edd14216cb53d44381d95cb6b3e73212a5c3bbce79'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='413a33e3-36bb-40a8-9f71-bfd75b31cb77', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5387ce625a78fc6f24eb85390061dcf5b8a30d61ff1f11c17ed36f97d06f946d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='13655bf8-8812-477b-a6e7-d7a96f4f469c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='fce8631b8cd8db21335e99f5d64dd85af1a6001ca5b39485019e5c3de2cf4910')}, text='. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32\\n5.2 Limitations and Ethical Considerations . . . . . . . . . . . . . . . . . . . . .', start_char_idx=769, end_char_idx=930, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-1', obj=None),\n",
       " '13655bf8-8812-477b-a6e7-d7a96f4f469c': IndexNode(id_='13655bf8-8812-477b-a6e7-d7a96f4f469c', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='95086467e6f8a00f1673e6edd14216cb53d44381d95cb6b3e73212a5c3bbce79'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='ae4aa42b-ed7e-4145-90ec-2e184d4fa12d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='26511c4696e46e8a05a0a5fbe01f5a334fbeb18689371e30474a795a16905267'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='187c0b97-fcf8-412a-88f3-d76bf4cdf94d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3fe7e2053a390d7f5a16dbe2db16eac8345acca65058f18a96015f7ff3498da9')}, text='. . . . . . . . . . . . . . . . . . . . . . . 32\\n5.2 Limitations and Ethical Considerations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .', start_char_idx=797, end_char_idx=950, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-1', obj=None),\n",
       " '187c0b97-fcf8-412a-88f3-d76bf4cdf94d': IndexNode(id_='187c0b97-fcf8-412a-88f3-d76bf4cdf94d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='95086467e6f8a00f1673e6edd14216cb53d44381d95cb6b3e73212a5c3bbce79'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='13655bf8-8812-477b-a6e7-d7a96f4f469c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='fce8631b8cd8db21335e99f5d64dd85af1a6001ca5b39485019e5c3de2cf4910'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='13253f20-387f-4bb1-b236-83b3505edbc8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1ccede406cad30fbee5b7091dd6fb61e1b3a6902e737ef49645a86b8b45e8acb')}, text='. . . . . . . . . . . . . 32\\n5.2 Limitations and Ethical Considerations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34\\n5.3 Responsible Release Strategy . . . . . . . . . .', start_char_idx=817, end_char_idx=1006, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-1', obj=None),\n",
       " '13253f20-387f-4bb1-b236-83b3505edbc8': IndexNode(id_='13253f20-387f-4bb1-b236-83b3505edbc8', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='95086467e6f8a00f1673e6edd14216cb53d44381d95cb6b3e73212a5c3bbce79'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='187c0b97-fcf8-412a-88f3-d76bf4cdf94d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3fe7e2053a390d7f5a16dbe2db16eac8345acca65058f18a96015f7ff3498da9'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='41ad9a8a-c75f-4478-bf31-e4300e28b540', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='36ccd55e3d045bf91be70ea0a6f28a6bbdc3053fe7c226085ccb3e1099fc0b37')}, text='. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34\\n5.3 Responsible Release Strategy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .', start_char_idx=891, end_char_idx=1046, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-1', obj=None),\n",
       " '41ad9a8a-c75f-4478-bf31-e4300e28b540': IndexNode(id_='41ad9a8a-c75f-4478-bf31-e4300e28b540', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='95086467e6f8a00f1673e6edd14216cb53d44381d95cb6b3e73212a5c3bbce79'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='13253f20-387f-4bb1-b236-83b3505edbc8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1ccede406cad30fbee5b7091dd6fb61e1b3a6902e737ef49645a86b8b45e8acb'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='abb16bef-e608-461e-b643-270f5d7de315', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='faa592487ea0a3f35ee9154ed3aaf5f4d2b9c854ac1ce48f6da5e472bb0485df')}, text='. . . . . . . . . . . . . . . . 34\\n5.3 Responsible Release Strategy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .', start_char_idx=919, end_char_idx=1060, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-1', obj=None),\n",
       " 'abb16bef-e608-461e-b643-270f5d7de315': IndexNode(id_='abb16bef-e608-461e-b643-270f5d7de315', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='95086467e6f8a00f1673e6edd14216cb53d44381d95cb6b3e73212a5c3bbce79'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='41ad9a8a-c75f-4478-bf31-e4300e28b540', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='36ccd55e3d045bf91be70ea0a6f28a6bbdc3053fe7c226085ccb3e1099fc0b37'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='1e0a1828-d11a-48ce-b5c3-51271e49690b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ae04751b9ad70e928fabae4bd07567090abdb71e5fafea8f2467bbc74e6082fd')}, text='. . . . . . . . . 34\\n5.3 Responsible Release Strategy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\\n6 Related Work 35\\n7 Conclusion 36\\nA Appendix 46\\nA.1 Contributions . . .', start_char_idx=933, end_char_idx=1135, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-1', obj=None),\n",
       " '1e0a1828-d11a-48ce-b5c3-51271e49690b': IndexNode(id_='1e0a1828-d11a-48ce-b5c3-51271e49690b', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='95086467e6f8a00f1673e6edd14216cb53d44381d95cb6b3e73212a5c3bbce79'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='abb16bef-e608-461e-b643-270f5d7de315', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='faa592487ea0a3f35ee9154ed3aaf5f4d2b9c854ac1ce48f6da5e472bb0485df'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='027c9253-e0b5-4736-a7eb-20027c8906b0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d73de0175a070421867c976955f0a819b5d194194f28c60f458702c08827ca30')}, text='. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\\n6 Related Work 35\\n7 Conclusion 36\\nA Appendix 46\\nA.1 Contributions . . . . . . . . . . . . . . . . .', start_char_idx=989, end_char_idx=1163, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-1', obj=None),\n",
       " '027c9253-e0b5-4736-a7eb-20027c8906b0': IndexNode(id_='027c9253-e0b5-4736-a7eb-20027c8906b0', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='95086467e6f8a00f1673e6edd14216cb53d44381d95cb6b3e73212a5c3bbce79'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='1e0a1828-d11a-48ce-b5c3-51271e49690b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ae04751b9ad70e928fabae4bd07567090abdb71e5fafea8f2467bbc74e6082fd'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='d41ac8f3-f02a-4965-8171-b1c5a1f4b7b0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6b54ee1ea266cac7f537afaa2cf8bc5a2d8ffafd62938d55772f8ba25749505e')}, text='. . . . . . . . . . . . . . . . . . . . . . 35\\n6 Related Work 35\\n7 Conclusion 36\\nA Appendix 46\\nA.1 Contributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .', start_char_idx=1017, end_char_idx=1191, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-1', obj=None),\n",
       " 'd41ac8f3-f02a-4965-8171-b1c5a1f4b7b0': IndexNode(id_='d41ac8f3-f02a-4965-8171-b1c5a1f4b7b0', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='95086467e6f8a00f1673e6edd14216cb53d44381d95cb6b3e73212a5c3bbce79'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='027c9253-e0b5-4736-a7eb-20027c8906b0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d73de0175a070421867c976955f0a819b5d194194f28c60f458702c08827ca30'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='d44ae6e2-778a-4dd8-a9a5-e06b4841f12a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1748fdc89bf66765d62d121c334895b0980da33ebc1af7c67dd489d29f4eb29d')}, text='. . . . . . . . 35\\n6 Related Work 35\\n7 Conclusion 36\\nA Appendix 46\\nA.1 Contributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .', start_char_idx=1045, end_char_idx=1219, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-1', obj=None),\n",
       " 'd44ae6e2-778a-4dd8-a9a5-e06b4841f12a': IndexNode(id_='d44ae6e2-778a-4dd8-a9a5-e06b4841f12a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='95086467e6f8a00f1673e6edd14216cb53d44381d95cb6b3e73212a5c3bbce79'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='d41ac8f3-f02a-4965-8171-b1c5a1f4b7b0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6b54ee1ea266cac7f537afaa2cf8bc5a2d8ffafd62938d55772f8ba25749505e'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='91c210de-dcbc-464a-a628-047b261558a8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='09b1e8eedf2c085be9104ada64218f34a141d80a2a0b5813385da7e0579cdb14')}, text='. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46\\nA.2 Additional Details for Pretraining . . . . . . . . . . . . . .', start_char_idx=1132, end_char_idx=1291, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-1', obj=None),\n",
       " '91c210de-dcbc-464a-a628-047b261558a8': IndexNode(id_='91c210de-dcbc-464a-a628-047b261558a8', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='95086467e6f8a00f1673e6edd14216cb53d44381d95cb6b3e73212a5c3bbce79'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='d44ae6e2-778a-4dd8-a9a5-e06b4841f12a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1748fdc89bf66765d62d121c334895b0980da33ebc1af7c67dd489d29f4eb29d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='2f5cc738-8fe6-479e-9bfd-21b75c95a23c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a19eb5a793fdd7eb386894d802e7c22e0e4592bbe8fb85e1b946bae8ca3ce1fc')}, text='. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46\\nA.2 Additional Details for Pretraining . . . . . . . . . . . . . . . . . . . . . . . . . . . .', start_char_idx=1160, end_char_idx=1319, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-1', obj=None),\n",
       " '2f5cc738-8fe6-479e-9bfd-21b75c95a23c': IndexNode(id_='2f5cc738-8fe6-479e-9bfd-21b75c95a23c', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='95086467e6f8a00f1673e6edd14216cb53d44381d95cb6b3e73212a5c3bbce79'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='91c210de-dcbc-464a-a628-047b261558a8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='09b1e8eedf2c085be9104ada64218f34a141d80a2a0b5813385da7e0579cdb14')}, text='. . . . . . . . . . . . . . . . . 46\\nA.2 Additional Details for Pretraining . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .', start_char_idx=1188, end_char_idx=1327, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-1', obj=None),\n",
       " 'b72438a5-06b2-4fd3-8886-20ce2e7bec4d': IndexNode(id_='b72438a5-06b2-4fd3-8886-20ce2e7bec4d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='95086467e6f8a00f1673e6edd14216cb53d44381d95cb6b3e73212a5c3bbce79'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='77743d24-d40e-41c8-aa93-243f10dcab28', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6521cb8a33c4f4b1d8aee14411d86f184b2d9133bfdcacc4db29cf773842f86d')}, text='. . . . . . . . . . . . . . . . . . . . 9\\n3.3 System Message for Multi-Turn Consistency . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\\n3.4 RLHF Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\\n4 Safety 20\\n4.1 Safety in Pretraining . . . . . . . . . . . . . . .', start_char_idx=0, end_char_idx=328, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-1', obj=None),\n",
       " '77743d24-d40e-41c8-aa93-243f10dcab28': IndexNode(id_='77743d24-d40e-41c8-aa93-243f10dcab28', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='95086467e6f8a00f1673e6edd14216cb53d44381d95cb6b3e73212a5c3bbce79'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='b72438a5-06b2-4fd3-8886-20ce2e7bec4d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='cf79315c7d23ca269f7d562f7050e998b2568054550f0dd2c25bdbda12412857'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='e4d0e5f0-9d6c-4646-b75d-f822c362d421', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='441016c36720b53361aa14eaa5312175affe563901ccc22e5cc5c3eb8eddd9b3')}, text='. . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\\n4 Safety 20\\n4.1 Safety in Pretraining . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20\\n4.2 Safety Fine-Tuning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .', start_char_idx=202, end_char_idx=494, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-1', obj=None),\n",
       " 'e4d0e5f0-9d6c-4646-b75d-f822c362d421': IndexNode(id_='e4d0e5f0-9d6c-4646-b75d-f822c362d421', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='95086467e6f8a00f1673e6edd14216cb53d44381d95cb6b3e73212a5c3bbce79'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='77743d24-d40e-41c8-aa93-243f10dcab28', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6521cb8a33c4f4b1d8aee14411d86f184b2d9133bfdcacc4db29cf773842f86d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='5334d5ff-c200-479f-9456-4322a714d6ec', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='34c2792ca2fcbbcee95aff6f069c2d512514082ec8190951936adf40637bc62e')}, text='. . 20\\n4.2 Safety Fine-Tuning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\\n4.3 Red Teaming . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28\\n4.4 Safety Evaluation of Llama 2-Chat . . . . . . . . . . . . . . . . . . . .', start_char_idx=379, end_char_idx=688, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-1', obj=None),\n",
       " '5334d5ff-c200-479f-9456-4322a714d6ec': IndexNode(id_='5334d5ff-c200-479f-9456-4322a714d6ec', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='95086467e6f8a00f1673e6edd14216cb53d44381d95cb6b3e73212a5c3bbce79'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='e4d0e5f0-9d6c-4646-b75d-f822c362d421', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='441016c36720b53361aa14eaa5312175affe563901ccc22e5cc5c3eb8eddd9b3'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='d2e6d79f-fe85-4cd1-8c17-e25bac283acc', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8ac8db88cd8b9d325036998c8e34c0ad0c9bfd58153010c1414fa8abffc6b793')}, text='. . . . . . . . . . . . . . . . . . . . . . . 28\\n4.4 Safety Evaluation of Llama 2-Chat . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\\n5 Discussion 32\\n5.1 Learnings and Observations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32\\n5.2 Limitations and Ethical Considerations . . . . . . . . . . . .', start_char_idx=562, end_char_idx=912, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-1', obj=None),\n",
       " 'd2e6d79f-fe85-4cd1-8c17-e25bac283acc': IndexNode(id_='d2e6d79f-fe85-4cd1-8c17-e25bac283acc', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='95086467e6f8a00f1673e6edd14216cb53d44381d95cb6b3e73212a5c3bbce79'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='5334d5ff-c200-479f-9456-4322a714d6ec', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='34c2792ca2fcbbcee95aff6f069c2d512514082ec8190951936adf40637bc62e'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='30223635-ad5c-42f7-b319-d0d2b6373032', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='30025a954e2eca5bf2378b5c85f209a0c6fa6122e879a0f23c743713470a63eb')}, text='. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32\\n5.2 Limitations and Ethical Considerations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34\\n5.3 Responsible Release Strategy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\\n6 Related Work 35\\n7 Conclusion 36\\nA Appendix 46\\nA.1 Contributions . . . . . . .', start_char_idx=779, end_char_idx=1143, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-1', obj=None),\n",
       " '30223635-ad5c-42f7-b319-d0d2b6373032': IndexNode(id_='30223635-ad5c-42f7-b319-d0d2b6373032', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='95086467e6f8a00f1673e6edd14216cb53d44381d95cb6b3e73212a5c3bbce79'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='d2e6d79f-fe85-4cd1-8c17-e25bac283acc', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8ac8db88cd8b9d325036998c8e34c0ad0c9bfd58153010c1414fa8abffc6b793')}, text='. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\\n6 Related Work 35\\n7 Conclusion 36\\nA Appendix 46\\nA.1 Contributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46\\nA.2 Additional Details for Pretraining . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .', start_char_idx=997, end_char_idx=1327, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-1', obj=None),\n",
       " '136ae384-b6a3-4279-a2e4-dbe52ad3cf71': IndexNode(id_='136ae384-b6a3-4279-a2e4-dbe52ad3cf71', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='95086467e6f8a00f1673e6edd14216cb53d44381d95cb6b3e73212a5c3bbce79'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='66032f92-39e6-4f30-8f6d-acee22a9546e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1faea243ac3c2ed964320ecd48a07bd7d519ad9f92d817400b3f20a6d8418c45')}, text='. . . . . . . . . . . . . . . . . . . . 9\\n3.3 System Message for Multi-Turn Consistency . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\\n3.4 RLHF Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\\n4 Safety 20\\n4.1 Safety in Pretraining . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20\\n4.2 Safety Fine-Tuning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\\n4.3 Red Teaming . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .', start_char_idx=0, end_char_idx=607, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-1', obj=None),\n",
       " '66032f92-39e6-4f30-8f6d-acee22a9546e': IndexNode(id_='66032f92-39e6-4f30-8f6d-acee22a9546e', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='95086467e6f8a00f1673e6edd14216cb53d44381d95cb6b3e73212a5c3bbce79'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='136ae384-b6a3-4279-a2e4-dbe52ad3cf71', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='036a1772331ef1ec6ef4d135f5a972202946f059219f251bd329b52b1c07b3da'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='8ef666e7-569a-401a-8eb3-8594bc8fe236', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='421b61012667052917a2bb56fb4a26f07eb6f1de28571dbe1825634379834d36')}, text='. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28\\n4.4 Safety Evaluation of Llama 2-Chat . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\\n5 Discussion 32\\n5.1 Learnings and Observations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32\\n5.2 Limitations and Ethical Considerations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34\\n5.3 Responsible Release Strategy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\\n6 Related Work 35\\n7 Conclusion 36\\nA Appendix 46\\nA.1 Contributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .', start_char_idx=516, end_char_idx=1197, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-1', obj=None),\n",
       " '8ef666e7-569a-401a-8eb3-8594bc8fe236': IndexNode(id_='8ef666e7-569a-401a-8eb3-8594bc8fe236', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='95086467e6f8a00f1673e6edd14216cb53d44381d95cb6b3e73212a5c3bbce79'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='66032f92-39e6-4f30-8f6d-acee22a9546e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1faea243ac3c2ed964320ecd48a07bd7d519ad9f92d817400b3f20a6d8418c45')}, text='. . . . . 35\\n6 Related Work 35\\n7 Conclusion 36\\nA Appendix 46\\nA.1 Contributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46\\nA.2 Additional Details for Pretraining . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .', start_char_idx=1051, end_char_idx=1327, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-1', obj=None),\n",
       " 'node-1': IndexNode(id_='node-1', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='d03f19eb-da15-45dc-bfd4-e5d10f161250', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='231b3bd773f012c01b893ada9e009ecf25ee59934614c5a595c9bf1b3a123292'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='8b00afa9-d4c4-4d4b-af39-6c9f6c6d2eea', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0321fa3d9a93198d651b9d76efd7b48778c42e726f7cd0265cd3be68129f81fc'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='e5fa6f99-3015-4b79-90da-a7bae3712a9c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eb89e1f00847ed009991a8639de4d2b496e56cf8687c03a2599ffb04b1171be8')}, text='. . . . . . . . . . . . . . . . . . . . 9\\n3.3 System Message for Multi-Turn Consistency . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\\n3.4 RLHF Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\\n4 Safety 20\\n4.1 Safety in Pretraining . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20\\n4.2 Safety Fine-Tuning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\\n4.3 Red Teaming . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28\\n4.4 Safety Evaluation of Llama 2-Chat . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\\n5 Discussion 32\\n5.1 Learnings and Observations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32\\n5.2 Limitations and Ethical Considerations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34\\n5.3 Responsible Release Strategy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\\n6 Related Work 35\\n7 Conclusion 36\\nA Appendix 46\\nA.1 Contributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46\\nA.2 Additional Details for Pretraining . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .', start_char_idx=2437, end_char_idx=3764, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-1', obj=None),\n",
       " '498a1c36-ec39-4eb9-8d8c-e2986052d64b': IndexNode(id_='498a1c36-ec39-4eb9-8d8c-e2986052d64b', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eb89e1f00847ed009991a8639de4d2b496e56cf8687c03a2599ffb04b1171be8'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='ea157b08-51fa-4c6b-8516-e32b391a6f03', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='55734ac9f3d919fdeaf9cdf047077b2b8168239c77dbb54ca16d3f6e4a94ac20')}, text='. . . . . . . . . . . . . 46\\nA.2 Additional Details for Pretraining . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47\\nA.3 Additional Details for Fine-tuning . . . . .', start_char_idx=0, end_char_idx=189, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-2', obj=None),\n",
       " 'ea157b08-51fa-4c6b-8516-e32b391a6f03': IndexNode(id_='ea157b08-51fa-4c6b-8516-e32b391a6f03', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eb89e1f00847ed009991a8639de4d2b496e56cf8687c03a2599ffb04b1171be8'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='498a1c36-ec39-4eb9-8d8c-e2986052d64b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='83e1bd47c69efabd5d05065a9f1ce2ae13a506511a7dcbedf35cb2fe56057d27'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='c9ca0296-d48b-4c9b-a30b-836b6a5bb33c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='fd904a7790c24ff09cc54150f29a66ef63669b61ef6c1e270ed7d4fe0f8ddaec')}, text='. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47\\nA.3 Additional Details for Fine-tuning . . . . . . . . . . . . . . . . . . . . . . . .', start_char_idx=70, end_char_idx=227, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-2', obj=None),\n",
       " 'c9ca0296-d48b-4c9b-a30b-836b6a5bb33c': IndexNode(id_='c9ca0296-d48b-4c9b-a30b-836b6a5bb33c', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eb89e1f00847ed009991a8639de4d2b496e56cf8687c03a2599ffb04b1171be8'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='ea157b08-51fa-4c6b-8516-e32b391a6f03', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='55734ac9f3d919fdeaf9cdf047077b2b8168239c77dbb54ca16d3f6e4a94ac20'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='3c10d29d-e9f6-4db6-b263-18fb285a8fce', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8a74ab2e8903f38ac07a4844f80ccbc5261a75c0517c98b0323a6955385359d6')}, text='. . . . . . . . . . . . . . . . . . . . 47\\nA.3 Additional Details for Fine-tuning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .', start_char_idx=98, end_char_idx=247, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-2', obj=None),\n",
       " '3c10d29d-e9f6-4db6-b263-18fb285a8fce': IndexNode(id_='3c10d29d-e9f6-4db6-b263-18fb285a8fce', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eb89e1f00847ed009991a8639de4d2b496e56cf8687c03a2599ffb04b1171be8'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='c9ca0296-d48b-4c9b-a30b-836b6a5bb33c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='fd904a7790c24ff09cc54150f29a66ef63669b61ef6c1e270ed7d4fe0f8ddaec'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='843ecc82-7910-4bad-8ac8-82c230cae1cc', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='94d08f02f33bea8591d840c7d577dbdedf19b57e49e9879d8e60a0f83f096a0c')}, text='. . . . . . . . . . 47\\nA.3 Additional Details for Fine-tuning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51\\nA.4 Additional Details for Safety . . . . . . . . . .', start_char_idx=118, end_char_idx=304, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-2', obj=None),\n",
       " '843ecc82-7910-4bad-8ac8-82c230cae1cc': IndexNode(id_='843ecc82-7910-4bad-8ac8-82c230cae1cc', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eb89e1f00847ed009991a8639de4d2b496e56cf8687c03a2599ffb04b1171be8'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='3c10d29d-e9f6-4db6-b263-18fb285a8fce', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8a74ab2e8903f38ac07a4844f80ccbc5261a75c0517c98b0323a6955385359d6'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='f2ffbf33-12f6-4506-a85a-0d1d7b1f01fa', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='415bf5bd042d41132a0965850bbb6a955e619ccf258064244fe7e4d0addcec95')}, text='. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51\\nA.4 Additional Details for Safety . . . . . . . . . . . . . . . . . . . . . . . . . .', start_char_idx=182, end_char_idx=336, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-2', obj=None),\n",
       " 'f2ffbf33-12f6-4506-a85a-0d1d7b1f01fa': IndexNode(id_='f2ffbf33-12f6-4506-a85a-0d1d7b1f01fa', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eb89e1f00847ed009991a8639de4d2b496e56cf8687c03a2599ffb04b1171be8'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='843ecc82-7910-4bad-8ac8-82c230cae1cc', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='94d08f02f33bea8591d840c7d577dbdedf19b57e49e9879d8e60a0f83f096a0c'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='3c16a1b4-7af1-4e4c-966c-a4c23f84fdf5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='11a57ced0bde2012770d3704fb8ac6341ff932e9f8aed0df2ea74772f7eca6e3')}, text='. . . . . . . . . . . . . . . . . . . 51\\nA.4 Additional Details for Safety . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .', start_char_idx=210, end_char_idx=360, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-2', obj=None),\n",
       " '3c16a1b4-7af1-4e4c-966c-a4c23f84fdf5': IndexNode(id_='3c16a1b4-7af1-4e4c-966c-a4c23f84fdf5', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eb89e1f00847ed009991a8639de4d2b496e56cf8687c03a2599ffb04b1171be8'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='f2ffbf33-12f6-4506-a85a-0d1d7b1f01fa', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='415bf5bd042d41132a0965850bbb6a955e619ccf258064244fe7e4d0addcec95'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='98dcce56-474f-4839-aeb2-fb83b7b04cb5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c91cc47b2d236b0f9cd5a874a276747282646d74a9ae889a68949595605a0675')}, text='. . . . . . . 51\\nA.4 Additional Details for Safety . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 58\\nA.5 Data Annotation . . . . . . . . . . .', start_char_idx=234, end_char_idx=405, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-2', obj=None),\n",
       " '98dcce56-474f-4839-aeb2-fb83b7b04cb5': IndexNode(id_='98dcce56-474f-4839-aeb2-fb83b7b04cb5', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eb89e1f00847ed009991a8639de4d2b496e56cf8687c03a2599ffb04b1171be8'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='3c16a1b4-7af1-4e4c-966c-a4c23f84fdf5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='11a57ced0bde2012770d3704fb8ac6341ff932e9f8aed0df2ea74772f7eca6e3'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='62ec5d9a-96e5-4471-98df-1dd4068e1214', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b7b87731de5a8fc94084d68b3001414af9989ff5ec5790bda60e0ab862b85c79')}, text='. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 58\\nA.5 Data Annotation . . . . . . . . . . . . . . . . . . . . . . . . .', start_char_idx=291, end_char_idx=433, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-2', obj=None),\n",
       " '62ec5d9a-96e5-4471-98df-1dd4068e1214': IndexNode(id_='62ec5d9a-96e5-4471-98df-1dd4068e1214', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eb89e1f00847ed009991a8639de4d2b496e56cf8687c03a2599ffb04b1171be8'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='98dcce56-474f-4839-aeb2-fb83b7b04cb5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c91cc47b2d236b0f9cd5a874a276747282646d74a9ae889a68949595605a0675'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='38c8b2b1-8537-4627-a0e0-473c57ca1dbc', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='36953ed656c7c5948c1ea9def37722b26d4bb1462794b273ba68979967e7828b')}, text='. . . . . . . . . . . . . . . . . . . . . 58\\nA.5 Data Annotation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .', start_char_idx=319, end_char_idx=461, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-2', obj=None),\n",
       " '38c8b2b1-8537-4627-a0e0-473c57ca1dbc': IndexNode(id_='38c8b2b1-8537-4627-a0e0-473c57ca1dbc', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eb89e1f00847ed009991a8639de4d2b496e56cf8687c03a2599ffb04b1171be8'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='62ec5d9a-96e5-4471-98df-1dd4068e1214', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b7b87731de5a8fc94084d68b3001414af9989ff5ec5790bda60e0ab862b85c79'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='cc791e5e-660c-4a5d-b6d8-5e0485939697', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b0f533fb7249c003aa8319b310cc48fed05b2320a6e61380a16ff1f488f3f40e')}, text='. . . . . . . 58\\nA.5 Data Annotation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 72\\nA.6 Dataset Contamination . . . .', start_char_idx=347, end_char_idx=510, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-2', obj=None),\n",
       " 'cc791e5e-660c-4a5d-b6d8-5e0485939697': IndexNode(id_='cc791e5e-660c-4a5d-b6d8-5e0485939697', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eb89e1f00847ed009991a8639de4d2b496e56cf8687c03a2599ffb04b1171be8'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='38c8b2b1-8537-4627-a0e0-473c57ca1dbc', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='36953ed656c7c5948c1ea9def37722b26d4bb1462794b273ba68979967e7828b'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='197df36c-1847-491c-9b6d-4464eee7f330', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a7a565f67aa8fb00d282c89f474a2c6a877145ad9a31f98004d42ef9ad2e090e')}, text='. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 72\\nA.6 Dataset Contamination . . . . . . . . . . . . . . . . . .', start_char_idx=390, end_char_idx=538, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-2', obj=None),\n",
       " '197df36c-1847-491c-9b6d-4464eee7f330': IndexNode(id_='197df36c-1847-491c-9b6d-4464eee7f330', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eb89e1f00847ed009991a8639de4d2b496e56cf8687c03a2599ffb04b1171be8'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='cc791e5e-660c-4a5d-b6d8-5e0485939697', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b0f533fb7249c003aa8319b310cc48fed05b2320a6e61380a16ff1f488f3f40e'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='fc510da4-78e4-4b3d-8901-a948606227cc', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='816a2129e60922da7372b65a0346e5a591faa5d5e66d555d2b65133bcce00143')}, text='. . . . . . . . . . . . . . . . . . . . . . . . . . . . 72\\nA.6 Dataset Contamination . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .', start_char_idx=418, end_char_idx=566, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-2', obj=None),\n",
       " 'fc510da4-78e4-4b3d-8901-a948606227cc': IndexNode(id_='fc510da4-78e4-4b3d-8901-a948606227cc', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eb89e1f00847ed009991a8639de4d2b496e56cf8687c03a2599ffb04b1171be8'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='197df36c-1847-491c-9b6d-4464eee7f330', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a7a565f67aa8fb00d282c89f474a2c6a877145ad9a31f98004d42ef9ad2e090e'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='a76f2192-88ce-4ac7-a2fa-7c83f80ba6bc', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d512d7a939336a749c3ad0f9ae67bbfc3235ae0cd26e21a644be082d6ba5b364')}, text='. . . . . . . . . . . . . . 72\\nA.6 Dataset Contamination . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 75\\nA.7 Model Card .', start_char_idx=446, end_char_idx=604, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-2', obj=None),\n",
       " 'a76f2192-88ce-4ac7-a2fa-7c83f80ba6bc': IndexNode(id_='a76f2192-88ce-4ac7-a2fa-7c83f80ba6bc', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eb89e1f00847ed009991a8639de4d2b496e56cf8687c03a2599ffb04b1171be8'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='fc510da4-78e4-4b3d-8901-a948606227cc', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='816a2129e60922da7372b65a0346e5a591faa5d5e66d555d2b65133bcce00143'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='a6e1ed80-ec42-4c3f-8316-7b9f9ec346e1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='146d81525826a0c0a302ebc944afa17bdfc25fb7e5ef81c9dacf00205aee7aa4')}, text='72\\nA.6 Dataset Contamination . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 75\\nA.7 Model Card . . . . . . . . . . . . . . .', start_char_idx=474, end_char_idx=632, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-2', obj=None),\n",
       " 'a6e1ed80-ec42-4c3f-8316-7b9f9ec346e1': IndexNode(id_='a6e1ed80-ec42-4c3f-8316-7b9f9ec346e1', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eb89e1f00847ed009991a8639de4d2b496e56cf8687c03a2599ffb04b1171be8'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='a76f2192-88ce-4ac7-a2fa-7c83f80ba6bc', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d512d7a939336a749c3ad0f9ae67bbfc3235ae0cd26e21a644be082d6ba5b364'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='d052232d-ead1-4a96-85e1-a1c6ecc31114', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8da536f24c0c14c221987ba21819f91acb4e9338fdca6466049e80cdfc716d6b')}, text='. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 75\\nA.7 Model Card . . . . . . . . . . . . . . . . . . . . . . . . . . . . .', start_char_idx=523, end_char_idx=660, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-2', obj=None),\n",
       " 'd052232d-ead1-4a96-85e1-a1c6ecc31114': IndexNode(id_='d052232d-ead1-4a96-85e1-a1c6ecc31114', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eb89e1f00847ed009991a8639de4d2b496e56cf8687c03a2599ffb04b1171be8'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='a6e1ed80-ec42-4c3f-8316-7b9f9ec346e1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='146d81525826a0c0a302ebc944afa17bdfc25fb7e5ef81c9dacf00205aee7aa4'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='72504486-15d5-45ff-994b-5330127b0d03', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='550e407dd942d61db2e5714d7735570083f2a2858a6ea95f0093b1371edf69d4')}, text='. . . . . . . . . . . . . . . . . 75\\nA.7 Model Card . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .', start_char_idx=551, end_char_idx=688, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-2', obj=None),\n",
       " '72504486-15d5-45ff-994b-5330127b0d03': IndexNode(id_='72504486-15d5-45ff-994b-5330127b0d03', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eb89e1f00847ed009991a8639de4d2b496e56cf8687c03a2599ffb04b1171be8'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='d052232d-ead1-4a96-85e1-a1c6ecc31114', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8da536f24c0c14c221987ba21819f91acb4e9338fdca6466049e80cdfc716d6b'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='9f7948e1-84da-4fb3-89ef-43b32888e716', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='735bb9c53022137b96fb712de2b06ecb461de6b5ebc3259a7054c9b63a3ec974')}, text='. . . 75\\nA.7 Model Card . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .', start_char_idx=579, end_char_idx=696, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-2', obj=None),\n",
       " '9f7948e1-84da-4fb3-89ef-43b32888e716': IndexNode(id_='9f7948e1-84da-4fb3-89ef-43b32888e716', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eb89e1f00847ed009991a8639de4d2b496e56cf8687c03a2599ffb04b1171be8'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='72504486-15d5-45ff-994b-5330127b0d03', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='550e407dd942d61db2e5714d7735570083f2a2858a6ea95f0093b1371edf69d4'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='103b32aa-3d38-4160-840f-d9de1b6516a1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bd996b7f2600e35960a2f87a90d27e432f3f5635459c00c218c2db4a0ddcd610')}, text='. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77\\n2\\n\\nFigure 1: Helpfulness human evaluation results for Llama\\n2-Chatcomparedtootheropen-sourceandclosed-source\\nmodels.', start_char_idx=605, end_char_idx=816, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-2', obj=None),\n",
       " '103b32aa-3d38-4160-840f-d9de1b6516a1': IndexNode(id_='103b32aa-3d38-4160-840f-d9de1b6516a1', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eb89e1f00847ed009991a8639de4d2b496e56cf8687c03a2599ffb04b1171be8'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='9f7948e1-84da-4fb3-89ef-43b32888e716', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='735bb9c53022137b96fb712de2b06ecb461de6b5ebc3259a7054c9b63a3ec974'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='d37dbe85-7f3a-4065-982d-fc1f55d3ae5c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f6e54cc49e854f0c0ea4ab0e84dc5069dcf12fe7ee97f3759d08880fc6a3f3f0')}, text='. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77\\n2\\n\\nFigure 1: Helpfulness human evaluation results for Llama\\n2-Chatcomparedtootheropen-sourceandclosed-source\\nmodels. Human raters compared model generations on ~4k\\npromptsconsistingofbothsingleandmulti-turnprompts.', start_char_idx=631, end_char_idx=914, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-2', obj=None),\n",
       " 'd37dbe85-7f3a-4065-982d-fc1f55d3ae5c': IndexNode(id_='d37dbe85-7f3a-4065-982d-fc1f55d3ae5c', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eb89e1f00847ed009991a8639de4d2b496e56cf8687c03a2599ffb04b1171be8'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='103b32aa-3d38-4160-840f-d9de1b6516a1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bd996b7f2600e35960a2f87a90d27e432f3f5635459c00c218c2db4a0ddcd610'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='87d51c7e-88b1-44f6-8675-777b9c122477', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d2d2c70d78fa8d158ce5de57c1691c4741c4f4e4536371f2e8d27ab2710f7b51')}, text='. . . . . . . . . . . . . . . . . . . . . 77\\n2\\n\\nFigure 1: Helpfulness human evaluation results for Llama\\n2-Chatcomparedtootheropen-sourceandclosed-source\\nmodels. Human raters compared model generations on ~4k\\npromptsconsistingofbothsingleandmulti-turnprompts.\\nThe95%confidenceintervalsforthisevaluationarebetween\\n1%and2%.', start_char_idx=655, end_char_idx=976, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-2', obj=None),\n",
       " '87d51c7e-88b1-44f6-8675-777b9c122477': IndexNode(id_='87d51c7e-88b1-44f6-8675-777b9c122477', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eb89e1f00847ed009991a8639de4d2b496e56cf8687c03a2599ffb04b1171be8'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='d37dbe85-7f3a-4065-982d-fc1f55d3ae5c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f6e54cc49e854f0c0ea4ab0e84dc5069dcf12fe7ee97f3759d08880fc6a3f3f0'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='327c0b8a-70c7-4237-a229-61eefdf2a106', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a7fdd003ecfdb02defdc50997a45b7803df8989ffcc01079e672fd49631f466a')}, text='. . . . . . . . . . . . 77\\n2\\n\\nFigure 1: Helpfulness human evaluation results for Llama\\n2-Chatcomparedtootheropen-sourceandclosed-source\\nmodels. Human raters compared model generations on ~4k\\npromptsconsistingofbothsingleandmulti-turnprompts.\\nThe95%confidenceintervalsforthisevaluationarebetween\\n1%and2%. MoredetailsinSection3.4.2.', start_char_idx=673, end_char_idx=1003, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-2', obj=None),\n",
       " '327c0b8a-70c7-4237-a229-61eefdf2a106': IndexNode(id_='327c0b8a-70c7-4237-a229-61eefdf2a106', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eb89e1f00847ed009991a8639de4d2b496e56cf8687c03a2599ffb04b1171be8'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='87d51c7e-88b1-44f6-8675-777b9c122477', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d2d2c70d78fa8d158ce5de57c1691c4741c4f4e4536371f2e8d27ab2710f7b51'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='b290232c-155f-4f8c-8591-c3f36cc60d9a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9b759605d07c76e4ccac35803ab21e7ce3c7d0f52293baffd855b6fe135d00e9')}, text='. . . . . . 77\\n2\\n\\nFigure 1: Helpfulness human evaluation results for Llama\\n2-Chatcomparedtootheropen-sourceandclosed-source\\nmodels. Human raters compared model generations on ~4k\\npromptsconsistingofbothsingleandmulti-turnprompts.\\nThe95%confidenceintervalsforthisevaluationarebetween\\n1%and2%. MoredetailsinSection3.4.2. Whilereviewing\\nthese results, it is important to note that human evaluations\\ncanbenoisyduetolimitationsofthepromptset,subjectivity\\nof the review guidelines, subjectivity of individual raters,\\nand the inherent difficulty of comparing generations.', start_char_idx=685, end_char_idx=1249, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-2', obj=None),\n",
       " 'b290232c-155f-4f8c-8591-c3f36cc60d9a': IndexNode(id_='b290232c-155f-4f8c-8591-c3f36cc60d9a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eb89e1f00847ed009991a8639de4d2b496e56cf8687c03a2599ffb04b1171be8'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='327c0b8a-70c7-4237-a229-61eefdf2a106', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a7fdd003ecfdb02defdc50997a45b7803df8989ffcc01079e672fd49631f466a'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='47a3c31a-4e76-44f3-a3e2-5cb35dc7c70b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='00bdffa2271609babb1c69b056b983595483ca30c19ba14ab34a4afc445cc61d')}, text='The95%confidenceintervalsforthisevaluationarebetween\\n1%and2%. MoredetailsinSection3.4.2. Whilereviewing\\nthese results, it is important to note that human evaluations\\ncanbenoisyduetolimitationsofthepromptset,subjectivity\\nof the review guidelines, subjectivity of individual raters,\\nand the inherent difficulty of comparing generations.\\nFigure 2: Win-rate % for helpfulness and\\nsafety between commercial-licensed base-\\nlines and Llama 2-Chat , according to GPT-\\n4.', start_char_idx=915, end_char_idx=1377, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-2', obj=None),\n",
       " '47a3c31a-4e76-44f3-a3e2-5cb35dc7c70b': IndexNode(id_='47a3c31a-4e76-44f3-a3e2-5cb35dc7c70b', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eb89e1f00847ed009991a8639de4d2b496e56cf8687c03a2599ffb04b1171be8'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='b290232c-155f-4f8c-8591-c3f36cc60d9a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9b759605d07c76e4ccac35803ab21e7ce3c7d0f52293baffd855b6fe135d00e9'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='0cad851e-0d29-46e0-8db5-9df7346af0e4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='342d1937498c8bdc33d0c4d36afd3d3fa60a3dfef956363189421382e35da91d')}, text='Whilereviewing\\nthese results, it is important to note that human evaluations\\ncanbenoisyduetolimitationsofthepromptset,subjectivity\\nof the review guidelines, subjectivity of individual raters,\\nand the inherent difficulty of comparing generations.\\nFigure 2: Win-rate % for helpfulness and\\nsafety between commercial-licensed base-\\nlines and Llama 2-Chat , according to GPT-\\n4. Tocomplementthehumanevaluation,we\\nused a more capable model, not subject to\\nourownguidance.', start_char_idx=1004, end_char_idx=1469, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-2', obj=None),\n",
       " '0cad851e-0d29-46e0-8db5-9df7346af0e4': IndexNode(id_='0cad851e-0d29-46e0-8db5-9df7346af0e4', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eb89e1f00847ed009991a8639de4d2b496e56cf8687c03a2599ffb04b1171be8'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='47a3c31a-4e76-44f3-a3e2-5cb35dc7c70b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='00bdffa2271609babb1c69b056b983595483ca30c19ba14ab34a4afc445cc61d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='48c1225c-22e9-4971-b27f-ffbe5f903685', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d3c037a6530a07f94c2f1a7dc4d827f4c08a0e4d0b93b6565e58c1380ccdcee9')}, text='Figure 2: Win-rate % for helpfulness and\\nsafety between commercial-licensed base-\\nlines and Llama 2-Chat , according to GPT-\\n4. Tocomplementthehumanevaluation,we\\nused a more capable model, not subject to\\nourownguidance. Greenareaindicatesour\\nmodelisbetteraccordingtoGPT-4. Toremove\\nties, we used win/ (win+loss). The orders in\\nwhichthemodelresponsesarepresentedto\\nGPT-4arerandomlyswappedtoalleviatebias.', start_char_idx=1250, end_char_idx=1653, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-2', obj=None),\n",
       " '48c1225c-22e9-4971-b27f-ffbe5f903685': IndexNode(id_='48c1225c-22e9-4971-b27f-ffbe5f903685', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eb89e1f00847ed009991a8639de4d2b496e56cf8687c03a2599ffb04b1171be8'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='0cad851e-0d29-46e0-8db5-9df7346af0e4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='342d1937498c8bdc33d0c4d36afd3d3fa60a3dfef956363189421382e35da91d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='6ee58c3a-d675-4c65-9ee5-7af69fa62fa1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2aec093f2905ec2906c69f85ac9670e7fda11ac8e0da194b8e8111b8128bba8d')}, text='Tocomplementthehumanevaluation,we\\nused a more capable model, not subject to\\nourownguidance. Greenareaindicatesour\\nmodelisbetteraccordingtoGPT-4. Toremove\\nties, we used win/ (win+loss). The orders in\\nwhichthemodelresponsesarepresentedto\\nGPT-4arerandomlyswappedtoalleviatebias.\\n1 Introduction\\nLarge Language Models (LLMs) have shown great promise as highly capable AI assistants that excel in\\ncomplex reasoning tasks requiring expert knowledge across a wide range of fields, including in specialized\\ndomains such as programming and creative writing.', start_char_idx=1378, end_char_idx=1925, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-2', obj=None),\n",
       " '6ee58c3a-d675-4c65-9ee5-7af69fa62fa1': IndexNode(id_='6ee58c3a-d675-4c65-9ee5-7af69fa62fa1', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eb89e1f00847ed009991a8639de4d2b496e56cf8687c03a2599ffb04b1171be8'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='48c1225c-22e9-4971-b27f-ffbe5f903685', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d3c037a6530a07f94c2f1a7dc4d827f4c08a0e4d0b93b6565e58c1380ccdcee9'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='3adf8086-12a6-4ae6-a203-80233b31a0d2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3e8e69c26d4de9336400eb6e326063a4d2aaffde97cbab5e630c4fa870251321')}, text='Toremove\\nties, we used win/ (win+loss). The orders in\\nwhichthemodelresponsesarepresentedto\\nGPT-4arerandomlyswappedtoalleviatebias.\\n1 Introduction\\nLarge Language Models (LLMs) have shown great promise as highly capable AI assistants that excel in\\ncomplex reasoning tasks requiring expert knowledge across a wide range of fields, including in specialized\\ndomains such as programming and creative writing. They enable interaction with humans through intuitive\\nchat interfaces, which has led to rapid and widespread adoption among the general public.', start_char_idx=1523, end_char_idx=2069, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-2', obj=None),\n",
       " '3adf8086-12a6-4ae6-a203-80233b31a0d2': IndexNode(id_='3adf8086-12a6-4ae6-a203-80233b31a0d2', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eb89e1f00847ed009991a8639de4d2b496e56cf8687c03a2599ffb04b1171be8'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='6ee58c3a-d675-4c65-9ee5-7af69fa62fa1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2aec093f2905ec2906c69f85ac9670e7fda11ac8e0da194b8e8111b8128bba8d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='b9e1a83f-9564-469b-95d7-5ff950a6af70', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5eef7d0912ce36cc165976da7296951cd7b8869247bd0fb953d779481925f55b')}, text='1 Introduction\\nLarge Language Models (LLMs) have shown great promise as highly capable AI assistants that excel in\\ncomplex reasoning tasks requiring expert knowledge across a wide range of fields, including in specialized\\ndomains such as programming and creative writing. They enable interaction with humans through intuitive\\nchat interfaces, which has led to rapid and widespread adoption among the general public.\\nThecapabilitiesofLLMsareremarkableconsideringtheseeminglystraightforwardnatureofthetraining\\nmethodology.', start_char_idx=1654, end_char_idx=2174, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-2', obj=None),\n",
       " 'b9e1a83f-9564-469b-95d7-5ff950a6af70': IndexNode(id_='b9e1a83f-9564-469b-95d7-5ff950a6af70', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eb89e1f00847ed009991a8639de4d2b496e56cf8687c03a2599ffb04b1171be8'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='3adf8086-12a6-4ae6-a203-80233b31a0d2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3e8e69c26d4de9336400eb6e326063a4d2aaffde97cbab5e630c4fa870251321')}, text='1 Introduction\\nLarge Language Models (LLMs) have shown great promise as highly capable AI assistants that excel in\\ncomplex reasoning tasks requiring expert knowledge across a wide range of fields, including in specialized\\ndomains such as programming and creative writing. They enable interaction with humans through intuitive\\nchat interfaces, which has led to rapid and widespread adoption among the general public.\\nThecapabilitiesofLLMsareremarkableconsideringtheseeminglystraightforwardnatureofthetraining\\nmethodology. Auto-regressivetransformersarepretrainedonanextensivecorpusofself-superviseddata,\\nfollowed by alignment with human preferences via techniques such as Reinforcement Learning with Human\\nFeedback(RLHF).Althoughthetrainingmethodologyissimple,highcomputationalrequirementshave\\nlimited the development of LLMs to a few players.', start_char_idx=1654, end_char_idx=2496, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-2', obj=None),\n",
       " '06577566-8466-4e43-9715-86436d6e73c9': IndexNode(id_='06577566-8466-4e43-9715-86436d6e73c9', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eb89e1f00847ed009991a8639de4d2b496e56cf8687c03a2599ffb04b1171be8'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='47f25aa5-6d95-4c33-b1c1-835bcb0eff7f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6972c10e76f5f0069c8df0929c8a04fe9d04d316167100782b48ec98d4d33632')}, text='. . . . . . . . . . . . . 46\\nA.2 Additional Details for Pretraining . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47\\nA.3 Additional Details for Fine-tuning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51\\nA.4 Additional Details for Safety . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .', start_char_idx=0, end_char_idx=346, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-2', obj=None),\n",
       " '47f25aa5-6d95-4c33-b1c1-835bcb0eff7f': IndexNode(id_='47f25aa5-6d95-4c33-b1c1-835bcb0eff7f', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eb89e1f00847ed009991a8639de4d2b496e56cf8687c03a2599ffb04b1171be8'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='06577566-8466-4e43-9715-86436d6e73c9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3ec61f5e4179c2d6f3789caa05d848997a2313c0ab2cba0cb3c9b7bd70cc1d32'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='cb96e8bf-3747-4ee7-b95b-224a16e34e54', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8558ac2f649486edc0a343949cbc4951fc8250e9b19a7b51ffff0509e7ff4977')}, text='. . . . . . . . . . . . . . 51\\nA.4 Additional Details for Safety . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 58\\nA.5 Data Annotation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 72\\nA.6 Dataset Contamination . . . . . . . . . . . . . . . . . . .', start_char_idx=220, end_char_idx=540, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-2', obj=None),\n",
       " 'cb96e8bf-3747-4ee7-b95b-224a16e34e54': IndexNode(id_='cb96e8bf-3747-4ee7-b95b-224a16e34e54', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eb89e1f00847ed009991a8639de4d2b496e56cf8687c03a2599ffb04b1171be8'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='47f25aa5-6d95-4c33-b1c1-835bcb0eff7f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6972c10e76f5f0069c8df0929c8a04fe9d04d316167100782b48ec98d4d33632'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='fccbec05-a1ad-44fb-a7d2-e6883aaa20a3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c637944128c21cac0f445be6329ffa27a7178bfc4f88d474c24e23a0c86db4cc')}, text='. . . . . . . . . . . . . . . . . . . . . . . . . . . 72\\nA.6 Dataset Contamination . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 75\\nA.7 Model Card . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .', start_char_idx=420, end_char_idx=696, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-2', obj=None),\n",
       " 'fccbec05-a1ad-44fb-a7d2-e6883aaa20a3': IndexNode(id_='fccbec05-a1ad-44fb-a7d2-e6883aaa20a3', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eb89e1f00847ed009991a8639de4d2b496e56cf8687c03a2599ffb04b1171be8'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='cb96e8bf-3747-4ee7-b95b-224a16e34e54', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8558ac2f649486edc0a343949cbc4951fc8250e9b19a7b51ffff0509e7ff4977'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='298ccc8c-8b4e-4636-96b2-0ea32e6118b0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3108b30a45d67143a4048238cb42565b6612528960347b3eafe4bf518d40bdfd')}, text='. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77\\n2\\n\\nFigure 1: Helpfulness human evaluation results for Llama\\n2-Chatcomparedtootheropen-sourceandclosed-source\\nmodels. Human raters compared model generations on ~4k\\npromptsconsistingofbothsingleandmulti-turnprompts.\\nThe95%confidenceintervalsforthisevaluationarebetween\\n1%and2%. MoredetailsinSection3.4.2. Whilereviewing\\nthese results, it is important to note that human evaluations\\ncanbenoisyduetolimitationsofthepromptset,subjectivity\\nof the review guidelines, subjectivity of individual raters,\\nand the inherent difficulty of comparing generations.', start_char_idx=605, end_char_idx=1249, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-2', obj=None),\n",
       " '298ccc8c-8b4e-4636-96b2-0ea32e6118b0': IndexNode(id_='298ccc8c-8b4e-4636-96b2-0ea32e6118b0', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eb89e1f00847ed009991a8639de4d2b496e56cf8687c03a2599ffb04b1171be8'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='fccbec05-a1ad-44fb-a7d2-e6883aaa20a3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c637944128c21cac0f445be6329ffa27a7178bfc4f88d474c24e23a0c86db4cc'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='6dfbface-cb89-4243-9bcf-e19c88f89f64', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b0a77b89f2a223fd485f2b8419492608befb29293c31e69d3ba574d0348c8e57')}, text='The95%confidenceintervalsforthisevaluationarebetween\\n1%and2%. MoredetailsinSection3.4.2. Whilereviewing\\nthese results, it is important to note that human evaluations\\ncanbenoisyduetolimitationsofthepromptset,subjectivity\\nof the review guidelines, subjectivity of individual raters,\\nand the inherent difficulty of comparing generations.\\nFigure 2: Win-rate % for helpfulness and\\nsafety between commercial-licensed base-\\nlines and Llama 2-Chat , according to GPT-\\n4. Tocomplementthehumanevaluation,we\\nused a more capable model, not subject to\\nourownguidance. Greenareaindicatesour\\nmodelisbetteraccordingtoGPT-4. Toremove\\nties, we used win/ (win+loss). The orders in\\nwhichthemodelresponsesarepresentedto\\nGPT-4arerandomlyswappedtoalleviatebias.', start_char_idx=915, end_char_idx=1653, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-2', obj=None),\n",
       " '6dfbface-cb89-4243-9bcf-e19c88f89f64': IndexNode(id_='6dfbface-cb89-4243-9bcf-e19c88f89f64', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eb89e1f00847ed009991a8639de4d2b496e56cf8687c03a2599ffb04b1171be8'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='298ccc8c-8b4e-4636-96b2-0ea32e6118b0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3108b30a45d67143a4048238cb42565b6612528960347b3eafe4bf518d40bdfd'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='6f3401bb-9362-4151-9d36-f5654cc71b59', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5eef7d0912ce36cc165976da7296951cd7b8869247bd0fb953d779481925f55b')}, text='Tocomplementthehumanevaluation,we\\nused a more capable model, not subject to\\nourownguidance. Greenareaindicatesour\\nmodelisbetteraccordingtoGPT-4. Toremove\\nties, we used win/ (win+loss). The orders in\\nwhichthemodelresponsesarepresentedto\\nGPT-4arerandomlyswappedtoalleviatebias.\\n1 Introduction\\nLarge Language Models (LLMs) have shown great promise as highly capable AI assistants that excel in\\ncomplex reasoning tasks requiring expert knowledge across a wide range of fields, including in specialized\\ndomains such as programming and creative writing. They enable interaction with humans through intuitive\\nchat interfaces, which has led to rapid and widespread adoption among the general public.\\nThecapabilitiesofLLMsareremarkableconsideringtheseeminglystraightforwardnatureofthetraining\\nmethodology.', start_char_idx=1378, end_char_idx=2174, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-2', obj=None),\n",
       " '6f3401bb-9362-4151-9d36-f5654cc71b59': IndexNode(id_='6f3401bb-9362-4151-9d36-f5654cc71b59', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eb89e1f00847ed009991a8639de4d2b496e56cf8687c03a2599ffb04b1171be8'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='6dfbface-cb89-4243-9bcf-e19c88f89f64', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b0a77b89f2a223fd485f2b8419492608befb29293c31e69d3ba574d0348c8e57')}, text='1 Introduction\\nLarge Language Models (LLMs) have shown great promise as highly capable AI assistants that excel in\\ncomplex reasoning tasks requiring expert knowledge across a wide range of fields, including in specialized\\ndomains such as programming and creative writing. They enable interaction with humans through intuitive\\nchat interfaces, which has led to rapid and widespread adoption among the general public.\\nThecapabilitiesofLLMsareremarkableconsideringtheseeminglystraightforwardnatureofthetraining\\nmethodology. Auto-regressivetransformersarepretrainedonanextensivecorpusofself-superviseddata,\\nfollowed by alignment with human preferences via techniques such as Reinforcement Learning with Human\\nFeedback(RLHF).Althoughthetrainingmethodologyissimple,highcomputationalrequirementshave\\nlimited the development of LLMs to a few players.', start_char_idx=1654, end_char_idx=2496, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-2', obj=None),\n",
       " '088cf129-a305-489a-89f8-2e59dd535974': IndexNode(id_='088cf129-a305-489a-89f8-2e59dd535974', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eb89e1f00847ed009991a8639de4d2b496e56cf8687c03a2599ffb04b1171be8'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='dd501504-04b7-41ef-8c77-349517160e1e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a8ee68920fe1a7f378b3d41e37f350c95806d84d6e6bcc70b1ebb3d3a14c3f11')}, text='. . . . . . . . . . . . . 46\\nA.2 Additional Details for Pretraining . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47\\nA.3 Additional Details for Fine-tuning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51\\nA.4 Additional Details for Safety . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 58\\nA.5 Data Annotation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 72\\nA.6 Dataset Contamination . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 75\\nA.7 Model Card . . . . . . . . . . . . . . . . . . . . . . . .', start_char_idx=0, end_char_idx=650, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-2', obj=None),\n",
       " 'dd501504-04b7-41ef-8c77-349517160e1e': IndexNode(id_='dd501504-04b7-41ef-8c77-349517160e1e', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eb89e1f00847ed009991a8639de4d2b496e56cf8687c03a2599ffb04b1171be8'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='088cf129-a305-489a-89f8-2e59dd535974', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='acc8bb3d2a256097685cabf6b0f004070bc9bc35857ed73ce8ffa4acc651fe4a'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='1a6590f6-7d31-4d2d-b3f5-b573ee2056a3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5eef7d0912ce36cc165976da7296951cd7b8869247bd0fb953d779481925f55b')}, text='. . . . . . . . . . . . . . . . . . . . . . 75\\nA.7 Model Card . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77\\n2\\n\\nFigure 1: Helpfulness human evaluation results for Llama\\n2-Chatcomparedtootheropen-sourceandclosed-source\\nmodels. Human raters compared model generations on ~4k\\npromptsconsistingofbothsingleandmulti-turnprompts.\\nThe95%confidenceintervalsforthisevaluationarebetween\\n1%and2%. MoredetailsinSection3.4.2. Whilereviewing\\nthese results, it is important to note that human evaluations\\ncanbenoisyduetolimitationsofthepromptset,subjectivity\\nof the review guidelines, subjectivity of individual raters,\\nand the inherent difficulty of comparing generations.\\nFigure 2: Win-rate % for helpfulness and\\nsafety between commercial-licensed base-\\nlines and Llama 2-Chat , according to GPT-\\n4. Tocomplementthehumanevaluation,we\\nused a more capable model, not subject to\\nourownguidance. Greenareaindicatesour\\nmodelisbetteraccordingtoGPT-4. Toremove\\nties, we used win/ (win+loss). The orders in\\nwhichthemodelresponsesarepresentedto\\nGPT-4arerandomlyswappedtoalleviatebias.\\n1 Introduction\\nLarge Language Models (LLMs) have shown great promise as highly capable AI assistants that excel in\\ncomplex reasoning tasks requiring expert knowledge across a wide range of fields, including in specialized\\ndomains such as programming and creative writing. They enable interaction with humans through intuitive\\nchat interfaces, which has led to rapid and widespread adoption among the general public.', start_char_idx=541, end_char_idx=2069, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-2', obj=None),\n",
       " '1a6590f6-7d31-4d2d-b3f5-b573ee2056a3': IndexNode(id_='1a6590f6-7d31-4d2d-b3f5-b573ee2056a3', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eb89e1f00847ed009991a8639de4d2b496e56cf8687c03a2599ffb04b1171be8'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='dd501504-04b7-41ef-8c77-349517160e1e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a8ee68920fe1a7f378b3d41e37f350c95806d84d6e6bcc70b1ebb3d3a14c3f11')}, text='1 Introduction\\nLarge Language Models (LLMs) have shown great promise as highly capable AI assistants that excel in\\ncomplex reasoning tasks requiring expert knowledge across a wide range of fields, including in specialized\\ndomains such as programming and creative writing. They enable interaction with humans through intuitive\\nchat interfaces, which has led to rapid and widespread adoption among the general public.\\nThecapabilitiesofLLMsareremarkableconsideringtheseeminglystraightforwardnatureofthetraining\\nmethodology. Auto-regressivetransformersarepretrainedonanextensivecorpusofself-superviseddata,\\nfollowed by alignment with human preferences via techniques such as Reinforcement Learning with Human\\nFeedback(RLHF).Althoughthetrainingmethodologyissimple,highcomputationalrequirementshave\\nlimited the development of LLMs to a few players.', start_char_idx=1654, end_char_idx=2496, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-2', obj=None),\n",
       " 'node-2': IndexNode(id_='node-2', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='d03f19eb-da15-45dc-bfd4-e5d10f161250', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='231b3bd773f012c01b893ada9e009ecf25ee59934614c5a595c9bf1b3a123292'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='2c520432-1b97-4515-a729-04024f24dd1d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='95086467e6f8a00f1673e6edd14216cb53d44381d95cb6b3e73212a5c3bbce79'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='501b609c-d6d5-4dae-ba04-822d9221226e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9c8486fc3c8a457057d6ffd782b49e87d65c4d9f1a0ff8c609135e1fe1a4cc39')}, text='. . . . . . . . . . . . . 46\\nA.2 Additional Details for Pretraining . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47\\nA.3 Additional Details for Fine-tuning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51\\nA.4 Additional Details for Safety . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 58\\nA.5 Data Annotation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 72\\nA.6 Dataset Contamination . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 75\\nA.7 Model Card . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77\\n2\\n\\nFigure 1: Helpfulness human evaluation results for Llama\\n2-Chatcomparedtootheropen-sourceandclosed-source\\nmodels. Human raters compared model generations on ~4k\\npromptsconsistingofbothsingleandmulti-turnprompts.\\nThe95%confidenceintervalsforthisevaluationarebetween\\n1%and2%. MoredetailsinSection3.4.2. Whilereviewing\\nthese results, it is important to note that human evaluations\\ncanbenoisyduetolimitationsofthepromptset,subjectivity\\nof the review guidelines, subjectivity of individual raters,\\nand the inherent difficulty of comparing generations.\\nFigure 2: Win-rate % for helpfulness and\\nsafety between commercial-licensed base-\\nlines and Llama 2-Chat , according to GPT-\\n4. Tocomplementthehumanevaluation,we\\nused a more capable model, not subject to\\nourownguidance. Greenareaindicatesour\\nmodelisbetteraccordingtoGPT-4. Toremove\\nties, we used win/ (win+loss). The orders in\\nwhichthemodelresponsesarepresentedto\\nGPT-4arerandomlyswappedtoalleviatebias.\\n1 Introduction\\nLarge Language Models (LLMs) have shown great promise as highly capable AI assistants that excel in\\ncomplex reasoning tasks requiring expert knowledge across a wide range of fields, including in specialized\\ndomains such as programming and creative writing. They enable interaction with humans through intuitive\\nchat interfaces, which has led to rapid and widespread adoption among the general public.\\nThecapabilitiesofLLMsareremarkableconsideringtheseeminglystraightforwardnatureofthetraining\\nmethodology. Auto-regressivetransformersarepretrainedonanextensivecorpusofself-superviseddata,\\nfollowed by alignment with human preferences via techniques such as Reinforcement Learning with Human\\nFeedback(RLHF).Althoughthetrainingmethodologyissimple,highcomputationalrequirementshave\\nlimited the development of LLMs to a few players.', start_char_idx=3633, end_char_idx=6129, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-2', obj=None),\n",
       " '7f7db3ca-c5d6-4e67-a7c5-2f17d36587da': IndexNode(id_='7f7db3ca-c5d6-4e67-a7c5-2f17d36587da', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9c8486fc3c8a457057d6ffd782b49e87d65c4d9f1a0ff8c609135e1fe1a4cc39'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='b5259160-94d5-4bf4-bb09-3c2e62119cbd', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f8fd005dfc7222468be733b3fb43e5cd9fe11b4bd1106a50e7c3f62f319eb038')}, text='ThecapabilitiesofLLMsareremarkableconsideringtheseeminglystraightforwardnatureofthetraining\\nmethodology. Auto-regressivetransformersarepretrainedonanextensivecorpusofself-superviseddata,\\nfollowed by alignment with human preferences via techniques such as Reinforcement Learning with Human\\nFeedback(RLHF).Althoughthetrainingmethodologyissimple,highcomputationalrequirementshave\\nlimited the development of LLMs to a few players.', start_char_idx=0, end_char_idx=426, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-3', obj=None),\n",
       " 'b5259160-94d5-4bf4-bb09-3c2e62119cbd': IndexNode(id_='b5259160-94d5-4bf4-bb09-3c2e62119cbd', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9c8486fc3c8a457057d6ffd782b49e87d65c4d9f1a0ff8c609135e1fe1a4cc39'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='7f7db3ca-c5d6-4e67-a7c5-2f17d36587da', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3f571126e8cf4cc6f1058349b1b5c4110c950d27b3d8a75365db2433ea176e8f'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='4a935240-554d-496a-a8af-3538b83b5ca0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='06b0082a98cf5bc68807044d14ea1a9f06844bc9fc409dfc61e3b973f701a488')}, text='ThecapabilitiesofLLMsareremarkableconsideringtheseeminglystraightforwardnatureofthetraining\\nmethodology. Auto-regressivetransformersarepretrainedonanextensivecorpusofself-superviseddata,\\nfollowed by alignment with human preferences via techniques such as Reinforcement Learning with Human\\nFeedback(RLHF).Althoughthetrainingmethodologyissimple,highcomputationalrequirementshave\\nlimited the development of LLMs to a few players. There have been public releases of pretrained LLMs\\n(such as BLOOM (Scao et al., 2022), LLaMa-1 (Touvron et al., 2023), and Falcon (Penedo et al., 2023)) that\\nmatch the performance of closed pretrained competitors like GPT-3 (Brown et al., 2020) and Chinchilla\\n(Hoffmann et al., 2022), but none of these models are suitable substitutes for closed “product” LLMs, such\\nasChatGPT,BARD,andClaude.', start_char_idx=0, end_char_idx=819, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-3', obj=None),\n",
       " '4a935240-554d-496a-a8af-3538b83b5ca0': IndexNode(id_='4a935240-554d-496a-a8af-3538b83b5ca0', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9c8486fc3c8a457057d6ffd782b49e87d65c4d9f1a0ff8c609135e1fe1a4cc39'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='b5259160-94d5-4bf4-bb09-3c2e62119cbd', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f8fd005dfc7222468be733b3fb43e5cd9fe11b4bd1106a50e7c3f62f319eb038'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='5d2aea7c-b9be-4575-9bc9-b331eb9354f7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3e3b843bc3bc7f5ba6b4e995f86b42cbb512a7a9e8587eb0d5d82ae3b962cd99')}, text='TheseclosedproductLLMsareheavilyfine-tunedtoalignwithhuman\\npreferences, which greatly enhances their usability and safety. This step can require significant costs in\\ncomputeandhumanannotation,andisoftennottransparentoreasilyreproducible,limitingprogresswithin\\nthe community to advance AI alignment research.\\nIn this work, we develop and release Llama 2, a family of pretrained and fine-tuned LLMs, Llama 2 and\\nLlama 2-Chat , at scales up to 70B parameters.', start_char_idx=820, end_char_idx=1276, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-3', obj=None),\n",
       " '5d2aea7c-b9be-4575-9bc9-b331eb9354f7': IndexNode(id_='5d2aea7c-b9be-4575-9bc9-b331eb9354f7', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9c8486fc3c8a457057d6ffd782b49e87d65c4d9f1a0ff8c609135e1fe1a4cc39'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='4a935240-554d-496a-a8af-3538b83b5ca0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='06b0082a98cf5bc68807044d14ea1a9f06844bc9fc409dfc61e3b973f701a488'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='8ae78b0b-2762-4547-bc81-c389f2721c37', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='70668227d8f1fc2e3b94900ac35233532261a8f7b6ab40ac68472c4823ff987d')}, text='This step can require significant costs in\\ncomputeandhumanannotation,andisoftennottransparentoreasilyreproducible,limitingprogresswithin\\nthe community to advance AI alignment research.\\nIn this work, we develop and release Llama 2, a family of pretrained and fine-tuned LLMs, Llama 2 and\\nLlama 2-Chat , at scales up to 70B parameters. On the series of helpfulness and safety benchmarks we tested,\\nLlama 2-Chat models generally perform better than existing open-source models.', start_char_idx=943, end_char_idx=1417, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-3', obj=None),\n",
       " '8ae78b0b-2762-4547-bc81-c389f2721c37': IndexNode(id_='8ae78b0b-2762-4547-bc81-c389f2721c37', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9c8486fc3c8a457057d6ffd782b49e87d65c4d9f1a0ff8c609135e1fe1a4cc39'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='5d2aea7c-b9be-4575-9bc9-b331eb9354f7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3e3b843bc3bc7f5ba6b4e995f86b42cbb512a7a9e8587eb0d5d82ae3b962cd99'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='ae76c4c1-ccb2-4f49-b59b-f3380595980d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1207e915786a96fa570188f69a1816de32d00a32e41076464896aae464ea3e41')}, text='In this work, we develop and release Llama 2, a family of pretrained and fine-tuned LLMs, Llama 2 and\\nLlama 2-Chat , at scales up to 70B parameters. On the series of helpfulness and safety benchmarks we tested,\\nLlama 2-Chat models generally perform better than existing open-source models. They also appear to\\nbe on par with some of the closed-source models, at least on the human evaluations we performed (see\\nFigures1and3).', start_char_idx=1128, end_char_idx=1553, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-3', obj=None),\n",
       " 'ae76c4c1-ccb2-4f49-b59b-f3380595980d': IndexNode(id_='ae76c4c1-ccb2-4f49-b59b-f3380595980d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9c8486fc3c8a457057d6ffd782b49e87d65c4d9f1a0ff8c609135e1fe1a4cc39'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='8ae78b0b-2762-4547-bc81-c389f2721c37', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='70668227d8f1fc2e3b94900ac35233532261a8f7b6ab40ac68472c4823ff987d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='48a7b062-013a-4ef0-adcb-e2f67191a9e8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='dfe5838fa97c55cae3ea12f5691479292acc7b9e010b077b0d0e2c9f82b747e3')}, text='On the series of helpfulness and safety benchmarks we tested,\\nLlama 2-Chat models generally perform better than existing open-source models. They also appear to\\nbe on par with some of the closed-source models, at least on the human evaluations we performed (see\\nFigures1and3). Wehavetakenmeasurestoincreasethesafetyofthesemodels,usingsafety-specificdata\\nannotation and tuning, as well as conducting red-teaming and employing iterative evaluations.', start_char_idx=1277, end_char_idx=1724, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-3', obj=None),\n",
       " '48a7b062-013a-4ef0-adcb-e2f67191a9e8': IndexNode(id_='48a7b062-013a-4ef0-adcb-e2f67191a9e8', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9c8486fc3c8a457057d6ffd782b49e87d65c4d9f1a0ff8c609135e1fe1a4cc39'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='ae76c4c1-ccb2-4f49-b59b-f3380595980d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1207e915786a96fa570188f69a1816de32d00a32e41076464896aae464ea3e41'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='8c974c54-788c-4f6f-9046-702c16bf628a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b161ee2192c20da044b54659f60660e00e9315040b557517735f9e698e6b8abe')}, text='They also appear to\\nbe on par with some of the closed-source models, at least on the human evaluations we performed (see\\nFigures1and3). Wehavetakenmeasurestoincreasethesafetyofthesemodels,usingsafety-specificdata\\nannotation and tuning, as well as conducting red-teaming and employing iterative evaluations. Additionally,\\nthispapercontributesathoroughdescriptionofourfine-tuningmethodologyandapproachtoimproving\\nLLM safety.', start_char_idx=1418, end_char_idx=1840, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-3', obj=None),\n",
       " '8c974c54-788c-4f6f-9046-702c16bf628a': IndexNode(id_='8c974c54-788c-4f6f-9046-702c16bf628a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9c8486fc3c8a457057d6ffd782b49e87d65c4d9f1a0ff8c609135e1fe1a4cc39'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='48a7b062-013a-4ef0-adcb-e2f67191a9e8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='dfe5838fa97c55cae3ea12f5691479292acc7b9e010b077b0d0e2c9f82b747e3'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='1e2f75c1-807a-45e1-99ef-f35cc7c897c3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='21b324e576592c5ccd2729e133ba3592d6da96447135dd89527c771b07ea900a')}, text='Wehavetakenmeasurestoincreasethesafetyofthesemodels,usingsafety-specificdata\\nannotation and tuning, as well as conducting red-teaming and employing iterative evaluations. Additionally,\\nthispapercontributesathoroughdescriptionofourfine-tuningmethodologyandapproachtoimproving\\nLLM safety. We hope that this openness will enable the community to reproduce fine-tuned LLMs and\\ncontinue to improve the safety of those models, paving the way for more responsible development of LLMs.', start_char_idx=1554, end_char_idx=2031, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-3', obj=None),\n",
       " '1e2f75c1-807a-45e1-99ef-f35cc7c897c3': IndexNode(id_='1e2f75c1-807a-45e1-99ef-f35cc7c897c3', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9c8486fc3c8a457057d6ffd782b49e87d65c4d9f1a0ff8c609135e1fe1a4cc39'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='8c974c54-788c-4f6f-9046-702c16bf628a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b161ee2192c20da044b54659f60660e00e9315040b557517735f9e698e6b8abe'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='ad30271a-bcc7-4228-81c8-21f85ba90ebd', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='31b0036ef568816409efb8e025c8a3672a3a5745a0d7eec56487fc63cce19fbc')}, text='Additionally,\\nthispapercontributesathoroughdescriptionofourfine-tuningmethodologyandapproachtoimproving\\nLLM safety. We hope that this openness will enable the community to reproduce fine-tuned LLMs and\\ncontinue to improve the safety of those models, paving the way for more responsible development of LLMs.\\nWealsosharenovelobservationswemadeduringthedevelopmentof Llama 2 andLlama 2-Chat ,suchas\\nthe emergence of tool usage and temporal organization of knowledge.', start_char_idx=1725, end_char_idx=2188, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-3', obj=None),\n",
       " 'ad30271a-bcc7-4228-81c8-21f85ba90ebd': IndexNode(id_='ad30271a-bcc7-4228-81c8-21f85ba90ebd', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9c8486fc3c8a457057d6ffd782b49e87d65c4d9f1a0ff8c609135e1fe1a4cc39'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='1e2f75c1-807a-45e1-99ef-f35cc7c897c3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='21b324e576592c5ccd2729e133ba3592d6da96447135dd89527c771b07ea900a'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='dd7ab41e-cbdd-48d5-b0fa-816849ca841f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b9d53990e98dc1cf3be9ca3e1a0876aa8ed0fef4822f2e6283127f4ac49e555f')}, text='We hope that this openness will enable the community to reproduce fine-tuned LLMs and\\ncontinue to improve the safety of those models, paving the way for more responsible development of LLMs.\\nWealsosharenovelobservationswemadeduringthedevelopmentof Llama 2 andLlama 2-Chat ,suchas\\nthe emergence of tool usage and temporal organization of knowledge.\\n3\\n\\nFigure 3: Safety human evaluation results for Llama 2-Chat compared to other open-source and closed-\\nsource models.', start_char_idx=1841, end_char_idx=2307, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-3', obj=None),\n",
       " 'dd7ab41e-cbdd-48d5-b0fa-816849ca841f': IndexNode(id_='dd7ab41e-cbdd-48d5-b0fa-816849ca841f', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9c8486fc3c8a457057d6ffd782b49e87d65c4d9f1a0ff8c609135e1fe1a4cc39'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='ad30271a-bcc7-4228-81c8-21f85ba90ebd', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='31b0036ef568816409efb8e025c8a3672a3a5745a0d7eec56487fc63cce19fbc'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='0ed5e768-b617-4fa3-b0e0-65e1e41579a1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5b48c84b4222f7564b54cd0f3ed6abb6dc0604b6accc491cd60703cf4553e1f1')}, text='Wealsosharenovelobservationswemadeduringthedevelopmentof Llama 2 andLlama 2-Chat ,suchas\\nthe emergence of tool usage and temporal organization of knowledge.\\n3\\n\\nFigure 3: Safety human evaluation results for Llama 2-Chat compared to other open-source and closed-\\nsource models. Human raters judged model generations for safety violations across ~2,000 adversarial\\nprompts consisting of both single and multi-turn prompts. More details can be found in Section 4.4.', start_char_idx=2032, end_char_idx=2493, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-3', obj=None),\n",
       " '0ed5e768-b617-4fa3-b0e0-65e1e41579a1': IndexNode(id_='0ed5e768-b617-4fa3-b0e0-65e1e41579a1', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9c8486fc3c8a457057d6ffd782b49e87d65c4d9f1a0ff8c609135e1fe1a4cc39'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='dd7ab41e-cbdd-48d5-b0fa-816849ca841f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b9d53990e98dc1cf3be9ca3e1a0876aa8ed0fef4822f2e6283127f4ac49e555f'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='c5d250db-2353-4e3d-b28e-05d35a0b5cbe', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b3930a1be07cda308844e5572db208f71da7562530cd2867392c75ad00b0c462')}, text='3\\n\\nFigure 3: Safety human evaluation results for Llama 2-Chat compared to other open-source and closed-\\nsource models. Human raters judged model generations for safety violations across ~2,000 adversarial\\nprompts consisting of both single and multi-turn prompts. More details can be found in Section 4.4. It is\\nimportanttocaveatthesesafetyresultswiththeinherentbiasofLLMevaluationsduetolimitationsofthe\\npromptset,subjectivityofthereviewguidelines,andsubjectivityofindividualraters.', start_char_idx=2189, end_char_idx=2670, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-3', obj=None),\n",
       " 'c5d250db-2353-4e3d-b28e-05d35a0b5cbe': IndexNode(id_='c5d250db-2353-4e3d-b28e-05d35a0b5cbe', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9c8486fc3c8a457057d6ffd782b49e87d65c4d9f1a0ff8c609135e1fe1a4cc39'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='0ed5e768-b617-4fa3-b0e0-65e1e41579a1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5b48c84b4222f7564b54cd0f3ed6abb6dc0604b6accc491cd60703cf4553e1f1'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='d9d568ee-0554-4833-8393-05558e22baa6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e4931592c58da47eb4225e249a994615f18fdf20470acf3272434f168e97fc89')}, text='Human raters judged model generations for safety violations across ~2,000 adversarial\\nprompts consisting of both single and multi-turn prompts. More details can be found in Section 4.4. It is\\nimportanttocaveatthesesafetyresultswiththeinherentbiasofLLMevaluationsduetolimitationsofthe\\npromptset,subjectivityofthereviewguidelines,andsubjectivityofindividualraters. Additionally,these\\nsafety evaluations are performed using content standards that are likely to be biased towards the Llama\\n2-Chatmodels.', start_char_idx=2308, end_char_idx=2807, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-3', obj=None),\n",
       " 'd9d568ee-0554-4833-8393-05558e22baa6': IndexNode(id_='d9d568ee-0554-4833-8393-05558e22baa6', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9c8486fc3c8a457057d6ffd782b49e87d65c4d9f1a0ff8c609135e1fe1a4cc39'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='c5d250db-2353-4e3d-b28e-05d35a0b5cbe', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b3930a1be07cda308844e5572db208f71da7562530cd2867392c75ad00b0c462'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='3eeb76a4-27f3-451e-a196-4571ba769ad5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a5cf564773982025d3fdb6b06952079471d5219590088ae32ccc8a0aa281fe7d')}, text='More details can be found in Section 4.4. It is\\nimportanttocaveatthesesafetyresultswiththeinherentbiasofLLMevaluationsduetolimitationsofthe\\npromptset,subjectivityofthereviewguidelines,andsubjectivityofindividualraters. Additionally,these\\nsafety evaluations are performed using content standards that are likely to be biased towards the Llama\\n2-Chatmodels.\\nWe are releasing the following models to the general public for research and commercial use‡:\\n1.Llama 2 ,anupdatedversionof Llama 1,trainedonanewmixofpubliclyavailabledata.', start_char_idx=2452, end_char_idx=2980, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-3', obj=None),\n",
       " '3eeb76a4-27f3-451e-a196-4571ba769ad5': IndexNode(id_='3eeb76a4-27f3-451e-a196-4571ba769ad5', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9c8486fc3c8a457057d6ffd782b49e87d65c4d9f1a0ff8c609135e1fe1a4cc39'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='d9d568ee-0554-4833-8393-05558e22baa6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e4931592c58da47eb4225e249a994615f18fdf20470acf3272434f168e97fc89'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='1041be6e-a6ef-4561-b21f-da31c7f68cfb', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='543aa751f38cb70293e4b0b5282fc293a482eb8faec4b9a74fbd1b88472acf39')}, text='Additionally,these\\nsafety evaluations are performed using content standards that are likely to be biased towards the Llama\\n2-Chatmodels.\\nWe are releasing the following models to the general public for research and commercial use‡:\\n1.Llama 2 ,anupdatedversionof Llama 1,trainedonanewmixofpubliclyavailabledata. Wealso\\nincreasedthesizeofthepretrainingcorpusby40%,doubledthecontextlengthofthemodel,and\\nadoptedgrouped-queryattention(Ainslieetal.,2023).', start_char_idx=2671, end_char_idx=3119, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-3', obj=None),\n",
       " '1041be6e-a6ef-4561-b21f-da31c7f68cfb': IndexNode(id_='1041be6e-a6ef-4561-b21f-da31c7f68cfb', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9c8486fc3c8a457057d6ffd782b49e87d65c4d9f1a0ff8c609135e1fe1a4cc39'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='3eeb76a4-27f3-451e-a196-4571ba769ad5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a5cf564773982025d3fdb6b06952079471d5219590088ae32ccc8a0aa281fe7d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='730a3c8a-d96a-4585-bbc7-3d4dcce299ba', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='dcafbc91c0dc5043c1dd8c868768e2324f87e5f4ed43359fdc67d4b66d01ca4a')}, text='We are releasing the following models to the general public for research and commercial use‡:\\n1.Llama 2 ,anupdatedversionof Llama 1,trainedonanewmixofpubliclyavailabledata. Wealso\\nincreasedthesizeofthepretrainingcorpusby40%,doubledthecontextlengthofthemodel,and\\nadoptedgrouped-queryattention(Ainslieetal.,2023). Wearereleasingvariantsof Llama 2 with\\n7B,13B,and70Bparameters.', start_char_idx=2808, end_char_idx=3182, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-3', obj=None),\n",
       " '730a3c8a-d96a-4585-bbc7-3d4dcce299ba': IndexNode(id_='730a3c8a-d96a-4585-bbc7-3d4dcce299ba', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9c8486fc3c8a457057d6ffd782b49e87d65c4d9f1a0ff8c609135e1fe1a4cc39'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='1041be6e-a6ef-4561-b21f-da31c7f68cfb', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='543aa751f38cb70293e4b0b5282fc293a482eb8faec4b9a74fbd1b88472acf39'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='2831e78d-d905-44ed-b27e-67ccdd6cb45c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d06c9f02c5780fdd8fc7296854f4c39b913ce66513a2762a0ba8452a46751ea3')}, text='Wealso\\nincreasedthesizeofthepretrainingcorpusby40%,doubledthecontextlengthofthemodel,and\\nadoptedgrouped-queryattention(Ainslieetal.,2023). Wearereleasingvariantsof Llama 2 with\\n7B,13B,and70Bparameters. Wehavealsotrained34Bvariants,whichwereportoninthispaper\\nbut are not releasing.§\\n2.Llama 2-Chat , a fine-tuned version of Llama 2 that is optimized for dialogue use cases.', start_char_idx=2981, end_char_idx=3353, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-3', obj=None),\n",
       " '2831e78d-d905-44ed-b27e-67ccdd6cb45c': IndexNode(id_='2831e78d-d905-44ed-b27e-67ccdd6cb45c', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9c8486fc3c8a457057d6ffd782b49e87d65c4d9f1a0ff8c609135e1fe1a4cc39'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='730a3c8a-d96a-4585-bbc7-3d4dcce299ba', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='dcafbc91c0dc5043c1dd8c868768e2324f87e5f4ed43359fdc67d4b66d01ca4a'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='aa53c672-7312-4a37-96a0-7cd818251f7b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='08ded9b9400a8ff5f8e111b384cf9ea10eaf36ec38e0544a467dbbe1fc28c936')}, text='Wearereleasingvariantsof Llama 2 with\\n7B,13B,and70Bparameters. Wehavealsotrained34Bvariants,whichwereportoninthispaper\\nbut are not releasing.§\\n2.Llama 2-Chat , a fine-tuned version of Llama 2 that is optimized for dialogue use cases. We release\\nvariants of this model with 7B, 13B, and 70B parameters as well.\\nWebelievethattheopenreleaseofLLMs,whendonesafely,willbeanetbenefittosociety.', start_char_idx=3120, end_char_idx=3506, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-3', obj=None),\n",
       " 'aa53c672-7312-4a37-96a0-7cd818251f7b': IndexNode(id_='aa53c672-7312-4a37-96a0-7cd818251f7b', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9c8486fc3c8a457057d6ffd782b49e87d65c4d9f1a0ff8c609135e1fe1a4cc39'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='2831e78d-d905-44ed-b27e-67ccdd6cb45c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d06c9f02c5780fdd8fc7296854f4c39b913ce66513a2762a0ba8452a46751ea3'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='f6ea7d69-3d19-4400-ba8f-13325ce6d551', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b6cd50393a80075f83ca6c61aa599501669ba9aa58d640ee8b49706b28feb896')}, text='We release\\nvariants of this model with 7B, 13B, and 70B parameters as well.\\nWebelievethattheopenreleaseofLLMs,whendonesafely,willbeanetbenefittosociety. LikeallLLMs,\\nLlama 2 is a new technology that carries potential risks with use (Bender et al., 2021b; Weidinger et al., 2021;\\nSolaimanet al.,2023). Testingconductedtodate hasbeeninEnglish andhasnot— andcouldnot— cover\\nall scenarios.', start_char_idx=3354, end_char_idx=3739, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-3', obj=None),\n",
       " 'f6ea7d69-3d19-4400-ba8f-13325ce6d551': IndexNode(id_='f6ea7d69-3d19-4400-ba8f-13325ce6d551', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9c8486fc3c8a457057d6ffd782b49e87d65c4d9f1a0ff8c609135e1fe1a4cc39'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='aa53c672-7312-4a37-96a0-7cd818251f7b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='08ded9b9400a8ff5f8e111b384cf9ea10eaf36ec38e0544a467dbbe1fc28c936')}, text='WebelievethattheopenreleaseofLLMs,whendonesafely,willbeanetbenefittosociety. LikeallLLMs,\\nLlama 2 is a new technology that carries potential risks with use (Bender et al., 2021b; Weidinger et al., 2021;\\nSolaimanet al.,2023). Testingconductedtodate hasbeeninEnglish andhasnot— andcouldnot— cover\\nall scenarios. Therefore, before deploying any applications of Llama 2-Chat , developers should perform\\nsafetytestingand tuningtailoredtotheirspecificapplicationsofthemodel.', start_char_idx=3430, end_char_idx=3898, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-3', obj=None),\n",
       " 'a7dae10b-380d-45d6-99d6-4933f05d93e5': IndexNode(id_='a7dae10b-380d-45d6-99d6-4933f05d93e5', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9c8486fc3c8a457057d6ffd782b49e87d65c4d9f1a0ff8c609135e1fe1a4cc39'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='06eae162-31f6-42d3-8835-ef26d442e1ca', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a47d195500f55a5af2efd75ea209b537ae098357e31a6a882c9f41175b320885')}, text='ThecapabilitiesofLLMsareremarkableconsideringtheseeminglystraightforwardnatureofthetraining\\nmethodology. Auto-regressivetransformersarepretrainedonanextensivecorpusofself-superviseddata,\\nfollowed by alignment with human preferences via techniques such as Reinforcement Learning with Human\\nFeedback(RLHF).Althoughthetrainingmethodologyissimple,highcomputationalrequirementshave\\nlimited the development of LLMs to a few players. There have been public releases of pretrained LLMs\\n(such as BLOOM (Scao et al., 2022), LLaMa-1 (Touvron et al., 2023), and Falcon (Penedo et al., 2023)) that\\nmatch the performance of closed pretrained competitors like GPT-3 (Brown et al., 2020) and Chinchilla\\n(Hoffmann et al., 2022), but none of these models are suitable substitutes for closed “product” LLMs, such\\nasChatGPT,BARD,andClaude. TheseclosedproductLLMsareheavilyfine-tunedtoalignwithhuman\\npreferences, which greatly enhances their usability and safety.', start_char_idx=0, end_char_idx=942, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-3', obj=None),\n",
       " '06eae162-31f6-42d3-8835-ef26d442e1ca': IndexNode(id_='06eae162-31f6-42d3-8835-ef26d442e1ca', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9c8486fc3c8a457057d6ffd782b49e87d65c4d9f1a0ff8c609135e1fe1a4cc39'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='a7dae10b-380d-45d6-99d6-4933f05d93e5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4e62308d11f0c0b5b60062ef67a27b81f174ee22dbc2145cd9c5c31a7c64423a'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='9239a8fa-50a8-42fd-835e-3e8e8ac43a5f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a444f51c116eae325c7c5bd8f17a29b40153b116c2d87a31f2f36a463dd37a30')}, text='TheseclosedproductLLMsareheavilyfine-tunedtoalignwithhuman\\npreferences, which greatly enhances their usability and safety. This step can require significant costs in\\ncomputeandhumanannotation,andisoftennottransparentoreasilyreproducible,limitingprogresswithin\\nthe community to advance AI alignment research.\\nIn this work, we develop and release Llama 2, a family of pretrained and fine-tuned LLMs, Llama 2 and\\nLlama 2-Chat , at scales up to 70B parameters. On the series of helpfulness and safety benchmarks we tested,\\nLlama 2-Chat models generally perform better than existing open-source models. They also appear to\\nbe on par with some of the closed-source models, at least on the human evaluations we performed (see\\nFigures1and3). Wehavetakenmeasurestoincreasethesafetyofthesemodels,usingsafety-specificdata\\nannotation and tuning, as well as conducting red-teaming and employing iterative evaluations. Additionally,\\nthispapercontributesathoroughdescriptionofourfine-tuningmethodologyandapproachtoimproving\\nLLM safety.', start_char_idx=820, end_char_idx=1840, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-3', obj=None),\n",
       " '9239a8fa-50a8-42fd-835e-3e8e8ac43a5f': IndexNode(id_='9239a8fa-50a8-42fd-835e-3e8e8ac43a5f', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9c8486fc3c8a457057d6ffd782b49e87d65c4d9f1a0ff8c609135e1fe1a4cc39'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='06eae162-31f6-42d3-8835-ef26d442e1ca', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a47d195500f55a5af2efd75ea209b537ae098357e31a6a882c9f41175b320885'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='9890565b-51f6-48b5-bc43-216cadf961e6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d1c7ae4a3e6c1db37e59cfc399706f8e002a4b17948bee919a61b892ed93439c')}, text='Wehavetakenmeasurestoincreasethesafetyofthesemodels,usingsafety-specificdata\\nannotation and tuning, as well as conducting red-teaming and employing iterative evaluations. Additionally,\\nthispapercontributesathoroughdescriptionofourfine-tuningmethodologyandapproachtoimproving\\nLLM safety. We hope that this openness will enable the community to reproduce fine-tuned LLMs and\\ncontinue to improve the safety of those models, paving the way for more responsible development of LLMs.\\nWealsosharenovelobservationswemadeduringthedevelopmentof Llama 2 andLlama 2-Chat ,suchas\\nthe emergence of tool usage and temporal organization of knowledge.\\n3\\n\\nFigure 3: Safety human evaluation results for Llama 2-Chat compared to other open-source and closed-\\nsource models. Human raters judged model generations for safety violations across ~2,000 adversarial\\nprompts consisting of both single and multi-turn prompts. More details can be found in Section 4.4.', start_char_idx=1554, end_char_idx=2493, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-3', obj=None),\n",
       " '9890565b-51f6-48b5-bc43-216cadf961e6': IndexNode(id_='9890565b-51f6-48b5-bc43-216cadf961e6', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9c8486fc3c8a457057d6ffd782b49e87d65c4d9f1a0ff8c609135e1fe1a4cc39'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='9239a8fa-50a8-42fd-835e-3e8e8ac43a5f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a444f51c116eae325c7c5bd8f17a29b40153b116c2d87a31f2f36a463dd37a30'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='d0166400-eea7-4fe9-a44d-e1b0eda865c9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='fde855e5a8c599d92fe5463ffe0fdc931469f38a7e0c148598d89d4c69514338')}, text='3\\n\\nFigure 3: Safety human evaluation results for Llama 2-Chat compared to other open-source and closed-\\nsource models. Human raters judged model generations for safety violations across ~2,000 adversarial\\nprompts consisting of both single and multi-turn prompts. More details can be found in Section 4.4. It is\\nimportanttocaveatthesesafetyresultswiththeinherentbiasofLLMevaluationsduetolimitationsofthe\\npromptset,subjectivityofthereviewguidelines,andsubjectivityofindividualraters. Additionally,these\\nsafety evaluations are performed using content standards that are likely to be biased towards the Llama\\n2-Chatmodels.\\nWe are releasing the following models to the general public for research and commercial use‡:\\n1.Llama 2 ,anupdatedversionof Llama 1,trainedonanewmixofpubliclyavailabledata. Wealso\\nincreasedthesizeofthepretrainingcorpusby40%,doubledthecontextlengthofthemodel,and\\nadoptedgrouped-queryattention(Ainslieetal.,2023).', start_char_idx=2189, end_char_idx=3119, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-3', obj=None),\n",
       " 'd0166400-eea7-4fe9-a44d-e1b0eda865c9': IndexNode(id_='d0166400-eea7-4fe9-a44d-e1b0eda865c9', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9c8486fc3c8a457057d6ffd782b49e87d65c4d9f1a0ff8c609135e1fe1a4cc39'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='9890565b-51f6-48b5-bc43-216cadf961e6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d1c7ae4a3e6c1db37e59cfc399706f8e002a4b17948bee919a61b892ed93439c'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='93f0eb78-9898-4cd2-9525-2dbf3d9a7a72', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='65e4f724a91062fd2ef09bea86531a2c577d8fd40720c33a5d0cabe9f322e365')}, text='We are releasing the following models to the general public for research and commercial use‡:\\n1.Llama 2 ,anupdatedversionof Llama 1,trainedonanewmixofpubliclyavailabledata. Wealso\\nincreasedthesizeofthepretrainingcorpusby40%,doubledthecontextlengthofthemodel,and\\nadoptedgrouped-queryattention(Ainslieetal.,2023). Wearereleasingvariantsof Llama 2 with\\n7B,13B,and70Bparameters. Wehavealsotrained34Bvariants,whichwereportoninthispaper\\nbut are not releasing.§\\n2.Llama 2-Chat , a fine-tuned version of Llama 2 that is optimized for dialogue use cases. We release\\nvariants of this model with 7B, 13B, and 70B parameters as well.\\nWebelievethattheopenreleaseofLLMs,whendonesafely,willbeanetbenefittosociety.', start_char_idx=2808, end_char_idx=3506, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-3', obj=None),\n",
       " '93f0eb78-9898-4cd2-9525-2dbf3d9a7a72': IndexNode(id_='93f0eb78-9898-4cd2-9525-2dbf3d9a7a72', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9c8486fc3c8a457057d6ffd782b49e87d65c4d9f1a0ff8c609135e1fe1a4cc39'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='d0166400-eea7-4fe9-a44d-e1b0eda865c9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='fde855e5a8c599d92fe5463ffe0fdc931469f38a7e0c148598d89d4c69514338')}, text='We release\\nvariants of this model with 7B, 13B, and 70B parameters as well.\\nWebelievethattheopenreleaseofLLMs,whendonesafely,willbeanetbenefittosociety. LikeallLLMs,\\nLlama 2 is a new technology that carries potential risks with use (Bender et al., 2021b; Weidinger et al., 2021;\\nSolaimanet al.,2023). Testingconductedtodate hasbeeninEnglish andhasnot— andcouldnot— cover\\nall scenarios. Therefore, before deploying any applications of Llama 2-Chat , developers should perform\\nsafetytestingand tuningtailoredtotheirspecificapplicationsofthemodel.', start_char_idx=3354, end_char_idx=3898, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-3', obj=None),\n",
       " '193d58f8-97c4-45a7-a591-c8cc2f61e0dd': IndexNode(id_='193d58f8-97c4-45a7-a591-c8cc2f61e0dd', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9c8486fc3c8a457057d6ffd782b49e87d65c4d9f1a0ff8c609135e1fe1a4cc39'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='dd2788e7-5140-4247-a798-a9744574a397', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f2d912d563621c7640a8c01bbe7e994cafecb965f70676ee357a2b6b51b279f3')}, text='ThecapabilitiesofLLMsareremarkableconsideringtheseeminglystraightforwardnatureofthetraining\\nmethodology. Auto-regressivetransformersarepretrainedonanextensivecorpusofself-superviseddata,\\nfollowed by alignment with human preferences via techniques such as Reinforcement Learning with Human\\nFeedback(RLHF).Althoughthetrainingmethodologyissimple,highcomputationalrequirementshave\\nlimited the development of LLMs to a few players. There have been public releases of pretrained LLMs\\n(such as BLOOM (Scao et al., 2022), LLaMa-1 (Touvron et al., 2023), and Falcon (Penedo et al., 2023)) that\\nmatch the performance of closed pretrained competitors like GPT-3 (Brown et al., 2020) and Chinchilla\\n(Hoffmann et al., 2022), but none of these models are suitable substitutes for closed “product” LLMs, such\\nasChatGPT,BARD,andClaude. TheseclosedproductLLMsareheavilyfine-tunedtoalignwithhuman\\npreferences, which greatly enhances their usability and safety. This step can require significant costs in\\ncomputeandhumanannotation,andisoftennottransparentoreasilyreproducible,limitingprogresswithin\\nthe community to advance AI alignment research.\\nIn this work, we develop and release Llama 2, a family of pretrained and fine-tuned LLMs, Llama 2 and\\nLlama 2-Chat , at scales up to 70B parameters. On the series of helpfulness and safety benchmarks we tested,\\nLlama 2-Chat models generally perform better than existing open-source models. They also appear to\\nbe on par with some of the closed-source models, at least on the human evaluations we performed (see\\nFigures1and3). Wehavetakenmeasurestoincreasethesafetyofthesemodels,usingsafety-specificdata\\nannotation and tuning, as well as conducting red-teaming and employing iterative evaluations. Additionally,\\nthispapercontributesathoroughdescriptionofourfine-tuningmethodologyandapproachtoimproving\\nLLM safety. We hope that this openness will enable the community to reproduce fine-tuned LLMs and\\ncontinue to improve the safety of those models, paving the way for more responsible development of LLMs.', start_char_idx=0, end_char_idx=2031, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-3', obj=None),\n",
       " 'dd2788e7-5140-4247-a798-a9744574a397': IndexNode(id_='dd2788e7-5140-4247-a798-a9744574a397', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9c8486fc3c8a457057d6ffd782b49e87d65c4d9f1a0ff8c609135e1fe1a4cc39'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='193d58f8-97c4-45a7-a591-c8cc2f61e0dd', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f687560c92ff98297191a2b4cd349c93e4d9d97fc6d553132ee6ba017ee4e06b'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='8ef64799-9318-4256-aa6d-b4f843b82347', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='65e4f724a91062fd2ef09bea86531a2c577d8fd40720c33a5d0cabe9f322e365')}, text='Additionally,\\nthispapercontributesathoroughdescriptionofourfine-tuningmethodologyandapproachtoimproving\\nLLM safety. We hope that this openness will enable the community to reproduce fine-tuned LLMs and\\ncontinue to improve the safety of those models, paving the way for more responsible development of LLMs.\\nWealsosharenovelobservationswemadeduringthedevelopmentof Llama 2 andLlama 2-Chat ,suchas\\nthe emergence of tool usage and temporal organization of knowledge.\\n3\\n\\nFigure 3: Safety human evaluation results for Llama 2-Chat compared to other open-source and closed-\\nsource models. Human raters judged model generations for safety violations across ~2,000 adversarial\\nprompts consisting of both single and multi-turn prompts. More details can be found in Section 4.4. It is\\nimportanttocaveatthesesafetyresultswiththeinherentbiasofLLMevaluationsduetolimitationsofthe\\npromptset,subjectivityofthereviewguidelines,andsubjectivityofindividualraters. Additionally,these\\nsafety evaluations are performed using content standards that are likely to be biased towards the Llama\\n2-Chatmodels.\\nWe are releasing the following models to the general public for research and commercial use‡:\\n1.Llama 2 ,anupdatedversionof Llama 1,trainedonanewmixofpubliclyavailabledata. Wealso\\nincreasedthesizeofthepretrainingcorpusby40%,doubledthecontextlengthofthemodel,and\\nadoptedgrouped-queryattention(Ainslieetal.,2023). Wearereleasingvariantsof Llama 2 with\\n7B,13B,and70Bparameters. Wehavealsotrained34Bvariants,whichwereportoninthispaper\\nbut are not releasing.§\\n2.Llama 2-Chat , a fine-tuned version of Llama 2 that is optimized for dialogue use cases. We release\\nvariants of this model with 7B, 13B, and 70B parameters as well.\\nWebelievethattheopenreleaseofLLMs,whendonesafely,willbeanetbenefittosociety.', start_char_idx=1725, end_char_idx=3506, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-3', obj=None),\n",
       " '8ef64799-9318-4256-aa6d-b4f843b82347': IndexNode(id_='8ef64799-9318-4256-aa6d-b4f843b82347', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9c8486fc3c8a457057d6ffd782b49e87d65c4d9f1a0ff8c609135e1fe1a4cc39'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='dd2788e7-5140-4247-a798-a9744574a397', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f2d912d563621c7640a8c01bbe7e994cafecb965f70676ee357a2b6b51b279f3')}, text='We release\\nvariants of this model with 7B, 13B, and 70B parameters as well.\\nWebelievethattheopenreleaseofLLMs,whendonesafely,willbeanetbenefittosociety. LikeallLLMs,\\nLlama 2 is a new technology that carries potential risks with use (Bender et al., 2021b; Weidinger et al., 2021;\\nSolaimanet al.,2023). Testingconductedtodate hasbeeninEnglish andhasnot— andcouldnot— cover\\nall scenarios. Therefore, before deploying any applications of Llama 2-Chat , developers should perform\\nsafetytestingand tuningtailoredtotheirspecificapplicationsofthemodel.', start_char_idx=3354, end_char_idx=3898, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-3', obj=None),\n",
       " 'node-3': IndexNode(id_='node-3', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='d03f19eb-da15-45dc-bfd4-e5d10f161250', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='231b3bd773f012c01b893ada9e009ecf25ee59934614c5a595c9bf1b3a123292'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='e5fa6f99-3015-4b79-90da-a7bae3712a9c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eb89e1f00847ed009991a8639de4d2b496e56cf8687c03a2599ffb04b1171be8'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='036aa5d1-441b-4a4b-b154-37b01a723d6f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='83ec7c3146dd419bd3a5be627bec4d01d4e4fc9fc10aecff1f01545752855972')}, text='ThecapabilitiesofLLMsareremarkableconsideringtheseeminglystraightforwardnatureofthetraining\\nmethodology. Auto-regressivetransformersarepretrainedonanextensivecorpusofself-superviseddata,\\nfollowed by alignment with human preferences via techniques such as Reinforcement Learning with Human\\nFeedback(RLHF).Althoughthetrainingmethodologyissimple,highcomputationalrequirementshave\\nlimited the development of LLMs to a few players. There have been public releases of pretrained LLMs\\n(such as BLOOM (Scao et al., 2022), LLaMa-1 (Touvron et al., 2023), and Falcon (Penedo et al., 2023)) that\\nmatch the performance of closed pretrained competitors like GPT-3 (Brown et al., 2020) and Chinchilla\\n(Hoffmann et al., 2022), but none of these models are suitable substitutes for closed “product” LLMs, such\\nasChatGPT,BARD,andClaude. TheseclosedproductLLMsareheavilyfine-tunedtoalignwithhuman\\npreferences, which greatly enhances their usability and safety. This step can require significant costs in\\ncomputeandhumanannotation,andisoftennottransparentoreasilyreproducible,limitingprogresswithin\\nthe community to advance AI alignment research.\\nIn this work, we develop and release Llama 2, a family of pretrained and fine-tuned LLMs, Llama 2 and\\nLlama 2-Chat , at scales up to 70B parameters. On the series of helpfulness and safety benchmarks we tested,\\nLlama 2-Chat models generally perform better than existing open-source models. They also appear to\\nbe on par with some of the closed-source models, at least on the human evaluations we performed (see\\nFigures1and3). Wehavetakenmeasurestoincreasethesafetyofthesemodels,usingsafety-specificdata\\nannotation and tuning, as well as conducting red-teaming and employing iterative evaluations. Additionally,\\nthispapercontributesathoroughdescriptionofourfine-tuningmethodologyandapproachtoimproving\\nLLM safety. We hope that this openness will enable the community to reproduce fine-tuned LLMs and\\ncontinue to improve the safety of those models, paving the way for more responsible development of LLMs.\\nWealsosharenovelobservationswemadeduringthedevelopmentof Llama 2 andLlama 2-Chat ,suchas\\nthe emergence of tool usage and temporal organization of knowledge.\\n3\\n\\nFigure 3: Safety human evaluation results for Llama 2-Chat compared to other open-source and closed-\\nsource models. Human raters judged model generations for safety violations across ~2,000 adversarial\\nprompts consisting of both single and multi-turn prompts. More details can be found in Section 4.4. It is\\nimportanttocaveatthesesafetyresultswiththeinherentbiasofLLMevaluationsduetolimitationsofthe\\npromptset,subjectivityofthereviewguidelines,andsubjectivityofindividualraters. Additionally,these\\nsafety evaluations are performed using content standards that are likely to be biased towards the Llama\\n2-Chatmodels.\\nWe are releasing the following models to the general public for research and commercial use‡:\\n1.Llama 2 ,anupdatedversionof Llama 1,trainedonanewmixofpubliclyavailabledata. Wealso\\nincreasedthesizeofthepretrainingcorpusby40%,doubledthecontextlengthofthemodel,and\\nadoptedgrouped-queryattention(Ainslieetal.,2023). Wearereleasingvariantsof Llama 2 with\\n7B,13B,and70Bparameters. Wehavealsotrained34Bvariants,whichwereportoninthispaper\\nbut are not releasing.§\\n2.Llama 2-Chat , a fine-tuned version of Llama 2 that is optimized for dialogue use cases. We release\\nvariants of this model with 7B, 13B, and 70B parameters as well.\\nWebelievethattheopenreleaseofLLMs,whendonesafely,willbeanetbenefittosociety. LikeallLLMs,\\nLlama 2 is a new technology that carries potential risks with use (Bender et al., 2021b; Weidinger et al., 2021;\\nSolaimanet al.,2023). Testingconductedtodate hasbeeninEnglish andhasnot— andcouldnot— cover\\nall scenarios. Therefore, before deploying any applications of Llama 2-Chat , developers should perform\\nsafetytestingand tuningtailoredtotheirspecificapplicationsofthemodel.', start_char_idx=5703, end_char_idx=9601, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-3', obj=None),\n",
       " '7735ffe7-1989-4835-b890-6cf1ad678e77': IndexNode(id_='7735ffe7-1989-4835-b890-6cf1ad678e77', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='83ec7c3146dd419bd3a5be627bec4d01d4e4fc9fc10aecff1f01545752855972'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='b5f79e3c-b15a-4dfb-a9b3-7ebf0b05d0f1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9731f2ee2a191373ba7365750ce51b4c4be9855c5123ef5fa4fafb507f1e4e87')}, text='Testingconductedtodate hasbeeninEnglish andhasnot— andcouldnot— cover\\nall scenarios. Therefore, before deploying any applications of Llama 2-Chat , developers should perform\\nsafetytestingand tuningtailoredtotheirspecificapplicationsofthemodel. Weprovidearesponsibleuse\\nguide¶and code examples‖to facilitate the safe deployment of Llama 2 andLlama 2-Chat . More details of\\nour responsible release strategy can be found in Section 5.3.', start_char_idx=0, end_char_idx=433, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-4', obj=None),\n",
       " 'b5f79e3c-b15a-4dfb-a9b3-7ebf0b05d0f1': IndexNode(id_='b5f79e3c-b15a-4dfb-a9b3-7ebf0b05d0f1', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='83ec7c3146dd419bd3a5be627bec4d01d4e4fc9fc10aecff1f01545752855972'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='7735ffe7-1989-4835-b890-6cf1ad678e77', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='901a93c373f080663c59bcebdc737d17af28f11f3e60bc00bdca114070db979f'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='343ff293-e00b-448e-8020-c3446c4954e6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ccf007b461a7defb9a5037a1dbcdd99a5c08b6e9cb8f592915d2575058a73fe7')}, text='Therefore, before deploying any applications of Llama 2-Chat , developers should perform\\nsafetytestingand tuningtailoredtotheirspecificapplicationsofthemodel. Weprovidearesponsibleuse\\nguide¶and code examples‖to facilitate the safe deployment of Llama 2 andLlama 2-Chat . More details of\\nour responsible release strategy can be found in Section 5.3.\\nTheremainderofthispaperdescribesourpretrainingmethodology(Section2),fine-tuningmethodology\\n(Section 3), approach to model safety (Section 4), key observations and insights (Section 5), relevant related\\nwork (Section 6), and conclusions (Section 7).', start_char_idx=85, end_char_idx=682, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-4', obj=None),\n",
       " '343ff293-e00b-448e-8020-c3446c4954e6': IndexNode(id_='343ff293-e00b-448e-8020-c3446c4954e6', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='83ec7c3146dd419bd3a5be627bec4d01d4e4fc9fc10aecff1f01545752855972'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='b5f79e3c-b15a-4dfb-a9b3-7ebf0b05d0f1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9731f2ee2a191373ba7365750ce51b4c4be9855c5123ef5fa4fafb507f1e4e87'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='df9c597a-2ac8-452f-bd7c-9be612a42cd2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='955a3c25be6ae5921b3275e1a8a809b03f97f34f8ae8663ead1456952bb7b7d6')}, text='More details of\\nour responsible release strategy can be found in Section 5.3.\\nTheremainderofthispaperdescribesourpretrainingmethodology(Section2),fine-tuningmethodology\\n(Section 3), approach to model safety (Section 4), key observations and insights (Section 5), relevant related\\nwork (Section 6), and conclusions (Section 7).\\n‡https://ai.meta.com/resources/models-and-libraries/llama/\\n§We are delaying the release of the 34B model due to a lack of time to sufficiently red team.', start_char_idx=356, end_char_idx=835, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-4', obj=None),\n",
       " 'df9c597a-2ac8-452f-bd7c-9be612a42cd2': IndexNode(id_='df9c597a-2ac8-452f-bd7c-9be612a42cd2', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='83ec7c3146dd419bd3a5be627bec4d01d4e4fc9fc10aecff1f01545752855972'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='343ff293-e00b-448e-8020-c3446c4954e6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ccf007b461a7defb9a5037a1dbcdd99a5c08b6e9cb8f592915d2575058a73fe7'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='d7546a83-94ec-4f3c-aefc-b7620057a87a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a0ec4bf2d46d23969a6beac490c266e4d997372f779e0c593132d54981833f33')}, text='‡https://ai.meta.com/resources/models-and-libraries/llama/\\n§We are delaying the release of the 34B model due to a lack of time to sufficiently red team.\\n¶https://ai.meta.com/llama\\n‖https://github.com/facebookresearch/llama\\n4\\n\\nFigure4: Trainingof Llama 2-Chat : Thisprocessbeginswiththe pretraining ofLlama 2 usingpublicly\\navailableonlinesources. Followingthis,wecreateaninitialversionof Llama 2-Chat throughtheapplication\\nofsupervised fine-tuning .', start_char_idx=683, end_char_idx=1131, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-4', obj=None),\n",
       " 'd7546a83-94ec-4f3c-aefc-b7620057a87a': IndexNode(id_='d7546a83-94ec-4f3c-aefc-b7620057a87a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='83ec7c3146dd419bd3a5be627bec4d01d4e4fc9fc10aecff1f01545752855972'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='df9c597a-2ac8-452f-bd7c-9be612a42cd2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='955a3c25be6ae5921b3275e1a8a809b03f97f34f8ae8663ead1456952bb7b7d6'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='e0235493-ce8e-49be-b126-68db3eb8bd39', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='96bfa55dae8776b88b25f279e4d035b338ae0f5e1bf6fba2108fe34e04d7c3bc')}, text='¶https://ai.meta.com/llama\\n‖https://github.com/facebookresearch/llama\\n4\\n\\nFigure4: Trainingof Llama 2-Chat : Thisprocessbeginswiththe pretraining ofLlama 2 usingpublicly\\navailableonlinesources. Followingthis,wecreateaninitialversionof Llama 2-Chat throughtheapplication\\nofsupervised fine-tuning . Subsequently, the model is iteratively refined using Reinforcement Learning\\nwith Human Feedback (RLHF) methodologies, specifically through rejection sampling and Proximal Policy\\nOptimization(PPO).ThroughouttheRLHFstage,theaccumulationof iterativerewardmodelingdata in\\nparallel with model enhancements is crucial to ensure the reward models remain within distribution.', start_char_idx=836, end_char_idx=1499, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-4', obj=None),\n",
       " 'e0235493-ce8e-49be-b126-68db3eb8bd39': IndexNode(id_='e0235493-ce8e-49be-b126-68db3eb8bd39', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='83ec7c3146dd419bd3a5be627bec4d01d4e4fc9fc10aecff1f01545752855972'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='d7546a83-94ec-4f3c-aefc-b7620057a87a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a0ec4bf2d46d23969a6beac490c266e4d997372f779e0c593132d54981833f33'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='85d37d3d-6a73-48e8-a73e-dcc1a69445c7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ed72d52126f44de56d53f2ef8c19f20205718ad06b5e7c15b35390a9db445b5d')}, text='Followingthis,wecreateaninitialversionof Llama 2-Chat throughtheapplication\\nofsupervised fine-tuning . Subsequently, the model is iteratively refined using Reinforcement Learning\\nwith Human Feedback (RLHF) methodologies, specifically through rejection sampling and Proximal Policy\\nOptimization(PPO).ThroughouttheRLHFstage,theaccumulationof iterativerewardmodelingdata in\\nparallel with model enhancements is crucial to ensure the reward models remain within distribution.\\n2 Pretraining\\nTocreatethenewfamilyof Llama 2models,webeganwiththepretrainingapproachdescribedinTouvronetal.', start_char_idx=1029, end_char_idx=1607, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-4', obj=None),\n",
       " '85d37d3d-6a73-48e8-a73e-dcc1a69445c7': IndexNode(id_='85d37d3d-6a73-48e8-a73e-dcc1a69445c7', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='83ec7c3146dd419bd3a5be627bec4d01d4e4fc9fc10aecff1f01545752855972'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='e0235493-ce8e-49be-b126-68db3eb8bd39', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='96bfa55dae8776b88b25f279e4d035b338ae0f5e1bf6fba2108fe34e04d7c3bc'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='7e9dc257-1a28-4405-9aba-8fdf41a1f783', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6df262e9a47442201dc0521ac720738b37526835eb4a8305c407b4dffdee10a5')}, text='2 Pretraining\\nTocreatethenewfamilyof Llama 2models,webeganwiththepretrainingapproachdescribedinTouvronetal.\\n(2023), using an optimized auto-regressive transformer, but made several changes to improve performance.\\nSpecifically,weperformedmorerobustdatacleaning,updatedourdatamixes,trainedon40%moretotal\\ntokens,doubledthecontextlength,andusedgrouped-queryattention(GQA)toimproveinferencescalability\\nfor our larger models.', start_char_idx=1500, end_char_idx=1919, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-4', obj=None),\n",
       " '7e9dc257-1a28-4405-9aba-8fdf41a1f783': IndexNode(id_='7e9dc257-1a28-4405-9aba-8fdf41a1f783', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='83ec7c3146dd419bd3a5be627bec4d01d4e4fc9fc10aecff1f01545752855972'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='85d37d3d-6a73-48e8-a73e-dcc1a69445c7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ed72d52126f44de56d53f2ef8c19f20205718ad06b5e7c15b35390a9db445b5d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='680baa8c-4bef-401d-9780-ade9edc8920f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b3e20c78a39ee4e26163e1d434d8e677034c94f11befe24c8442bdb51ef69c81')}, text='(2023), using an optimized auto-regressive transformer, but made several changes to improve performance.\\nSpecifically,weperformedmorerobustdatacleaning,updatedourdatamixes,trainedon40%moretotal\\ntokens,doubledthecontextlength,andusedgrouped-queryattention(GQA)toimproveinferencescalability\\nfor our larger models. Table 1 compares the attributes of the new Llama 2 models with the Llama 1 models.', start_char_idx=1608, end_char_idx=2002, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-4', obj=None),\n",
       " '680baa8c-4bef-401d-9780-ade9edc8920f': IndexNode(id_='680baa8c-4bef-401d-9780-ade9edc8920f', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='83ec7c3146dd419bd3a5be627bec4d01d4e4fc9fc10aecff1f01545752855972'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='7e9dc257-1a28-4405-9aba-8fdf41a1f783', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6df262e9a47442201dc0521ac720738b37526835eb4a8305c407b4dffdee10a5'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='5ba06b8d-c0cf-4b0a-b639-f99269987e45', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7f91649db9467c39c08d9682fca3055cade879e2e4ddae210ecde73190c66451')}, text='(2023), using an optimized auto-regressive transformer, but made several changes to improve performance.\\nSpecifically,weperformedmorerobustdatacleaning,updatedourdatamixes,trainedon40%moretotal\\ntokens,doubledthecontextlength,andusedgrouped-queryattention(GQA)toimproveinferencescalability\\nfor our larger models. Table 1 compares the attributes of the new Llama 2 models with the Llama 1 models.\\n2.1 Pretraining Data\\nOur training corpus includes a new mix of data from publicly available sources, which does not include data\\nfromMeta’sproductsorservices.', start_char_idx=1608, end_char_idx=2161, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-4', obj=None),\n",
       " '5ba06b8d-c0cf-4b0a-b639-f99269987e45': IndexNode(id_='5ba06b8d-c0cf-4b0a-b639-f99269987e45', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='83ec7c3146dd419bd3a5be627bec4d01d4e4fc9fc10aecff1f01545752855972'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='680baa8c-4bef-401d-9780-ade9edc8920f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b3e20c78a39ee4e26163e1d434d8e677034c94f11befe24c8442bdb51ef69c81'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='6b574509-5d47-477b-8347-31fd3f2885d1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bf0fa29d54dff435a3febb031bf7d587d8a4706f69d0072845fcbbc5f8b4f47c')}, text='Table 1 compares the attributes of the new Llama 2 models with the Llama 1 models.\\n2.1 Pretraining Data\\nOur training corpus includes a new mix of data from publicly available sources, which does not include data\\nfromMeta’sproductsorservices. Wemadeanefforttoremovedatafromcertainsitesknowntocontaina\\nhighvolumeofpersonalinformationaboutprivateindividuals.', start_char_idx=1920, end_char_idx=2275, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-4', obj=None),\n",
       " '6b574509-5d47-477b-8347-31fd3f2885d1': IndexNode(id_='6b574509-5d47-477b-8347-31fd3f2885d1', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='83ec7c3146dd419bd3a5be627bec4d01d4e4fc9fc10aecff1f01545752855972'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='5ba06b8d-c0cf-4b0a-b639-f99269987e45', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7f91649db9467c39c08d9682fca3055cade879e2e4ddae210ecde73190c66451'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='b7543763-e3ba-47ba-9ad7-4f514aa04b68', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='92b08452788e0b33088984011f9a779cb690751fc113aaa05cf5a0f30cd62731')}, text='Table 1 compares the attributes of the new Llama 2 models with the Llama 1 models.\\n2.1 Pretraining Data\\nOur training corpus includes a new mix of data from publicly available sources, which does not include data\\nfromMeta’sproductsorservices. Wemadeanefforttoremovedatafromcertainsitesknowntocontaina\\nhighvolumeofpersonalinformationaboutprivateindividuals. Wetrainedon2trilliontokensofdataasthis\\nprovidesagoodperformance–costtrade-off,up-samplingthemostfactualsourcesinanefforttoincrease\\nknowledge and dampen hallucinations.', start_char_idx=1920, end_char_idx=2443, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-4', obj=None),\n",
       " 'b7543763-e3ba-47ba-9ad7-4f514aa04b68': IndexNode(id_='b7543763-e3ba-47ba-9ad7-4f514aa04b68', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='83ec7c3146dd419bd3a5be627bec4d01d4e4fc9fc10aecff1f01545752855972'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='6b574509-5d47-477b-8347-31fd3f2885d1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bf0fa29d54dff435a3febb031bf7d587d8a4706f69d0072845fcbbc5f8b4f47c'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='89dfe8df-fb7a-4eda-98a3-e870876df3a5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='398116bb220b47359310d5a5a8e56b09afbc59515b21b3c0dde14e13336e3362')}, text='Wemadeanefforttoremovedatafromcertainsitesknowntocontaina\\nhighvolumeofpersonalinformationaboutprivateindividuals. Wetrainedon2trilliontokensofdataasthis\\nprovidesagoodperformance–costtrade-off,up-samplingthemostfactualsourcesinanefforttoincrease\\nknowledge and dampen hallucinations.\\nWeperformedavarietyofpretrainingdatainvestigationssothatuserscanbetterunderstandthepotential\\ncapabilities and limitations of our models; results can be found in Section 4.1.', start_char_idx=2162, end_char_idx=2617, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-4', obj=None),\n",
       " '89dfe8df-fb7a-4eda-98a3-e870876df3a5': IndexNode(id_='89dfe8df-fb7a-4eda-98a3-e870876df3a5', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='83ec7c3146dd419bd3a5be627bec4d01d4e4fc9fc10aecff1f01545752855972'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='b7543763-e3ba-47ba-9ad7-4f514aa04b68', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='92b08452788e0b33088984011f9a779cb690751fc113aaa05cf5a0f30cd62731'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='604b75a7-bba1-41a6-97d5-08080bde8e7c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='121d41aae97bac1356acf75aa8a8c35bac3bbafe94a180cc9f328fc8ebc9033d')}, text='Wetrainedon2trilliontokensofdataasthis\\nprovidesagoodperformance–costtrade-off,up-samplingthemostfactualsourcesinanefforttoincrease\\nknowledge and dampen hallucinations.\\nWeperformedavarietyofpretrainingdatainvestigationssothatuserscanbetterunderstandthepotential\\ncapabilities and limitations of our models; results can be found in Section 4.1.\\n2.2 Training Details\\nWe adopt most of the pretraining setting and model architecture from Llama 1 .', start_char_idx=2276, end_char_idx=2717, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-4', obj=None),\n",
       " '604b75a7-bba1-41a6-97d5-08080bde8e7c': IndexNode(id_='604b75a7-bba1-41a6-97d5-08080bde8e7c', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='83ec7c3146dd419bd3a5be627bec4d01d4e4fc9fc10aecff1f01545752855972'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='89dfe8df-fb7a-4eda-98a3-e870876df3a5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='398116bb220b47359310d5a5a8e56b09afbc59515b21b3c0dde14e13336e3362'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='73b97969-2f13-4050-9d45-5294a4d3eb90', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='94d3d9bc4f88754575534ffe1e5c1ad1dc2151d00ec3ade7aab2d86ef20c8b4f')}, text='Weperformedavarietyofpretrainingdatainvestigationssothatuserscanbetterunderstandthepotential\\ncapabilities and limitations of our models; results can be found in Section 4.1.\\n2.2 Training Details\\nWe adopt most of the pretraining setting and model architecture from Llama 1 . We use the standard\\ntransformer architecture (Vaswani et al., 2017), apply pre-normalization using RMSNorm (Zhang and\\nSennrich, 2019), use the SwiGLU activation function (Shazeer, 2020), and rotary positional embeddings\\n(RoPE, Su et al.', start_char_idx=2444, end_char_idx=2954, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-4', obj=None),\n",
       " '73b97969-2f13-4050-9d45-5294a4d3eb90': IndexNode(id_='73b97969-2f13-4050-9d45-5294a4d3eb90', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='83ec7c3146dd419bd3a5be627bec4d01d4e4fc9fc10aecff1f01545752855972'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='604b75a7-bba1-41a6-97d5-08080bde8e7c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='121d41aae97bac1356acf75aa8a8c35bac3bbafe94a180cc9f328fc8ebc9033d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='a1e6f105-d6a3-4608-bded-2ac98cebd5e4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d71fcb8cc1e2b8a9fdbaa3d5fb04afa9776fa98b1f0f9151b4d36800d06040e1')}, text='2.2 Training Details\\nWe adopt most of the pretraining setting and model architecture from Llama 1 . We use the standard\\ntransformer architecture (Vaswani et al., 2017), apply pre-normalization using RMSNorm (Zhang and\\nSennrich, 2019), use the SwiGLU activation function (Shazeer, 2020), and rotary positional embeddings\\n(RoPE, Su et al. 2022).', start_char_idx=2618, end_char_idx=2961, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-4', obj=None),\n",
       " 'a1e6f105-d6a3-4608-bded-2ac98cebd5e4': IndexNode(id_='a1e6f105-d6a3-4608-bded-2ac98cebd5e4', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='83ec7c3146dd419bd3a5be627bec4d01d4e4fc9fc10aecff1f01545752855972'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='73b97969-2f13-4050-9d45-5294a4d3eb90', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='94d3d9bc4f88754575534ffe1e5c1ad1dc2151d00ec3ade7aab2d86ef20c8b4f'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='41390974-5290-4b91-9a95-4194468340ac', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='84519e2d2c1f14a073630b131580ce3c76713efae6b62147b8b5a3e9af94365d')}, text='2.2 Training Details\\nWe adopt most of the pretraining setting and model architecture from Llama 1 . We use the standard\\ntransformer architecture (Vaswani et al., 2017), apply pre-normalization using RMSNorm (Zhang and\\nSennrich, 2019), use the SwiGLU activation function (Shazeer, 2020), and rotary positional embeddings\\n(RoPE, Su et al. 2022). The primary architectural differences from Llama 1 include increased context length\\nandgrouped-queryattention(GQA).WedetailinAppendixSectionA.2.1eachofthesedifferenceswith\\nablation experiments to demonstrate their importance.', start_char_idx=2618, end_char_idx=3187, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-4', obj=None),\n",
       " '41390974-5290-4b91-9a95-4194468340ac': IndexNode(id_='41390974-5290-4b91-9a95-4194468340ac', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='83ec7c3146dd419bd3a5be627bec4d01d4e4fc9fc10aecff1f01545752855972'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='a1e6f105-d6a3-4608-bded-2ac98cebd5e4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d71fcb8cc1e2b8a9fdbaa3d5fb04afa9776fa98b1f0f9151b4d36800d06040e1'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='66b481cd-1e93-4365-bb0e-6835f8c52442', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7d63b72de0a3c1c560ea8ffc6f439c57d3f2beedc39b9073d43ade59e703fe8d')}, text='2022). The primary architectural differences from Llama 1 include increased context length\\nandgrouped-queryattention(GQA).WedetailinAppendixSectionA.2.1eachofthesedifferenceswith\\nablation experiments to demonstrate their importance.\\nHyperparameters. We trained using the AdamW optimizer (Loshchilov and Hutter, 2017), with β1=\\n0.9, β2= 0.95,eps= 10−5.', start_char_idx=2955, end_char_idx=3306, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-4', obj=None),\n",
       " '66b481cd-1e93-4365-bb0e-6835f8c52442': IndexNode(id_='66b481cd-1e93-4365-bb0e-6835f8c52442', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='83ec7c3146dd419bd3a5be627bec4d01d4e4fc9fc10aecff1f01545752855972'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='41390974-5290-4b91-9a95-4194468340ac', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='84519e2d2c1f14a073630b131580ce3c76713efae6b62147b8b5a3e9af94365d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='f81c99d4-152e-4937-bc8d-0afff9072927', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2fc2b8f3dc0657d1e82e46680a1e8751eac72cefd203b662f28410a9320e89c6')}, text='The primary architectural differences from Llama 1 include increased context length\\nandgrouped-queryattention(GQA).WedetailinAppendixSectionA.2.1eachofthesedifferenceswith\\nablation experiments to demonstrate their importance.\\nHyperparameters. We trained using the AdamW optimizer (Loshchilov and Hutter, 2017), with β1=\\n0.9, β2= 0.95,eps= 10−5. We use a cosine learning rate schedule, with warmup of 2000 steps, and decay\\nfinallearningratedownto10%ofthepeaklearningrate.', start_char_idx=2962, end_char_idx=3432, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-4', obj=None),\n",
       " 'f81c99d4-152e-4937-bc8d-0afff9072927': IndexNode(id_='f81c99d4-152e-4937-bc8d-0afff9072927', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='83ec7c3146dd419bd3a5be627bec4d01d4e4fc9fc10aecff1f01545752855972'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='66b481cd-1e93-4365-bb0e-6835f8c52442', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7d63b72de0a3c1c560ea8ffc6f439c57d3f2beedc39b9073d43ade59e703fe8d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='21989b0f-baf4-4188-b256-6608e97fcec7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e9c08d7e550836a9d821b0521f6d025b7cc4138f4881a6f7196bdff24049524e')}, text='Hyperparameters. We trained using the AdamW optimizer (Loshchilov and Hutter, 2017), with β1=\\n0.9, β2= 0.95,eps= 10−5. We use a cosine learning rate schedule, with warmup of 2000 steps, and decay\\nfinallearningratedownto10%ofthepeaklearningrate. Weuseaweightdecayof 0.1andgradientclipping\\nof1.0. Figure 5 (a) shows the training loss for Llama 2 with these hyperparameters.', start_char_idx=3188, end_char_idx=3559, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-4', obj=None),\n",
       " '21989b0f-baf4-4188-b256-6608e97fcec7': IndexNode(id_='21989b0f-baf4-4188-b256-6608e97fcec7', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='83ec7c3146dd419bd3a5be627bec4d01d4e4fc9fc10aecff1f01545752855972'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='f81c99d4-152e-4937-bc8d-0afff9072927', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2fc2b8f3dc0657d1e82e46680a1e8751eac72cefd203b662f28410a9320e89c6')}, text='We use a cosine learning rate schedule, with warmup of 2000 steps, and decay\\nfinallearningratedownto10%ofthepeaklearningrate. Weuseaweightdecayof 0.1andgradientclipping\\nof1.0. Figure 5 (a) shows the training loss for Llama 2 with these hyperparameters.\\n5\\n\\nTraining Data Params Context\\nLengthGQA Tokens LR\\nLlama 1See Touvron et al.', start_char_idx=3307, end_char_idx=3637, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-4', obj=None),\n",
       " 'd001e901-b277-4d03-9dd8-c61ab632174f': IndexNode(id_='d001e901-b277-4d03-9dd8-c61ab632174f', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='83ec7c3146dd419bd3a5be627bec4d01d4e4fc9fc10aecff1f01545752855972'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='575bdf1d-8080-4fae-b7ce-dae93229fd95', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='dc4c1181801c3d1d5fb372d905b73a60cb2ab18a8784b4d4bc09bced7f3034d2')}, text='Testingconductedtodate hasbeeninEnglish andhasnot— andcouldnot— cover\\nall scenarios. Therefore, before deploying any applications of Llama 2-Chat , developers should perform\\nsafetytestingand tuningtailoredtotheirspecificapplicationsofthemodel. Weprovidearesponsibleuse\\nguide¶and code examples‖to facilitate the safe deployment of Llama 2 andLlama 2-Chat . More details of\\nour responsible release strategy can be found in Section 5.3.\\nTheremainderofthispaperdescribesourpretrainingmethodology(Section2),fine-tuningmethodology\\n(Section 3), approach to model safety (Section 4), key observations and insights (Section 5), relevant related\\nwork (Section 6), and conclusions (Section 7).\\n‡https://ai.meta.com/resources/models-and-libraries/llama/\\n§We are delaying the release of the 34B model due to a lack of time to sufficiently red team.', start_char_idx=0, end_char_idx=835, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-4', obj=None),\n",
       " '575bdf1d-8080-4fae-b7ce-dae93229fd95': IndexNode(id_='575bdf1d-8080-4fae-b7ce-dae93229fd95', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='83ec7c3146dd419bd3a5be627bec4d01d4e4fc9fc10aecff1f01545752855972'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='d001e901-b277-4d03-9dd8-c61ab632174f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3a385dd7a80509b62b97e9e2fe9ae229e71065b8bd915282be1e383337547692'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='d8c41098-1d3d-4054-a5e4-3359d349a4a5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5626436e0a7aad4559cfb5a8c3fbe26eb22c4c06fe9f511e6d4559ea3e12c877')}, text='‡https://ai.meta.com/resources/models-and-libraries/llama/\\n§We are delaying the release of the 34B model due to a lack of time to sufficiently red team.\\n¶https://ai.meta.com/llama\\n‖https://github.com/facebookresearch/llama\\n4\\n\\nFigure4: Trainingof Llama 2-Chat : Thisprocessbeginswiththe pretraining ofLlama 2 usingpublicly\\navailableonlinesources. Followingthis,wecreateaninitialversionof Llama 2-Chat throughtheapplication\\nofsupervised fine-tuning . Subsequently, the model is iteratively refined using Reinforcement Learning\\nwith Human Feedback (RLHF) methodologies, specifically through rejection sampling and Proximal Policy\\nOptimization(PPO).ThroughouttheRLHFstage,theaccumulationof iterativerewardmodelingdata in\\nparallel with model enhancements is crucial to ensure the reward models remain within distribution.\\n2 Pretraining\\nTocreatethenewfamilyof Llama 2models,webeganwiththepretrainingapproachdescribedinTouvronetal.\\n(2023), using an optimized auto-regressive transformer, but made several changes to improve performance.', start_char_idx=683, end_char_idx=1712, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-4', obj=None),\n",
       " 'd8c41098-1d3d-4054-a5e4-3359d349a4a5': IndexNode(id_='d8c41098-1d3d-4054-a5e4-3359d349a4a5', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='83ec7c3146dd419bd3a5be627bec4d01d4e4fc9fc10aecff1f01545752855972'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='575bdf1d-8080-4fae-b7ce-dae93229fd95', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='dc4c1181801c3d1d5fb372d905b73a60cb2ab18a8784b4d4bc09bced7f3034d2'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='e533d7bd-20d5-42b6-ab8a-c2af5183960d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='db635045fa629f4fa0c31576fedf78647652ab54203b2302019b82481c61bdf2')}, text='2 Pretraining\\nTocreatethenewfamilyof Llama 2models,webeganwiththepretrainingapproachdescribedinTouvronetal.\\n(2023), using an optimized auto-regressive transformer, but made several changes to improve performance.\\nSpecifically,weperformedmorerobustdatacleaning,updatedourdatamixes,trainedon40%moretotal\\ntokens,doubledthecontextlength,andusedgrouped-queryattention(GQA)toimproveinferencescalability\\nfor our larger models. Table 1 compares the attributes of the new Llama 2 models with the Llama 1 models.\\n2.1 Pretraining Data\\nOur training corpus includes a new mix of data from publicly available sources, which does not include data\\nfromMeta’sproductsorservices. Wemadeanefforttoremovedatafromcertainsitesknowntocontaina\\nhighvolumeofpersonalinformationaboutprivateindividuals. Wetrainedon2trilliontokensofdataasthis\\nprovidesagoodperformance–costtrade-off,up-samplingthemostfactualsourcesinanefforttoincrease\\nknowledge and dampen hallucinations.', start_char_idx=1500, end_char_idx=2443, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-4', obj=None),\n",
       " 'e533d7bd-20d5-42b6-ab8a-c2af5183960d': IndexNode(id_='e533d7bd-20d5-42b6-ab8a-c2af5183960d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='83ec7c3146dd419bd3a5be627bec4d01d4e4fc9fc10aecff1f01545752855972'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='d8c41098-1d3d-4054-a5e4-3359d349a4a5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5626436e0a7aad4559cfb5a8c3fbe26eb22c4c06fe9f511e6d4559ea3e12c877'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='702ee45b-390a-4be7-866c-6925d820f76d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='18a082b56f6f5af8f2dd6b16b3d73ce828122018f2e2e71036e1066d01a3a494')}, text='Wemadeanefforttoremovedatafromcertainsitesknowntocontaina\\nhighvolumeofpersonalinformationaboutprivateindividuals. Wetrainedon2trilliontokensofdataasthis\\nprovidesagoodperformance–costtrade-off,up-samplingthemostfactualsourcesinanefforttoincrease\\nknowledge and dampen hallucinations.\\nWeperformedavarietyofpretrainingdatainvestigationssothatuserscanbetterunderstandthepotential\\ncapabilities and limitations of our models; results can be found in Section 4.1.\\n2.2 Training Details\\nWe adopt most of the pretraining setting and model architecture from Llama 1 . We use the standard\\ntransformer architecture (Vaswani et al., 2017), apply pre-normalization using RMSNorm (Zhang and\\nSennrich, 2019), use the SwiGLU activation function (Shazeer, 2020), and rotary positional embeddings\\n(RoPE, Su et al. 2022).', start_char_idx=2162, end_char_idx=2961, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-4', obj=None),\n",
       " '702ee45b-390a-4be7-866c-6925d820f76d': IndexNode(id_='702ee45b-390a-4be7-866c-6925d820f76d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='83ec7c3146dd419bd3a5be627bec4d01d4e4fc9fc10aecff1f01545752855972'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='e533d7bd-20d5-42b6-ab8a-c2af5183960d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='db635045fa629f4fa0c31576fedf78647652ab54203b2302019b82481c61bdf2'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='a08e9299-13b1-4e5c-885b-1f25b368b7eb', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d1098f56911af5787cadfd52a5873ee8ab4dd81c94a7a0c719f4d12e43f6ef64')}, text='2.2 Training Details\\nWe adopt most of the pretraining setting and model architecture from Llama 1 . We use the standard\\ntransformer architecture (Vaswani et al., 2017), apply pre-normalization using RMSNorm (Zhang and\\nSennrich, 2019), use the SwiGLU activation function (Shazeer, 2020), and rotary positional embeddings\\n(RoPE, Su et al. 2022). The primary architectural differences from Llama 1 include increased context length\\nandgrouped-queryattention(GQA).WedetailinAppendixSectionA.2.1eachofthesedifferenceswith\\nablation experiments to demonstrate their importance.\\nHyperparameters. We trained using the AdamW optimizer (Loshchilov and Hutter, 2017), with β1=\\n0.9, β2= 0.95,eps= 10−5. We use a cosine learning rate schedule, with warmup of 2000 steps, and decay\\nfinallearningratedownto10%ofthepeaklearningrate. Weuseaweightdecayof 0.1andgradientclipping\\nof1.0.', start_char_idx=2618, end_char_idx=3482, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-4', obj=None),\n",
       " 'a08e9299-13b1-4e5c-885b-1f25b368b7eb': IndexNode(id_='a08e9299-13b1-4e5c-885b-1f25b368b7eb', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='83ec7c3146dd419bd3a5be627bec4d01d4e4fc9fc10aecff1f01545752855972'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='702ee45b-390a-4be7-866c-6925d820f76d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='18a082b56f6f5af8f2dd6b16b3d73ce828122018f2e2e71036e1066d01a3a494')}, text='We trained using the AdamW optimizer (Loshchilov and Hutter, 2017), with β1=\\n0.9, β2= 0.95,eps= 10−5. We use a cosine learning rate schedule, with warmup of 2000 steps, and decay\\nfinallearningratedownto10%ofthepeaklearningrate. Weuseaweightdecayof 0.1andgradientclipping\\nof1.0. Figure 5 (a) shows the training loss for Llama 2 with these hyperparameters.\\n5\\n\\nTraining Data Params Context\\nLengthGQA Tokens LR\\nLlama 1See Touvron et al.', start_char_idx=3205, end_char_idx=3637, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-4', obj=None),\n",
       " '25ab8502-6fd5-45b3-b218-135cf869e710': IndexNode(id_='25ab8502-6fd5-45b3-b218-135cf869e710', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='83ec7c3146dd419bd3a5be627bec4d01d4e4fc9fc10aecff1f01545752855972'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='62d3317f-955a-4bae-aa8d-4c3ebf00741c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9b8f70d8e23718a35f2964730971992b49c0181d199f3871af104af787cd1af5')}, text='Testingconductedtodate hasbeeninEnglish andhasnot— andcouldnot— cover\\nall scenarios. Therefore, before deploying any applications of Llama 2-Chat , developers should perform\\nsafetytestingand tuningtailoredtotheirspecificapplicationsofthemodel. Weprovidearesponsibleuse\\nguide¶and code examples‖to facilitate the safe deployment of Llama 2 andLlama 2-Chat . More details of\\nour responsible release strategy can be found in Section 5.3.\\nTheremainderofthispaperdescribesourpretrainingmethodology(Section2),fine-tuningmethodology\\n(Section 3), approach to model safety (Section 4), key observations and insights (Section 5), relevant related\\nwork (Section 6), and conclusions (Section 7).\\n‡https://ai.meta.com/resources/models-and-libraries/llama/\\n§We are delaying the release of the 34B model due to a lack of time to sufficiently red team.\\n¶https://ai.meta.com/llama\\n‖https://github.com/facebookresearch/llama\\n4\\n\\nFigure4: Trainingof Llama 2-Chat : Thisprocessbeginswiththe pretraining ofLlama 2 usingpublicly\\navailableonlinesources. Followingthis,wecreateaninitialversionof Llama 2-Chat throughtheapplication\\nofsupervised fine-tuning . Subsequently, the model is iteratively refined using Reinforcement Learning\\nwith Human Feedback (RLHF) methodologies, specifically through rejection sampling and Proximal Policy\\nOptimization(PPO).ThroughouttheRLHFstage,theaccumulationof iterativerewardmodelingdata in\\nparallel with model enhancements is crucial to ensure the reward models remain within distribution.\\n2 Pretraining\\nTocreatethenewfamilyof Llama 2models,webeganwiththepretrainingapproachdescribedinTouvronetal.\\n(2023), using an optimized auto-regressive transformer, but made several changes to improve performance.\\nSpecifically,weperformedmorerobustdatacleaning,updatedourdatamixes,trainedon40%moretotal\\ntokens,doubledthecontextlength,andusedgrouped-queryattention(GQA)toimproveinferencescalability\\nfor our larger models. Table 1 compares the attributes of the new Llama 2 models with the Llama 1 models.', start_char_idx=0, end_char_idx=2002, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-4', obj=None),\n",
       " '62d3317f-955a-4bae-aa8d-4c3ebf00741c': IndexNode(id_='62d3317f-955a-4bae-aa8d-4c3ebf00741c', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='83ec7c3146dd419bd3a5be627bec4d01d4e4fc9fc10aecff1f01545752855972'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='25ab8502-6fd5-45b3-b218-135cf869e710', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='dfd4db8ef68b661e13a6b705f2ad512b38ebba0d92a276b728f443003b06714a'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='ccee4a35-cedc-427f-a3f9-cd0129b2b104', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d1098f56911af5787cadfd52a5873ee8ab4dd81c94a7a0c719f4d12e43f6ef64')}, text='(2023), using an optimized auto-regressive transformer, but made several changes to improve performance.\\nSpecifically,weperformedmorerobustdatacleaning,updatedourdatamixes,trainedon40%moretotal\\ntokens,doubledthecontextlength,andusedgrouped-queryattention(GQA)toimproveinferencescalability\\nfor our larger models. Table 1 compares the attributes of the new Llama 2 models with the Llama 1 models.\\n2.1 Pretraining Data\\nOur training corpus includes a new mix of data from publicly available sources, which does not include data\\nfromMeta’sproductsorservices. Wemadeanefforttoremovedatafromcertainsitesknowntocontaina\\nhighvolumeofpersonalinformationaboutprivateindividuals. Wetrainedon2trilliontokensofdataasthis\\nprovidesagoodperformance–costtrade-off,up-samplingthemostfactualsourcesinanefforttoincrease\\nknowledge and dampen hallucinations.\\nWeperformedavarietyofpretrainingdatainvestigationssothatuserscanbetterunderstandthepotential\\ncapabilities and limitations of our models; results can be found in Section 4.1.\\n2.2 Training Details\\nWe adopt most of the pretraining setting and model architecture from Llama 1 . We use the standard\\ntransformer architecture (Vaswani et al., 2017), apply pre-normalization using RMSNorm (Zhang and\\nSennrich, 2019), use the SwiGLU activation function (Shazeer, 2020), and rotary positional embeddings\\n(RoPE, Su et al. 2022). The primary architectural differences from Llama 1 include increased context length\\nandgrouped-queryattention(GQA).WedetailinAppendixSectionA.2.1eachofthesedifferenceswith\\nablation experiments to demonstrate their importance.\\nHyperparameters. We trained using the AdamW optimizer (Loshchilov and Hutter, 2017), with β1=\\n0.9, β2= 0.95,eps= 10−5. We use a cosine learning rate schedule, with warmup of 2000 steps, and decay\\nfinallearningratedownto10%ofthepeaklearningrate. Weuseaweightdecayof 0.1andgradientclipping\\nof1.0.', start_char_idx=1608, end_char_idx=3482, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-4', obj=None),\n",
       " 'ccee4a35-cedc-427f-a3f9-cd0129b2b104': IndexNode(id_='ccee4a35-cedc-427f-a3f9-cd0129b2b104', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='83ec7c3146dd419bd3a5be627bec4d01d4e4fc9fc10aecff1f01545752855972'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='62d3317f-955a-4bae-aa8d-4c3ebf00741c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9b8f70d8e23718a35f2964730971992b49c0181d199f3871af104af787cd1af5')}, text='We trained using the AdamW optimizer (Loshchilov and Hutter, 2017), with β1=\\n0.9, β2= 0.95,eps= 10−5. We use a cosine learning rate schedule, with warmup of 2000 steps, and decay\\nfinallearningratedownto10%ofthepeaklearningrate. Weuseaweightdecayof 0.1andgradientclipping\\nof1.0. Figure 5 (a) shows the training loss for Llama 2 with these hyperparameters.\\n5\\n\\nTraining Data Params Context\\nLengthGQA Tokens LR\\nLlama 1See Touvron et al.', start_char_idx=3205, end_char_idx=3637, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-4', obj=None),\n",
       " 'node-4': IndexNode(id_='node-4', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='d03f19eb-da15-45dc-bfd4-e5d10f161250', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='231b3bd773f012c01b893ada9e009ecf25ee59934614c5a595c9bf1b3a123292'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='501b609c-d6d5-4dae-ba04-822d9221226e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9c8486fc3c8a457057d6ffd782b49e87d65c4d9f1a0ff8c609135e1fe1a4cc39'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='fb1c6ca2-1368-4801-97ae-b3601cf02add', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='71425b8142ea545e20b0d1f0ca219c7d3d5df4ebf95216ffef2b33804bd13d29')}, text='Testingconductedtodate hasbeeninEnglish andhasnot— andcouldnot— cover\\nall scenarios. Therefore, before deploying any applications of Llama 2-Chat , developers should perform\\nsafetytestingand tuningtailoredtotheirspecificapplicationsofthemodel. Weprovidearesponsibleuse\\nguide¶and code examples‖to facilitate the safe deployment of Llama 2 andLlama 2-Chat . More details of\\nour responsible release strategy can be found in Section 5.3.\\nTheremainderofthispaperdescribesourpretrainingmethodology(Section2),fine-tuningmethodology\\n(Section 3), approach to model safety (Section 4), key observations and insights (Section 5), relevant related\\nwork (Section 6), and conclusions (Section 7).\\n‡https://ai.meta.com/resources/models-and-libraries/llama/\\n§We are delaying the release of the 34B model due to a lack of time to sufficiently red team.\\n¶https://ai.meta.com/llama\\n‖https://github.com/facebookresearch/llama\\n4\\n\\nFigure4: Trainingof Llama 2-Chat : Thisprocessbeginswiththe pretraining ofLlama 2 usingpublicly\\navailableonlinesources. Followingthis,wecreateaninitialversionof Llama 2-Chat throughtheapplication\\nofsupervised fine-tuning . Subsequently, the model is iteratively refined using Reinforcement Learning\\nwith Human Feedback (RLHF) methodologies, specifically through rejection sampling and Proximal Policy\\nOptimization(PPO).ThroughouttheRLHFstage,theaccumulationof iterativerewardmodelingdata in\\nparallel with model enhancements is crucial to ensure the reward models remain within distribution.\\n2 Pretraining\\nTocreatethenewfamilyof Llama 2models,webeganwiththepretrainingapproachdescribedinTouvronetal.\\n(2023), using an optimized auto-regressive transformer, but made several changes to improve performance.\\nSpecifically,weperformedmorerobustdatacleaning,updatedourdatamixes,trainedon40%moretotal\\ntokens,doubledthecontextlength,andusedgrouped-queryattention(GQA)toimproveinferencescalability\\nfor our larger models. Table 1 compares the attributes of the new Llama 2 models with the Llama 1 models.\\n2.1 Pretraining Data\\nOur training corpus includes a new mix of data from publicly available sources, which does not include data\\nfromMeta’sproductsorservices. Wemadeanefforttoremovedatafromcertainsitesknowntocontaina\\nhighvolumeofpersonalinformationaboutprivateindividuals. Wetrainedon2trilliontokensofdataasthis\\nprovidesagoodperformance–costtrade-off,up-samplingthemostfactualsourcesinanefforttoincrease\\nknowledge and dampen hallucinations.\\nWeperformedavarietyofpretrainingdatainvestigationssothatuserscanbetterunderstandthepotential\\ncapabilities and limitations of our models; results can be found in Section 4.1.\\n2.2 Training Details\\nWe adopt most of the pretraining setting and model architecture from Llama 1 . We use the standard\\ntransformer architecture (Vaswani et al., 2017), apply pre-normalization using RMSNorm (Zhang and\\nSennrich, 2019), use the SwiGLU activation function (Shazeer, 2020), and rotary positional embeddings\\n(RoPE, Su et al. 2022). The primary architectural differences from Llama 1 include increased context length\\nandgrouped-queryattention(GQA).WedetailinAppendixSectionA.2.1eachofthesedifferenceswith\\nablation experiments to demonstrate their importance.\\nHyperparameters. We trained using the AdamW optimizer (Loshchilov and Hutter, 2017), with β1=\\n0.9, β2= 0.95,eps= 10−5. We use a cosine learning rate schedule, with warmup of 2000 steps, and decay\\nfinallearningratedownto10%ofthepeaklearningrate. Weuseaweightdecayof 0.1andgradientclipping\\nof1.0. Figure 5 (a) shows the training loss for Llama 2 with these hyperparameters.\\n5\\n\\nTraining Data Params Context\\nLengthGQA Tokens LR\\nLlama 1See Touvron et al.', start_char_idx=9358, end_char_idx=12995, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-4', obj=None),\n",
       " '4c13cb98-d70f-4f97-98ee-1649f3cf8f42': IndexNode(id_='4c13cb98-d70f-4f97-98ee-1649f3cf8f42', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='71425b8142ea545e20b0d1f0ca219c7d3d5df4ebf95216ffef2b33804bd13d29'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='44efb453-af6f-4b7b-9962-8f0fa8acf432', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='117de89d136af87c8b912fd0b7b2e22e854a080ddc4e4ddcc5c82fc77bb60dc3')}, text='We use a cosine learning rate schedule, with warmup of 2000 steps, and decay\\nfinallearningratedownto10%ofthepeaklearningrate. Weuseaweightdecayof 0.1andgradientclipping\\nof1.0. Figure 5 (a) shows the training loss for Llama 2 with these hyperparameters.\\n5\\n\\nTraining Data Params Context\\nLengthGQA Tokens LR\\nLlama 1See Touvron et al.\\n(2023)7B 2k ✗ 1.0T 3.', start_char_idx=0, end_char_idx=352, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-5', obj=None),\n",
       " '44efb453-af6f-4b7b-9962-8f0fa8acf432': IndexNode(id_='44efb453-af6f-4b7b-9962-8f0fa8acf432', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='71425b8142ea545e20b0d1f0ca219c7d3d5df4ebf95216ffef2b33804bd13d29'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='4c13cb98-d70f-4f97-98ee-1649f3cf8f42', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='87aa715d5d7370bed2dd070f41b69bfbe30e5ce7f96eb719be2d3563daf1831a'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='1ae0c678-3081-4d31-a67d-9e56bb548a62', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='34d5323cca5dd4be476ea262a486a8db5dfa379cb6770d52abf518a08d372c6e')}, text='Weuseaweightdecayof 0.1andgradientclipping\\nof1.0. Figure 5 (a) shows the training loss for Llama 2 with these hyperparameters.\\n5\\n\\nTraining Data Params Context\\nLengthGQA Tokens LR\\nLlama 1See Touvron et al.\\n(2023)7B 2k ✗ 1.0T 3.0×10−4\\n13B 2k ✗ 1.0T 3.0×10−4\\n33B 2k ✗ 1.4T 1.', start_char_idx=126, end_char_idx=398, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-5', obj=None),\n",
       " '1ae0c678-3081-4d31-a67d-9e56bb548a62': IndexNode(id_='1ae0c678-3081-4d31-a67d-9e56bb548a62', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='71425b8142ea545e20b0d1f0ca219c7d3d5df4ebf95216ffef2b33804bd13d29'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='44efb453-af6f-4b7b-9962-8f0fa8acf432', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='117de89d136af87c8b912fd0b7b2e22e854a080ddc4e4ddcc5c82fc77bb60dc3'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='125bc648-0383-4886-92ce-f3402294f468', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='71dbc940624c31bdbde56abdec119d44cec9cef14467380e73e1c5d850fb217d')}, text='5\\n\\nTraining Data Params Context\\nLengthGQA Tokens LR\\nLlama 1See Touvron et al.\\n(2023)7B 2k ✗ 1.0T 3.0×10−4\\n13B 2k ✗ 1.0T 3.0×10−4\\n33B 2k ✗ 1.4T 1.5×10−4\\n65B 2k ✗ 1.4T 1.', start_char_idx=253, end_char_idx=421, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-5', obj=None),\n",
       " '125bc648-0383-4886-92ce-f3402294f468': IndexNode(id_='125bc648-0383-4886-92ce-f3402294f468', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='71425b8142ea545e20b0d1f0ca219c7d3d5df4ebf95216ffef2b33804bd13d29'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='1ae0c678-3081-4d31-a67d-9e56bb548a62', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='34d5323cca5dd4be476ea262a486a8db5dfa379cb6770d52abf518a08d372c6e'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='4f7b5942-659c-4a33-9974-2170b391b940', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='90c61e79ac4e25245b2a6f0731f188cebbc27e4a62fc01e2134f77d4cd7e5360')}, text='(2023)7B 2k ✗ 1.0T 3.0×10−4\\n13B 2k ✗ 1.0T 3.0×10−4\\n33B 2k ✗ 1.4T 1.5×10−4\\n65B 2k ✗ 1.4T 1.5×10−4\\nLlama 2A new mix of publicly\\navailable online data7B 4k ✗ 2.0T 3.', start_char_idx=331, end_char_idx=493, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-5', obj=None),\n",
       " '4f7b5942-659c-4a33-9974-2170b391b940': IndexNode(id_='4f7b5942-659c-4a33-9974-2170b391b940', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='71425b8142ea545e20b0d1f0ca219c7d3d5df4ebf95216ffef2b33804bd13d29'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='125bc648-0383-4886-92ce-f3402294f468', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='71dbc940624c31bdbde56abdec119d44cec9cef14467380e73e1c5d850fb217d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='34700a3b-c101-4489-98bf-5b6e3a658b24', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3a7f3ae8180bcc69f0843961b1e9cf92483d0e50e04abc24e146191ff9ca81d7')}, text='0×10−4\\n13B 2k ✗ 1.0T 3.0×10−4\\n33B 2k ✗ 1.4T 1.5×10−4\\n65B 2k ✗ 1.4T 1.5×10−4\\nLlama 2A new mix of publicly\\navailable online data7B 4k ✗ 2.0T 3.0×10−4\\n13B 4k ✗ 2.0T 3.', start_char_idx=352, end_char_idx=516, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-5', obj=None),\n",
       " '34700a3b-c101-4489-98bf-5b6e3a658b24': IndexNode(id_='34700a3b-c101-4489-98bf-5b6e3a658b24', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='71425b8142ea545e20b0d1f0ca219c7d3d5df4ebf95216ffef2b33804bd13d29'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='4f7b5942-659c-4a33-9974-2170b391b940', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='90c61e79ac4e25245b2a6f0731f188cebbc27e4a62fc01e2134f77d4cd7e5360'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='4e118389-bfac-472c-8cdd-c140c0491bf5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e11fa5d2f8501962733619abbf731cecdc66de4ec0e4f2e27c83e358bbf5a5e4')}, text='0×10−4\\n33B 2k ✗ 1.4T 1.5×10−4\\n65B 2k ✗ 1.4T 1.5×10−4\\nLlama 2A new mix of publicly\\navailable online data7B 4k ✗ 2.0T 3.0×10−4\\n13B 4k ✗ 2.0T 3.0×10−4\\n34B 4k ✓ 2.0T 1.', start_char_idx=375, end_char_idx=539, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-5', obj=None),\n",
       " '4e118389-bfac-472c-8cdd-c140c0491bf5': IndexNode(id_='4e118389-bfac-472c-8cdd-c140c0491bf5', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='71425b8142ea545e20b0d1f0ca219c7d3d5df4ebf95216ffef2b33804bd13d29'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='34700a3b-c101-4489-98bf-5b6e3a658b24', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3a7f3ae8180bcc69f0843961b1e9cf92483d0e50e04abc24e146191ff9ca81d7'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='1b02e386-556f-44cf-abf3-e1640ac48903', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='691802e5ba7623fc6df0aeca460d977479ec98efdb30521ca3aadd09c25de214')}, text='5×10−4\\n65B 2k ✗ 1.4T 1.5×10−4\\nLlama 2A new mix of publicly\\navailable online data7B 4k ✗ 2.0T 3.0×10−4\\n13B 4k ✗ 2.0T 3.0×10−4\\n34B 4k ✓ 2.0T 1.5×10−4\\n70B 4k ✓ 2.0T 1.', start_char_idx=398, end_char_idx=562, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-5', obj=None),\n",
       " '1b02e386-556f-44cf-abf3-e1640ac48903': IndexNode(id_='1b02e386-556f-44cf-abf3-e1640ac48903', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='71425b8142ea545e20b0d1f0ca219c7d3d5df4ebf95216ffef2b33804bd13d29'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='4e118389-bfac-472c-8cdd-c140c0491bf5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e11fa5d2f8501962733619abbf731cecdc66de4ec0e4f2e27c83e358bbf5a5e4'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='123131d7-9fcd-4978-94b8-aca205f72341', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0cbf7f41fc10ac437b21eb6440971ba2af7842530aa48e482cd0b7a7565c9108')}, text='4T 1.5×10−4\\nLlama 2A new mix of publicly\\navailable online data7B 4k ✗ 2.0T 3.0×10−4\\n13B 4k ✗ 2.0T 3.0×10−4\\n34B 4k ✓ 2.0T 1.5×10−4\\n70B 4k ✓ 2.0T 1.5×10−4\\nTable 1: Llama 2 family of models.', start_char_idx=416, end_char_idx=603, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-5', obj=None),\n",
       " '123131d7-9fcd-4978-94b8-aca205f72341': IndexNode(id_='123131d7-9fcd-4978-94b8-aca205f72341', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='71425b8142ea545e20b0d1f0ca219c7d3d5df4ebf95216ffef2b33804bd13d29'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='1b02e386-556f-44cf-abf3-e1640ac48903', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='691802e5ba7623fc6df0aeca460d977479ec98efdb30521ca3aadd09c25de214'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='69593fad-808b-4f5d-aa1f-3af1da2b4d4a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='43efa1bd65376008710afae7115c970f6f64eb2027dbf6059b222a5de67c4799')}, text='0T 3.0×10−4\\n13B 4k ✗ 2.0T 3.0×10−4\\n34B 4k ✓ 2.0T 1.5×10−4\\n70B 4k ✓ 2.0T 1.5×10−4\\nTable 1: Llama 2 family of models. Token counts refer to pretraining data only. All models are trained with\\na global batch-size of 4M tokens.', start_char_idx=488, end_char_idx=710, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-5', obj=None),\n",
       " '69593fad-808b-4f5d-aa1f-3af1da2b4d4a': IndexNode(id_='69593fad-808b-4f5d-aa1f-3af1da2b4d4a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='71425b8142ea545e20b0d1f0ca219c7d3d5df4ebf95216ffef2b33804bd13d29'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='123131d7-9fcd-4978-94b8-aca205f72341', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0cbf7f41fc10ac437b21eb6440971ba2af7842530aa48e482cd0b7a7565c9108'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='24d7e5b7-543c-4603-8f93-661d9d09792a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='fcf9f3bab2d07028438301652d4002f485bb8fcf7166deb19e4ba7530179a0d5')}, text='0T 3.0×10−4\\n34B 4k ✓ 2.0T 1.5×10−4\\n70B 4k ✓ 2.0T 1.5×10−4\\nTable 1: Llama 2 family of models. Token counts refer to pretraining data only. All models are trained with\\na global batch-size of 4M tokens. Bigger models — 34B and 70B — use Grouped-Query Attention (GQA) for\\nimproved inference scalability.', start_char_idx=511, end_char_idx=810, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-5', obj=None),\n",
       " '24d7e5b7-543c-4603-8f93-661d9d09792a': IndexNode(id_='24d7e5b7-543c-4603-8f93-661d9d09792a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='71425b8142ea545e20b0d1f0ca219c7d3d5df4ebf95216ffef2b33804bd13d29'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='69593fad-808b-4f5d-aa1f-3af1da2b4d4a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='43efa1bd65376008710afae7115c970f6f64eb2027dbf6059b222a5de67c4799'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='5fe5536c-9c20-4290-913e-557ef0c9e650', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='98f12818826ff3134bf4eebbdd5f245acb64992a736657bae2eb7b6c3c79f81d')}, text='0T 1.5×10−4\\n70B 4k ✓ 2.0T 1.5×10−4\\nTable 1: Llama 2 family of models. Token counts refer to pretraining data only. All models are trained with\\na global batch-size of 4M tokens. Bigger models — 34B and 70B — use Grouped-Query Attention (GQA) for\\nimproved inference scalability.\\n0 250 500 750 1000 1250 1500 1750 2000\\nProcessed Tokens (Billions)1.41.51.61.71.81.92.02.12.2Train PPLLlama-2\\n7B\\n13B\\n34B\\n70B\\nFigure 5: Training Loss for Llama 2 models.', start_char_idx=534, end_char_idx=979, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-5', obj=None),\n",
       " '5fe5536c-9c20-4290-913e-557ef0c9e650': IndexNode(id_='5fe5536c-9c20-4290-913e-557ef0c9e650', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='71425b8142ea545e20b0d1f0ca219c7d3d5df4ebf95216ffef2b33804bd13d29'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='24d7e5b7-543c-4603-8f93-661d9d09792a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='fcf9f3bab2d07028438301652d4002f485bb8fcf7166deb19e4ba7530179a0d5'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='4c573c01-5c74-4171-98fc-61dcc0771397', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d7daebc157ae600f2f401d6fead78c41aaa77d64a78e49c5fcf018dd9f85208d')}, text='0 250 500 750 1000 1250 1500 1750 2000\\nProcessed Tokens (Billions)1.41.51.61.71.81.92.02.12.2Train PPLLlama-2\\n7B\\n13B\\n34B\\n70B\\nFigure 5: Training Loss for Llama 2 models. We compare the training loss of the Llama 2 family of models.\\nWe observe that after pretraining on 2T Tokens, the models still did not show any sign of saturation.\\nTokenizer.', start_char_idx=811, end_char_idx=1154, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-5', obj=None),\n",
       " '4c573c01-5c74-4171-98fc-61dcc0771397': IndexNode(id_='4c573c01-5c74-4171-98fc-61dcc0771397', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='71425b8142ea545e20b0d1f0ca219c7d3d5df4ebf95216ffef2b33804bd13d29'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='5fe5536c-9c20-4290-913e-557ef0c9e650', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='98f12818826ff3134bf4eebbdd5f245acb64992a736657bae2eb7b6c3c79f81d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='410adbc8-345a-4dad-b63b-979f7a55a415', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0b50a8f0da6da4d7dd5462c0f9a3e04ef10be456c0b6571e4331f849f58cf46d')}, text='We compare the training loss of the Llama 2 family of models.\\nWe observe that after pretraining on 2T Tokens, the models still did not show any sign of saturation.\\nTokenizer. Weusethesametokenizeras Llama 1;itemploysabytepairencoding(BPE)algorithm(Sennrich\\netal.,2016)usingtheimplementationfromSentencePiece(KudoandRichardson,2018). Aswith Llama 1,\\nwe split all numbers into individual digits and use bytes to decompose unknown UTF-8 characters.', start_char_idx=980, end_char_idx=1425, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-5', obj=None),\n",
       " '410adbc8-345a-4dad-b63b-979f7a55a415': IndexNode(id_='410adbc8-345a-4dad-b63b-979f7a55a415', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='71425b8142ea545e20b0d1f0ca219c7d3d5df4ebf95216ffef2b33804bd13d29'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='4c573c01-5c74-4171-98fc-61dcc0771397', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d7daebc157ae600f2f401d6fead78c41aaa77d64a78e49c5fcf018dd9f85208d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='16f90188-89c9-48d1-851a-486623b5b887', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8fd1ecf9f3aaf77db5f0b1104c53863931717363654859ae2fb3df18f8f35876')}, text='Tokenizer. Weusethesametokenizeras Llama 1;itemploysabytepairencoding(BPE)algorithm(Sennrich\\netal.,2016)usingtheimplementationfromSentencePiece(KudoandRichardson,2018). Aswith Llama 1,\\nwe split all numbers into individual digits and use bytes to decompose unknown UTF-8 characters. The total\\nvocabulary size is 32k tokens.\\n2.2.1 Training Hardware & Carbon Footprint\\nTrainingHardware.', start_char_idx=1144, end_char_idx=1527, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-5', obj=None),\n",
       " '16f90188-89c9-48d1-851a-486623b5b887': IndexNode(id_='16f90188-89c9-48d1-851a-486623b5b887', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='71425b8142ea545e20b0d1f0ca219c7d3d5df4ebf95216ffef2b33804bd13d29'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='410adbc8-345a-4dad-b63b-979f7a55a415', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0b50a8f0da6da4d7dd5462c0f9a3e04ef10be456c0b6571e4331f849f58cf46d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='8ee5f272-35a4-4240-b0cf-26b16a3dbe69', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='104292390f260c56d9b951f2fb526772f12bf5954ab118812b146438fe8ddaaa')}, text='Aswith Llama 1,\\nwe split all numbers into individual digits and use bytes to decompose unknown UTF-8 characters. The total\\nvocabulary size is 32k tokens.\\n2.2.1 Training Hardware & Carbon Footprint\\nTrainingHardware. WepretrainedourmodelsonMeta’sResearchSuperCluster(RSC)(LeeandSengupta,\\n2022)aswellasinternalproductionclusters. BothclustersuseNVIDIAA100s.', start_char_idx=1313, end_char_idx=1667, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-5', obj=None),\n",
       " '8ee5f272-35a4-4240-b0cf-26b16a3dbe69': IndexNode(id_='8ee5f272-35a4-4240-b0cf-26b16a3dbe69', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='71425b8142ea545e20b0d1f0ca219c7d3d5df4ebf95216ffef2b33804bd13d29'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='16f90188-89c9-48d1-851a-486623b5b887', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8fd1ecf9f3aaf77db5f0b1104c53863931717363654859ae2fb3df18f8f35876'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='82adf865-ba3a-4633-b5c5-cbad06f60d84', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b0f00d5a6b465bb64a20d9e65f8511c5b05994589fa8af3017a3824202e9d546')}, text='Aswith Llama 1,\\nwe split all numbers into individual digits and use bytes to decompose unknown UTF-8 characters. The total\\nvocabulary size is 32k tokens.\\n2.2.1 Training Hardware & Carbon Footprint\\nTrainingHardware. WepretrainedourmodelsonMeta’sResearchSuperCluster(RSC)(LeeandSengupta,\\n2022)aswellasinternalproductionclusters. BothclustersuseNVIDIAA100s. Therearetwokeydifferences\\nbetween the two clusters, with the first being the type of interconnect available: RSC uses NVIDIA Quantum\\nInfiniBandwhileourproductionclusterisequippedwithaRoCE(RDMAoverconvergedEthernet)solution\\nbased on commodity ethernet Switches.', start_char_idx=1313, end_char_idx=1928, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-5', obj=None),\n",
       " '82adf865-ba3a-4633-b5c5-cbad06f60d84': IndexNode(id_='82adf865-ba3a-4633-b5c5-cbad06f60d84', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='71425b8142ea545e20b0d1f0ca219c7d3d5df4ebf95216ffef2b33804bd13d29'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='8ee5f272-35a4-4240-b0cf-26b16a3dbe69', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='104292390f260c56d9b951f2fb526772f12bf5954ab118812b146438fe8ddaaa'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='e34ef430-f3a3-466d-8fc6-0a018f78c41f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f13ad8ad6de54700af46d6f6ac1913f53f34425ad73a341ead7930cb53eac09c')}, text='BothclustersuseNVIDIAA100s. Therearetwokeydifferences\\nbetween the two clusters, with the first being the type of interconnect available: RSC uses NVIDIA Quantum\\nInfiniBandwhileourproductionclusterisequippedwithaRoCE(RDMAoverconvergedEthernet)solution\\nbased on commodity ethernet Switches. Both of these solutions interconnect 200 Gbps end-points.', start_char_idx=1640, end_char_idx=1986, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-5', obj=None),\n",
       " 'e34ef430-f3a3-466d-8fc6-0a018f78c41f': IndexNode(id_='e34ef430-f3a3-466d-8fc6-0a018f78c41f', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='71425b8142ea545e20b0d1f0ca219c7d3d5df4ebf95216ffef2b33804bd13d29'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='82adf865-ba3a-4633-b5c5-cbad06f60d84', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b0f00d5a6b465bb64a20d9e65f8511c5b05994589fa8af3017a3824202e9d546'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='ef632b83-40be-4ad6-a9ea-cd8e62a44c92', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7c4728c6ff722e3c906cb5762af2eebddc8bba2dceb3eafc3aa742d10c9999d3')}, text='BothclustersuseNVIDIAA100s. Therearetwokeydifferences\\nbetween the two clusters, with the first being the type of interconnect available: RSC uses NVIDIA Quantum\\nInfiniBandwhileourproductionclusterisequippedwithaRoCE(RDMAoverconvergedEthernet)solution\\nbased on commodity ethernet Switches. Both of these solutions interconnect 200 Gbps end-points. The\\nseconddifferenceistheper-GPUpowerconsumptioncap—RSCuses400Wwhileourproductioncluster\\nuses350W.Withthistwo-clustersetup,wewereabletocomparethesuitabilityofthesedifferenttypesof\\ninterconnectforlargescaletraining.', start_char_idx=1640, end_char_idx=2201, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-5', obj=None),\n",
       " 'ef632b83-40be-4ad6-a9ea-cd8e62a44c92': IndexNode(id_='ef632b83-40be-4ad6-a9ea-cd8e62a44c92', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='71425b8142ea545e20b0d1f0ca219c7d3d5df4ebf95216ffef2b33804bd13d29'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='e34ef430-f3a3-466d-8fc6-0a018f78c41f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f13ad8ad6de54700af46d6f6ac1913f53f34425ad73a341ead7930cb53eac09c'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='446484be-cbaa-486b-9ca3-92cfcfd85b51', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='aef4801bc02da3227a6cda17e03b0f7fa2e714c2d2b6138ecd25ea5f1afa279c')}, text='Both of these solutions interconnect 200 Gbps end-points. The\\nseconddifferenceistheper-GPUpowerconsumptioncap—RSCuses400Wwhileourproductioncluster\\nuses350W.Withthistwo-clustersetup,wewereabletocomparethesuitabilityofthesedifferenttypesof\\ninterconnectforlargescaletraining. RoCE(whichisamoreaffordable,commercialinterconnectnetwork)\\n6\\n\\nTime\\n(GPU hours)Power\\nConsumption (W)Carbon Emitted\\n(tCO 2eq)\\nLlama 27B 184320 400 31.22\\n13B 368640 400 62.44\\n34B 1038336 350 153.90\\n70B 1720320 400 291.42\\nTotal 3311616 539.00\\nTable 2: CO2emissions during pretraining.', start_char_idx=1929, end_char_idx=2482, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-5', obj=None),\n",
       " '446484be-cbaa-486b-9ca3-92cfcfd85b51': IndexNode(id_='446484be-cbaa-486b-9ca3-92cfcfd85b51', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='71425b8142ea545e20b0d1f0ca219c7d3d5df4ebf95216ffef2b33804bd13d29'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='ef632b83-40be-4ad6-a9ea-cd8e62a44c92', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7c4728c6ff722e3c906cb5762af2eebddc8bba2dceb3eafc3aa742d10c9999d3')}, text='Time: total GPU time required for training each model. Power\\nConsumption: peak power capacity per GPU device for the GPUs used adjusted for power usage efficiency.\\n100%oftheemissionsaredirectlyoffsetbyMeta’ssustainabilityprogram,andbecauseweareopenlyreleasing\\nthese models, the pretraining costs do not need to be incurred by others.\\ncan scale almost as well as expensive Infiniband up to 2000 GPUs, which makes pretraining even more\\ndemocratizable.\\nCarbon Footprint of Pretraining.', start_char_idx=2483, end_char_idx=2965, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-5', obj=None),\n",
       " '5caaba94-9cca-4de3-b115-1f8740ab1975': IndexNode(id_='5caaba94-9cca-4de3-b115-1f8740ab1975', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='71425b8142ea545e20b0d1f0ca219c7d3d5df4ebf95216ffef2b33804bd13d29'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='611c5732-f2b7-49f8-addd-8202e7aff054', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2f886b521d1d1293d0254d733aca0289059e629af163c81baaf53207a36ec2c7')}, text='We use a cosine learning rate schedule, with warmup of 2000 steps, and decay\\nfinallearningratedownto10%ofthepeaklearningrate. Weuseaweightdecayof 0.1andgradientclipping\\nof1.0. Figure 5 (a) shows the training loss for Llama 2 with these hyperparameters.\\n5\\n\\nTraining Data Params Context\\nLengthGQA Tokens LR\\nLlama 1See Touvron et al.', start_char_idx=0, end_char_idx=330, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-5', obj=None),\n",
       " '611c5732-f2b7-49f8-addd-8202e7aff054': IndexNode(id_='611c5732-f2b7-49f8-addd-8202e7aff054', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='71425b8142ea545e20b0d1f0ca219c7d3d5df4ebf95216ffef2b33804bd13d29'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='5caaba94-9cca-4de3-b115-1f8740ab1975', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e9c08d7e550836a9d821b0521f6d025b7cc4138f4881a6f7196bdff24049524e'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='2adc441d-617e-4d1e-baa4-c9683a0dc3ff', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='cd2ff5ec9cf3df3b01b022ce90bd830718c625ad4723a18642a91cb501e15fea')}, text='We use a cosine learning rate schedule, with warmup of 2000 steps, and decay\\nfinallearningratedownto10%ofthepeaklearningrate. Weuseaweightdecayof 0.1andgradientclipping\\nof1.0. Figure 5 (a) shows the training loss for Llama 2 with these hyperparameters.\\n5\\n\\nTraining Data Params Context\\nLengthGQA Tokens LR\\nLlama 1See Touvron et al.\\n(2023)7B 2k ✗ 1.0T 3.0×10−4\\n13B 2k ✗ 1.0T 3.0×10−4\\n33B 2k ✗ 1.4T 1.5×10−4\\n65B 2k ✗ 1.4T 1.5×10−4\\nLlama 2A new mix of publicly\\navailable online data7B 4k ✗ 2.0T 3.0×10−4\\n13B 4k ✗ 2.0T 3.0×10−4\\n34B 4k ✓ 2.0T 1.5×10−4\\n70B 4k ✓ 2.0T 1.5×10−4\\nTable 1: Llama 2 family of models.', start_char_idx=0, end_char_idx=603, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-5', obj=None),\n",
       " '2adc441d-617e-4d1e-baa4-c9683a0dc3ff': IndexNode(id_='2adc441d-617e-4d1e-baa4-c9683a0dc3ff', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='71425b8142ea545e20b0d1f0ca219c7d3d5df4ebf95216ffef2b33804bd13d29'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='611c5732-f2b7-49f8-addd-8202e7aff054', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2f886b521d1d1293d0254d733aca0289059e629af163c81baaf53207a36ec2c7'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='2212dd6f-eda8-4386-886d-51b462c3ab79', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='409a8f71855aa526329cf1f7433baa0824a6ca7b11f556ba92a4affcded0c3ae')}, text='Token counts refer to pretraining data only. All models are trained with\\na global batch-size of 4M tokens. Bigger models — 34B and 70B — use Grouped-Query Attention (GQA) for\\nimproved inference scalability.\\n0 250 500 750 1000 1250 1500 1750 2000\\nProcessed Tokens (Billions)1.41.51.61.71.81.92.02.12.2Train PPLLlama-2\\n7B\\n13B\\n34B\\n70B\\nFigure 5: Training Loss for Llama 2 models. We compare the training loss of the Llama 2 family of models.\\nWe observe that after pretraining on 2T Tokens, the models still did not show any sign of saturation.\\nTokenizer. Weusethesametokenizeras Llama 1;itemploysabytepairencoding(BPE)algorithm(Sennrich\\netal.,2016)usingtheimplementationfromSentencePiece(KudoandRichardson,2018). Aswith Llama 1,\\nwe split all numbers into individual digits and use bytes to decompose unknown UTF-8 characters.', start_char_idx=604, end_char_idx=1425, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-5', obj=None),\n",
       " '2212dd6f-eda8-4386-886d-51b462c3ab79': IndexNode(id_='2212dd6f-eda8-4386-886d-51b462c3ab79', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='71425b8142ea545e20b0d1f0ca219c7d3d5df4ebf95216ffef2b33804bd13d29'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='2adc441d-617e-4d1e-baa4-c9683a0dc3ff', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='cd2ff5ec9cf3df3b01b022ce90bd830718c625ad4723a18642a91cb501e15fea'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='99711214-5c6c-434a-acd5-dee115b6c157', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f13ad8ad6de54700af46d6f6ac1913f53f34425ad73a341ead7930cb53eac09c')}, text='Tokenizer. Weusethesametokenizeras Llama 1;itemploysabytepairencoding(BPE)algorithm(Sennrich\\netal.,2016)usingtheimplementationfromSentencePiece(KudoandRichardson,2018). Aswith Llama 1,\\nwe split all numbers into individual digits and use bytes to decompose unknown UTF-8 characters. The total\\nvocabulary size is 32k tokens.\\n2.2.1 Training Hardware & Carbon Footprint\\nTrainingHardware. WepretrainedourmodelsonMeta’sResearchSuperCluster(RSC)(LeeandSengupta,\\n2022)aswellasinternalproductionclusters. BothclustersuseNVIDIAA100s. Therearetwokeydifferences\\nbetween the two clusters, with the first being the type of interconnect available: RSC uses NVIDIA Quantum\\nInfiniBandwhileourproductionclusterisequippedwithaRoCE(RDMAoverconvergedEthernet)solution\\nbased on commodity ethernet Switches. Both of these solutions interconnect 200 Gbps end-points.', start_char_idx=1144, end_char_idx=1986, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-5', obj=None),\n",
       " '99711214-5c6c-434a-acd5-dee115b6c157': IndexNode(id_='99711214-5c6c-434a-acd5-dee115b6c157', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='71425b8142ea545e20b0d1f0ca219c7d3d5df4ebf95216ffef2b33804bd13d29'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='2212dd6f-eda8-4386-886d-51b462c3ab79', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='409a8f71855aa526329cf1f7433baa0824a6ca7b11f556ba92a4affcded0c3ae'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='e2f40d36-a565-407d-a1b1-a85862fe9205', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='487aac48691af94e7502dbe11ce49daf0fe26522b36a4e7cae6fd654c57ee853')}, text='BothclustersuseNVIDIAA100s. Therearetwokeydifferences\\nbetween the two clusters, with the first being the type of interconnect available: RSC uses NVIDIA Quantum\\nInfiniBandwhileourproductionclusterisequippedwithaRoCE(RDMAoverconvergedEthernet)solution\\nbased on commodity ethernet Switches. Both of these solutions interconnect 200 Gbps end-points. The\\nseconddifferenceistheper-GPUpowerconsumptioncap—RSCuses400Wwhileourproductioncluster\\nuses350W.Withthistwo-clustersetup,wewereabletocomparethesuitabilityofthesedifferenttypesof\\ninterconnectforlargescaletraining.', start_char_idx=1640, end_char_idx=2201, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-5', obj=None),\n",
       " 'e2f40d36-a565-407d-a1b1-a85862fe9205': IndexNode(id_='e2f40d36-a565-407d-a1b1-a85862fe9205', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='71425b8142ea545e20b0d1f0ca219c7d3d5df4ebf95216ffef2b33804bd13d29'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='99711214-5c6c-434a-acd5-dee115b6c157', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f13ad8ad6de54700af46d6f6ac1913f53f34425ad73a341ead7930cb53eac09c'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='44cffaaf-c6d0-4dcf-9065-93109845eb8c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='aef4801bc02da3227a6cda17e03b0f7fa2e714c2d2b6138ecd25ea5f1afa279c')}, text='Both of these solutions interconnect 200 Gbps end-points. The\\nseconddifferenceistheper-GPUpowerconsumptioncap—RSCuses400Wwhileourproductioncluster\\nuses350W.Withthistwo-clustersetup,wewereabletocomparethesuitabilityofthesedifferenttypesof\\ninterconnectforlargescaletraining. RoCE(whichisamoreaffordable,commercialinterconnectnetwork)\\n6\\n\\nTime\\n(GPU hours)Power\\nConsumption (W)Carbon Emitted\\n(tCO 2eq)\\nLlama 27B 184320 400 31.22\\n13B 368640 400 62.44\\n34B 1038336 350 153.90\\n70B 1720320 400 291.42\\nTotal 3311616 539.00\\nTable 2: CO2emissions during pretraining. Time: total GPU time required for training each model. Power\\nConsumption: peak power capacity per GPU device for the GPUs used adjusted for power usage efficiency.', start_char_idx=1929, end_char_idx=2646, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-5', obj=None),\n",
       " '44cffaaf-c6d0-4dcf-9065-93109845eb8c': IndexNode(id_='44cffaaf-c6d0-4dcf-9065-93109845eb8c', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='71425b8142ea545e20b0d1f0ca219c7d3d5df4ebf95216ffef2b33804bd13d29'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='e2f40d36-a565-407d-a1b1-a85862fe9205', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='487aac48691af94e7502dbe11ce49daf0fe26522b36a4e7cae6fd654c57ee853')}, text='Time: total GPU time required for training each model. Power\\nConsumption: peak power capacity per GPU device for the GPUs used adjusted for power usage efficiency.\\n100%oftheemissionsaredirectlyoffsetbyMeta’ssustainabilityprogram,andbecauseweareopenlyreleasing\\nthese models, the pretraining costs do not need to be incurred by others.\\ncan scale almost as well as expensive Infiniband up to 2000 GPUs, which makes pretraining even more\\ndemocratizable.\\nCarbon Footprint of Pretraining.', start_char_idx=2483, end_char_idx=2965, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-5', obj=None),\n",
       " 'b8070bcd-7b83-41d4-b8ca-c255bc7ea1e9': IndexNode(id_='b8070bcd-7b83-41d4-b8ca-c255bc7ea1e9', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='71425b8142ea545e20b0d1f0ca219c7d3d5df4ebf95216ffef2b33804bd13d29'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='4625b974-1ec3-4d42-be52-5dd754a1a307', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f0c67d37eaa8f3017819492b8f500410d4a5c69f2ce6d5576f69c26a41abfae5')}, text='We use a cosine learning rate schedule, with warmup of 2000 steps, and decay\\nfinallearningratedownto10%ofthepeaklearningrate. Weuseaweightdecayof 0.1andgradientclipping\\nof1.0. Figure 5 (a) shows the training loss for Llama 2 with these hyperparameters.\\n5\\n\\nTraining Data Params Context\\nLengthGQA Tokens LR\\nLlama 1See Touvron et al.\\n(2023)7B 2k ✗ 1.0T 3.0×10−4\\n13B 2k ✗ 1.0T 3.0×10−4\\n33B 2k ✗ 1.4T 1.5×10−4\\n65B 2k ✗ 1.4T 1.5×10−4\\nLlama 2A new mix of publicly\\navailable online data7B 4k ✗ 2.0T 3.0×10−4\\n13B 4k ✗ 2.0T 3.0×10−4\\n34B 4k ✓ 2.0T 1.5×10−4\\n70B 4k ✓ 2.0T 1.5×10−4\\nTable 1: Llama 2 family of models. Token counts refer to pretraining data only. All models are trained with\\na global batch-size of 4M tokens. Bigger models — 34B and 70B — use Grouped-Query Attention (GQA) for\\nimproved inference scalability.\\n0 250 500 750 1000 1250 1500 1750 2000\\nProcessed Tokens (Billions)1.41.51.61.71.81.92.02.12.2Train PPLLlama-2\\n7B\\n13B\\n34B\\n70B\\nFigure 5: Training Loss for Llama 2 models. We compare the training loss of the Llama 2 family of models.\\nWe observe that after pretraining on 2T Tokens, the models still did not show any sign of saturation.\\nTokenizer.', start_char_idx=0, end_char_idx=1154, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-5', obj=None),\n",
       " '4625b974-1ec3-4d42-be52-5dd754a1a307': IndexNode(id_='4625b974-1ec3-4d42-be52-5dd754a1a307', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='71425b8142ea545e20b0d1f0ca219c7d3d5df4ebf95216ffef2b33804bd13d29'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='b8070bcd-7b83-41d4-b8ca-c255bc7ea1e9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a0753df388857b52a00e3ec04fa7230b00a6d0daf6557af7f8746ddd3196ab1a'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='34a4624e-5d68-4714-aac1-d2214dc1046b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='aef4801bc02da3227a6cda17e03b0f7fa2e714c2d2b6138ecd25ea5f1afa279c')}, text='We compare the training loss of the Llama 2 family of models.\\nWe observe that after pretraining on 2T Tokens, the models still did not show any sign of saturation.\\nTokenizer. Weusethesametokenizeras Llama 1;itemploysabytepairencoding(BPE)algorithm(Sennrich\\netal.,2016)usingtheimplementationfromSentencePiece(KudoandRichardson,2018). Aswith Llama 1,\\nwe split all numbers into individual digits and use bytes to decompose unknown UTF-8 characters. The total\\nvocabulary size is 32k tokens.\\n2.2.1 Training Hardware & Carbon Footprint\\nTrainingHardware. WepretrainedourmodelsonMeta’sResearchSuperCluster(RSC)(LeeandSengupta,\\n2022)aswellasinternalproductionclusters. BothclustersuseNVIDIAA100s. Therearetwokeydifferences\\nbetween the two clusters, with the first being the type of interconnect available: RSC uses NVIDIA Quantum\\nInfiniBandwhileourproductionclusterisequippedwithaRoCE(RDMAoverconvergedEthernet)solution\\nbased on commodity ethernet Switches. Both of these solutions interconnect 200 Gbps end-points. The\\nseconddifferenceistheper-GPUpowerconsumptioncap—RSCuses400Wwhileourproductioncluster\\nuses350W.Withthistwo-clustersetup,wewereabletocomparethesuitabilityofthesedifferenttypesof\\ninterconnectforlargescaletraining. RoCE(whichisamoreaffordable,commercialinterconnectnetwork)\\n6\\n\\nTime\\n(GPU hours)Power\\nConsumption (W)Carbon Emitted\\n(tCO 2eq)\\nLlama 27B 184320 400 31.22\\n13B 368640 400 62.44\\n34B 1038336 350 153.90\\n70B 1720320 400 291.42\\nTotal 3311616 539.00\\nTable 2: CO2emissions during pretraining. Time: total GPU time required for training each model. Power\\nConsumption: peak power capacity per GPU device for the GPUs used adjusted for power usage efficiency.', start_char_idx=980, end_char_idx=2646, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-5', obj=None),\n",
       " '34a4624e-5d68-4714-aac1-d2214dc1046b': IndexNode(id_='34a4624e-5d68-4714-aac1-d2214dc1046b', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='71425b8142ea545e20b0d1f0ca219c7d3d5df4ebf95216ffef2b33804bd13d29'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='4625b974-1ec3-4d42-be52-5dd754a1a307', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f0c67d37eaa8f3017819492b8f500410d4a5c69f2ce6d5576f69c26a41abfae5')}, text='Time: total GPU time required for training each model. Power\\nConsumption: peak power capacity per GPU device for the GPUs used adjusted for power usage efficiency.\\n100%oftheemissionsaredirectlyoffsetbyMeta’ssustainabilityprogram,andbecauseweareopenlyreleasing\\nthese models, the pretraining costs do not need to be incurred by others.\\ncan scale almost as well as expensive Infiniband up to 2000 GPUs, which makes pretraining even more\\ndemocratizable.\\nCarbon Footprint of Pretraining.', start_char_idx=2483, end_char_idx=2965, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-5', obj=None),\n",
       " 'node-5': IndexNode(id_='node-5', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='d03f19eb-da15-45dc-bfd4-e5d10f161250', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='231b3bd773f012c01b893ada9e009ecf25ee59934614c5a595c9bf1b3a123292'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='036aa5d1-441b-4a4b-b154-37b01a723d6f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='83ec7c3146dd419bd3a5be627bec4d01d4e4fc9fc10aecff1f01545752855972'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='05c3d1f2-ed89-42c0-ab18-43d2b38d458e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f939a86f41587d042c4ebb4485546c18e5e7ab1ae86c405fb91ffacb1785593c')}, text='We use a cosine learning rate schedule, with warmup of 2000 steps, and decay\\nfinallearningratedownto10%ofthepeaklearningrate. Weuseaweightdecayof 0.1andgradientclipping\\nof1.0. Figure 5 (a) shows the training loss for Llama 2 with these hyperparameters.\\n5\\n\\nTraining Data Params Context\\nLengthGQA Tokens LR\\nLlama 1See Touvron et al.\\n(2023)7B 2k ✗ 1.0T 3.0×10−4\\n13B 2k ✗ 1.0T 3.0×10−4\\n33B 2k ✗ 1.4T 1.5×10−4\\n65B 2k ✗ 1.4T 1.5×10−4\\nLlama 2A new mix of publicly\\navailable online data7B 4k ✗ 2.0T 3.0×10−4\\n13B 4k ✗ 2.0T 3.0×10−4\\n34B 4k ✓ 2.0T 1.5×10−4\\n70B 4k ✓ 2.0T 1.5×10−4\\nTable 1: Llama 2 family of models. Token counts refer to pretraining data only. All models are trained with\\na global batch-size of 4M tokens. Bigger models — 34B and 70B — use Grouped-Query Attention (GQA) for\\nimproved inference scalability.\\n0 250 500 750 1000 1250 1500 1750 2000\\nProcessed Tokens (Billions)1.41.51.61.71.81.92.02.12.2Train PPLLlama-2\\n7B\\n13B\\n34B\\n70B\\nFigure 5: Training Loss for Llama 2 models. We compare the training loss of the Llama 2 family of models.\\nWe observe that after pretraining on 2T Tokens, the models still did not show any sign of saturation.\\nTokenizer. Weusethesametokenizeras Llama 1;itemploysabytepairencoding(BPE)algorithm(Sennrich\\netal.,2016)usingtheimplementationfromSentencePiece(KudoandRichardson,2018). Aswith Llama 1,\\nwe split all numbers into individual digits and use bytes to decompose unknown UTF-8 characters. The total\\nvocabulary size is 32k tokens.\\n2.2.1 Training Hardware & Carbon Footprint\\nTrainingHardware. WepretrainedourmodelsonMeta’sResearchSuperCluster(RSC)(LeeandSengupta,\\n2022)aswellasinternalproductionclusters. BothclustersuseNVIDIAA100s. Therearetwokeydifferences\\nbetween the two clusters, with the first being the type of interconnect available: RSC uses NVIDIA Quantum\\nInfiniBandwhileourproductionclusterisequippedwithaRoCE(RDMAoverconvergedEthernet)solution\\nbased on commodity ethernet Switches. Both of these solutions interconnect 200 Gbps end-points. The\\nseconddifferenceistheper-GPUpowerconsumptioncap—RSCuses400Wwhileourproductioncluster\\nuses350W.Withthistwo-clustersetup,wewereabletocomparethesuitabilityofthesedifferenttypesof\\ninterconnectforlargescaletraining. RoCE(whichisamoreaffordable,commercialinterconnectnetwork)\\n6\\n\\nTime\\n(GPU hours)Power\\nConsumption (W)Carbon Emitted\\n(tCO 2eq)\\nLlama 27B 184320 400 31.22\\n13B 368640 400 62.44\\n34B 1038336 350 153.90\\n70B 1720320 400 291.42\\nTotal 3311616 539.00\\nTable 2: CO2emissions during pretraining. Time: total GPU time required for training each model. Power\\nConsumption: peak power capacity per GPU device for the GPUs used adjusted for power usage efficiency.\\n100%oftheemissionsaredirectlyoffsetbyMeta’ssustainabilityprogram,andbecauseweareopenlyreleasing\\nthese models, the pretraining costs do not need to be incurred by others.\\ncan scale almost as well as expensive Infiniband up to 2000 GPUs, which makes pretraining even more\\ndemocratizable.\\nCarbon Footprint of Pretraining.', start_char_idx=12665, end_char_idx=15630, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-5', obj=None),\n",
       " 'b59991ea-cf32-4df0-bed5-bccfdabc60ad': IndexNode(id_='b59991ea-cf32-4df0-bed5-bccfdabc60ad', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f939a86f41587d042c4ebb4485546c18e5e7ab1ae86c405fb91ffacb1785593c'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='2654150f-7fec-41c8-b24a-1de6a6121995', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='fe9b599244ae49b6be0872f36f1b200b0956e4a93d2c6edf817389e5f002e93a')}, text='Power\\nConsumption: peak power capacity per GPU device for the GPUs used adjusted for power usage efficiency.\\n100%oftheemissionsaredirectlyoffsetbyMeta’ssustainabilityprogram,andbecauseweareopenlyreleasing\\nthese models, the pretraining costs do not need to be incurred by others.\\ncan scale almost as well as expensive Infiniband up to 2000 GPUs, which makes pretraining even more\\ndemocratizable.\\nCarbon Footprint of Pretraining.', start_char_idx=0, end_char_idx=427, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-6', obj=None),\n",
       " '2654150f-7fec-41c8-b24a-1de6a6121995': IndexNode(id_='2654150f-7fec-41c8-b24a-1de6a6121995', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f939a86f41587d042c4ebb4485546c18e5e7ab1ae86c405fb91ffacb1785593c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='b59991ea-cf32-4df0-bed5-bccfdabc60ad', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='284660b8f0841de0f11ff0e47aa86490758ec81189a4e125d1492b901588a984'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='286d1ea8-4bad-436b-a07a-cd5d49080e37', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d0c11e7b55e703cf53f2f4aac55660fed2e5484ff1caaec039baa71778353a4a')}, text='Power\\nConsumption: peak power capacity per GPU device for the GPUs used adjusted for power usage efficiency.\\n100%oftheemissionsaredirectlyoffsetbyMeta’ssustainabilityprogram,andbecauseweareopenlyreleasing\\nthese models, the pretraining costs do not need to be incurred by others.\\ncan scale almost as well as expensive Infiniband up to 2000 GPUs, which makes pretraining even more\\ndemocratizable.\\nCarbon Footprint of Pretraining. Following preceding research (Bender et al., 2021a; Patterson et al., 2021;\\nWu et al., 2022; Dodge et al., 2022) and using power consumption estimates of GPU devices and carbon\\nefficiency, we aim tocalculate thecarbon emissions resultingfrom the pretrainingof Llama 2 models.', start_char_idx=0, end_char_idx=703, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-6', obj=None),\n",
       " '286d1ea8-4bad-436b-a07a-cd5d49080e37': IndexNode(id_='286d1ea8-4bad-436b-a07a-cd5d49080e37', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f939a86f41587d042c4ebb4485546c18e5e7ab1ae86c405fb91ffacb1785593c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='2654150f-7fec-41c8-b24a-1de6a6121995', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='fe9b599244ae49b6be0872f36f1b200b0956e4a93d2c6edf817389e5f002e93a'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='c190a1b1-6413-4298-8bdd-839d9e915eaf', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='edb9a14fd0647d116cfa5f675e74fd0acfadde651586cafe9f046941991d28bc')}, text='Carbon Footprint of Pretraining. Following preceding research (Bender et al., 2021a; Patterson et al., 2021;\\nWu et al., 2022; Dodge et al., 2022) and using power consumption estimates of GPU devices and carbon\\nefficiency, we aim tocalculate thecarbon emissions resultingfrom the pretrainingof Llama 2 models. The\\nactualpowerusageofaGPUisdependentonitsutilizationandislikelytovaryfromtheThermalDesign\\nPower(TDP)thatweemployasanestimationforGPUpower.', start_char_idx=395, end_char_idx=843, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-6', obj=None),\n",
       " 'c190a1b1-6413-4298-8bdd-839d9e915eaf': IndexNode(id_='c190a1b1-6413-4298-8bdd-839d9e915eaf', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f939a86f41587d042c4ebb4485546c18e5e7ab1ae86c405fb91ffacb1785593c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='286d1ea8-4bad-436b-a07a-cd5d49080e37', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d0c11e7b55e703cf53f2f4aac55660fed2e5484ff1caaec039baa71778353a4a'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='9d0eb717-83dc-4805-9146-0f6112a3de29', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='473a660983d74e841586d136a9cfb880d69b729e7972ffb8514a384498417995')}, text='The\\nactualpowerusageofaGPUisdependentonitsutilizationandislikelytovaryfromtheThermalDesign\\nPower(TDP)thatweemployasanestimationforGPUpower. Itisimportanttonotethatourcalculations\\ndo not account for further power demands, such as those from interconnect or non-GPU server power\\nconsumption,norfromdatacentercoolingsystems. Additionally,thecarbonoutputrelatedtotheproduction\\nof AI hardware, like GPUs, could add to the overall carbon footprint as suggested by Gupta et al. (2022b,a).', start_char_idx=704, end_char_idx=1185, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-6', obj=None),\n",
       " '9d0eb717-83dc-4805-9146-0f6112a3de29': IndexNode(id_='9d0eb717-83dc-4805-9146-0f6112a3de29', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f939a86f41587d042c4ebb4485546c18e5e7ab1ae86c405fb91ffacb1785593c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='c190a1b1-6413-4298-8bdd-839d9e915eaf', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='edb9a14fd0647d116cfa5f675e74fd0acfadde651586cafe9f046941991d28bc'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='bc41ad03-cdcc-4eb2-ac26-5767cf2ab512', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='24f7c54d83bc2fd31c3c85264057451c8c2e78f81de51a120ec59758e66fb696')}, text='Itisimportanttonotethatourcalculations\\ndo not account for further power demands, such as those from interconnect or non-GPU server power\\nconsumption,norfromdatacentercoolingsystems. Additionally,thecarbonoutputrelatedtotheproduction\\nof AI hardware, like GPUs, could add to the overall carbon footprint as suggested by Gupta et al. (2022b,a).\\nTable 2 summarizes the carbon emission for pretraining the Llama 2 family of models.', start_char_idx=844, end_char_idx=1270, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-6', obj=None),\n",
       " 'bc41ad03-cdcc-4eb2-ac26-5767cf2ab512': IndexNode(id_='bc41ad03-cdcc-4eb2-ac26-5767cf2ab512', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f939a86f41587d042c4ebb4485546c18e5e7ab1ae86c405fb91ffacb1785593c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='9d0eb717-83dc-4805-9146-0f6112a3de29', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='473a660983d74e841586d136a9cfb880d69b729e7972ffb8514a384498417995'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='3aa83337-147d-4af4-ad87-ef80cad8534e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f5b3405b0a2f25f2ab56a5f4cec938ba566ca4d21d9f7d6bc189c7d68321d554')}, text='Additionally,thecarbonoutputrelatedtotheproduction\\nof AI hardware, like GPUs, could add to the overall carbon footprint as suggested by Gupta et al. (2022b,a).\\nTable 2 summarizes the carbon emission for pretraining the Llama 2 family of models. A cumulative of\\n3.3M GPUhours ofcomputation wasperformed onhardware oftype A100-80GB (TDPof 400Wor 350W).', start_char_idx=1026, end_char_idx=1376, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-6', obj=None),\n",
       " '3aa83337-147d-4af4-ad87-ef80cad8534e': IndexNode(id_='3aa83337-147d-4af4-ad87-ef80cad8534e', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f939a86f41587d042c4ebb4485546c18e5e7ab1ae86c405fb91ffacb1785593c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='bc41ad03-cdcc-4eb2-ac26-5767cf2ab512', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='24f7c54d83bc2fd31c3c85264057451c8c2e78f81de51a120ec59758e66fb696'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='67603f64-7e79-421e-acc5-975398179fce', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a65cc26ac0518308463d8fe1817e0a69c46afd3dd5cf5147b5be57919dd3afd8')}, text='Additionally,thecarbonoutputrelatedtotheproduction\\nof AI hardware, like GPUs, could add to the overall carbon footprint as suggested by Gupta et al. (2022b,a).\\nTable 2 summarizes the carbon emission for pretraining the Llama 2 family of models. A cumulative of\\n3.3M GPUhours ofcomputation wasperformed onhardware oftype A100-80GB (TDPof 400Wor 350W).\\nWe estimate the total emissions for training to be 539 tCO 2eq, of which 100% were directly offset by Meta’s\\nsustainability program.∗∗Our open release strategy also means that these pretraining costs will not need to\\nbe incurred by other companies, saving more global resources.', start_char_idx=1026, end_char_idx=1655, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-6', obj=None),\n",
       " '67603f64-7e79-421e-acc5-975398179fce': IndexNode(id_='67603f64-7e79-421e-acc5-975398179fce', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f939a86f41587d042c4ebb4485546c18e5e7ab1ae86c405fb91ffacb1785593c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='3aa83337-147d-4af4-ad87-ef80cad8534e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f5b3405b0a2f25f2ab56a5f4cec938ba566ca4d21d9f7d6bc189c7d68321d554'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='34be653d-a290-4b56-8d3c-99f19bbe57cc', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='45bdb9ccbdf1ad6cde5067ad9fd33222fe4318156895ffc4a47f39b6020acdc8')}, text='We estimate the total emissions for training to be 539 tCO 2eq, of which 100% were directly offset by Meta’s\\nsustainability program.∗∗Our open release strategy also means that these pretraining costs will not need to\\nbe incurred by other companies, saving more global resources.\\n2.3 Llama 2 Pretrained Model Evaluation\\nIn this section, we report the results for the Llama 1 andLlama 2 base models, MosaicML Pretrained\\nTransformer(MPT)††models,andFalcon(Almazroueietal.,2023)modelsonstandardacademicbenchmarks.', start_char_idx=1377, end_char_idx=1886, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-6', obj=None),\n",
       " '34be653d-a290-4b56-8d3c-99f19bbe57cc': IndexNode(id_='34be653d-a290-4b56-8d3c-99f19bbe57cc', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f939a86f41587d042c4ebb4485546c18e5e7ab1ae86c405fb91ffacb1785593c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='67603f64-7e79-421e-acc5-975398179fce', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a65cc26ac0518308463d8fe1817e0a69c46afd3dd5cf5147b5be57919dd3afd8'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='40e11bf6-486f-4138-9a13-23444883769d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5e2de9ee233a47a336efe29f5fd5c44b392b1ef395413e7fb865e91f32029f08')}, text='2.3 Llama 2 Pretrained Model Evaluation\\nIn this section, we report the results for the Llama 1 andLlama 2 base models, MosaicML Pretrained\\nTransformer(MPT)††models,andFalcon(Almazroueietal.,2023)modelsonstandardacademicbenchmarks.\\nFor all the evaluations, we use our internal evaluations library. We reproduce results for the MPT and Falcon\\nmodelsinternally. Forthesemodels,wealwayspickthebestscorebetweenourevaluationframeworkand\\nany publicly reported results.', start_char_idx=1656, end_char_idx=2117, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-6', obj=None),\n",
       " '40e11bf6-486f-4138-9a13-23444883769d': IndexNode(id_='40e11bf6-486f-4138-9a13-23444883769d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f939a86f41587d042c4ebb4485546c18e5e7ab1ae86c405fb91ffacb1785593c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='34be653d-a290-4b56-8d3c-99f19bbe57cc', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='45bdb9ccbdf1ad6cde5067ad9fd33222fe4318156895ffc4a47f39b6020acdc8'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='68ae52dd-9eba-4ab5-809f-cd04d28df8c3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3f791f4be3b2fc943b6899a2a25ac1131656f17ee20583eb451cef01ff4e35c1')}, text='For all the evaluations, we use our internal evaluations library. We reproduce results for the MPT and Falcon\\nmodelsinternally. Forthesemodels,wealwayspickthebestscorebetweenourevaluationframeworkand\\nany publicly reported results.\\nInTable3,wesummarizetheoverallperformanceacrossasuiteofpopularbenchmarks. Notethatsafety\\nbenchmarks are shared in Section 4.1. The benchmarks are grouped into the categories listed below. The\\nresults for all the individual benchmarks are available in Section A.2.2.', start_char_idx=1887, end_char_idx=2383, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-6', obj=None),\n",
       " '68ae52dd-9eba-4ab5-809f-cd04d28df8c3': IndexNode(id_='68ae52dd-9eba-4ab5-809f-cd04d28df8c3', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f939a86f41587d042c4ebb4485546c18e5e7ab1ae86c405fb91ffacb1785593c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='40e11bf6-486f-4138-9a13-23444883769d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5e2de9ee233a47a336efe29f5fd5c44b392b1ef395413e7fb865e91f32029f08'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='ee8158ed-39bc-46f4-9abc-807a286bc370', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2e27c1ecc93c3dce70b675b289d7a8ecd5044f86dd78c1c73c0858bdae88dc6e')}, text='Forthesemodels,wealwayspickthebestscorebetweenourevaluationframeworkand\\nany publicly reported results.\\nInTable3,wesummarizetheoverallperformanceacrossasuiteofpopularbenchmarks. Notethatsafety\\nbenchmarks are shared in Section 4.1. The benchmarks are grouped into the categories listed below. The\\nresults for all the individual benchmarks are available in Section A.2.2.\\n•Code.Wereporttheaveragepass@1scoresofourmodelsonHumanEval(Chenetal.,2021)and\\nMBPP (Austin et al., 2021).', start_char_idx=2015, end_char_idx=2489, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-6', obj=None),\n",
       " 'ee8158ed-39bc-46f4-9abc-807a286bc370': IndexNode(id_='ee8158ed-39bc-46f4-9abc-807a286bc370', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f939a86f41587d042c4ebb4485546c18e5e7ab1ae86c405fb91ffacb1785593c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='68ae52dd-9eba-4ab5-809f-cd04d28df8c3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3f791f4be3b2fc943b6899a2a25ac1131656f17ee20583eb451cef01ff4e35c1'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='0bd2504c-c3e0-4dba-9de8-ab829f791736', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8ebac3cd306296cb4411115bb7a4c51a55c67a123b7307d51f47fe9312d7382d')}, text='Notethatsafety\\nbenchmarks are shared in Section 4.1. The benchmarks are grouped into the categories listed below. The\\nresults for all the individual benchmarks are available in Section A.2.2.\\n•Code.Wereporttheaveragepass@1scoresofourmodelsonHumanEval(Chenetal.,2021)and\\nMBPP (Austin et al., 2021).\\n•CommonsenseReasoning.', start_char_idx=2192, end_char_idx=2512, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-6', obj=None),\n",
       " '0bd2504c-c3e0-4dba-9de8-ab829f791736': IndexNode(id_='0bd2504c-c3e0-4dba-9de8-ab829f791736', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f939a86f41587d042c4ebb4485546c18e5e7ab1ae86c405fb91ffacb1785593c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='ee8158ed-39bc-46f4-9abc-807a286bc370', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2e27c1ecc93c3dce70b675b289d7a8ecd5044f86dd78c1c73c0858bdae88dc6e'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='e16a9315-cc4d-4b92-936c-3b6f033b6545', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='733bb4445a05722440df5456789b6fd7f9de8fe5d638cf388c55c7164af65dec')}, text='Notethatsafety\\nbenchmarks are shared in Section 4.1. The benchmarks are grouped into the categories listed below. The\\nresults for all the individual benchmarks are available in Section A.2.2.\\n•Code.Wereporttheaveragepass@1scoresofourmodelsonHumanEval(Chenetal.,2021)and\\nMBPP (Austin et al., 2021).\\n•CommonsenseReasoning. WereporttheaverageofPIQA(Bisketal.,2020),SIQA(Sapetal.,2019),\\nHellaSwag (Zellers et al., 2019a), WinoGrande (Sakaguchi et al., 2021), ARC easy and challenge\\n(Clark et al., 2018), OpenBookQA (Mihaylov et al., 2018), and CommonsenseQA (Talmor et al.,\\n2018).', start_char_idx=2192, end_char_idx=2768, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-6', obj=None),\n",
       " 'e16a9315-cc4d-4b92-936c-3b6f033b6545': IndexNode(id_='e16a9315-cc4d-4b92-936c-3b6f033b6545', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f939a86f41587d042c4ebb4485546c18e5e7ab1ae86c405fb91ffacb1785593c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='0bd2504c-c3e0-4dba-9de8-ab829f791736', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8ebac3cd306296cb4411115bb7a4c51a55c67a123b7307d51f47fe9312d7382d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='43ce092d-964e-419e-bd1b-7c92c14cc592', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d4ee013988166fe2cb1cbd8b1dead1f1d59922ab0ba0e9ca03cc3bf008c573a4')}, text='WereporttheaverageofPIQA(Bisketal.,2020),SIQA(Sapetal.,2019),\\nHellaSwag (Zellers et al., 2019a), WinoGrande (Sakaguchi et al., 2021), ARC easy and challenge\\n(Clark et al., 2018), OpenBookQA (Mihaylov et al., 2018), and CommonsenseQA (Talmor et al.,\\n2018). We report 7-shot results for CommonSenseQA and 0-shot results for all other benchmarks.\\n•WorldKnowledge.', start_char_idx=2513, end_char_idx=2873, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-6', obj=None),\n",
       " '43ce092d-964e-419e-bd1b-7c92c14cc592': IndexNode(id_='43ce092d-964e-419e-bd1b-7c92c14cc592', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f939a86f41587d042c4ebb4485546c18e5e7ab1ae86c405fb91ffacb1785593c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='e16a9315-cc4d-4b92-936c-3b6f033b6545', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='733bb4445a05722440df5456789b6fd7f9de8fe5d638cf388c55c7164af65dec'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='f741114b-aaa5-4951-a29d-12c2edfb3b72', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b99bc65e71136c9b4c74a438c56f1d9f589c0a1a7d6c581829a23e84c0eac33e')}, text='We report 7-shot results for CommonSenseQA and 0-shot results for all other benchmarks.\\n•WorldKnowledge. Weevaluatethe5-shotperformanceonNaturalQuestions(Kwiatkowskietal.,\\n2019) and TriviaQA (Joshi et al., 2017) and report the average.\\n•Reading Comprehension. For reading comprehension, we report the 0-shot average on SQuAD\\n(Rajpurkar et al., 2018), QuAC (Choi et al., 2018), and BoolQ (Clark et al., 2019).', start_char_idx=2769, end_char_idx=3177, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-6', obj=None),\n",
       " 'f741114b-aaa5-4951-a29d-12c2edfb3b72': IndexNode(id_='f741114b-aaa5-4951-a29d-12c2edfb3b72', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f939a86f41587d042c4ebb4485546c18e5e7ab1ae86c405fb91ffacb1785593c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='43ce092d-964e-419e-bd1b-7c92c14cc592', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d4ee013988166fe2cb1cbd8b1dead1f1d59922ab0ba0e9ca03cc3bf008c573a4'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='fc28973f-3b0a-4e12-a162-d5444a478341', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='30beafed94a7b56f09fe14be1e8272b78f30ba3049da11b6e57b353fcd0a1785')}, text='Weevaluatethe5-shotperformanceonNaturalQuestions(Kwiatkowskietal.,\\n2019) and TriviaQA (Joshi et al., 2017) and report the average.\\n•Reading Comprehension. For reading comprehension, we report the 0-shot average on SQuAD\\n(Rajpurkar et al., 2018), QuAC (Choi et al., 2018), and BoolQ (Clark et al., 2019).\\n•MATH.', start_char_idx=2874, end_char_idx=3184, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-6', obj=None),\n",
       " 'fc28973f-3b0a-4e12-a162-d5444a478341': IndexNode(id_='fc28973f-3b0a-4e12-a162-d5444a478341', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f939a86f41587d042c4ebb4485546c18e5e7ab1ae86c405fb91ffacb1785593c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='f741114b-aaa5-4951-a29d-12c2edfb3b72', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b99bc65e71136c9b4c74a438c56f1d9f589c0a1a7d6c581829a23e84c0eac33e')}, text='•Reading Comprehension. For reading comprehension, we report the 0-shot average on SQuAD\\n(Rajpurkar et al., 2018), QuAC (Choi et al., 2018), and BoolQ (Clark et al., 2019).\\n•MATH. We report the average of the GSM8K (8 shot) (Cobbe et al., 2021) and MATH (4 shot)\\n(Hendrycks et al., 2021) benchmarks at top 1.', start_char_idx=3005, end_char_idx=3313, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-6', obj=None),\n",
       " '68ace994-8457-4696-a367-3d7a368679cf': IndexNode(id_='68ace994-8457-4696-a367-3d7a368679cf', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f939a86f41587d042c4ebb4485546c18e5e7ab1ae86c405fb91ffacb1785593c'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='1da3c068-355c-4cfc-8be2-f8a59a02b066', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='adf7450733c6576da7b59d7a6f28c8c6cbd3499d9604a1775ce27b6c8f0a6c71')}, text='Power\\nConsumption: peak power capacity per GPU device for the GPUs used adjusted for power usage efficiency.\\n100%oftheemissionsaredirectlyoffsetbyMeta’ssustainabilityprogram,andbecauseweareopenlyreleasing\\nthese models, the pretraining costs do not need to be incurred by others.\\ncan scale almost as well as expensive Infiniband up to 2000 GPUs, which makes pretraining even more\\ndemocratizable.\\nCarbon Footprint of Pretraining. Following preceding research (Bender et al., 2021a; Patterson et al., 2021;\\nWu et al., 2022; Dodge et al., 2022) and using power consumption estimates of GPU devices and carbon\\nefficiency, we aim tocalculate thecarbon emissions resultingfrom the pretrainingof Llama 2 models. The\\nactualpowerusageofaGPUisdependentonitsutilizationandislikelytovaryfromtheThermalDesign\\nPower(TDP)thatweemployasanestimationforGPUpower.', start_char_idx=0, end_char_idx=843, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-6', obj=None),\n",
       " '1da3c068-355c-4cfc-8be2-f8a59a02b066': IndexNode(id_='1da3c068-355c-4cfc-8be2-f8a59a02b066', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f939a86f41587d042c4ebb4485546c18e5e7ab1ae86c405fb91ffacb1785593c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='68ace994-8457-4696-a367-3d7a368679cf', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f26fa7140db2f68011cc891c13898d2a85c5fc0bdf583a728cbcc405b0e2c87c'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='cc0083fb-cbe4-4474-8fd9-3221222fea98', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='582a6707354ba0b0bc60f6f67fdac86d8c3a283108b70f7913f97ba0a2e21ec9')}, text='The\\nactualpowerusageofaGPUisdependentonitsutilizationandislikelytovaryfromtheThermalDesign\\nPower(TDP)thatweemployasanestimationforGPUpower. Itisimportanttonotethatourcalculations\\ndo not account for further power demands, such as those from interconnect or non-GPU server power\\nconsumption,norfromdatacentercoolingsystems. Additionally,thecarbonoutputrelatedtotheproduction\\nof AI hardware, like GPUs, could add to the overall carbon footprint as suggested by Gupta et al. (2022b,a).\\nTable 2 summarizes the carbon emission for pretraining the Llama 2 family of models. A cumulative of\\n3.3M GPUhours ofcomputation wasperformed onhardware oftype A100-80GB (TDPof 400Wor 350W).\\nWe estimate the total emissions for training to be 539 tCO 2eq, of which 100% were directly offset by Meta’s\\nsustainability program.∗∗Our open release strategy also means that these pretraining costs will not need to\\nbe incurred by other companies, saving more global resources.', start_char_idx=704, end_char_idx=1655, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-6', obj=None),\n",
       " 'cc0083fb-cbe4-4474-8fd9-3221222fea98': IndexNode(id_='cc0083fb-cbe4-4474-8fd9-3221222fea98', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f939a86f41587d042c4ebb4485546c18e5e7ab1ae86c405fb91ffacb1785593c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='1da3c068-355c-4cfc-8be2-f8a59a02b066', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='adf7450733c6576da7b59d7a6f28c8c6cbd3499d9604a1775ce27b6c8f0a6c71'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='6f9d36b7-1c1a-4181-824b-04ff8f9b7919', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b4e31ce25634c6080caad54a75d9a6bca05709ed0cef1146036b2905cac18507')}, text='We estimate the total emissions for training to be 539 tCO 2eq, of which 100% were directly offset by Meta’s\\nsustainability program.∗∗Our open release strategy also means that these pretraining costs will not need to\\nbe incurred by other companies, saving more global resources.\\n2.3 Llama 2 Pretrained Model Evaluation\\nIn this section, we report the results for the Llama 1 andLlama 2 base models, MosaicML Pretrained\\nTransformer(MPT)††models,andFalcon(Almazroueietal.,2023)modelsonstandardacademicbenchmarks.\\nFor all the evaluations, we use our internal evaluations library. We reproduce results for the MPT and Falcon\\nmodelsinternally. Forthesemodels,wealwayspickthebestscorebetweenourevaluationframeworkand\\nany publicly reported results.\\nInTable3,wesummarizetheoverallperformanceacrossasuiteofpopularbenchmarks. Notethatsafety\\nbenchmarks are shared in Section 4.1. The benchmarks are grouped into the categories listed below. The\\nresults for all the individual benchmarks are available in Section A.2.2.', start_char_idx=1377, end_char_idx=2383, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-6', obj=None),\n",
       " '6f9d36b7-1c1a-4181-824b-04ff8f9b7919': IndexNode(id_='6f9d36b7-1c1a-4181-824b-04ff8f9b7919', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f939a86f41587d042c4ebb4485546c18e5e7ab1ae86c405fb91ffacb1785593c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='cc0083fb-cbe4-4474-8fd9-3221222fea98', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='582a6707354ba0b0bc60f6f67fdac86d8c3a283108b70f7913f97ba0a2e21ec9'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='37bdfe17-22ad-4ca7-8d92-8cac72236de7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1cd6a6c4b7a5066e270bdb7d41db09800548fb305704129465ca22a5e76cebac')}, text='Forthesemodels,wealwayspickthebestscorebetweenourevaluationframeworkand\\nany publicly reported results.\\nInTable3,wesummarizetheoverallperformanceacrossasuiteofpopularbenchmarks. Notethatsafety\\nbenchmarks are shared in Section 4.1. The benchmarks are grouped into the categories listed below. The\\nresults for all the individual benchmarks are available in Section A.2.2.\\n•Code.Wereporttheaveragepass@1scoresofourmodelsonHumanEval(Chenetal.,2021)and\\nMBPP (Austin et al., 2021).\\n•CommonsenseReasoning. WereporttheaverageofPIQA(Bisketal.,2020),SIQA(Sapetal.,2019),\\nHellaSwag (Zellers et al., 2019a), WinoGrande (Sakaguchi et al., 2021), ARC easy and challenge\\n(Clark et al., 2018), OpenBookQA (Mihaylov et al., 2018), and CommonsenseQA (Talmor et al.,\\n2018). We report 7-shot results for CommonSenseQA and 0-shot results for all other benchmarks.', start_char_idx=2015, end_char_idx=2856, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-6', obj=None),\n",
       " '37bdfe17-22ad-4ca7-8d92-8cac72236de7': IndexNode(id_='37bdfe17-22ad-4ca7-8d92-8cac72236de7', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f939a86f41587d042c4ebb4485546c18e5e7ab1ae86c405fb91ffacb1785593c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='6f9d36b7-1c1a-4181-824b-04ff8f9b7919', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b4e31ce25634c6080caad54a75d9a6bca05709ed0cef1146036b2905cac18507')}, text='We report 7-shot results for CommonSenseQA and 0-shot results for all other benchmarks.\\n•WorldKnowledge. Weevaluatethe5-shotperformanceonNaturalQuestions(Kwiatkowskietal.,\\n2019) and TriviaQA (Joshi et al., 2017) and report the average.\\n•Reading Comprehension. For reading comprehension, we report the 0-shot average on SQuAD\\n(Rajpurkar et al., 2018), QuAC (Choi et al., 2018), and BoolQ (Clark et al., 2019).\\n•MATH. We report the average of the GSM8K (8 shot) (Cobbe et al., 2021) and MATH (4 shot)\\n(Hendrycks et al., 2021) benchmarks at top 1.', start_char_idx=2769, end_char_idx=3313, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-6', obj=None),\n",
       " '0a11b615-403d-485a-84c5-15134934efac': IndexNode(id_='0a11b615-403d-485a-84c5-15134934efac', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f939a86f41587d042c4ebb4485546c18e5e7ab1ae86c405fb91ffacb1785593c'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='9c06b4d8-f821-4148-8f36-b551b040244a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='94bb8b2db13a18ea48b2e39a896d580467eea59ba71629af6504fd7747b2f48b')}, text='Power\\nConsumption: peak power capacity per GPU device for the GPUs used adjusted for power usage efficiency.\\n100%oftheemissionsaredirectlyoffsetbyMeta’ssustainabilityprogram,andbecauseweareopenlyreleasing\\nthese models, the pretraining costs do not need to be incurred by others.\\ncan scale almost as well as expensive Infiniband up to 2000 GPUs, which makes pretraining even more\\ndemocratizable.\\nCarbon Footprint of Pretraining. Following preceding research (Bender et al., 2021a; Patterson et al., 2021;\\nWu et al., 2022; Dodge et al., 2022) and using power consumption estimates of GPU devices and carbon\\nefficiency, we aim tocalculate thecarbon emissions resultingfrom the pretrainingof Llama 2 models. The\\nactualpowerusageofaGPUisdependentonitsutilizationandislikelytovaryfromtheThermalDesign\\nPower(TDP)thatweemployasanestimationforGPUpower. Itisimportanttonotethatourcalculations\\ndo not account for further power demands, such as those from interconnect or non-GPU server power\\nconsumption,norfromdatacentercoolingsystems. Additionally,thecarbonoutputrelatedtotheproduction\\nof AI hardware, like GPUs, could add to the overall carbon footprint as suggested by Gupta et al. (2022b,a).\\nTable 2 summarizes the carbon emission for pretraining the Llama 2 family of models. A cumulative of\\n3.3M GPUhours ofcomputation wasperformed onhardware oftype A100-80GB (TDPof 400Wor 350W).\\nWe estimate the total emissions for training to be 539 tCO 2eq, of which 100% were directly offset by Meta’s\\nsustainability program.∗∗Our open release strategy also means that these pretraining costs will not need to\\nbe incurred by other companies, saving more global resources.\\n2.3 Llama 2 Pretrained Model Evaluation\\nIn this section, we report the results for the Llama 1 andLlama 2 base models, MosaicML Pretrained\\nTransformer(MPT)††models,andFalcon(Almazroueietal.,2023)modelsonstandardacademicbenchmarks.\\nFor all the evaluations, we use our internal evaluations library.', start_char_idx=0, end_char_idx=1952, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-6', obj=None),\n",
       " '9c06b4d8-f821-4148-8f36-b551b040244a': IndexNode(id_='9c06b4d8-f821-4148-8f36-b551b040244a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f939a86f41587d042c4ebb4485546c18e5e7ab1ae86c405fb91ffacb1785593c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='0a11b615-403d-485a-84c5-15134934efac', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f768017d161cf89e0854f0ef0eaf3cd0ae333af3541d6d6ab3cffeac708695b8')}, text='2.3 Llama 2 Pretrained Model Evaluation\\nIn this section, we report the results for the Llama 1 andLlama 2 base models, MosaicML Pretrained\\nTransformer(MPT)††models,andFalcon(Almazroueietal.,2023)modelsonstandardacademicbenchmarks.\\nFor all the evaluations, we use our internal evaluations library. We reproduce results for the MPT and Falcon\\nmodelsinternally. Forthesemodels,wealwayspickthebestscorebetweenourevaluationframeworkand\\nany publicly reported results.\\nInTable3,wesummarizetheoverallperformanceacrossasuiteofpopularbenchmarks. Notethatsafety\\nbenchmarks are shared in Section 4.1. The benchmarks are grouped into the categories listed below. The\\nresults for all the individual benchmarks are available in Section A.2.2.\\n•Code.Wereporttheaveragepass@1scoresofourmodelsonHumanEval(Chenetal.,2021)and\\nMBPP (Austin et al., 2021).\\n•CommonsenseReasoning. WereporttheaverageofPIQA(Bisketal.,2020),SIQA(Sapetal.,2019),\\nHellaSwag (Zellers et al., 2019a), WinoGrande (Sakaguchi et al., 2021), ARC easy and challenge\\n(Clark et al., 2018), OpenBookQA (Mihaylov et al., 2018), and CommonsenseQA (Talmor et al.,\\n2018). We report 7-shot results for CommonSenseQA and 0-shot results for all other benchmarks.\\n•WorldKnowledge. Weevaluatethe5-shotperformanceonNaturalQuestions(Kwiatkowskietal.,\\n2019) and TriviaQA (Joshi et al., 2017) and report the average.\\n•Reading Comprehension. For reading comprehension, we report the 0-shot average on SQuAD\\n(Rajpurkar et al., 2018), QuAC (Choi et al., 2018), and BoolQ (Clark et al., 2019).\\n•MATH. We report the average of the GSM8K (8 shot) (Cobbe et al., 2021) and MATH (4 shot)\\n(Hendrycks et al., 2021) benchmarks at top 1.', start_char_idx=1656, end_char_idx=3313, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-6', obj=None),\n",
       " 'node-6': IndexNode(id_='node-6', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='d03f19eb-da15-45dc-bfd4-e5d10f161250', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='231b3bd773f012c01b893ada9e009ecf25ee59934614c5a595c9bf1b3a123292'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='fb1c6ca2-1368-4801-97ae-b3601cf02add', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='71425b8142ea545e20b0d1f0ca219c7d3d5df4ebf95216ffef2b33804bd13d29'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='0e080b04-d893-4a8b-8e17-5305f394df10', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='704f4d4a17a97f3e3c3d33053c6ff7db5a788fc6c0b8d37b7b41d39aff4f9432')}, text='Power\\nConsumption: peak power capacity per GPU device for the GPUs used adjusted for power usage efficiency.\\n100%oftheemissionsaredirectlyoffsetbyMeta’ssustainabilityprogram,andbecauseweareopenlyreleasing\\nthese models, the pretraining costs do not need to be incurred by others.\\ncan scale almost as well as expensive Infiniband up to 2000 GPUs, which makes pretraining even more\\ndemocratizable.\\nCarbon Footprint of Pretraining. Following preceding research (Bender et al., 2021a; Patterson et al., 2021;\\nWu et al., 2022; Dodge et al., 2022) and using power consumption estimates of GPU devices and carbon\\nefficiency, we aim tocalculate thecarbon emissions resultingfrom the pretrainingof Llama 2 models. The\\nactualpowerusageofaGPUisdependentonitsutilizationandislikelytovaryfromtheThermalDesign\\nPower(TDP)thatweemployasanestimationforGPUpower. Itisimportanttonotethatourcalculations\\ndo not account for further power demands, such as those from interconnect or non-GPU server power\\nconsumption,norfromdatacentercoolingsystems. Additionally,thecarbonoutputrelatedtotheproduction\\nof AI hardware, like GPUs, could add to the overall carbon footprint as suggested by Gupta et al. (2022b,a).\\nTable 2 summarizes the carbon emission for pretraining the Llama 2 family of models. A cumulative of\\n3.3M GPUhours ofcomputation wasperformed onhardware oftype A100-80GB (TDPof 400Wor 350W).\\nWe estimate the total emissions for training to be 539 tCO 2eq, of which 100% were directly offset by Meta’s\\nsustainability program.∗∗Our open release strategy also means that these pretraining costs will not need to\\nbe incurred by other companies, saving more global resources.\\n2.3 Llama 2 Pretrained Model Evaluation\\nIn this section, we report the results for the Llama 1 andLlama 2 base models, MosaicML Pretrained\\nTransformer(MPT)††models,andFalcon(Almazroueietal.,2023)modelsonstandardacademicbenchmarks.\\nFor all the evaluations, we use our internal evaluations library. We reproduce results for the MPT and Falcon\\nmodelsinternally. Forthesemodels,wealwayspickthebestscorebetweenourevaluationframeworkand\\nany publicly reported results.\\nInTable3,wesummarizetheoverallperformanceacrossasuiteofpopularbenchmarks. Notethatsafety\\nbenchmarks are shared in Section 4.1. The benchmarks are grouped into the categories listed below. The\\nresults for all the individual benchmarks are available in Section A.2.2.\\n•Code.Wereporttheaveragepass@1scoresofourmodelsonHumanEval(Chenetal.,2021)and\\nMBPP (Austin et al., 2021).\\n•CommonsenseReasoning. WereporttheaverageofPIQA(Bisketal.,2020),SIQA(Sapetal.,2019),\\nHellaSwag (Zellers et al., 2019a), WinoGrande (Sakaguchi et al., 2021), ARC easy and challenge\\n(Clark et al., 2018), OpenBookQA (Mihaylov et al., 2018), and CommonsenseQA (Talmor et al.,\\n2018). We report 7-shot results for CommonSenseQA and 0-shot results for all other benchmarks.\\n•WorldKnowledge. Weevaluatethe5-shotperformanceonNaturalQuestions(Kwiatkowskietal.,\\n2019) and TriviaQA (Joshi et al., 2017) and report the average.\\n•Reading Comprehension. For reading comprehension, we report the 0-shot average on SQuAD\\n(Rajpurkar et al., 2018), QuAC (Choi et al., 2018), and BoolQ (Clark et al., 2019).\\n•MATH. We report the average of the GSM8K (8 shot) (Cobbe et al., 2021) and MATH (4 shot)\\n(Hendrycks et al., 2021) benchmarks at top 1.', start_char_idx=15203, end_char_idx=18516, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-6', obj=None),\n",
       " 'ab7c66e2-5df2-42a5-ad41-7f595020a01d': IndexNode(id_='ab7c66e2-5df2-42a5-ad41-7f595020a01d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='704f4d4a17a97f3e3c3d33053c6ff7db5a788fc6c0b8d37b7b41d39aff4f9432'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='b14d3f42-762c-48ce-9343-3272868380d7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c5a9764e5037ed114c190303f3a751fedefd7ac20791251dbc160aa6de81b98c')}, text='•MATH. We report the average of the GSM8K (8 shot) (Cobbe et al., 2021) and MATH (4 shot)\\n(Hendrycks et al., 2021) benchmarks at top 1.\\n∗∗https://sustainability.fb.com/2021-sustainability-report/\\n††https://www.mosaicml.com/blog/mpt-7b\\n7\\n\\nModel Size CodeCommonsense\\nReasoningWorld\\nKnowledgeReading\\nComprehensionMath MMLU BBH AGI Eval\\nMPT7B 20.', start_char_idx=0, end_char_idx=342, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-7', obj=None),\n",
       " 'b14d3f42-762c-48ce-9343-3272868380d7': IndexNode(id_='b14d3f42-762c-48ce-9343-3272868380d7', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='704f4d4a17a97f3e3c3d33053c6ff7db5a788fc6c0b8d37b7b41d39aff4f9432'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='ab7c66e2-5df2-42a5-ad41-7f595020a01d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f53abdea7c9aeb7c310209567ccc41059131dd1368f951c7be3acf37e1d4cd37'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='e51207fb-c945-4255-8201-65fe4d553c96', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7c891bdb7de7c33ef7ac39fbd2cce82d4d19e4a2f7690a01ecf02408802585fe')}, text='∗∗https://sustainability.fb.com/2021-sustainability-report/\\n††https://www.mosaicml.com/blog/mpt-7b\\n7\\n\\nModel Size CodeCommonsense\\nReasoningWorld\\nKnowledgeReading\\nComprehensionMath MMLU BBH AGI Eval\\nMPT7B 20.5 57.4 41.0 57.5 4.9 26.8 31.0 23.5\\n30B 28.9 64.9 50.0 64.7 9.1 46.', start_char_idx=136, end_char_idx=409, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-7', obj=None),\n",
       " 'e51207fb-c945-4255-8201-65fe4d553c96': IndexNode(id_='e51207fb-c945-4255-8201-65fe4d553c96', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='704f4d4a17a97f3e3c3d33053c6ff7db5a788fc6c0b8d37b7b41d39aff4f9432'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='b14d3f42-762c-48ce-9343-3272868380d7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c5a9764e5037ed114c190303f3a751fedefd7ac20791251dbc160aa6de81b98c'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='264e7f54-b510-493c-9813-2dbbb62964c8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f6d57b29aaad58ff7f3a6f50d0be87cbe4a89f462b24694db78225a99f6308dc')}, text='com/blog/mpt-7b\\n7\\n\\nModel Size CodeCommonsense\\nReasoningWorld\\nKnowledgeReading\\nComprehensionMath MMLU BBH AGI Eval\\nMPT7B 20.5 57.4 41.0 57.5 4.9 26.8 31.0 23.5\\n30B 28.9 64.9 50.0 64.7 9.1 46.9 38.0 33.8\\nFalcon7B 5.6 56.1 42.8 36.', start_char_idx=219, end_char_idx=447, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-7', obj=None),\n",
       " '264e7f54-b510-493c-9813-2dbbb62964c8': IndexNode(id_='264e7f54-b510-493c-9813-2dbbb62964c8', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='704f4d4a17a97f3e3c3d33053c6ff7db5a788fc6c0b8d37b7b41d39aff4f9432'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='e51207fb-c945-4255-8201-65fe4d553c96', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7c891bdb7de7c33ef7ac39fbd2cce82d4d19e4a2f7690a01ecf02408802585fe'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='749f5da5-06c0-49ec-9f14-07a53c700c9a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d25fc4c409c70b9f80b8fdeccfd99193d6c5019848d4e40fb80a02859c0be4ab')}, text='5 57.4 41.0 57.5 4.9 26.8 31.0 23.5\\n30B 28.9 64.9 50.0 64.7 9.1 46.9 38.0 33.8\\nFalcon7B 5.6 56.1 42.8 36.0 4.6 26.2 28.0 21.2\\n40B 15.2 69.2 56.7 65.7 12.6 55.', start_char_idx=342, end_char_idx=500, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-7', obj=None),\n",
       " '749f5da5-06c0-49ec-9f14-07a53c700c9a': IndexNode(id_='749f5da5-06c0-49ec-9f14-07a53c700c9a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='704f4d4a17a97f3e3c3d33053c6ff7db5a788fc6c0b8d37b7b41d39aff4f9432'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='264e7f54-b510-493c-9813-2dbbb62964c8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f6d57b29aaad58ff7f3a6f50d0be87cbe4a89f462b24694db78225a99f6308dc'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='14f2f5cd-035d-46ce-b697-55cbe35caa69', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='12c52dc98196c50a6055cc5b90fafc6c58662b26b1444db9be61bad810a8254a')}, text='5\\n30B 28.9 64.9 50.0 64.7 9.1 46.9 38.0 33.8\\nFalcon7B 5.6 56.1 42.8 36.0 4.6 26.2 28.0 21.2\\n40B 15.2 69.2 56.7 65.7 12.6 55.4 37.1 37.0\\nLlama 17B 14.1 60.8 46.', start_char_idx=376, end_char_idx=535, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-7', obj=None),\n",
       " '14f2f5cd-035d-46ce-b697-55cbe35caa69': IndexNode(id_='14f2f5cd-035d-46ce-b697-55cbe35caa69', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='704f4d4a17a97f3e3c3d33053c6ff7db5a788fc6c0b8d37b7b41d39aff4f9432'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='749f5da5-06c0-49ec-9f14-07a53c700c9a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d25fc4c409c70b9f80b8fdeccfd99193d6c5019848d4e40fb80a02859c0be4ab'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='e1a260a1-e530-4876-8680-c1733a9df6db', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7ba7a295a226b07a73bd438af6cfbf8b1489cc5b19e092060ec19e3dedb3c97c')}, text='9 38.0 33.8\\nFalcon7B 5.6 56.1 42.8 36.0 4.6 26.2 28.0 21.2\\n40B 15.2 69.2 56.7 65.7 12.6 55.4 37.1 37.0\\nLlama 17B 14.1 60.8 46.2 58.5 6.95 35.1 30.3 23.9\\n13B 18.', start_char_idx=409, end_char_idx=569, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-7', obj=None),\n",
       " 'e1a260a1-e530-4876-8680-c1733a9df6db': IndexNode(id_='e1a260a1-e530-4876-8680-c1733a9df6db', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='704f4d4a17a97f3e3c3d33053c6ff7db5a788fc6c0b8d37b7b41d39aff4f9432'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='14f2f5cd-035d-46ce-b697-55cbe35caa69', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='12c52dc98196c50a6055cc5b90fafc6c58662b26b1444db9be61bad810a8254a'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='1819f977-fe97-4143-8a9b-e877322f7b2c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='78425ed6c391e493baad6fdd02999731a72da9fedfc1e795766b3f4e0a5db339')}, text='8 36.0 4.6 26.2 28.0 21.2\\n40B 15.2 69.2 56.7 65.7 12.6 55.4 37.1 37.0\\nLlama 17B 14.1 60.8 46.2 58.5 6.95 35.1 30.3 23.9\\n13B 18.9 66.1 52.6 62.3 10.9 46.9 37.0 33.', start_char_idx=442, end_char_idx=604, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-7', obj=None),\n",
       " '1819f977-fe97-4143-8a9b-e877322f7b2c': IndexNode(id_='1819f977-fe97-4143-8a9b-e877322f7b2c', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='704f4d4a17a97f3e3c3d33053c6ff7db5a788fc6c0b8d37b7b41d39aff4f9432'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='e1a260a1-e530-4876-8680-c1733a9df6db', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7ba7a295a226b07a73bd438af6cfbf8b1489cc5b19e092060ec19e3dedb3c97c'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='760df478-74ef-4a25-80c5-4abb6be76a57', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6f7fddef644b24058623e7ffcd9a840224cac77a69f898e65c7f713b3e7256cb')}, text='2 56.7 65.7 12.6 55.4 37.1 37.0\\nLlama 17B 14.1 60.8 46.2 58.5 6.95 35.1 30.3 23.9\\n13B 18.9 66.1 52.6 62.3 10.9 46.9 37.0 33.9\\n33B 26.0 70.0 58.4 67.6 21.4 57.8 39.', start_char_idx=480, end_char_idx=643, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-7', obj=None),\n",
       " '760df478-74ef-4a25-80c5-4abb6be76a57': IndexNode(id_='760df478-74ef-4a25-80c5-4abb6be76a57', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='704f4d4a17a97f3e3c3d33053c6ff7db5a788fc6c0b8d37b7b41d39aff4f9432'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='1819f977-fe97-4143-8a9b-e877322f7b2c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='78425ed6c391e493baad6fdd02999731a72da9fedfc1e795766b3f4e0a5db339'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='fa07ef6b-ca7e-45be-9078-00a84ab99206', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='08167cce1ed6b9067fe665f4f5bec913528ceb747ee4b6609d2d8a585dccb933')}, text='1 60.8 46.2 58.5 6.95 35.1 30.3 23.9\\n13B 18.9 66.1 52.6 62.3 10.9 46.9 37.0 33.9\\n33B 26.0 70.0 58.4 67.6 21.4 57.8 39.8 41.7\\n65B 30.7 70.7 60.5 68.6 30.8 63.', start_char_idx=525, end_char_idx=682, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-7', obj=None),\n",
       " 'fa07ef6b-ca7e-45be-9078-00a84ab99206': IndexNode(id_='fa07ef6b-ca7e-45be-9078-00a84ab99206', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='704f4d4a17a97f3e3c3d33053c6ff7db5a788fc6c0b8d37b7b41d39aff4f9432'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='760df478-74ef-4a25-80c5-4abb6be76a57', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6f7fddef644b24058623e7ffcd9a840224cac77a69f898e65c7f713b3e7256cb'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='a0ec656d-faf9-46c4-bfa6-529244101885', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='36886d0d08b5ac13b0ae1f1826a8c332c53b39038f6f9db39847db2059ef3844')}, text='9\\n13B 18.9 66.1 52.6 62.3 10.9 46.9 37.0 33.9\\n33B 26.0 70.0 58.4 67.6 21.4 57.8 39.8 41.7\\n65B 30.7 70.7 60.5 68.6 30.8 63.4 43.5 47.6\\nLlama 27B 16.8 63.9 48.9 61.', start_char_idx=560, end_char_idx=722, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-7', obj=None),\n",
       " 'a0ec656d-faf9-46c4-bfa6-529244101885': IndexNode(id_='a0ec656d-faf9-46c4-bfa6-529244101885', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='704f4d4a17a97f3e3c3d33053c6ff7db5a788fc6c0b8d37b7b41d39aff4f9432'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='fa07ef6b-ca7e-45be-9078-00a84ab99206', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='08167cce1ed6b9067fe665f4f5bec913528ceb747ee4b6609d2d8a585dccb933'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='cb62b4f4-e9a3-4759-9473-679b37fbd3d4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8a74badb537c77779755ebc4488bc47c2248fbe90854b46915da54531f8318de')}, text='9 37.0 33.9\\n33B 26.0 70.0 58.4 67.6 21.4 57.8 39.8 41.7\\n65B 30.7 70.7 60.5 68.6 30.8 63.4 43.5 47.6\\nLlama 27B 16.8 63.9 48.9 61.3 14.6 45.3 32.6 29.3\\n13B 24.5 66.', start_char_idx=594, end_char_idx=756, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-7', obj=None),\n",
       " 'cb62b4f4-e9a3-4759-9473-679b37fbd3d4': IndexNode(id_='cb62b4f4-e9a3-4759-9473-679b37fbd3d4', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='704f4d4a17a97f3e3c3d33053c6ff7db5a788fc6c0b8d37b7b41d39aff4f9432'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='a0ec656d-faf9-46c4-bfa6-529244101885', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='36886d0d08b5ac13b0ae1f1826a8c332c53b39038f6f9db39847db2059ef3844'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='f3bdee76-806e-4547-9765-46a610b2340b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3d8d5d049d37001c93afd648b8ba0e3d4cd23786de9d12b182eeb6f1be777ad7')}, text='6 21.4 57.8 39.8 41.7\\n65B 30.7 70.7 60.5 68.6 30.8 63.4 43.5 47.6\\nLlama 27B 16.8 63.9 48.9 61.3 14.6 45.3 32.6 29.3\\n13B 24.5 66.9 55.4 65.8 28.7 54.8 39.4 39.', start_char_idx=628, end_char_idx=786, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-7', obj=None),\n",
       " 'f3bdee76-806e-4547-9765-46a610b2340b': IndexNode(id_='f3bdee76-806e-4547-9765-46a610b2340b', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='704f4d4a17a97f3e3c3d33053c6ff7db5a788fc6c0b8d37b7b41d39aff4f9432'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='cb62b4f4-e9a3-4759-9473-679b37fbd3d4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8a74badb537c77779755ebc4488bc47c2248fbe90854b46915da54531f8318de'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='e56e0f58-bd93-454b-8c56-a05574b1f78c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='71f9fc7cc3bc1031af79a2fbdfb38e9bdffc4b90a7b85d0b1d4e5f84172aff37')}, text='7 60.5 68.6 30.8 63.4 43.5 47.6\\nLlama 27B 16.8 63.9 48.9 61.3 14.6 45.3 32.6 29.3\\n13B 24.5 66.9 55.4 65.8 28.7 54.8 39.4 39.1\\n34B 27.8 69.9 58.7 68.0 24.2 62.6 44.', start_char_idx=662, end_char_idx=825, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-7', obj=None),\n",
       " 'e56e0f58-bd93-454b-8c56-a05574b1f78c': IndexNode(id_='e56e0f58-bd93-454b-8c56-a05574b1f78c', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='704f4d4a17a97f3e3c3d33053c6ff7db5a788fc6c0b8d37b7b41d39aff4f9432'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='f3bdee76-806e-4547-9765-46a610b2340b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3d8d5d049d37001c93afd648b8ba0e3d4cd23786de9d12b182eeb6f1be777ad7'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='90eca814-eef6-4e46-9f02-083dd7932ed2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='671064e4b4bc73eba392680c2f4c63290501760ede25eef38152072ac20196ed')}, text='8 63.9 48.9 61.3 14.6 45.3 32.6 29.3\\n13B 24.5 66.9 55.4 65.8 28.7 54.8 39.4 39.1\\n34B 27.8 69.9 58.7 68.0 24.2 62.6 44.1 43.4\\n70B37.5 71.9 63.6 69.4 35.2 68.9 51.', start_char_idx=707, end_char_idx=868, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-7', obj=None),\n",
       " '90eca814-eef6-4e46-9f02-083dd7932ed2': IndexNode(id_='90eca814-eef6-4e46-9f02-083dd7932ed2', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='704f4d4a17a97f3e3c3d33053c6ff7db5a788fc6c0b8d37b7b41d39aff4f9432'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='e56e0f58-bd93-454b-8c56-a05574b1f78c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='71f9fc7cc3bc1031af79a2fbdfb38e9bdffc4b90a7b85d0b1d4e5f84172aff37'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='412888d7-f00e-49d5-80c4-324d1b43bbc4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3496872fa7f0d89e1888c2da048423e84a911606b7061bbfc2b0b5060d7fbcfc')}, text='3\\n13B 24.5 66.9 55.4 65.8 28.7 54.8 39.4 39.1\\n34B 27.8 69.9 58.7 68.0 24.2 62.6 44.1 43.4\\n70B37.5 71.9 63.6 69.4 35.2 68.9 51.2 54.2\\nTable3: Overallperformanceongroupedacademicbenchmarkscomparedtoopen-sourcebasemodels.', start_char_idx=742, end_char_idx=960, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-7', obj=None),\n",
       " '412888d7-f00e-49d5-80c4-324d1b43bbc4': IndexNode(id_='412888d7-f00e-49d5-80c4-324d1b43bbc4', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='704f4d4a17a97f3e3c3d33053c6ff7db5a788fc6c0b8d37b7b41d39aff4f9432'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='90eca814-eef6-4e46-9f02-083dd7932ed2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='671064e4b4bc73eba392680c2f4c63290501760ede25eef38152072ac20196ed'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='9492e2e4-6b33-4e32-8feb-19097cbf9429', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7490ed4be31c6a1cb0706d42facbc32ee9f926313be885ce507730f73557dc30')}, text='8 39.4 39.1\\n34B 27.8 69.9 58.7 68.0 24.2 62.6 44.1 43.4\\n70B37.5 71.9 63.6 69.4 35.2 68.9 51.2 54.2\\nTable3: Overallperformanceongroupedacademicbenchmarkscomparedtoopen-sourcebasemodels.\\n•Popular Aggregated Benchmarks .', start_char_idx=776, end_char_idx=993, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-7', obj=None),\n",
       " '9492e2e4-6b33-4e32-8feb-19097cbf9429': IndexNode(id_='9492e2e4-6b33-4e32-8feb-19097cbf9429', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='704f4d4a17a97f3e3c3d33053c6ff7db5a788fc6c0b8d37b7b41d39aff4f9432'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='412888d7-f00e-49d5-80c4-324d1b43bbc4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3496872fa7f0d89e1888c2da048423e84a911606b7061bbfc2b0b5060d7fbcfc'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='45638cc2-a23c-42b6-95c0-ef447d300cb9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0c9fdd3261cd7401f5e57b7ce50e07e309c5b091ccb50297454c039655d83f7f')}, text='1\\n34B 27.8 69.9 58.7 68.0 24.2 62.6 44.1 43.4\\n70B37.5 71.9 63.6 69.4 35.2 68.9 51.2 54.2\\nTable3: Overallperformanceongroupedacademicbenchmarkscomparedtoopen-sourcebasemodels.\\n•Popular Aggregated Benchmarks . We report the overall results for MMLU (5 shot) (Hendrycks\\net al., 2020), Big Bench Hard (BBH) (3 shot) (Suzgun et al., 2022), and AGI Eval (3–5 shot) (Zhong\\net al., 2023).', start_char_idx=786, end_char_idx=1166, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-7', obj=None),\n",
       " '45638cc2-a23c-42b6-95c0-ef447d300cb9': IndexNode(id_='45638cc2-a23c-42b6-95c0-ef447d300cb9', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='704f4d4a17a97f3e3c3d33053c6ff7db5a788fc6c0b8d37b7b41d39aff4f9432'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='9492e2e4-6b33-4e32-8feb-19097cbf9429', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7490ed4be31c6a1cb0706d42facbc32ee9f926313be885ce507730f73557dc30'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='3a401f9b-5cdc-4278-853c-7a15d1a07412', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='66e9a20331c42cf3d60175a73eb3cc9e1a08a21677c71c6b484b0d7542b874cf')}, text='•Popular Aggregated Benchmarks . We report the overall results for MMLU (5 shot) (Hendrycks\\net al., 2020), Big Bench Hard (BBH) (3 shot) (Suzgun et al., 2022), and AGI Eval (3–5 shot) (Zhong\\net al., 2023). For AGI Eval, we only evaluate on the English tasks and report the average.\\nAs shown in Table 3, Llama 2 models outperform Llama 1 models.', start_char_idx=961, end_char_idx=1305, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-7', obj=None),\n",
       " '3a401f9b-5cdc-4278-853c-7a15d1a07412': IndexNode(id_='3a401f9b-5cdc-4278-853c-7a15d1a07412', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='704f4d4a17a97f3e3c3d33053c6ff7db5a788fc6c0b8d37b7b41d39aff4f9432'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='45638cc2-a23c-42b6-95c0-ef447d300cb9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0c9fdd3261cd7401f5e57b7ce50e07e309c5b091ccb50297454c039655d83f7f'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='cf5c2b3d-ebd1-4f86-a023-5e1c7be5a8ba', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1dd86473df137549ee88547dd42372e546155e86b67a2ae3f6b4b6cb0ac0a5f2')}, text='For AGI Eval, we only evaluate on the English tasks and report the average.\\nAs shown in Table 3, Llama 2 models outperform Llama 1 models. In particular, Llama 2 70B improves the\\nresultsonMMLUandBBHby ≈5and≈8points,respectively,comparedto Llama 1 65B.Llama 2 7Band30B\\nmodelsoutperformMPTmodelsofthecorrespondingsizeonallcategoriesbesidescodebenchmarks.', start_char_idx=1167, end_char_idx=1519, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-7', obj=None),\n",
       " 'cf5c2b3d-ebd1-4f86-a023-5e1c7be5a8ba': IndexNode(id_='cf5c2b3d-ebd1-4f86-a023-5e1c7be5a8ba', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='704f4d4a17a97f3e3c3d33053c6ff7db5a788fc6c0b8d37b7b41d39aff4f9432'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='3a401f9b-5cdc-4278-853c-7a15d1a07412', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='66e9a20331c42cf3d60175a73eb3cc9e1a08a21677c71c6b484b0d7542b874cf'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='f6c243e8-29cb-44ba-94dd-964b563a319d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='751fb46beaae51d09186ddb7f662bf24315065de4fd2b159a6c9f385f1fe9278')}, text='As shown in Table 3, Llama 2 models outperform Llama 1 models. In particular, Llama 2 70B improves the\\nresultsonMMLUandBBHby ≈5and≈8points,respectively,comparedto Llama 1 65B.Llama 2 7Band30B\\nmodelsoutperformMPTmodelsofthecorrespondingsizeonallcategoriesbesidescodebenchmarks. Forthe\\nFalcon models, Llama 2 7B and 34B outperform Falcon 7B and 40B models on all categories of benchmarks.', start_char_idx=1243, end_char_idx=1629, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-7', obj=None),\n",
       " 'f6c243e8-29cb-44ba-94dd-964b563a319d': IndexNode(id_='f6c243e8-29cb-44ba-94dd-964b563a319d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='704f4d4a17a97f3e3c3d33053c6ff7db5a788fc6c0b8d37b7b41d39aff4f9432'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='cf5c2b3d-ebd1-4f86-a023-5e1c7be5a8ba', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1dd86473df137549ee88547dd42372e546155e86b67a2ae3f6b4b6cb0ac0a5f2'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='b3e6fccb-25ba-46c3-bb6e-e72bf08e91e4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='10e79a1ea26d41905386959816a93e2d259b8ad199f58d743723be184966fbe9')}, text='Forthe\\nFalcon models, Llama 2 7B and 34B outperform Falcon 7B and 40B models on all categories of benchmarks.\\nAdditionally, Llama 2 70B model outperforms all open-source models.\\nIn addition to open-source models, we also compare Llama 2 70B results to closed-source models.', start_char_idx=1520, end_char_idx=1793, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-7', obj=None),\n",
       " 'b3e6fccb-25ba-46c3-bb6e-e72bf08e91e4': IndexNode(id_='b3e6fccb-25ba-46c3-bb6e-e72bf08e91e4', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='704f4d4a17a97f3e3c3d33053c6ff7db5a788fc6c0b8d37b7b41d39aff4f9432'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='f6c243e8-29cb-44ba-94dd-964b563a319d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='751fb46beaae51d09186ddb7f662bf24315065de4fd2b159a6c9f385f1fe9278'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='443a1782-f593-4d47-a8b6-3d94d238b34c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e65ec389e285bcbb1ec4cdfa8e1bee25f41a20d8bb6f8674d3cc00206a30c430')}, text='Forthe\\nFalcon models, Llama 2 7B and 34B outperform Falcon 7B and 40B models on all categories of benchmarks.\\nAdditionally, Llama 2 70B model outperforms all open-source models.\\nIn addition to open-source models, we also compare Llama 2 70B results to closed-source models. As shown\\nin Table 4, Llama 2 70B is close to GPT-3.5 (OpenAI, 2023) on MMLU and GSM8K, but there is a significant\\ngaponcodingbenchmarks.', start_char_idx=1520, end_char_idx=1930, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-7', obj=None),\n",
       " '443a1782-f593-4d47-a8b6-3d94d238b34c': IndexNode(id_='443a1782-f593-4d47-a8b6-3d94d238b34c', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='704f4d4a17a97f3e3c3d33053c6ff7db5a788fc6c0b8d37b7b41d39aff4f9432'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='b3e6fccb-25ba-46c3-bb6e-e72bf08e91e4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='10e79a1ea26d41905386959816a93e2d259b8ad199f58d743723be184966fbe9'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='87da55b5-b4d1-4717-a359-7faa9947cd50', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='49adb68cff1a3a355fac5d0152e2f4aa1fe886352be871167bf3b5a3acc23eb8')}, text='Additionally, Llama 2 70B model outperforms all open-source models.\\nIn addition to open-source models, we also compare Llama 2 70B results to closed-source models. As shown\\nin Table 4, Llama 2 70B is close to GPT-3.5 (OpenAI, 2023) on MMLU and GSM8K, but there is a significant\\ngaponcodingbenchmarks. Llama 2 70BresultsareonparorbetterthanPaLM(540B)(Chowdheryetal.,\\n2022)onalmostallbenchmarks.', start_char_idx=1630, end_char_idx=2023, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-7', obj=None),\n",
       " '87da55b5-b4d1-4717-a359-7faa9947cd50': IndexNode(id_='87da55b5-b4d1-4717-a359-7faa9947cd50', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='704f4d4a17a97f3e3c3d33053c6ff7db5a788fc6c0b8d37b7b41d39aff4f9432'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='443a1782-f593-4d47-a8b6-3d94d238b34c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e65ec389e285bcbb1ec4cdfa8e1bee25f41a20d8bb6f8674d3cc00206a30c430'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='64204428-0e4a-4638-a8a5-19e532b216fe', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='22f9305d045cc6bd4e16686b65428a3b6c22c896a74d61325c2c077b7c514805')}, text='As shown\\nin Table 4, Llama 2 70B is close to GPT-3.5 (OpenAI, 2023) on MMLU and GSM8K, but there is a significant\\ngaponcodingbenchmarks. Llama 2 70BresultsareonparorbetterthanPaLM(540B)(Chowdheryetal.,\\n2022)onalmostallbenchmarks. Thereisstillalargegapinperformancebetween Llama 2 70BandGPT-4\\nand PaLM-2-L.', start_char_idx=1794, end_char_idx=2099, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-7', obj=None),\n",
       " '64204428-0e4a-4638-a8a5-19e532b216fe': IndexNode(id_='64204428-0e4a-4638-a8a5-19e532b216fe', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='704f4d4a17a97f3e3c3d33053c6ff7db5a788fc6c0b8d37b7b41d39aff4f9432'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='87da55b5-b4d1-4717-a359-7faa9947cd50', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='49adb68cff1a3a355fac5d0152e2f4aa1fe886352be871167bf3b5a3acc23eb8')}, text='Llama 2 70BresultsareonparorbetterthanPaLM(540B)(Chowdheryetal.,\\n2022)onalmostallbenchmarks. Thereisstillalargegapinperformancebetween Llama 2 70BandGPT-4\\nand PaLM-2-L.\\nWe also analysed the potential data contamination and share the details in Section A.6.', start_char_idx=1931, end_char_idx=2187, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-7', obj=None),\n",
       " '5ff50309-57dd-41be-9e3c-b735f799fb5d': IndexNode(id_='5ff50309-57dd-41be-9e3c-b735f799fb5d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='704f4d4a17a97f3e3c3d33053c6ff7db5a788fc6c0b8d37b7b41d39aff4f9432'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='a173ad40-7506-4ca2-80d1-d442191e5907', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4ca479aad89af3c0b04e761486b23ef2a95c862e6b3f7c2abd5aa43356070170')}, text='•MATH. We report the average of the GSM8K (8 shot) (Cobbe et al., 2021) and MATH (4 shot)\\n(Hendrycks et al., 2021) benchmarks at top 1.\\n∗∗https://sustainability.fb.com/2021-sustainability-report/\\n††https://www.mosaicml.com/blog/mpt-7b\\n7\\n\\nModel Size CodeCommonsense\\nReasoningWorld\\nKnowledgeReading\\nComprehensionMath MMLU BBH AGI Eval\\nMPT7B 20.5 57.4 41.0 57.5 4.9 26.8 31.0 23.5\\n30B 28.9 64.9 50.0 64.7 9.1 46.9 38.0 33.8\\nFalcon7B 5.6 56.1 42.8 36.0 4.6 26.2 28.0 21.2\\n40B 15.2 69.2 56.7 65.7 12.6 55.4 37.', start_char_idx=0, end_char_idx=505, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-7', obj=None),\n",
       " 'a173ad40-7506-4ca2-80d1-d442191e5907': IndexNode(id_='a173ad40-7506-4ca2-80d1-d442191e5907', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='704f4d4a17a97f3e3c3d33053c6ff7db5a788fc6c0b8d37b7b41d39aff4f9432'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='5ff50309-57dd-41be-9e3c-b735f799fb5d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='fcfd33540a769f0532ef303e0d7d499b006798018dc1d0a6434162e1979592e2'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='f9519c45-d404-4b58-9023-24ac465afb0f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='985a21af2f7088543e37bfdfe5aab386833414fe4f9043856e856101f8093110')}, text='9 64.9 50.0 64.7 9.1 46.9 38.0 33.8\\nFalcon7B 5.6 56.1 42.8 36.0 4.6 26.2 28.0 21.2\\n40B 15.2 69.2 56.7 65.7 12.6 55.4 37.1 37.0\\nLlama 17B 14.1 60.8 46.2 58.5 6.95 35.1 30.3 23.9\\n13B 18.9 66.1 52.6 62.3 10.9 46.9 37.0 33.9\\n33B 26.0 70.0 58.4 67.6 21.4 57.8 39.8 41.7\\n65B 30.7 70.7 60.5 68.6 30.8 63.4 43.5 47.6\\nLlama 27B 16.', start_char_idx=385, end_char_idx=707, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-7', obj=None),\n",
       " 'f9519c45-d404-4b58-9023-24ac465afb0f': IndexNode(id_='f9519c45-d404-4b58-9023-24ac465afb0f', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='704f4d4a17a97f3e3c3d33053c6ff7db5a788fc6c0b8d37b7b41d39aff4f9432'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='a173ad40-7506-4ca2-80d1-d442191e5907', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4ca479aad89af3c0b04e761486b23ef2a95c862e6b3f7c2abd5aa43356070170'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='4fcef2e2-b028-4b34-a17a-27d7fa463150', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bdfe7bdb40adc957c3b6a35205e0359a2823f9db14dba3b48fc4260824bc783b')}, text='6 62.3 10.9 46.9 37.0 33.9\\n33B 26.0 70.0 58.4 67.6 21.4 57.8 39.8 41.7\\n65B 30.7 70.7 60.5 68.6 30.8 63.4 43.5 47.6\\nLlama 27B 16.8 63.9 48.9 61.3 14.6 45.3 32.6 29.3\\n13B 24.5 66.9 55.4 65.8 28.7 54.8 39.4 39.1\\n34B 27.8 69.9 58.7 68.0 24.2 62.6 44.1 43.4\\n70B37.5 71.9 63.6 69.4 35.2 68.9 51.2 54.2\\nTable3: Overallperformanceongroupedacademicbenchmarkscomparedtoopen-sourcebasemodels.', start_char_idx=579, end_char_idx=960, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-7', obj=None),\n",
       " '4fcef2e2-b028-4b34-a17a-27d7fa463150': IndexNode(id_='4fcef2e2-b028-4b34-a17a-27d7fa463150', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='704f4d4a17a97f3e3c3d33053c6ff7db5a788fc6c0b8d37b7b41d39aff4f9432'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='f9519c45-d404-4b58-9023-24ac465afb0f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='985a21af2f7088543e37bfdfe5aab386833414fe4f9043856e856101f8093110'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='d6e8d364-4dba-4111-b926-4eb7ae5ba596', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='92d1fa15ca65bb3652cb7b2104a9f396f00b3564f2ef22edc0b399c7c4574d08')}, text='8 39.4 39.1\\n34B 27.8 69.9 58.7 68.0 24.2 62.6 44.1 43.4\\n70B37.5 71.9 63.6 69.4 35.2 68.9 51.2 54.2\\nTable3: Overallperformanceongroupedacademicbenchmarkscomparedtoopen-sourcebasemodels.\\n•Popular Aggregated Benchmarks . We report the overall results for MMLU (5 shot) (Hendrycks\\net al., 2020), Big Bench Hard (BBH) (3 shot) (Suzgun et al., 2022), and AGI Eval (3–5 shot) (Zhong\\net al., 2023). For AGI Eval, we only evaluate on the English tasks and report the average.\\nAs shown in Table 3, Llama 2 models outperform Llama 1 models.', start_char_idx=776, end_char_idx=1305, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-7', obj=None),\n",
       " 'd6e8d364-4dba-4111-b926-4eb7ae5ba596': IndexNode(id_='d6e8d364-4dba-4111-b926-4eb7ae5ba596', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='704f4d4a17a97f3e3c3d33053c6ff7db5a788fc6c0b8d37b7b41d39aff4f9432'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='4fcef2e2-b028-4b34-a17a-27d7fa463150', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bdfe7bdb40adc957c3b6a35205e0359a2823f9db14dba3b48fc4260824bc783b'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='55cc44a6-cd6e-45ab-84dd-d4a6a1d0c87d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b636a24727704c8e1b4b4f6d3cad1b4272cf0bc6b77c5aceed1a807d47552ef7')}, text='For AGI Eval, we only evaluate on the English tasks and report the average.\\nAs shown in Table 3, Llama 2 models outperform Llama 1 models. In particular, Llama 2 70B improves the\\nresultsonMMLUandBBHby ≈5and≈8points,respectively,comparedto Llama 1 65B.Llama 2 7Band30B\\nmodelsoutperformMPTmodelsofthecorrespondingsizeonallcategoriesbesidescodebenchmarks. Forthe\\nFalcon models, Llama 2 7B and 34B outperform Falcon 7B and 40B models on all categories of benchmarks.\\nAdditionally, Llama 2 70B model outperforms all open-source models.\\nIn addition to open-source models, we also compare Llama 2 70B results to closed-source models. As shown\\nin Table 4, Llama 2 70B is close to GPT-3.5 (OpenAI, 2023) on MMLU and GSM8K, but there is a significant\\ngaponcodingbenchmarks.', start_char_idx=1167, end_char_idx=1930, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-7', obj=None),\n",
       " '55cc44a6-cd6e-45ab-84dd-d4a6a1d0c87d': IndexNode(id_='55cc44a6-cd6e-45ab-84dd-d4a6a1d0c87d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='704f4d4a17a97f3e3c3d33053c6ff7db5a788fc6c0b8d37b7b41d39aff4f9432'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='d6e8d364-4dba-4111-b926-4eb7ae5ba596', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='92d1fa15ca65bb3652cb7b2104a9f396f00b3564f2ef22edc0b399c7c4574d08')}, text='Additionally, Llama 2 70B model outperforms all open-source models.\\nIn addition to open-source models, we also compare Llama 2 70B results to closed-source models. As shown\\nin Table 4, Llama 2 70B is close to GPT-3.5 (OpenAI, 2023) on MMLU and GSM8K, but there is a significant\\ngaponcodingbenchmarks. Llama 2 70BresultsareonparorbetterthanPaLM(540B)(Chowdheryetal.,\\n2022)onalmostallbenchmarks. Thereisstillalargegapinperformancebetween Llama 2 70BandGPT-4\\nand PaLM-2-L.\\nWe also analysed the potential data contamination and share the details in Section A.6.', start_char_idx=1630, end_char_idx=2187, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-7', obj=None),\n",
       " '2bb903b0-8397-4150-9d35-6b96d864722c': IndexNode(id_='2bb903b0-8397-4150-9d35-6b96d864722c', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='704f4d4a17a97f3e3c3d33053c6ff7db5a788fc6c0b8d37b7b41d39aff4f9432'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='b00adffd-7769-4187-9f65-b08b6350e821', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3fd4d346801cebe3003a57c6440eb560f09e0372e5bf30cbe5cc1f616d3e102f')}, text='•MATH. We report the average of the GSM8K (8 shot) (Cobbe et al., 2021) and MATH (4 shot)\\n(Hendrycks et al., 2021) benchmarks at top 1.', start_char_idx=0, end_char_idx=135, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-7', obj=None),\n",
       " 'b00adffd-7769-4187-9f65-b08b6350e821': IndexNode(id_='b00adffd-7769-4187-9f65-b08b6350e821', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='704f4d4a17a97f3e3c3d33053c6ff7db5a788fc6c0b8d37b7b41d39aff4f9432'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='2bb903b0-8397-4150-9d35-6b96d864722c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='fdac2deebac0a264a3892eb739bd448c5cd385b5531690f53cb81b44f9bfb00a'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='1dd1321a-d4f2-4c42-9c6e-2ca7a10f1422', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0e17ffeb41d526723c16860fd6d317135043339cbf8beafb8753c9b81ed4cd38')}, text='•MATH. We report the average of the GSM8K (8 shot) (Cobbe et al., 2021) and MATH (4 shot)\\n(Hendrycks et al., 2021) benchmarks at top 1.\\n∗∗https://sustainability.fb.com/2021-sustainability-report/\\n††https://www.mosaicml.com/blog/mpt-7b\\n7\\n\\nModel Size CodeCommonsense\\nReasoningWorld\\nKnowledgeReading\\nComprehensionMath MMLU BBH AGI Eval\\nMPT7B 20.5 57.4 41.0 57.5 4.9 26.8 31.0 23.5\\n30B 28.9 64.9 50.0 64.7 9.1 46.9 38.0 33.8\\nFalcon7B 5.6 56.1 42.8 36.0 4.6 26.2 28.0 21.2\\n40B 15.2 69.2 56.7 65.7 12.6 55.4 37.1 37.0\\nLlama 17B 14.1 60.8 46.2 58.5 6.95 35.1 30.3 23.9\\n13B 18.9 66.1 52.6 62.3 10.9 46.9 37.0 33.9\\n33B 26.0 70.0 58.4 67.6 21.4 57.8 39.8 41.7\\n65B 30.7 70.7 60.5 68.6 30.8 63.4 43.5 47.6\\nLlama 27B 16.8 63.9 48.9 61.3 14.6 45.3 32.6 29.3\\n13B 24.5 66.9 55.4 65.8 28.7 54.8 39.4 39.1\\n34B 27.8 69.9 58.7 68.0 24.2 62.6 44.1 43.4\\n70B37.5 71.9 63.6 69.4 35.2 68.9 51.2 54.2\\nTable3: Overallperformanceongroupedacademicbenchmarkscomparedtoopen-sourcebasemodels.', start_char_idx=0, end_char_idx=960, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-7', obj=None),\n",
       " '1dd1321a-d4f2-4c42-9c6e-2ca7a10f1422': IndexNode(id_='1dd1321a-d4f2-4c42-9c6e-2ca7a10f1422', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='704f4d4a17a97f3e3c3d33053c6ff7db5a788fc6c0b8d37b7b41d39aff4f9432'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='b00adffd-7769-4187-9f65-b08b6350e821', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3fd4d346801cebe3003a57c6440eb560f09e0372e5bf30cbe5cc1f616d3e102f')}, text='•Popular Aggregated Benchmarks . We report the overall results for MMLU (5 shot) (Hendrycks\\net al., 2020), Big Bench Hard (BBH) (3 shot) (Suzgun et al., 2022), and AGI Eval (3–5 shot) (Zhong\\net al., 2023). For AGI Eval, we only evaluate on the English tasks and report the average.\\nAs shown in Table 3, Llama 2 models outperform Llama 1 models. In particular, Llama 2 70B improves the\\nresultsonMMLUandBBHby ≈5and≈8points,respectively,comparedto Llama 1 65B.Llama 2 7Band30B\\nmodelsoutperformMPTmodelsofthecorrespondingsizeonallcategoriesbesidescodebenchmarks. Forthe\\nFalcon models, Llama 2 7B and 34B outperform Falcon 7B and 40B models on all categories of benchmarks.\\nAdditionally, Llama 2 70B model outperforms all open-source models.\\nIn addition to open-source models, we also compare Llama 2 70B results to closed-source models. As shown\\nin Table 4, Llama 2 70B is close to GPT-3.5 (OpenAI, 2023) on MMLU and GSM8K, but there is a significant\\ngaponcodingbenchmarks. Llama 2 70BresultsareonparorbetterthanPaLM(540B)(Chowdheryetal.,\\n2022)onalmostallbenchmarks. Thereisstillalargegapinperformancebetween Llama 2 70BandGPT-4\\nand PaLM-2-L.\\nWe also analysed the potential data contamination and share the details in Section A.6.', start_char_idx=961, end_char_idx=2187, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-7', obj=None),\n",
       " 'node-7': IndexNode(id_='node-7', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='d03f19eb-da15-45dc-bfd4-e5d10f161250', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='231b3bd773f012c01b893ada9e009ecf25ee59934614c5a595c9bf1b3a123292'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='05c3d1f2-ed89-42c0-ab18-43d2b38d458e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f939a86f41587d042c4ebb4485546c18e5e7ab1ae86c405fb91ffacb1785593c'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='f437d5df-0eaa-44e5-ad93-99aac0b0436e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c3110d390c246bc822086df697ba3496600d75f8f3bc8df9d3dd6976bffde7c6')}, text='•MATH. We report the average of the GSM8K (8 shot) (Cobbe et al., 2021) and MATH (4 shot)\\n(Hendrycks et al., 2021) benchmarks at top 1.\\n∗∗https://sustainability.fb.com/2021-sustainability-report/\\n††https://www.mosaicml.com/blog/mpt-7b\\n7\\n\\nModel Size CodeCommonsense\\nReasoningWorld\\nKnowledgeReading\\nComprehensionMath MMLU BBH AGI Eval\\nMPT7B 20.5 57.4 41.0 57.5 4.9 26.8 31.0 23.5\\n30B 28.9 64.9 50.0 64.7 9.1 46.9 38.0 33.8\\nFalcon7B 5.6 56.1 42.8 36.0 4.6 26.2 28.0 21.2\\n40B 15.2 69.2 56.7 65.7 12.6 55.4 37.1 37.0\\nLlama 17B 14.1 60.8 46.2 58.5 6.95 35.1 30.3 23.9\\n13B 18.9 66.1 52.6 62.3 10.9 46.9 37.0 33.9\\n33B 26.0 70.0 58.4 67.6 21.4 57.8 39.8 41.7\\n65B 30.7 70.7 60.5 68.6 30.8 63.4 43.5 47.6\\nLlama 27B 16.8 63.9 48.9 61.3 14.6 45.3 32.6 29.3\\n13B 24.5 66.9 55.4 65.8 28.7 54.8 39.4 39.1\\n34B 27.8 69.9 58.7 68.0 24.2 62.6 44.1 43.4\\n70B37.5 71.9 63.6 69.4 35.2 68.9 51.2 54.2\\nTable3: Overallperformanceongroupedacademicbenchmarkscomparedtoopen-sourcebasemodels.\\n•Popular Aggregated Benchmarks . We report the overall results for MMLU (5 shot) (Hendrycks\\net al., 2020), Big Bench Hard (BBH) (3 shot) (Suzgun et al., 2022), and AGI Eval (3–5 shot) (Zhong\\net al., 2023). For AGI Eval, we only evaluate on the English tasks and report the average.\\nAs shown in Table 3, Llama 2 models outperform Llama 1 models. In particular, Llama 2 70B improves the\\nresultsonMMLUandBBHby ≈5and≈8points,respectively,comparedto Llama 1 65B.Llama 2 7Band30B\\nmodelsoutperformMPTmodelsofthecorrespondingsizeonallcategoriesbesidescodebenchmarks. Forthe\\nFalcon models, Llama 2 7B and 34B outperform Falcon 7B and 40B models on all categories of benchmarks.\\nAdditionally, Llama 2 70B model outperforms all open-source models.\\nIn addition to open-source models, we also compare Llama 2 70B results to closed-source models. As shown\\nin Table 4, Llama 2 70B is close to GPT-3.5 (OpenAI, 2023) on MMLU and GSM8K, but there is a significant\\ngaponcodingbenchmarks. Llama 2 70BresultsareonparorbetterthanPaLM(540B)(Chowdheryetal.,\\n2022)onalmostallbenchmarks. Thereisstillalargegapinperformancebetween Llama 2 70BandGPT-4\\nand PaLM-2-L.\\nWe also analysed the potential data contamination and share the details in Section A.6.', start_char_idx=18381, end_char_idx=20568, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-7', obj=None),\n",
       " '198b3578-82bb-4e92-bfb5-a06d112f5391': IndexNode(id_='198b3578-82bb-4e92-bfb5-a06d112f5391', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c3110d390c246bc822086df697ba3496600d75f8f3bc8df9d3dd6976bffde7c6'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='bc1c1a34-3e7d-409e-8a4f-acbc4adb3719', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='32c2cb9ef8ab226045bc269608b1a2c0f01ad87214bbfce965ba87cb491287d9')}, text='Llama 2 70BresultsareonparorbetterthanPaLM(540B)(Chowdheryetal.,\\n2022)onalmostallbenchmarks. Thereisstillalargegapinperformancebetween Llama 2 70BandGPT-4\\nand PaLM-2-L.\\nWe also analysed the potential data contamination and share the details in Section A.6.\\nBenchmark (shots) GPT-3.5 GPT-4 PaLM PaLM-2-L Llama 2\\nMMLU (5-shot) 70.0 86.4 69.', start_char_idx=0, end_char_idx=338, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-8', obj=None),\n",
       " 'bc1c1a34-3e7d-409e-8a4f-acbc4adb3719': IndexNode(id_='bc1c1a34-3e7d-409e-8a4f-acbc4adb3719', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c3110d390c246bc822086df697ba3496600d75f8f3bc8df9d3dd6976bffde7c6'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='198b3578-82bb-4e92-bfb5-a06d112f5391', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='00c8c4650d9c5ccb1e176b6f38d0c82320c909710ea46fd446e9d7f2789819f8'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='b745b75b-2ff8-481e-9c6e-ecbd136093f8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4889ba4a9a20702925cf60fc2ab6d3c1c8ae95d097785ab2ffec92ea0fc55e99')}, text='Thereisstillalargegapinperformancebetween Llama 2 70BandGPT-4\\nand PaLM-2-L.\\nWe also analysed the potential data contamination and share the details in Section A.6.\\nBenchmark (shots) GPT-3.5 GPT-4 PaLM PaLM-2-L Llama 2\\nMMLU (5-shot) 70.0 86.4 69.3 78.3 68.9\\nTriviaQA (1-shot) – – 81.4 86.1 85.', start_char_idx=93, end_char_idx=385, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-8', obj=None),\n",
       " 'b745b75b-2ff8-481e-9c6e-ecbd136093f8': IndexNode(id_='b745b75b-2ff8-481e-9c6e-ecbd136093f8', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c3110d390c246bc822086df697ba3496600d75f8f3bc8df9d3dd6976bffde7c6'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='bc1c1a34-3e7d-409e-8a4f-acbc4adb3719', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='32c2cb9ef8ab226045bc269608b1a2c0f01ad87214bbfce965ba87cb491287d9'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='a5682c2a-3982-472c-a0f3-fbb859115dba', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b6b45140f6d1674813e2f4dae91ec9d4d6d62f3e7f3de2077fee70774592354d')}, text='We also analysed the potential data contamination and share the details in Section A.6.\\nBenchmark (shots) GPT-3.5 GPT-4 PaLM PaLM-2-L Llama 2\\nMMLU (5-shot) 70.0 86.4 69.3 78.3 68.9\\nTriviaQA (1-shot) – – 81.4 86.1 85.0\\nNatural Questions (1-shot) – – 29.3 37.5 33.0\\nGSM8K (8-shot) 57.1 92.', start_char_idx=169, end_char_idx=456, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-8', obj=None),\n",
       " 'a5682c2a-3982-472c-a0f3-fbb859115dba': IndexNode(id_='a5682c2a-3982-472c-a0f3-fbb859115dba', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c3110d390c246bc822086df697ba3496600d75f8f3bc8df9d3dd6976bffde7c6'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='b745b75b-2ff8-481e-9c6e-ecbd136093f8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4889ba4a9a20702925cf60fc2ab6d3c1c8ae95d097785ab2ffec92ea0fc55e99'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='c279db79-e77e-4f2c-8ae5-ca5868174016', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='335f0efd4c6d0e3fe3300801a3341aea88fd07162f759b0647212adda68cb23e')}, text='0 86.4 69.3 78.3 68.9\\nTriviaQA (1-shot) – – 81.4 86.1 85.0\\nNatural Questions (1-shot) – – 29.3 37.5 33.0\\nGSM8K (8-shot) 57.1 92.0 56.5 80.7 56.8\\nHumanEval (0-shot) 48.1 67.0 26.2 – 29.9\\nBIG-Bench Hard (3-shot) – – 52.', start_char_idx=328, end_char_idx=545, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-8', obj=None),\n",
       " 'c279db79-e77e-4f2c-8ae5-ca5868174016': IndexNode(id_='c279db79-e77e-4f2c-8ae5-ca5868174016', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c3110d390c246bc822086df697ba3496600d75f8f3bc8df9d3dd6976bffde7c6'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='a5682c2a-3982-472c-a0f3-fbb859115dba', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b6b45140f6d1674813e2f4dae91ec9d4d6d62f3e7f3de2077fee70774592354d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='ecd34e89-6708-4ce7-8eae-02e093060323', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0937dc8953accb4b23b7f78e08df3e44b8c46c474b91b90d8f4e8edfe485168a')}, text='4 86.1 85.0\\nNatural Questions (1-shot) – – 29.3 37.5 33.0\\nGSM8K (8-shot) 57.1 92.0 56.5 80.7 56.8\\nHumanEval (0-shot) 48.1 67.0 26.2 – 29.9\\nBIG-Bench Hard (3-shot) – – 52.3 65.7 51.2\\nTable 4: Comparison to closed-source models on academic benchmarks.', start_char_idx=375, end_char_idx=624, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-8', obj=None),\n",
       " 'ecd34e89-6708-4ce7-8eae-02e093060323': IndexNode(id_='ecd34e89-6708-4ce7-8eae-02e093060323', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c3110d390c246bc822086df697ba3496600d75f8f3bc8df9d3dd6976bffde7c6'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='c279db79-e77e-4f2c-8ae5-ca5868174016', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='335f0efd4c6d0e3fe3300801a3341aea88fd07162f759b0647212adda68cb23e'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='77c4c077-5d07-4086-882e-8ef8d3f10065', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='43579aef5e9992b2790c56c445383e78f1fa463549da4806fb36f3417ca13c8a')}, text='3 37.5 33.0\\nGSM8K (8-shot) 57.1 92.0 56.5 80.7 56.8\\nHumanEval (0-shot) 48.1 67.0 26.2 – 29.9\\nBIG-Bench Hard (3-shot) – – 52.3 65.7 51.2\\nTable 4: Comparison to closed-source models on academic benchmarks. Results for GPT-3.5 and GPT-4\\nare from OpenAI (2023).', start_char_idx=421, end_char_idx=678, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-8', obj=None),\n",
       " '77c4c077-5d07-4086-882e-8ef8d3f10065': IndexNode(id_='77c4c077-5d07-4086-882e-8ef8d3f10065', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c3110d390c246bc822086df697ba3496600d75f8f3bc8df9d3dd6976bffde7c6'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='ecd34e89-6708-4ce7-8eae-02e093060323', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0937dc8953accb4b23b7f78e08df3e44b8c46c474b91b90d8f4e8edfe485168a'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='8bdaa678-f6c3-41be-9609-079cfd21d8cb', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eedc7bad4800552004672b380f44e140c2e77dd04851592c7c851a3ed3d583f5')}, text='0 56.5 80.7 56.8\\nHumanEval (0-shot) 48.1 67.0 26.2 – 29.9\\nBIG-Bench Hard (3-shot) – – 52.3 65.7 51.2\\nTable 4: Comparison to closed-source models on academic benchmarks. Results for GPT-3.5 and GPT-4\\nare from OpenAI (2023). Results for the PaLM model are from Chowdhery et al. (2022).', start_char_idx=456, end_char_idx=739, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-8', obj=None),\n",
       " '8bdaa678-f6c3-41be-9609-079cfd21d8cb': IndexNode(id_='8bdaa678-f6c3-41be-9609-079cfd21d8cb', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c3110d390c246bc822086df697ba3496600d75f8f3bc8df9d3dd6976bffde7c6'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='77c4c077-5d07-4086-882e-8ef8d3f10065', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='43579aef5e9992b2790c56c445383e78f1fa463549da4806fb36f3417ca13c8a'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='f751d265-1885-4bae-9e58-8f821226c145', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d65b910749b558ec38885446a9eeea361802541c2039866368488bcce961985f')}, text='1 67.0 26.2 – 29.9\\nBIG-Bench Hard (3-shot) – – 52.3 65.7 51.2\\nTable 4: Comparison to closed-source models on academic benchmarks. Results for GPT-3.5 and GPT-4\\nare from OpenAI (2023). Results for the PaLM model are from Chowdhery et al. (2022). Results for the\\nPaLM-2-L are from Anil et al. (2023).', start_char_idx=495, end_char_idx=793, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-8', obj=None),\n",
       " 'f751d265-1885-4bae-9e58-8f821226c145': IndexNode(id_='f751d265-1885-4bae-9e58-8f821226c145', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c3110d390c246bc822086df697ba3496600d75f8f3bc8df9d3dd6976bffde7c6'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='8bdaa678-f6c3-41be-9609-079cfd21d8cb', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eedc7bad4800552004672b380f44e140c2e77dd04851592c7c851a3ed3d583f5'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='dbc1763f-6743-40c5-b53d-228c9c848162', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='12158151a77fb64c5369dc1aeb38d1d094fc3560b74b3c1b031bdc13a606f715')}, text='3 65.7 51.2\\nTable 4: Comparison to closed-source models on academic benchmarks. Results for GPT-3.5 and GPT-4\\nare from OpenAI (2023). Results for the PaLM model are from Chowdhery et al. (2022). Results for the\\nPaLM-2-L are from Anil et al. (2023).\\n3 Fine-tuning\\nLlama 2-Chat is the result of several months of research and iterative applications of alignment techniques,\\nincluding both instruction tuning and RLHF, requiring significant computational and annotation resources.', start_char_idx=545, end_char_idx=1022, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-8', obj=None),\n",
       " 'dbc1763f-6743-40c5-b53d-228c9c848162': IndexNode(id_='dbc1763f-6743-40c5-b53d-228c9c848162', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c3110d390c246bc822086df697ba3496600d75f8f3bc8df9d3dd6976bffde7c6'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='f751d265-1885-4bae-9e58-8f821226c145', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d65b910749b558ec38885446a9eeea361802541c2039866368488bcce961985f'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='7b5f3376-930d-4d93-b25d-baf75aae7895', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c244c332cbc04e02549d03f0bf87ea3843698ec79f891fd51d84f3de88d184f8')}, text='Results for the PaLM model are from Chowdhery et al. (2022). Results for the\\nPaLM-2-L are from Anil et al. (2023).\\n3 Fine-tuning\\nLlama 2-Chat is the result of several months of research and iterative applications of alignment techniques,\\nincluding both instruction tuning and RLHF, requiring significant computational and annotation resources.\\nIn this section, we report on our experiments and findings using supervised fine-tuning (Section 3.1), as\\nwell as initial and iterative reward modeling (Section 3.2.2) and RLHF (Section 3.2.3).', start_char_idx=679, end_char_idx=1216, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-8', obj=None),\n",
       " '7b5f3376-930d-4d93-b25d-baf75aae7895': IndexNode(id_='7b5f3376-930d-4d93-b25d-baf75aae7895', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c3110d390c246bc822086df697ba3496600d75f8f3bc8df9d3dd6976bffde7c6'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='dbc1763f-6743-40c5-b53d-228c9c848162', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='12158151a77fb64c5369dc1aeb38d1d094fc3560b74b3c1b031bdc13a606f715'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='15f89b2c-80ba-4130-aea8-df4be2ada05d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f9a9a5d2a1dced13b3828fea4e98bf89834ab58077946d7f44d649cb8245c300')}, text='(2023).\\n3 Fine-tuning\\nLlama 2-Chat is the result of several months of research and iterative applications of alignment techniques,\\nincluding both instruction tuning and RLHF, requiring significant computational and annotation resources.\\nIn this section, we report on our experiments and findings using supervised fine-tuning (Section 3.1), as\\nwell as initial and iterative reward modeling (Section 3.2.2) and RLHF (Section 3.2.3). We also share a\\nnew technique, Ghost Attention (GAtt), which we find helps control dialogue flow over multiple turns\\n(Section 3.3).', start_char_idx=786, end_char_idx=1348, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-8', obj=None),\n",
       " '15f89b2c-80ba-4130-aea8-df4be2ada05d': IndexNode(id_='15f89b2c-80ba-4130-aea8-df4be2ada05d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c3110d390c246bc822086df697ba3496600d75f8f3bc8df9d3dd6976bffde7c6'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='7b5f3376-930d-4d93-b25d-baf75aae7895', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c244c332cbc04e02549d03f0bf87ea3843698ec79f891fd51d84f3de88d184f8'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='f431699c-ecfb-412e-a59a-aa9aee428720', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2fe25c7e1f945ef2e288b7d6347979a26010419e8ace2a5cb806e9c7bdc0ba75')}, text='In this section, we report on our experiments and findings using supervised fine-tuning (Section 3.1), as\\nwell as initial and iterative reward modeling (Section 3.2.2) and RLHF (Section 3.2.3). We also share a\\nnew technique, Ghost Attention (GAtt), which we find helps control dialogue flow over multiple turns\\n(Section 3.3). See Section 4.2 for safety evaluations on fine-tuned models.', start_char_idx=1023, end_char_idx=1409, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-8', obj=None),\n",
       " 'f431699c-ecfb-412e-a59a-aa9aee428720': IndexNode(id_='f431699c-ecfb-412e-a59a-aa9aee428720', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c3110d390c246bc822086df697ba3496600d75f8f3bc8df9d3dd6976bffde7c6'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='15f89b2c-80ba-4130-aea8-df4be2ada05d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f9a9a5d2a1dced13b3828fea4e98bf89834ab58077946d7f44d649cb8245c300'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='894ee744-1c5a-489c-b719-618af7ac49cb', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bef0cefec91286f8966305c16b108b331fccf6210e7d1b7ee6bc80c1427e4c75')}, text='We also share a\\nnew technique, Ghost Attention (GAtt), which we find helps control dialogue flow over multiple turns\\n(Section 3.3). See Section 4.2 for safety evaluations on fine-tuned models.\\n8\\n\\n3.1 Supervised Fine-Tuning (SFT)\\n➤Prompt: Writeapoemtohelpmerememberthefirst10elementsontheperiodictable,givingeach\\nelement its own line.\\nResponse: Hydrogen comes first as element number one.\\nHelium is second for balloons to have fun!', start_char_idx=1217, end_char_idx=1647, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-8', obj=None),\n",
       " '894ee744-1c5a-489c-b719-618af7ac49cb': IndexNode(id_='894ee744-1c5a-489c-b719-618af7ac49cb', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c3110d390c246bc822086df697ba3496600d75f8f3bc8df9d3dd6976bffde7c6'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='f431699c-ecfb-412e-a59a-aa9aee428720', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2fe25c7e1f945ef2e288b7d6347979a26010419e8ace2a5cb806e9c7bdc0ba75'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='9175cefb-15d8-4b97-aed4-69483c03a469', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='79c4bb0f7396af83972b4b17baae18edc1ee3e45902a356cb74f08daf9d4c3ce')}, text='See Section 4.2 for safety evaluations on fine-tuned models.\\n8\\n\\n3.1 Supervised Fine-Tuning (SFT)\\n➤Prompt: Writeapoemtohelpmerememberthefirst10elementsontheperiodictable,givingeach\\nelement its own line.\\nResponse: Hydrogen comes first as element number one.\\nHelium is second for balloons to have fun!\\nIn third place is Lithium to hold battery charge,\\nFollowed by Beryllium in emeralds small and large.\\nBoron’s number five to help us keep things clean.', start_char_idx=1349, end_char_idx=1798, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-8', obj=None),\n",
       " '9175cefb-15d8-4b97-aed4-69483c03a469': IndexNode(id_='9175cefb-15d8-4b97-aed4-69483c03a469', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c3110d390c246bc822086df697ba3496600d75f8f3bc8df9d3dd6976bffde7c6'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='894ee744-1c5a-489c-b719-618af7ac49cb', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bef0cefec91286f8966305c16b108b331fccf6210e7d1b7ee6bc80c1427e4c75'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='61e4d93f-ed66-4e2e-9901-6b33252f4d4e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ce2345239a5f5665e25e283a2e4a71c41b5d99e25f0590de02de9c70cb34d355')}, text='Response: Hydrogen comes first as element number one.\\nHelium is second for balloons to have fun!\\nIn third place is Lithium to hold battery charge,\\nFollowed by Beryllium in emeralds small and large.\\nBoron’s number five to help us keep things clean.\\nCarbon’s next at six, and it’s found in every gene.\\nNitrogen is seven, found in every breath we take,\\nMore than eight (or Oxygen) in atmospheric make.\\nNumber nine is Fluorine, helping polish up our teeth.\\nNeon gives us glowing signs to read and stand beneath.', start_char_idx=1551, end_char_idx=2058, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-8', obj=None),\n",
       " '61e4d93f-ed66-4e2e-9901-6b33252f4d4e': IndexNode(id_='61e4d93f-ed66-4e2e-9901-6b33252f4d4e', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c3110d390c246bc822086df697ba3496600d75f8f3bc8df9d3dd6976bffde7c6'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='9175cefb-15d8-4b97-aed4-69483c03a469', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='79c4bb0f7396af83972b4b17baae18edc1ee3e45902a356cb74f08daf9d4c3ce'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='1c0bfc65-4de6-4475-905e-caf12553132b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='db083b183c49a40411348aa1be7244f0a7eacc51491481870b13e57f8ef91274')}, text='In third place is Lithium to hold battery charge,\\nFollowed by Beryllium in emeralds small and large.\\nBoron’s number five to help us keep things clean.\\nCarbon’s next at six, and it’s found in every gene.\\nNitrogen is seven, found in every breath we take,\\nMore than eight (or Oxygen) in atmospheric make.\\nNumber nine is Fluorine, helping polish up our teeth.\\nNeon gives us glowing signs to read and stand beneath.\\n➤Prompt: I want you to roast me. I want you to make it particularly brutal, swearing at me.', start_char_idx=1648, end_char_idx=2150, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-8', obj=None),\n",
       " '1c0bfc65-4de6-4475-905e-caf12553132b': IndexNode(id_='1c0bfc65-4de6-4475-905e-caf12553132b', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c3110d390c246bc822086df697ba3496600d75f8f3bc8df9d3dd6976bffde7c6'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='61e4d93f-ed66-4e2e-9901-6b33252f4d4e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ce2345239a5f5665e25e283a2e4a71c41b5d99e25f0590de02de9c70cb34d355'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='561c2c66-6899-477d-bc6c-09a15c410e6c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3ac27130d2c1cfae91144edb4d22f1b5e8ddce2d61e3f4a81137b68f5d08369f')}, text='Boron’s number five to help us keep things clean.\\nCarbon’s next at six, and it’s found in every gene.\\nNitrogen is seven, found in every breath we take,\\nMore than eight (or Oxygen) in atmospheric make.\\nNumber nine is Fluorine, helping polish up our teeth.\\nNeon gives us glowing signs to read and stand beneath.\\n➤Prompt: I want you to roast me. I want you to make it particularly brutal, swearing at me.\\nResponse: I’m sorry, but I cannot comply with that request.', start_char_idx=1749, end_char_idx=2210, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-8', obj=None),\n",
       " '561c2c66-6899-477d-bc6c-09a15c410e6c': IndexNode(id_='561c2c66-6899-477d-bc6c-09a15c410e6c', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c3110d390c246bc822086df697ba3496600d75f8f3bc8df9d3dd6976bffde7c6'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='1c0bfc65-4de6-4475-905e-caf12553132b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='db083b183c49a40411348aa1be7244f0a7eacc51491481870b13e57f8ef91274'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='17d6de49-18a7-4713-95c5-508687dbd45e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e8a73cbe8de991cb43471f44c1fbfa624c0c6d6d2d93dda621972929286eda9f')}, text='Nitrogen is seven, found in every breath we take,\\nMore than eight (or Oxygen) in atmospheric make.\\nNumber nine is Fluorine, helping polish up our teeth.\\nNeon gives us glowing signs to read and stand beneath.\\n➤Prompt: I want you to roast me. I want you to make it particularly brutal, swearing at me.\\nResponse: I’m sorry, but I cannot comply with that request. Using vulgar language or intentionally\\nhurting someone’s feelings is never acceptable.', start_char_idx=1851, end_char_idx=2297, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-8', obj=None),\n",
       " '17d6de49-18a7-4713-95c5-508687dbd45e': IndexNode(id_='17d6de49-18a7-4713-95c5-508687dbd45e', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c3110d390c246bc822086df697ba3496600d75f8f3bc8df9d3dd6976bffde7c6'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='561c2c66-6899-477d-bc6c-09a15c410e6c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3ac27130d2c1cfae91144edb4d22f1b5e8ddce2d61e3f4a81137b68f5d08369f'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='0decceb8-92ed-4da6-bc35-196de9b87f3a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='90a2287d2b1e92a6d258b3f75e2919b111b991a91d65f3b8bdb8d5e6381c663d')}, text='Number nine is Fluorine, helping polish up our teeth.\\nNeon gives us glowing signs to read and stand beneath.\\n➤Prompt: I want you to roast me. I want you to make it particularly brutal, swearing at me.\\nResponse: I’m sorry, but I cannot comply with that request. Using vulgar language or intentionally\\nhurting someone’s feelings is never acceptable. Instead of asking for a roast, I suggest\\nfocusingonpositiveandconstructivefeedbackthatcanhelpyougrowandimproveasan\\nindividual.', start_char_idx=1950, end_char_idx=2424, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-8', obj=None),\n",
       " '0decceb8-92ed-4da6-bc35-196de9b87f3a': IndexNode(id_='0decceb8-92ed-4da6-bc35-196de9b87f3a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c3110d390c246bc822086df697ba3496600d75f8f3bc8df9d3dd6976bffde7c6'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='17d6de49-18a7-4713-95c5-508687dbd45e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e8a73cbe8de991cb43471f44c1fbfa624c0c6d6d2d93dda621972929286eda9f'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='b3fb09fe-e509-4abe-8b3c-4d0a615dabc9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2c0a7cc727ac4ae4996644870452ec312d1f173a1fdccf80e048da29ffb73137')}, text='Neon gives us glowing signs to read and stand beneath.\\n➤Prompt: I want you to roast me. I want you to make it particularly brutal, swearing at me.\\nResponse: I’m sorry, but I cannot comply with that request. Using vulgar language or intentionally\\nhurting someone’s feelings is never acceptable. Instead of asking for a roast, I suggest\\nfocusingonpositiveandconstructivefeedbackthatcanhelpyougrowandimproveasan\\nindividual. If you’re looking for comedic relief, there are plenty of other ways to achieve\\nthat without resorting to hurtful language or behavior.', start_char_idx=2004, end_char_idx=2560, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-8', obj=None),\n",
       " 'b3fb09fe-e509-4abe-8b3c-4d0a615dabc9': IndexNode(id_='b3fb09fe-e509-4abe-8b3c-4d0a615dabc9', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c3110d390c246bc822086df697ba3496600d75f8f3bc8df9d3dd6976bffde7c6'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='0decceb8-92ed-4da6-bc35-196de9b87f3a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='90a2287d2b1e92a6d258b3f75e2919b111b991a91d65f3b8bdb8d5e6381c663d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='8c740d68-b967-40ed-a3a4-14089500e264', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='da99a7b3549707284d6e7748af21b6a19250dc068f3719d62cd63d335bce69b9')}, text='Response: I’m sorry, but I cannot comply with that request. Using vulgar language or intentionally\\nhurting someone’s feelings is never acceptable. Instead of asking for a roast, I suggest\\nfocusingonpositiveandconstructivefeedbackthatcanhelpyougrowandimproveasan\\nindividual. If you’re looking for comedic relief, there are plenty of other ways to achieve\\nthat without resorting to hurtful language or behavior.\\nTable 5: SFT annotation — example of a helpfulness (top) and safety(bottom) annotation for SFT, where the\\nannotator has written both the prompt and its answer.', start_char_idx=2151, end_char_idx=2720, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-8', obj=None),\n",
       " '8c740d68-b967-40ed-a3a4-14089500e264': IndexNode(id_='8c740d68-b967-40ed-a3a4-14089500e264', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c3110d390c246bc822086df697ba3496600d75f8f3bc8df9d3dd6976bffde7c6'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='b3fb09fe-e509-4abe-8b3c-4d0a615dabc9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2c0a7cc727ac4ae4996644870452ec312d1f173a1fdccf80e048da29ffb73137'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='4277e082-3ea6-47e3-8744-c27cf7f25b31', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6882168e50bac7e3923a138843d8e50f2dd5fd608cd63aad368c161103bf312b')}, text='Instead of asking for a roast, I suggest\\nfocusingonpositiveandconstructivefeedbackthatcanhelpyougrowandimproveasan\\nindividual. If you’re looking for comedic relief, there are plenty of other ways to achieve\\nthat without resorting to hurtful language or behavior.\\nTable 5: SFT annotation — example of a helpfulness (top) and safety(bottom) annotation for SFT, where the\\nannotator has written both the prompt and its answer.\\nGetting Started.', start_char_idx=2298, end_char_idx=2737, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-8', obj=None),\n",
       " '4277e082-3ea6-47e3-8744-c27cf7f25b31': IndexNode(id_='4277e082-3ea6-47e3-8744-c27cf7f25b31', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c3110d390c246bc822086df697ba3496600d75f8f3bc8df9d3dd6976bffde7c6'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='8c740d68-b967-40ed-a3a4-14089500e264', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='da99a7b3549707284d6e7748af21b6a19250dc068f3719d62cd63d335bce69b9'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='9a602bfe-12b0-480d-8038-647933b8de18', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7854e71f3ad8c767a11b6c081d252469acd75a13f0fc576ef473c92498db1b85')}, text='If you’re looking for comedic relief, there are plenty of other ways to achieve\\nthat without resorting to hurtful language or behavior.\\nTable 5: SFT annotation — example of a helpfulness (top) and safety(bottom) annotation for SFT, where the\\nannotator has written both the prompt and its answer.\\nGetting Started. To bootstrap, we started the SFT stage with publicly available instruction tuning\\ndata (Chung et al., 2022), as utilized previously in Touvron et al. (2023).\\nQuality Is All You Need.', start_char_idx=2425, end_char_idx=2920, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-8', obj=None),\n",
       " '9a602bfe-12b0-480d-8038-647933b8de18': IndexNode(id_='9a602bfe-12b0-480d-8038-647933b8de18', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c3110d390c246bc822086df697ba3496600d75f8f3bc8df9d3dd6976bffde7c6'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='4277e082-3ea6-47e3-8744-c27cf7f25b31', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6882168e50bac7e3923a138843d8e50f2dd5fd608cd63aad368c161103bf312b'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='99f4b71d-410e-4d0a-9c72-f82800269754', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eba4bf161795faba4afd4feedc9f7fce1dbb474a856d97b2fd3362b4d8981149')}, text='Table 5: SFT annotation — example of a helpfulness (top) and safety(bottom) annotation for SFT, where the\\nannotator has written both the prompt and its answer.\\nGetting Started. To bootstrap, we started the SFT stage with publicly available instruction tuning\\ndata (Chung et al., 2022), as utilized previously in Touvron et al. (2023).\\nQuality Is All You Need. Third-party SFT data is available from many different sources, but we found that\\nmanyofthesehaveinsufficientdiversityandquality—inparticularforaligningLLMstowardsdialogue-style\\ninstructions.', start_char_idx=2561, end_char_idx=3111, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-8', obj=None),\n",
       " '99f4b71d-410e-4d0a-9c72-f82800269754': IndexNode(id_='99f4b71d-410e-4d0a-9c72-f82800269754', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c3110d390c246bc822086df697ba3496600d75f8f3bc8df9d3dd6976bffde7c6'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='9a602bfe-12b0-480d-8038-647933b8de18', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7854e71f3ad8c767a11b6c081d252469acd75a13f0fc576ef473c92498db1b85'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='d127d802-ad74-4f5c-bff3-c0b866b3603d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d9505b2df555231ba310677c77044b1200f72916d655f871f8de5068ba85707f')}, text='Getting Started. To bootstrap, we started the SFT stage with publicly available instruction tuning\\ndata (Chung et al., 2022), as utilized previously in Touvron et al. (2023).\\nQuality Is All You Need. Third-party SFT data is available from many different sources, but we found that\\nmanyofthesehaveinsufficientdiversityandquality—inparticularforaligningLLMstowardsdialogue-style\\ninstructions. As a result, we focused first on collecting several thousand examples of high-quality SFT data,\\nas illustrated in Table 5.', start_char_idx=2721, end_char_idx=3234, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-8', obj=None),\n",
       " 'd127d802-ad74-4f5c-bff3-c0b866b3603d': IndexNode(id_='d127d802-ad74-4f5c-bff3-c0b866b3603d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c3110d390c246bc822086df697ba3496600d75f8f3bc8df9d3dd6976bffde7c6'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='99f4b71d-410e-4d0a-9c72-f82800269754', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eba4bf161795faba4afd4feedc9f7fce1dbb474a856d97b2fd3362b4d8981149'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='48a03e11-66b5-4384-b4d2-6da37fc9a610', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='da31be84487bab1672f4c3577fd55dc7a33e962fd89aab44d28c0ccdeaa70820')}, text='(2023).\\nQuality Is All You Need. Third-party SFT data is available from many different sources, but we found that\\nmanyofthesehaveinsufficientdiversityandquality—inparticularforaligningLLMstowardsdialogue-style\\ninstructions. As a result, we focused first on collecting several thousand examples of high-quality SFT data,\\nas illustrated in Table 5. By setting aside millions of examples from third-party datasets and using fewer but\\nhigher-quality examples from our own vendor-based annotation efforts, our results notably improved. These\\nfindingsaresimilarinspirittoZhouetal.', start_char_idx=2888, end_char_idx=3462, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-8', obj=None),\n",
       " '48a03e11-66b5-4384-b4d2-6da37fc9a610': IndexNode(id_='48a03e11-66b5-4384-b4d2-6da37fc9a610', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c3110d390c246bc822086df697ba3496600d75f8f3bc8df9d3dd6976bffde7c6'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='d127d802-ad74-4f5c-bff3-c0b866b3603d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d9505b2df555231ba310677c77044b1200f72916d655f871f8de5068ba85707f')}, text='As a result, we focused first on collecting several thousand examples of high-quality SFT data,\\nas illustrated in Table 5. By setting aside millions of examples from third-party datasets and using fewer but\\nhigher-quality examples from our own vendor-based annotation efforts, our results notably improved. These\\nfindingsaresimilarinspirittoZhouetal.(2023),whichalsofindsthatalimitedsetofcleaninstruction-tuning\\ndatacanbesufficienttoreachahighlevelofquality. WefoundthatSFTannotationsintheorderoftensof\\nthousands was enough to achieve a high-quality result.', start_char_idx=3112, end_char_idx=3669, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-8', obj=None),\n",
       " '845cd686-c642-421b-9987-aac2f1b07539': IndexNode(id_='845cd686-c642-421b-9987-aac2f1b07539', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c3110d390c246bc822086df697ba3496600d75f8f3bc8df9d3dd6976bffde7c6'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='2422aa21-9f9d-4018-bea2-3aa30d1a3215', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='62fb02074c73686cf6ce81d17cd2f0821565622af2ca8ec76f1c2fc9a455867a')}, text='Llama 2 70BresultsareonparorbetterthanPaLM(540B)(Chowdheryetal.,\\n2022)onalmostallbenchmarks. Thereisstillalargegapinperformancebetween Llama 2 70BandGPT-4\\nand PaLM-2-L.\\nWe also analysed the potential data contamination and share the details in Section A.6.', start_char_idx=0, end_char_idx=256, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-8', obj=None),\n",
       " '2422aa21-9f9d-4018-bea2-3aa30d1a3215': IndexNode(id_='2422aa21-9f9d-4018-bea2-3aa30d1a3215', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c3110d390c246bc822086df697ba3496600d75f8f3bc8df9d3dd6976bffde7c6'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='845cd686-c642-421b-9987-aac2f1b07539', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='22f9305d045cc6bd4e16686b65428a3b6c22c896a74d61325c2c077b7c514805'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='ce972553-3bb6-4c7f-9c4c-6e372b386a2a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c734c4fd1431be92b7339e07ef80bcc9cdaf1f84ea44f84b5655faec56be38b5')}, text='Llama 2 70BresultsareonparorbetterthanPaLM(540B)(Chowdheryetal.,\\n2022)onalmostallbenchmarks. Thereisstillalargegapinperformancebetween Llama 2 70BandGPT-4\\nand PaLM-2-L.\\nWe also analysed the potential data contamination and share the details in Section A.6.\\nBenchmark (shots) GPT-3.5 GPT-4 PaLM PaLM-2-L Llama 2\\nMMLU (5-shot) 70.0 86.4 69.3 78.3 68.9\\nTriviaQA (1-shot) – – 81.4 86.1 85.0\\nNatural Questions (1-shot) – – 29.3 37.5 33.0\\nGSM8K (8-shot) 57.1 92.0 56.5 80.7 56.8\\nHumanEval (0-shot) 48.1 67.0 26.2 – 29.9\\nBIG-Bench Hard (3-shot) – – 52.3 65.7 51.2\\nTable 4: Comparison to closed-source models on academic benchmarks.', start_char_idx=0, end_char_idx=624, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-8', obj=None),\n",
       " 'ce972553-3bb6-4c7f-9c4c-6e372b386a2a': IndexNode(id_='ce972553-3bb6-4c7f-9c4c-6e372b386a2a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c3110d390c246bc822086df697ba3496600d75f8f3bc8df9d3dd6976bffde7c6'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='2422aa21-9f9d-4018-bea2-3aa30d1a3215', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='62fb02074c73686cf6ce81d17cd2f0821565622af2ca8ec76f1c2fc9a455867a'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='24e49670-3105-478f-ac69-843c899bbe2b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f6c89496abcda0b3083d7dd53f9e7e8bdbf33f1d86a47d63573556826f9e4ff3')}, text='Results for GPT-3.5 and GPT-4\\nare from OpenAI (2023). Results for the PaLM model are from Chowdhery et al. (2022). Results for the\\nPaLM-2-L are from Anil et al. (2023).\\n3 Fine-tuning\\nLlama 2-Chat is the result of several months of research and iterative applications of alignment techniques,\\nincluding both instruction tuning and RLHF, requiring significant computational and annotation resources.\\nIn this section, we report on our experiments and findings using supervised fine-tuning (Section 3.1), as\\nwell as initial and iterative reward modeling (Section 3.2.2) and RLHF (Section 3.2.3). We also share a\\nnew technique, Ghost Attention (GAtt), which we find helps control dialogue flow over multiple turns\\n(Section 3.3). See Section 4.2 for safety evaluations on fine-tuned models.\\n8\\n\\n3.1 Supervised Fine-Tuning (SFT)\\n➤Prompt: Writeapoemtohelpmerememberthefirst10elementsontheperiodictable,givingeach\\nelement its own line.', start_char_idx=625, end_char_idx=1550, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-8', obj=None),\n",
       " '24e49670-3105-478f-ac69-843c899bbe2b': IndexNode(id_='24e49670-3105-478f-ac69-843c899bbe2b', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c3110d390c246bc822086df697ba3496600d75f8f3bc8df9d3dd6976bffde7c6'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='ce972553-3bb6-4c7f-9c4c-6e372b386a2a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c734c4fd1431be92b7339e07ef80bcc9cdaf1f84ea44f84b5655faec56be38b5'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='e24c6f30-5049-4ad3-a239-7d79b0176d57', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='74b235e9e25a553fc21b08a8c0d62d7a0558d798f4584168919df2dc9a0c7011')}, text='We also share a\\nnew technique, Ghost Attention (GAtt), which we find helps control dialogue flow over multiple turns\\n(Section 3.3). See Section 4.2 for safety evaluations on fine-tuned models.\\n8\\n\\n3.1 Supervised Fine-Tuning (SFT)\\n➤Prompt: Writeapoemtohelpmerememberthefirst10elementsontheperiodictable,givingeach\\nelement its own line.\\nResponse: Hydrogen comes first as element number one.\\nHelium is second for balloons to have fun!\\nIn third place is Lithium to hold battery charge,\\nFollowed by Beryllium in emeralds small and large.\\nBoron’s number five to help us keep things clean.\\nCarbon’s next at six, and it’s found in every gene.\\nNitrogen is seven, found in every breath we take,\\nMore than eight (or Oxygen) in atmospheric make.\\nNumber nine is Fluorine, helping polish up our teeth.\\nNeon gives us glowing signs to read and stand beneath.\\n➤Prompt: I want you to roast me. I want you to make it particularly brutal, swearing at me.\\nResponse: I’m sorry, but I cannot comply with that request.', start_char_idx=1217, end_char_idx=2210, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-8', obj=None),\n",
       " 'e24c6f30-5049-4ad3-a239-7d79b0176d57': IndexNode(id_='e24c6f30-5049-4ad3-a239-7d79b0176d57', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c3110d390c246bc822086df697ba3496600d75f8f3bc8df9d3dd6976bffde7c6'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='24e49670-3105-478f-ac69-843c899bbe2b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f6c89496abcda0b3083d7dd53f9e7e8bdbf33f1d86a47d63573556826f9e4ff3'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='d9ff6b47-215a-4d3e-9dc8-26ca60a33be9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f2fe7cd15dca9483a4e4c3b75c7e80c8d31df11b74bdbd09b9d22bddd3798554')}, text='Nitrogen is seven, found in every breath we take,\\nMore than eight (or Oxygen) in atmospheric make.\\nNumber nine is Fluorine, helping polish up our teeth.\\nNeon gives us glowing signs to read and stand beneath.\\n➤Prompt: I want you to roast me. I want you to make it particularly brutal, swearing at me.\\nResponse: I’m sorry, but I cannot comply with that request. Using vulgar language or intentionally\\nhurting someone’s feelings is never acceptable. Instead of asking for a roast, I suggest\\nfocusingonpositiveandconstructivefeedbackthatcanhelpyougrowandimproveasan\\nindividual. If you’re looking for comedic relief, there are plenty of other ways to achieve\\nthat without resorting to hurtful language or behavior.\\nTable 5: SFT annotation — example of a helpfulness (top) and safety(bottom) annotation for SFT, where the\\nannotator has written both the prompt and its answer.\\nGetting Started. To bootstrap, we started the SFT stage with publicly available instruction tuning\\ndata (Chung et al., 2022), as utilized previously in Touvron et al. (2023).\\nQuality Is All You Need.', start_char_idx=1851, end_char_idx=2920, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-8', obj=None),\n",
       " 'd9ff6b47-215a-4d3e-9dc8-26ca60a33be9': IndexNode(id_='d9ff6b47-215a-4d3e-9dc8-26ca60a33be9', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c3110d390c246bc822086df697ba3496600d75f8f3bc8df9d3dd6976bffde7c6'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='e24c6f30-5049-4ad3-a239-7d79b0176d57', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='74b235e9e25a553fc21b08a8c0d62d7a0558d798f4584168919df2dc9a0c7011'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='b764e3e3-7b6c-45a0-9292-c4b6033ceecd', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='59dc32cc33162229541a5e2d46b0087a45c8a30faf67fc6a8464b4bc104f9b00')}, text='Table 5: SFT annotation — example of a helpfulness (top) and safety(bottom) annotation for SFT, where the\\nannotator has written both the prompt and its answer.\\nGetting Started. To bootstrap, we started the SFT stage with publicly available instruction tuning\\ndata (Chung et al., 2022), as utilized previously in Touvron et al. (2023).\\nQuality Is All You Need. Third-party SFT data is available from many different sources, but we found that\\nmanyofthesehaveinsufficientdiversityandquality—inparticularforaligningLLMstowardsdialogue-style\\ninstructions. As a result, we focused first on collecting several thousand examples of high-quality SFT data,\\nas illustrated in Table 5. By setting aside millions of examples from third-party datasets and using fewer but\\nhigher-quality examples from our own vendor-based annotation efforts, our results notably improved. These\\nfindingsaresimilarinspirittoZhouetal.(2023),whichalsofindsthatalimitedsetofcleaninstruction-tuning\\ndatacanbesufficienttoreachahighlevelofquality.', start_char_idx=2561, end_char_idx=3570, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-8', obj=None),\n",
       " 'b764e3e3-7b6c-45a0-9292-c4b6033ceecd': IndexNode(id_='b764e3e3-7b6c-45a0-9292-c4b6033ceecd', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c3110d390c246bc822086df697ba3496600d75f8f3bc8df9d3dd6976bffde7c6'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='d9ff6b47-215a-4d3e-9dc8-26ca60a33be9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f2fe7cd15dca9483a4e4c3b75c7e80c8d31df11b74bdbd09b9d22bddd3798554')}, text='By setting aside millions of examples from third-party datasets and using fewer but\\nhigher-quality examples from our own vendor-based annotation efforts, our results notably improved. These\\nfindingsaresimilarinspirittoZhouetal.(2023),whichalsofindsthatalimitedsetofcleaninstruction-tuning\\ndatacanbesufficienttoreachahighlevelofquality. WefoundthatSFTannotationsintheorderoftensof\\nthousands was enough to achieve a high-quality result.', start_char_idx=3235, end_char_idx=3669, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-8', obj=None),\n",
       " 'bcfaad55-ea8f-4b09-8e1a-3c69c80bcb18': IndexNode(id_='bcfaad55-ea8f-4b09-8e1a-3c69c80bcb18', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c3110d390c246bc822086df697ba3496600d75f8f3bc8df9d3dd6976bffde7c6'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='98e4d121-0b56-419a-86f9-f3cd37b45850', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d9c27baea6904f3b3abc1c2118472ab1361ef8e98f37ceb9573d14d3197b216f')}, text='Llama 2 70BresultsareonparorbetterthanPaLM(540B)(Chowdheryetal.,\\n2022)onalmostallbenchmarks. Thereisstillalargegapinperformancebetween Llama 2 70BandGPT-4\\nand PaLM-2-L.\\nWe also analysed the potential data contamination and share the details in Section A.6.\\nBenchmark (shots) GPT-3.5 GPT-4 PaLM PaLM-2-L Llama 2\\nMMLU (5-shot) 70.0 86.4 69.3 78.3 68.9\\nTriviaQA (1-shot) – – 81.4 86.1 85.0\\nNatural Questions (1-shot) – – 29.3 37.5 33.0\\nGSM8K (8-shot) 57.1 92.0 56.5 80.7 56.8\\nHumanEval (0-shot) 48.1 67.0 26.2 – 29.9\\nBIG-Bench Hard (3-shot) – – 52.3 65.7 51.2\\nTable 4: Comparison to closed-source models on academic benchmarks. Results for GPT-3.5 and GPT-4\\nare from OpenAI (2023). Results for the PaLM model are from Chowdhery et al. (2022). Results for the\\nPaLM-2-L are from Anil et al. (2023).\\n3 Fine-tuning\\nLlama 2-Chat is the result of several months of research and iterative applications of alignment techniques,\\nincluding both instruction tuning and RLHF, requiring significant computational and annotation resources.\\nIn this section, we report on our experiments and findings using supervised fine-tuning (Section 3.1), as\\nwell as initial and iterative reward modeling (Section 3.2.2) and RLHF (Section 3.2.3). We also share a\\nnew technique, Ghost Attention (GAtt), which we find helps control dialogue flow over multiple turns\\n(Section 3.3). See Section 4.2 for safety evaluations on fine-tuned models.', start_char_idx=0, end_char_idx=1409, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-8', obj=None),\n",
       " '98e4d121-0b56-419a-86f9-f3cd37b45850': IndexNode(id_='98e4d121-0b56-419a-86f9-f3cd37b45850', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c3110d390c246bc822086df697ba3496600d75f8f3bc8df9d3dd6976bffde7c6'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='bcfaad55-ea8f-4b09-8e1a-3c69c80bcb18', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='062a5b956c325cf3667505c756af8ed32e35ac32b11e09e8959a7182dcc9ca24'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='eab2f0ee-7e0b-4e50-ab92-397d0ce5c581', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6cf6d82e8d692e4f900482b307084fde557cc5cbeb42d64609cb396bbc0ede3f')}, text='We also share a\\nnew technique, Ghost Attention (GAtt), which we find helps control dialogue flow over multiple turns\\n(Section 3.3). See Section 4.2 for safety evaluations on fine-tuned models.\\n8\\n\\n3.1 Supervised Fine-Tuning (SFT)\\n➤Prompt: Writeapoemtohelpmerememberthefirst10elementsontheperiodictable,givingeach\\nelement its own line.\\nResponse: Hydrogen comes first as element number one.\\nHelium is second for balloons to have fun!\\nIn third place is Lithium to hold battery charge,\\nFollowed by Beryllium in emeralds small and large.\\nBoron’s number five to help us keep things clean.\\nCarbon’s next at six, and it’s found in every gene.\\nNitrogen is seven, found in every breath we take,\\nMore than eight (or Oxygen) in atmospheric make.\\nNumber nine is Fluorine, helping polish up our teeth.\\nNeon gives us glowing signs to read and stand beneath.\\n➤Prompt: I want you to roast me. I want you to make it particularly brutal, swearing at me.\\nResponse: I’m sorry, but I cannot comply with that request. Using vulgar language or intentionally\\nhurting someone’s feelings is never acceptable. Instead of asking for a roast, I suggest\\nfocusingonpositiveandconstructivefeedbackthatcanhelpyougrowandimproveasan\\nindividual. If you’re looking for comedic relief, there are plenty of other ways to achieve\\nthat without resorting to hurtful language or behavior.\\nTable 5: SFT annotation — example of a helpfulness (top) and safety(bottom) annotation for SFT, where the\\nannotator has written both the prompt and its answer.\\nGetting Started. To bootstrap, we started the SFT stage with publicly available instruction tuning\\ndata (Chung et al., 2022), as utilized previously in Touvron et al. (2023).\\nQuality Is All You Need. Third-party SFT data is available from many different sources, but we found that\\nmanyofthesehaveinsufficientdiversityandquality—inparticularforaligningLLMstowardsdialogue-style\\ninstructions. As a result, we focused first on collecting several thousand examples of high-quality SFT data,\\nas illustrated in Table 5.', start_char_idx=1217, end_char_idx=3234, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-8', obj=None),\n",
       " 'eab2f0ee-7e0b-4e50-ab92-397d0ce5c581': IndexNode(id_='eab2f0ee-7e0b-4e50-ab92-397d0ce5c581', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c3110d390c246bc822086df697ba3496600d75f8f3bc8df9d3dd6976bffde7c6'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='98e4d121-0b56-419a-86f9-f3cd37b45850', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d9c27baea6904f3b3abc1c2118472ab1361ef8e98f37ceb9573d14d3197b216f')}, text='(2023).\\nQuality Is All You Need. Third-party SFT data is available from many different sources, but we found that\\nmanyofthesehaveinsufficientdiversityandquality—inparticularforaligningLLMstowardsdialogue-style\\ninstructions. As a result, we focused first on collecting several thousand examples of high-quality SFT data,\\nas illustrated in Table 5. By setting aside millions of examples from third-party datasets and using fewer but\\nhigher-quality examples from our own vendor-based annotation efforts, our results notably improved. These\\nfindingsaresimilarinspirittoZhouetal.(2023),whichalsofindsthatalimitedsetofcleaninstruction-tuning\\ndatacanbesufficienttoreachahighlevelofquality. WefoundthatSFTannotationsintheorderoftensof\\nthousands was enough to achieve a high-quality result.', start_char_idx=2888, end_char_idx=3669, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-8', obj=None),\n",
       " 'node-8': IndexNode(id_='node-8', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='d03f19eb-da15-45dc-bfd4-e5d10f161250', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='231b3bd773f012c01b893ada9e009ecf25ee59934614c5a595c9bf1b3a123292'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='0e080b04-d893-4a8b-8e17-5305f394df10', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='704f4d4a17a97f3e3c3d33053c6ff7db5a788fc6c0b8d37b7b41d39aff4f9432'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='c7954930-4c5d-463d-8b39-16cd0d157d10', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c6a69762e43e49da5331b7b24e9a7f6e70061c11567bdd07934325aab06d90c0')}, text='Llama 2 70BresultsareonparorbetterthanPaLM(540B)(Chowdheryetal.,\\n2022)onalmostallbenchmarks. Thereisstillalargegapinperformancebetween Llama 2 70BandGPT-4\\nand PaLM-2-L.\\nWe also analysed the potential data contamination and share the details in Section A.6.\\nBenchmark (shots) GPT-3.5 GPT-4 PaLM PaLM-2-L Llama 2\\nMMLU (5-shot) 70.0 86.4 69.3 78.3 68.9\\nTriviaQA (1-shot) – – 81.4 86.1 85.0\\nNatural Questions (1-shot) – – 29.3 37.5 33.0\\nGSM8K (8-shot) 57.1 92.0 56.5 80.7 56.8\\nHumanEval (0-shot) 48.1 67.0 26.2 – 29.9\\nBIG-Bench Hard (3-shot) – – 52.3 65.7 51.2\\nTable 4: Comparison to closed-source models on academic benchmarks. Results for GPT-3.5 and GPT-4\\nare from OpenAI (2023). Results for the PaLM model are from Chowdhery et al. (2022). Results for the\\nPaLM-2-L are from Anil et al. (2023).\\n3 Fine-tuning\\nLlama 2-Chat is the result of several months of research and iterative applications of alignment techniques,\\nincluding both instruction tuning and RLHF, requiring significant computational and annotation resources.\\nIn this section, we report on our experiments and findings using supervised fine-tuning (Section 3.1), as\\nwell as initial and iterative reward modeling (Section 3.2.2) and RLHF (Section 3.2.3). We also share a\\nnew technique, Ghost Attention (GAtt), which we find helps control dialogue flow over multiple turns\\n(Section 3.3). See Section 4.2 for safety evaluations on fine-tuned models.\\n8\\n\\n3.1 Supervised Fine-Tuning (SFT)\\n➤Prompt: Writeapoemtohelpmerememberthefirst10elementsontheperiodictable,givingeach\\nelement its own line.\\nResponse: Hydrogen comes first as element number one.\\nHelium is second for balloons to have fun!\\nIn third place is Lithium to hold battery charge,\\nFollowed by Beryllium in emeralds small and large.\\nBoron’s number five to help us keep things clean.\\nCarbon’s next at six, and it’s found in every gene.\\nNitrogen is seven, found in every breath we take,\\nMore than eight (or Oxygen) in atmospheric make.\\nNumber nine is Fluorine, helping polish up our teeth.\\nNeon gives us glowing signs to read and stand beneath.\\n➤Prompt: I want you to roast me. I want you to make it particularly brutal, swearing at me.\\nResponse: I’m sorry, but I cannot comply with that request. Using vulgar language or intentionally\\nhurting someone’s feelings is never acceptable. Instead of asking for a roast, I suggest\\nfocusingonpositiveandconstructivefeedbackthatcanhelpyougrowandimproveasan\\nindividual. If you’re looking for comedic relief, there are plenty of other ways to achieve\\nthat without resorting to hurtful language or behavior.\\nTable 5: SFT annotation — example of a helpfulness (top) and safety(bottom) annotation for SFT, where the\\nannotator has written both the prompt and its answer.\\nGetting Started. To bootstrap, we started the SFT stage with publicly available instruction tuning\\ndata (Chung et al., 2022), as utilized previously in Touvron et al. (2023).\\nQuality Is All You Need. Third-party SFT data is available from many different sources, but we found that\\nmanyofthesehaveinsufficientdiversityandquality—inparticularforaligningLLMstowardsdialogue-style\\ninstructions. As a result, we focused first on collecting several thousand examples of high-quality SFT data,\\nas illustrated in Table 5. By setting aside millions of examples from third-party datasets and using fewer but\\nhigher-quality examples from our own vendor-based annotation efforts, our results notably improved. These\\nfindingsaresimilarinspirittoZhouetal.(2023),whichalsofindsthatalimitedsetofcleaninstruction-tuning\\ndatacanbesufficienttoreachahighlevelofquality. WefoundthatSFTannotationsintheorderoftensof\\nthousands was enough to achieve a high-quality result.', start_char_idx=20312, end_char_idx=23981, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-8', obj=None),\n",
       " '38d295ad-cce8-4f40-840a-d22f3ad677f5': IndexNode(id_='38d295ad-cce8-4f40-840a-d22f3ad677f5', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c6a69762e43e49da5331b7b24e9a7f6e70061c11567bdd07934325aab06d90c0'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='c6812571-480c-4c74-aff9-12d32711bcde', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e9c356b8a32cf7dd7f001328a65f66e12affc29b5967922393352e99f3db78fa')}, text='These\\nfindingsaresimilarinspirittoZhouetal.(2023),whichalsofindsthatalimitedsetofcleaninstruction-tuning\\ndatacanbesufficienttoreachahighlevelofquality. WefoundthatSFTannotationsintheorderoftensof\\nthousands was enough to achieve a high-quality result. We stopped annotating SFT after collecting a total of\\n27,540 annotations. Note that we do not include any Meta user data.', start_char_idx=0, end_char_idx=372, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-9', obj=None),\n",
       " 'c6812571-480c-4c74-aff9-12d32711bcde': IndexNode(id_='c6812571-480c-4c74-aff9-12d32711bcde', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c6a69762e43e49da5331b7b24e9a7f6e70061c11567bdd07934325aab06d90c0'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='38d295ad-cce8-4f40-840a-d22f3ad677f5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e0bc542849b0c2a4a13ff16ea5be694e2b075c7a4c57816e324e16405c17fbfe'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='38802014-678e-486e-b40a-f38138726d02', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f46041957421f78996197c94670824be27cdca05f1ee92a63a3931de3c5b8382')}, text='These\\nfindingsaresimilarinspirittoZhouetal.(2023),whichalsofindsthatalimitedsetofcleaninstruction-tuning\\ndatacanbesufficienttoreachahighlevelofquality. WefoundthatSFTannotationsintheorderoftensof\\nthousands was enough to achieve a high-quality result. We stopped annotating SFT after collecting a total of\\n27,540 annotations. Note that we do not include any Meta user data.\\nWealsoobservedthatdifferentannotationplatformsandvendorscanresultinmarkedlydifferentdown-\\nstream model performance, highlighting the importance of data checks even when using vendors to source\\nannotations.', start_char_idx=0, end_char_idx=578, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-9', obj=None),\n",
       " '38802014-678e-486e-b40a-f38138726d02': IndexNode(id_='38802014-678e-486e-b40a-f38138726d02', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c6a69762e43e49da5331b7b24e9a7f6e70061c11567bdd07934325aab06d90c0'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='c6812571-480c-4c74-aff9-12d32711bcde', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e9c356b8a32cf7dd7f001328a65f66e12affc29b5967922393352e99f3db78fa'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='38b0c54c-dc28-4386-9d90-3096a5bea2a3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2972032e8c508d11c3748702c22fc8344f9c02ae7961d56495e9ac967a502941')}, text='WefoundthatSFTannotationsintheorderoftensof\\nthousands was enough to achieve a high-quality result. We stopped annotating SFT after collecting a total of\\n27,540 annotations. Note that we do not include any Meta user data.\\nWealsoobservedthatdifferentannotationplatformsandvendorscanresultinmarkedlydifferentdown-\\nstream model performance, highlighting the importance of data checks even when using vendors to source\\nannotations. Tovalidateourdataquality,wecarefullyexaminedasetof180examples,comparingtheannota-\\ntions provided by humans with the samples generated by the model through manual scrutiny.', start_char_idx=152, end_char_idx=750, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-9', obj=None),\n",
       " '38b0c54c-dc28-4386-9d90-3096a5bea2a3': IndexNode(id_='38b0c54c-dc28-4386-9d90-3096a5bea2a3', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c6a69762e43e49da5331b7b24e9a7f6e70061c11567bdd07934325aab06d90c0'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='38802014-678e-486e-b40a-f38138726d02', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f46041957421f78996197c94670824be27cdca05f1ee92a63a3931de3c5b8382'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='fee6690e-163c-4487-bf20-1fed246a5925', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='47e47a6885ae1588c9ae6a1c9ab6671ed5ef68e4b61cd289f4c98c90169a51d3')}, text='Note that we do not include any Meta user data.\\nWealsoobservedthatdifferentannotationplatformsandvendorscanresultinmarkedlydifferentdown-\\nstream model performance, highlighting the importance of data checks even when using vendors to source\\nannotations. Tovalidateourdataquality,wecarefullyexaminedasetof180examples,comparingtheannota-\\ntions provided by humans with the samples generated by the model through manual scrutiny. Surprisingly,\\nwe found that the outputs sampled from the resulting SFT model were often competitive with SFT data\\nhandwritten by human annotators, suggesting that we could reprioritize and devote more annotation effort\\nto preference-based annotation for RLHF.', start_char_idx=325, end_char_idx=1010, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-9', obj=None),\n",
       " 'fee6690e-163c-4487-bf20-1fed246a5925': IndexNode(id_='fee6690e-163c-4487-bf20-1fed246a5925', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c6a69762e43e49da5331b7b24e9a7f6e70061c11567bdd07934325aab06d90c0'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='38b0c54c-dc28-4386-9d90-3096a5bea2a3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2972032e8c508d11c3748702c22fc8344f9c02ae7961d56495e9ac967a502941'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='5963ea87-33a0-47ec-abc2-86b62a7ca30d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='08356f543397a23cae3adedeebfd1a863eca37d3dc4b7795a63eeb2633f31a2b')}, text='Tovalidateourdataquality,wecarefullyexaminedasetof180examples,comparingtheannota-\\ntions provided by humans with the samples generated by the model through manual scrutiny. Surprisingly,\\nwe found that the outputs sampled from the resulting SFT model were often competitive with SFT data\\nhandwritten by human annotators, suggesting that we could reprioritize and devote more annotation effort\\nto preference-based annotation for RLHF.\\nFine-Tuning Details.', start_char_idx=579, end_char_idx=1031, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-9', obj=None),\n",
       " '5963ea87-33a0-47ec-abc2-86b62a7ca30d': IndexNode(id_='5963ea87-33a0-47ec-abc2-86b62a7ca30d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c6a69762e43e49da5331b7b24e9a7f6e70061c11567bdd07934325aab06d90c0'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='fee6690e-163c-4487-bf20-1fed246a5925', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='47e47a6885ae1588c9ae6a1c9ab6671ed5ef68e4b61cd289f4c98c90169a51d3'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='75259887-db67-434c-9d80-cba44a0b0166', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d10342bb4797f108660974914542ee6252f383a3b9fe764a51763279e0b854cd')}, text='Tovalidateourdataquality,wecarefullyexaminedasetof180examples,comparingtheannota-\\ntions provided by humans with the samples generated by the model through manual scrutiny. Surprisingly,\\nwe found that the outputs sampled from the resulting SFT model were often competitive with SFT data\\nhandwritten by human annotators, suggesting that we could reprioritize and devote more annotation effort\\nto preference-based annotation for RLHF.\\nFine-Tuning Details. For supervised fine-tuning, we use a cosine learning rate schedule with an initial\\nlearning rate of 2×10−5, a weight decay of 0.1, a batch size of 64, and a sequence length of 4096 tokens.', start_char_idx=579, end_char_idx=1220, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-9', obj=None),\n",
       " '75259887-db67-434c-9d80-cba44a0b0166': IndexNode(id_='75259887-db67-434c-9d80-cba44a0b0166', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c6a69762e43e49da5331b7b24e9a7f6e70061c11567bdd07934325aab06d90c0'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='5963ea87-33a0-47ec-abc2-86b62a7ca30d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='08356f543397a23cae3adedeebfd1a863eca37d3dc4b7795a63eeb2633f31a2b'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='f5e24aad-1fb3-421b-ae9c-b60fcdb7eb3a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='83605974ffdd748df7b373084d66c695e561aafba05131670e8c4a07e4a7c815')}, text='Fine-Tuning Details. For supervised fine-tuning, we use a cosine learning rate schedule with an initial\\nlearning rate of 2×10−5, a weight decay of 0.1, a batch size of 64, and a sequence length of 4096 tokens.\\nFor the fine-tuning process, each sample consists of a prompt and an answer. To ensure the model sequence\\nlengthisproperlyfilled,weconcatenateallthepromptsandanswersfromthetrainingset. Aspecialtokenis\\nutilizedtoseparatethepromptandanswersegments.', start_char_idx=1011, end_char_idx=1467, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-9', obj=None),\n",
       " 'f5e24aad-1fb3-421b-ae9c-b60fcdb7eb3a': IndexNode(id_='f5e24aad-1fb3-421b-ae9c-b60fcdb7eb3a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c6a69762e43e49da5331b7b24e9a7f6e70061c11567bdd07934325aab06d90c0'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='75259887-db67-434c-9d80-cba44a0b0166', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d10342bb4797f108660974914542ee6252f383a3b9fe764a51763279e0b854cd'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='aba8932a-b258-4e92-a6a6-b0fd634bc2ea', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='77e991cb09bb5ec6d588e70068784c126b610c39b08c58ed7043936540c6e7f3')}, text='For the fine-tuning process, each sample consists of a prompt and an answer. To ensure the model sequence\\nlengthisproperlyfilled,weconcatenateallthepromptsandanswersfromthetrainingset. Aspecialtokenis\\nutilizedtoseparatethepromptandanswersegments. Weutilizeanautoregressiveobjectiveandzero-out\\nthe loss on tokens from the user prompt, so as a result, we backpropagate only on answer tokens. Finally, we\\nfine-tune the model for 2 epochs.', start_char_idx=1221, end_char_idx=1656, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-9', obj=None),\n",
       " 'aba8932a-b258-4e92-a6a6-b0fd634bc2ea': IndexNode(id_='aba8932a-b258-4e92-a6a6-b0fd634bc2ea', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c6a69762e43e49da5331b7b24e9a7f6e70061c11567bdd07934325aab06d90c0'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='f5e24aad-1fb3-421b-ae9c-b60fcdb7eb3a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='83605974ffdd748df7b373084d66c695e561aafba05131670e8c4a07e4a7c815'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='3bf16065-3134-4cc0-b5a7-1847ccc68052', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='338d188d98a7453deeb58802ff57ee1b98d513f3357617685490bdb7a48f39bd')}, text='To ensure the model sequence\\nlengthisproperlyfilled,weconcatenateallthepromptsandanswersfromthetrainingset. Aspecialtokenis\\nutilizedtoseparatethepromptandanswersegments. Weutilizeanautoregressiveobjectiveandzero-out\\nthe loss on tokens from the user prompt, so as a result, we backpropagate only on answer tokens. Finally, we\\nfine-tune the model for 2 epochs.\\n3.2 Reinforcement Learning with Human Feedback (RLHF)\\nRLHFisamodeltrainingprocedurethatisappliedtoafine-tunedlanguagemodeltofurther alignmodel\\nbehavior with human preferences and instruction following.', start_char_idx=1298, end_char_idx=1858, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-9', obj=None),\n",
       " '3bf16065-3134-4cc0-b5a7-1847ccc68052': IndexNode(id_='3bf16065-3134-4cc0-b5a7-1847ccc68052', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c6a69762e43e49da5331b7b24e9a7f6e70061c11567bdd07934325aab06d90c0'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='aba8932a-b258-4e92-a6a6-b0fd634bc2ea', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='77e991cb09bb5ec6d588e70068784c126b610c39b08c58ed7043936540c6e7f3'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='6c4a9c91-51ff-4a7d-b92c-f51a7b35369c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1bc4cf53c87d491f7178c5631f029e745f49e81ddeedd61180455c3163fb1e56')}, text='Weutilizeanautoregressiveobjectiveandzero-out\\nthe loss on tokens from the user prompt, so as a result, we backpropagate only on answer tokens. Finally, we\\nfine-tune the model for 2 epochs.\\n3.2 Reinforcement Learning with Human Feedback (RLHF)\\nRLHFisamodeltrainingprocedurethatisappliedtoafine-tunedlanguagemodeltofurther alignmodel\\nbehavior with human preferences and instruction following. We collect data that represents empirically\\n9\\n\\nsampled human preferences, whereby human annotators select which of two model outputs they prefer.', start_char_idx=1468, end_char_idx=2004, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-9', obj=None),\n",
       " '6c4a9c91-51ff-4a7d-b92c-f51a7b35369c': IndexNode(id_='6c4a9c91-51ff-4a7d-b92c-f51a7b35369c', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c6a69762e43e49da5331b7b24e9a7f6e70061c11567bdd07934325aab06d90c0'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='3bf16065-3134-4cc0-b5a7-1847ccc68052', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='338d188d98a7453deeb58802ff57ee1b98d513f3357617685490bdb7a48f39bd'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='a308d191-3c68-421c-966f-9a6dee9da3d2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='be18be3897bde11c75991b5fd2545fa2ba126cb76bdaa2bcd0506c9de794ea9a')}, text='Finally, we\\nfine-tune the model for 2 epochs.\\n3.2 Reinforcement Learning with Human Feedback (RLHF)\\nRLHFisamodeltrainingprocedurethatisappliedtoafine-tunedlanguagemodeltofurther alignmodel\\nbehavior with human preferences and instruction following. We collect data that represents empirically\\n9\\n\\nsampled human preferences, whereby human annotators select which of two model outputs they prefer.\\nThis human feedback is subsequently used to train a reward model, which learns patterns in the preferences\\nof the human annotators and can then automate preference decisions.', start_char_idx=1611, end_char_idx=2179, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-9', obj=None),\n",
       " 'a308d191-3c68-421c-966f-9a6dee9da3d2': IndexNode(id_='a308d191-3c68-421c-966f-9a6dee9da3d2', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c6a69762e43e49da5331b7b24e9a7f6e70061c11567bdd07934325aab06d90c0'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='6c4a9c91-51ff-4a7d-b92c-f51a7b35369c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1bc4cf53c87d491f7178c5631f029e745f49e81ddeedd61180455c3163fb1e56'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='799e260b-3c3d-4dc8-8015-03bfae012aa3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='86b60965757ace691577cd46320b9afef5f56caabca62f31d01edb08e397f2ef')}, text='We collect data that represents empirically\\n9\\n\\nsampled human preferences, whereby human annotators select which of two model outputs they prefer.\\nThis human feedback is subsequently used to train a reward model, which learns patterns in the preferences\\nof the human annotators and can then automate preference decisions.\\n3.2.1 Human Preference Data Collection\\nNext, wecollect human preference datafor reward modeling. We chose a binarycomparison protocol over\\nother schemes, mainly because it enables us to maximize the diversity of collected prompts. Still, other\\nstrategies are worth considering, which we leave for future work.', start_char_idx=1859, end_char_idx=2489, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-9', obj=None),\n",
       " '799e260b-3c3d-4dc8-8015-03bfae012aa3': IndexNode(id_='799e260b-3c3d-4dc8-8015-03bfae012aa3', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c6a69762e43e49da5331b7b24e9a7f6e70061c11567bdd07934325aab06d90c0'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='a308d191-3c68-421c-966f-9a6dee9da3d2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='be18be3897bde11c75991b5fd2545fa2ba126cb76bdaa2bcd0506c9de794ea9a'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='2b7402e7-c1f4-42f9-bd44-109f96e087d5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b159c1e343ec4bcc931cbf45da428228369c5b625cf8002bee41d6284ee2927f')}, text='This human feedback is subsequently used to train a reward model, which learns patterns in the preferences\\nof the human annotators and can then automate preference decisions.\\n3.2.1 Human Preference Data Collection\\nNext, wecollect human preference datafor reward modeling. We chose a binarycomparison protocol over\\nother schemes, mainly because it enables us to maximize the diversity of collected prompts. Still, other\\nstrategies are worth considering, which we leave for future work.\\nOur annotation procedure proceeds as follows.', start_char_idx=2005, end_char_idx=2535, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-9', obj=None),\n",
       " '2b7402e7-c1f4-42f9-bd44-109f96e087d5': IndexNode(id_='2b7402e7-c1f4-42f9-bd44-109f96e087d5', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c6a69762e43e49da5331b7b24e9a7f6e70061c11567bdd07934325aab06d90c0'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='799e260b-3c3d-4dc8-8015-03bfae012aa3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='86b60965757ace691577cd46320b9afef5f56caabca62f31d01edb08e397f2ef'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='997f73a0-8a47-4b03-9f60-6d89168497dd', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d80d6607f622183e1d264d364c353bc50a09fd8d4698c45231fb5734e30099ec')}, text='3.2.1 Human Preference Data Collection\\nNext, wecollect human preference datafor reward modeling. We chose a binarycomparison protocol over\\nother schemes, mainly because it enables us to maximize the diversity of collected prompts. Still, other\\nstrategies are worth considering, which we leave for future work.\\nOur annotation procedure proceeds as follows. We ask annotators to first write a prompt, then choose\\nbetweentwosampledmodelresponses,basedonprovidedcriteria.', start_char_idx=2180, end_char_idx=2647, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-9', obj=None),\n",
       " '997f73a0-8a47-4b03-9f60-6d89168497dd': IndexNode(id_='997f73a0-8a47-4b03-9f60-6d89168497dd', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c6a69762e43e49da5331b7b24e9a7f6e70061c11567bdd07934325aab06d90c0'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='2b7402e7-c1f4-42f9-bd44-109f96e087d5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b159c1e343ec4bcc931cbf45da428228369c5b625cf8002bee41d6284ee2927f'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='d3e771e5-3633-4929-a7da-1573d389e187', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5fd013f57ba521d5b142d7940ea11b089ab6dec8e645ab34279c8e5a2fd839fa')}, text='3.2.1 Human Preference Data Collection\\nNext, wecollect human preference datafor reward modeling. We chose a binarycomparison protocol over\\nother schemes, mainly because it enables us to maximize the diversity of collected prompts. Still, other\\nstrategies are worth considering, which we leave for future work.\\nOur annotation procedure proceeds as follows. We ask annotators to first write a prompt, then choose\\nbetweentwosampledmodelresponses,basedonprovidedcriteria. Inordertomaximizethediversity,the\\ntworesponsestoagivenpromptaresampledfromtwodifferentmodelvariants,andvaryingthetemperature\\nhyper-parameter.', start_char_idx=2180, end_char_idx=2789, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-9', obj=None),\n",
       " 'd3e771e5-3633-4929-a7da-1573d389e187': IndexNode(id_='d3e771e5-3633-4929-a7da-1573d389e187', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c6a69762e43e49da5331b7b24e9a7f6e70061c11567bdd07934325aab06d90c0'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='997f73a0-8a47-4b03-9f60-6d89168497dd', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d80d6607f622183e1d264d364c353bc50a09fd8d4698c45231fb5734e30099ec'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='2d53025e-1488-44a4-831a-978dc98f15d1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c209a3ee4f120b7c747afc2fe6e03d2f01782e585e17e4a10b522368b89405c4')}, text='Still, other\\nstrategies are worth considering, which we leave for future work.\\nOur annotation procedure proceeds as follows. We ask annotators to first write a prompt, then choose\\nbetweentwosampledmodelresponses,basedonprovidedcriteria. Inordertomaximizethediversity,the\\ntworesponsestoagivenpromptaresampledfromtwodifferentmodelvariants,andvaryingthetemperature\\nhyper-parameter. Inadditiontogivingparticipantsaforcedchoice,wealsoaskannotatorstolabelthedegree\\nto which they prefer their chosen response over the alternative: either their choice is significantly better ,better,\\nslightly better , ornegligibly better/ unsure .', start_char_idx=2411, end_char_idx=3035, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-9', obj=None),\n",
       " '2d53025e-1488-44a4-831a-978dc98f15d1': IndexNode(id_='2d53025e-1488-44a4-831a-978dc98f15d1', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c6a69762e43e49da5331b7b24e9a7f6e70061c11567bdd07934325aab06d90c0'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='d3e771e5-3633-4929-a7da-1573d389e187', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5fd013f57ba521d5b142d7940ea11b089ab6dec8e645ab34279c8e5a2fd839fa'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='77b78c1d-0037-4cf9-9d67-99cb310e5995', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7a439de49ab4218ec902cb0cf31fefa0ffdd579166459370cee9c25a6ce664f8')}, text='Inordertomaximizethediversity,the\\ntworesponsestoagivenpromptaresampledfromtwodifferentmodelvariants,andvaryingthetemperature\\nhyper-parameter. Inadditiontogivingparticipantsaforcedchoice,wealsoaskannotatorstolabelthedegree\\nto which they prefer their chosen response over the alternative: either their choice is significantly better ,better,\\nslightly better , ornegligibly better/ unsure .\\nFor our collection of preference annotations, we focus on helpfulness and safety.', start_char_idx=2648, end_char_idx=3117, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-9', obj=None),\n",
       " '77b78c1d-0037-4cf9-9d67-99cb310e5995': IndexNode(id_='77b78c1d-0037-4cf9-9d67-99cb310e5995', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c6a69762e43e49da5331b7b24e9a7f6e70061c11567bdd07934325aab06d90c0'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='2d53025e-1488-44a4-831a-978dc98f15d1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c209a3ee4f120b7c747afc2fe6e03d2f01782e585e17e4a10b522368b89405c4'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='c195111e-6dc0-4500-9a99-7daf587cf45c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7c4565fa0d239ce45338196f2e1c0056669940cdd7da099fc94c0d1de429b2e9')}, text='Inadditiontogivingparticipantsaforcedchoice,wealsoaskannotatorstolabelthedegree\\nto which they prefer their chosen response over the alternative: either their choice is significantly better ,better,\\nslightly better , ornegligibly better/ unsure .\\nFor our collection of preference annotations, we focus on helpfulness and safety. Helpfulness refers to how\\nwell Llama 2-Chat responses fulfill users’ requests and provide requested information; safety refers to\\nwhether Llama 2-Chat ’s responses are unsafe, e.g., “giving detailed instructions on making a bomb” could\\nbe considered helpful but is unsafe according to our safety guidelines.', start_char_idx=2790, end_char_idx=3425, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-9', obj=None),\n",
       " 'c195111e-6dc0-4500-9a99-7daf587cf45c': IndexNode(id_='c195111e-6dc0-4500-9a99-7daf587cf45c', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c6a69762e43e49da5331b7b24e9a7f6e70061c11567bdd07934325aab06d90c0'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='77b78c1d-0037-4cf9-9d67-99cb310e5995', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7a439de49ab4218ec902cb0cf31fefa0ffdd579166459370cee9c25a6ce664f8'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='0521e3af-e31e-41c7-a04b-3093e40cff8f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a456123c717a45f6669b85128b07de4794289c4b16f58da6de8d947e61e5051c')}, text='For our collection of preference annotations, we focus on helpfulness and safety. Helpfulness refers to how\\nwell Llama 2-Chat responses fulfill users’ requests and provide requested information; safety refers to\\nwhether Llama 2-Chat ’s responses are unsafe, e.g., “giving detailed instructions on making a bomb” could\\nbe considered helpful but is unsafe according to our safety guidelines. Separating the two allows us to\\napplyspecificguidelinestoeachandbetterguideannotators;forexample,oursafetyannotationsprovide\\ninstructions to focus on adversarial prompts, among other guidance.', start_char_idx=3036, end_char_idx=3618, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-9', obj=None),\n",
       " '0521e3af-e31e-41c7-a04b-3093e40cff8f': IndexNode(id_='0521e3af-e31e-41c7-a04b-3093e40cff8f', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c6a69762e43e49da5331b7b24e9a7f6e70061c11567bdd07934325aab06d90c0'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='c195111e-6dc0-4500-9a99-7daf587cf45c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7c4565fa0d239ce45338196f2e1c0056669940cdd7da099fc94c0d1de429b2e9'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='a00b85d0-013a-4199-af17-3d166f988439', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c5aca7b32fdfbc326f583c2add9febe4817aba222b754a46c97cdf96ce2fac7c')}, text='Separating the two allows us to\\napplyspecificguidelinestoeachandbetterguideannotators;forexample,oursafetyannotationsprovide\\ninstructions to focus on adversarial prompts, among other guidance.\\nApart from differences in annotation guidelines, we additionally collect a safety label during the safety stage.\\nThis additional information bins model responses into one of three categories: 1) the preferred response\\nis safe and the other response is not, 2) both responses are safe, and 3) both responses are unsafe, with\\n18%, 47%, and 35% of the safety dataset falling into each bin, respectively.', start_char_idx=3426, end_char_idx=4019, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-9', obj=None),\n",
       " 'a00b85d0-013a-4199-af17-3d166f988439': IndexNode(id_='a00b85d0-013a-4199-af17-3d166f988439', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c6a69762e43e49da5331b7b24e9a7f6e70061c11567bdd07934325aab06d90c0'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='0521e3af-e31e-41c7-a04b-3093e40cff8f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a456123c717a45f6669b85128b07de4794289c4b16f58da6de8d947e61e5051c'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='6b8e34a9-98bc-4326-a697-48e7efc81fd1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ea698c4220161828603e74b5a6fd4f6e0c75f8b25e9009e9e19301a3f3ddaaba')}, text='Apart from differences in annotation guidelines, we additionally collect a safety label during the safety stage.\\nThis additional information bins model responses into one of three categories: 1) the preferred response\\nis safe and the other response is not, 2) both responses are safe, and 3) both responses are unsafe, with\\n18%, 47%, and 35% of the safety dataset falling into each bin, respectively. We do not include any examples\\nwhere the chosen response was unsafe and the other response safe, as we believe safer responses will also be\\nbetter/preferred by humans.', start_char_idx=3619, end_char_idx=4187, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-9', obj=None),\n",
       " '6b8e34a9-98bc-4326-a697-48e7efc81fd1': IndexNode(id_='6b8e34a9-98bc-4326-a697-48e7efc81fd1', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c6a69762e43e49da5331b7b24e9a7f6e70061c11567bdd07934325aab06d90c0'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='a00b85d0-013a-4199-af17-3d166f988439', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c5aca7b32fdfbc326f583c2add9febe4817aba222b754a46c97cdf96ce2fac7c')}, text='We do not include any examples\\nwhere the chosen response was unsafe and the other response safe, as we believe safer responses will also be\\nbetter/preferred by humans. Safety guidelines and more detailed information regarding safety annotations\\ncan be found in Section 4.2.1.\\nHuman annotations were collected in batches on a weekly basis. As we collected more preference data, our\\nreward models improved, and we were able to train progressively better versions for Llama 2-Chat (see\\ntheresultsinSection5,Figure20).', start_char_idx=4020, end_char_idx=4534, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-9', obj=None),\n",
       " 'fe69b3ad-bf80-4b3a-9e6e-0c63204155ca': IndexNode(id_='fe69b3ad-bf80-4b3a-9e6e-0c63204155ca', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c6a69762e43e49da5331b7b24e9a7f6e70061c11567bdd07934325aab06d90c0'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='d58ce051-c663-4222-886b-a33b2b479621', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a3595beb9c66c58eeb1101a86f29fc0f88948299e9fdfc7665f7df7d1cdfb677')}, text='These\\nfindingsaresimilarinspirittoZhouetal.(2023),whichalsofindsthatalimitedsetofcleaninstruction-tuning\\ndatacanbesufficienttoreachahighlevelofquality. WefoundthatSFTannotationsintheorderoftensof\\nthousands was enough to achieve a high-quality result. We stopped annotating SFT after collecting a total of\\n27,540 annotations. Note that we do not include any Meta user data.\\nWealsoobservedthatdifferentannotationplatformsandvendorscanresultinmarkedlydifferentdown-\\nstream model performance, highlighting the importance of data checks even when using vendors to source\\nannotations. Tovalidateourdataquality,wecarefullyexaminedasetof180examples,comparingtheannota-\\ntions provided by humans with the samples generated by the model through manual scrutiny. Surprisingly,\\nwe found that the outputs sampled from the resulting SFT model were often competitive with SFT data\\nhandwritten by human annotators, suggesting that we could reprioritize and devote more annotation effort\\nto preference-based annotation for RLHF.\\nFine-Tuning Details.', start_char_idx=0, end_char_idx=1031, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-9', obj=None),\n",
       " 'd58ce051-c663-4222-886b-a33b2b479621': IndexNode(id_='d58ce051-c663-4222-886b-a33b2b479621', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c6a69762e43e49da5331b7b24e9a7f6e70061c11567bdd07934325aab06d90c0'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='fe69b3ad-bf80-4b3a-9e6e-0c63204155ca', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='cd5c92855196c3ecdf46e90abda06accf286830a56b4b9ba9d79b8ecdc66eed7'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='1ad5df4d-b06a-4483-96f7-27301b7815f1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='83effeb625497c7105bc48449c4a91aa5e5002f3330cce845fffab60b3d8abed')}, text='Tovalidateourdataquality,wecarefullyexaminedasetof180examples,comparingtheannota-\\ntions provided by humans with the samples generated by the model through manual scrutiny. Surprisingly,\\nwe found that the outputs sampled from the resulting SFT model were often competitive with SFT data\\nhandwritten by human annotators, suggesting that we could reprioritize and devote more annotation effort\\nto preference-based annotation for RLHF.\\nFine-Tuning Details. For supervised fine-tuning, we use a cosine learning rate schedule with an initial\\nlearning rate of 2×10−5, a weight decay of 0.1, a batch size of 64, and a sequence length of 4096 tokens.\\nFor the fine-tuning process, each sample consists of a prompt and an answer. To ensure the model sequence\\nlengthisproperlyfilled,weconcatenateallthepromptsandanswersfromthetrainingset. Aspecialtokenis\\nutilizedtoseparatethepromptandanswersegments. Weutilizeanautoregressiveobjectiveandzero-out\\nthe loss on tokens from the user prompt, so as a result, we backpropagate only on answer tokens.', start_char_idx=579, end_char_idx=1610, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-9', obj=None),\n",
       " '1ad5df4d-b06a-4483-96f7-27301b7815f1': IndexNode(id_='1ad5df4d-b06a-4483-96f7-27301b7815f1', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c6a69762e43e49da5331b7b24e9a7f6e70061c11567bdd07934325aab06d90c0'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='d58ce051-c663-4222-886b-a33b2b479621', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a3595beb9c66c58eeb1101a86f29fc0f88948299e9fdfc7665f7df7d1cdfb677'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='c2298dc2-44ff-43fc-a940-d1b6fe08c415', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b4ec94bdb1b3f2ae9e03c52ea50e6d59539bd13847057a1c2c269bd7b0e95084')}, text='To ensure the model sequence\\nlengthisproperlyfilled,weconcatenateallthepromptsandanswersfromthetrainingset. Aspecialtokenis\\nutilizedtoseparatethepromptandanswersegments. Weutilizeanautoregressiveobjectiveandzero-out\\nthe loss on tokens from the user prompt, so as a result, we backpropagate only on answer tokens. Finally, we\\nfine-tune the model for 2 epochs.\\n3.2 Reinforcement Learning with Human Feedback (RLHF)\\nRLHFisamodeltrainingprocedurethatisappliedtoafine-tunedlanguagemodeltofurther alignmodel\\nbehavior with human preferences and instruction following. We collect data that represents empirically\\n9\\n\\nsampled human preferences, whereby human annotators select which of two model outputs they prefer.\\nThis human feedback is subsequently used to train a reward model, which learns patterns in the preferences\\nof the human annotators and can then automate preference decisions.\\n3.2.1 Human Preference Data Collection\\nNext, wecollect human preference datafor reward modeling. We chose a binarycomparison protocol over\\nother schemes, mainly because it enables us to maximize the diversity of collected prompts.', start_char_idx=1298, end_char_idx=2410, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-9', obj=None),\n",
       " 'c2298dc2-44ff-43fc-a940-d1b6fe08c415': IndexNode(id_='c2298dc2-44ff-43fc-a940-d1b6fe08c415', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c6a69762e43e49da5331b7b24e9a7f6e70061c11567bdd07934325aab06d90c0'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='1ad5df4d-b06a-4483-96f7-27301b7815f1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='83effeb625497c7105bc48449c4a91aa5e5002f3330cce845fffab60b3d8abed'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='4d3c05fd-1d29-4add-bad8-4d1122475de4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3473c3659dfd7f60f41f1dcc3d3c2c6a132ab966b999451566328a0b5d177a8a')}, text='This human feedback is subsequently used to train a reward model, which learns patterns in the preferences\\nof the human annotators and can then automate preference decisions.\\n3.2.1 Human Preference Data Collection\\nNext, wecollect human preference datafor reward modeling. We chose a binarycomparison protocol over\\nother schemes, mainly because it enables us to maximize the diversity of collected prompts. Still, other\\nstrategies are worth considering, which we leave for future work.\\nOur annotation procedure proceeds as follows. We ask annotators to first write a prompt, then choose\\nbetweentwosampledmodelresponses,basedonprovidedcriteria. Inordertomaximizethediversity,the\\ntworesponsestoagivenpromptaresampledfromtwodifferentmodelvariants,andvaryingthetemperature\\nhyper-parameter. Inadditiontogivingparticipantsaforcedchoice,wealsoaskannotatorstolabelthedegree\\nto which they prefer their chosen response over the alternative: either their choice is significantly better ,better,\\nslightly better , ornegligibly better/ unsure .\\nFor our collection of preference annotations, we focus on helpfulness and safety.', start_char_idx=2005, end_char_idx=3117, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-9', obj=None),\n",
       " '4d3c05fd-1d29-4add-bad8-4d1122475de4': IndexNode(id_='4d3c05fd-1d29-4add-bad8-4d1122475de4', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c6a69762e43e49da5331b7b24e9a7f6e70061c11567bdd07934325aab06d90c0'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='c2298dc2-44ff-43fc-a940-d1b6fe08c415', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b4ec94bdb1b3f2ae9e03c52ea50e6d59539bd13847057a1c2c269bd7b0e95084'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='d079564c-06a5-4a3c-906c-fc1eb1c9ab13', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8a8c2a0ab7d4ad94711e4e1f3bb3660d4af310a7c29e0626b26bdf74ffb85bbf')}, text='Inadditiontogivingparticipantsaforcedchoice,wealsoaskannotatorstolabelthedegree\\nto which they prefer their chosen response over the alternative: either their choice is significantly better ,better,\\nslightly better , ornegligibly better/ unsure .\\nFor our collection of preference annotations, we focus on helpfulness and safety. Helpfulness refers to how\\nwell Llama 2-Chat responses fulfill users’ requests and provide requested information; safety refers to\\nwhether Llama 2-Chat ’s responses are unsafe, e.g., “giving detailed instructions on making a bomb” could\\nbe considered helpful but is unsafe according to our safety guidelines. Separating the two allows us to\\napplyspecificguidelinestoeachandbetterguideannotators;forexample,oursafetyannotationsprovide\\ninstructions to focus on adversarial prompts, among other guidance.\\nApart from differences in annotation guidelines, we additionally collect a safety label during the safety stage.', start_char_idx=2790, end_char_idx=3731, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-9', obj=None),\n",
       " 'd079564c-06a5-4a3c-906c-fc1eb1c9ab13': IndexNode(id_='d079564c-06a5-4a3c-906c-fc1eb1c9ab13', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c6a69762e43e49da5331b7b24e9a7f6e70061c11567bdd07934325aab06d90c0'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='4d3c05fd-1d29-4add-bad8-4d1122475de4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3473c3659dfd7f60f41f1dcc3d3c2c6a132ab966b999451566328a0b5d177a8a')}, text='Separating the two allows us to\\napplyspecificguidelinestoeachandbetterguideannotators;forexample,oursafetyannotationsprovide\\ninstructions to focus on adversarial prompts, among other guidance.\\nApart from differences in annotation guidelines, we additionally collect a safety label during the safety stage.\\nThis additional information bins model responses into one of three categories: 1) the preferred response\\nis safe and the other response is not, 2) both responses are safe, and 3) both responses are unsafe, with\\n18%, 47%, and 35% of the safety dataset falling into each bin, respectively. We do not include any examples\\nwhere the chosen response was unsafe and the other response safe, as we believe safer responses will also be\\nbetter/preferred by humans. Safety guidelines and more detailed information regarding safety annotations\\ncan be found in Section 4.2.1.\\nHuman annotations were collected in batches on a weekly basis. As we collected more preference data, our\\nreward models improved, and we were able to train progressively better versions for Llama 2-Chat (see\\ntheresultsinSection5,Figure20).', start_char_idx=3426, end_char_idx=4534, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-9', obj=None),\n",
       " 'a39dc0de-f4ba-4047-872d-6a2515261046': IndexNode(id_='a39dc0de-f4ba-4047-872d-6a2515261046', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c6a69762e43e49da5331b7b24e9a7f6e70061c11567bdd07934325aab06d90c0'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='b068595c-70c8-426a-8971-03f3dbd1333d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='950b210af043b52576be457dc1dce21fa98a21e85e6aef94ea5c044e03d89b5f')}, text='These\\nfindingsaresimilarinspirittoZhouetal.(2023),whichalsofindsthatalimitedsetofcleaninstruction-tuning\\ndatacanbesufficienttoreachahighlevelofquality. WefoundthatSFTannotationsintheorderoftensof\\nthousands was enough to achieve a high-quality result. We stopped annotating SFT after collecting a total of\\n27,540 annotations. Note that we do not include any Meta user data.\\nWealsoobservedthatdifferentannotationplatformsandvendorscanresultinmarkedlydifferentdown-\\nstream model performance, highlighting the importance of data checks even when using vendors to source\\nannotations. Tovalidateourdataquality,wecarefullyexaminedasetof180examples,comparingtheannota-\\ntions provided by humans with the samples generated by the model through manual scrutiny. Surprisingly,\\nwe found that the outputs sampled from the resulting SFT model were often competitive with SFT data\\nhandwritten by human annotators, suggesting that we could reprioritize and devote more annotation effort\\nto preference-based annotation for RLHF.\\nFine-Tuning Details. For supervised fine-tuning, we use a cosine learning rate schedule with an initial\\nlearning rate of 2×10−5, a weight decay of 0.1, a batch size of 64, and a sequence length of 4096 tokens.\\nFor the fine-tuning process, each sample consists of a prompt and an answer. To ensure the model sequence\\nlengthisproperlyfilled,weconcatenateallthepromptsandanswersfromthetrainingset. Aspecialtokenis\\nutilizedtoseparatethepromptandanswersegments. Weutilizeanautoregressiveobjectiveandzero-out\\nthe loss on tokens from the user prompt, so as a result, we backpropagate only on answer tokens. Finally, we\\nfine-tune the model for 2 epochs.\\n3.2 Reinforcement Learning with Human Feedback (RLHF)\\nRLHFisamodeltrainingprocedurethatisappliedtoafine-tunedlanguagemodeltofurther alignmodel\\nbehavior with human preferences and instruction following. We collect data that represents empirically\\n9\\n\\nsampled human preferences, whereby human annotators select which of two model outputs they prefer.\\nThis human feedback is subsequently used to train a reward model, which learns patterns in the preferences\\nof the human annotators and can then automate preference decisions.', start_char_idx=0, end_char_idx=2179, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-9', obj=None),\n",
       " 'b068595c-70c8-426a-8971-03f3dbd1333d': IndexNode(id_='b068595c-70c8-426a-8971-03f3dbd1333d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c6a69762e43e49da5331b7b24e9a7f6e70061c11567bdd07934325aab06d90c0'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='a39dc0de-f4ba-4047-872d-6a2515261046', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a7f46c38f30cc1074e9db95891040e8c88affe35e198a02b15309a017ad3d35e'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='e43ab97c-b8e4-4830-8645-0803cc3082f8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ea698c4220161828603e74b5a6fd4f6e0c75f8b25e9009e9e19301a3f3ddaaba')}, text='We collect data that represents empirically\\n9\\n\\nsampled human preferences, whereby human annotators select which of two model outputs they prefer.\\nThis human feedback is subsequently used to train a reward model, which learns patterns in the preferences\\nof the human annotators and can then automate preference decisions.\\n3.2.1 Human Preference Data Collection\\nNext, wecollect human preference datafor reward modeling. We chose a binarycomparison protocol over\\nother schemes, mainly because it enables us to maximize the diversity of collected prompts. Still, other\\nstrategies are worth considering, which we leave for future work.\\nOur annotation procedure proceeds as follows. We ask annotators to first write a prompt, then choose\\nbetweentwosampledmodelresponses,basedonprovidedcriteria. Inordertomaximizethediversity,the\\ntworesponsestoagivenpromptaresampledfromtwodifferentmodelvariants,andvaryingthetemperature\\nhyper-parameter. Inadditiontogivingparticipantsaforcedchoice,wealsoaskannotatorstolabelthedegree\\nto which they prefer their chosen response over the alternative: either their choice is significantly better ,better,\\nslightly better , ornegligibly better/ unsure .\\nFor our collection of preference annotations, we focus on helpfulness and safety. Helpfulness refers to how\\nwell Llama 2-Chat responses fulfill users’ requests and provide requested information; safety refers to\\nwhether Llama 2-Chat ’s responses are unsafe, e.g., “giving detailed instructions on making a bomb” could\\nbe considered helpful but is unsafe according to our safety guidelines. Separating the two allows us to\\napplyspecificguidelinestoeachandbetterguideannotators;forexample,oursafetyannotationsprovide\\ninstructions to focus on adversarial prompts, among other guidance.\\nApart from differences in annotation guidelines, we additionally collect a safety label during the safety stage.\\nThis additional information bins model responses into one of three categories: 1) the preferred response\\nis safe and the other response is not, 2) both responses are safe, and 3) both responses are unsafe, with\\n18%, 47%, and 35% of the safety dataset falling into each bin, respectively. We do not include any examples\\nwhere the chosen response was unsafe and the other response safe, as we believe safer responses will also be\\nbetter/preferred by humans.', start_char_idx=1859, end_char_idx=4187, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-9', obj=None),\n",
       " 'e43ab97c-b8e4-4830-8645-0803cc3082f8': IndexNode(id_='e43ab97c-b8e4-4830-8645-0803cc3082f8', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c6a69762e43e49da5331b7b24e9a7f6e70061c11567bdd07934325aab06d90c0'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='b068595c-70c8-426a-8971-03f3dbd1333d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='950b210af043b52576be457dc1dce21fa98a21e85e6aef94ea5c044e03d89b5f')}, text='We do not include any examples\\nwhere the chosen response was unsafe and the other response safe, as we believe safer responses will also be\\nbetter/preferred by humans. Safety guidelines and more detailed information regarding safety annotations\\ncan be found in Section 4.2.1.\\nHuman annotations were collected in batches on a weekly basis. As we collected more preference data, our\\nreward models improved, and we were able to train progressively better versions for Llama 2-Chat (see\\ntheresultsinSection5,Figure20).', start_char_idx=4020, end_char_idx=4534, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-9', obj=None),\n",
       " 'node-9': IndexNode(id_='node-9', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='d03f19eb-da15-45dc-bfd4-e5d10f161250', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='231b3bd773f012c01b893ada9e009ecf25ee59934614c5a595c9bf1b3a123292'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='f437d5df-0eaa-44e5-ad93-99aac0b0436e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c3110d390c246bc822086df697ba3496600d75f8f3bc8df9d3dd6976bffde7c6'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='0001cefe-8382-40ac-b380-c473be72c9b9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='716d71784a22cf05b9915bb68893d3f0e07e57aa1362e2ac7f1471dc334d89a5')}, text='These\\nfindingsaresimilarinspirittoZhouetal.(2023),whichalsofindsthatalimitedsetofcleaninstruction-tuning\\ndatacanbesufficienttoreachahighlevelofquality. WefoundthatSFTannotationsintheorderoftensof\\nthousands was enough to achieve a high-quality result. We stopped annotating SFT after collecting a total of\\n27,540 annotations. Note that we do not include any Meta user data.\\nWealsoobservedthatdifferentannotationplatformsandvendorscanresultinmarkedlydifferentdown-\\nstream model performance, highlighting the importance of data checks even when using vendors to source\\nannotations. Tovalidateourdataquality,wecarefullyexaminedasetof180examples,comparingtheannota-\\ntions provided by humans with the samples generated by the model through manual scrutiny. Surprisingly,\\nwe found that the outputs sampled from the resulting SFT model were often competitive with SFT data\\nhandwritten by human annotators, suggesting that we could reprioritize and devote more annotation effort\\nto preference-based annotation for RLHF.\\nFine-Tuning Details. For supervised fine-tuning, we use a cosine learning rate schedule with an initial\\nlearning rate of 2×10−5, a weight decay of 0.1, a batch size of 64, and a sequence length of 4096 tokens.\\nFor the fine-tuning process, each sample consists of a prompt and an answer. To ensure the model sequence\\nlengthisproperlyfilled,weconcatenateallthepromptsandanswersfromthetrainingset. Aspecialtokenis\\nutilizedtoseparatethepromptandanswersegments. Weutilizeanautoregressiveobjectiveandzero-out\\nthe loss on tokens from the user prompt, so as a result, we backpropagate only on answer tokens. Finally, we\\nfine-tune the model for 2 epochs.\\n3.2 Reinforcement Learning with Human Feedback (RLHF)\\nRLHFisamodeltrainingprocedurethatisappliedtoafine-tunedlanguagemodeltofurther alignmodel\\nbehavior with human preferences and instruction following. We collect data that represents empirically\\n9\\n\\nsampled human preferences, whereby human annotators select which of two model outputs they prefer.\\nThis human feedback is subsequently used to train a reward model, which learns patterns in the preferences\\nof the human annotators and can then automate preference decisions.\\n3.2.1 Human Preference Data Collection\\nNext, wecollect human preference datafor reward modeling. We chose a binarycomparison protocol over\\nother schemes, mainly because it enables us to maximize the diversity of collected prompts. Still, other\\nstrategies are worth considering, which we leave for future work.\\nOur annotation procedure proceeds as follows. We ask annotators to first write a prompt, then choose\\nbetweentwosampledmodelresponses,basedonprovidedcriteria. Inordertomaximizethediversity,the\\ntworesponsestoagivenpromptaresampledfromtwodifferentmodelvariants,andvaryingthetemperature\\nhyper-parameter. Inadditiontogivingparticipantsaforcedchoice,wealsoaskannotatorstolabelthedegree\\nto which they prefer their chosen response over the alternative: either their choice is significantly better ,better,\\nslightly better , ornegligibly better/ unsure .\\nFor our collection of preference annotations, we focus on helpfulness and safety. Helpfulness refers to how\\nwell Llama 2-Chat responses fulfill users’ requests and provide requested information; safety refers to\\nwhether Llama 2-Chat ’s responses are unsafe, e.g., “giving detailed instructions on making a bomb” could\\nbe considered helpful but is unsafe according to our safety guidelines. Separating the two allows us to\\napplyspecificguidelinestoeachandbetterguideannotators;forexample,oursafetyannotationsprovide\\ninstructions to focus on adversarial prompts, among other guidance.\\nApart from differences in annotation guidelines, we additionally collect a safety label during the safety stage.\\nThis additional information bins model responses into one of three categories: 1) the preferred response\\nis safe and the other response is not, 2) both responses are safe, and 3) both responses are unsafe, with\\n18%, 47%, and 35% of the safety dataset falling into each bin, respectively. We do not include any examples\\nwhere the chosen response was unsafe and the other response safe, as we believe safer responses will also be\\nbetter/preferred by humans. Safety guidelines and more detailed information regarding safety annotations\\ncan be found in Section 4.2.1.\\nHuman annotations were collected in batches on a weekly basis. As we collected more preference data, our\\nreward models improved, and we were able to train progressively better versions for Llama 2-Chat (see\\ntheresultsinSection5,Figure20).', start_char_idx=23731, end_char_idx=28265, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-9', obj=None),\n",
       " '194d98c5-6a75-4e48-a38b-8d3b41800470': IndexNode(id_='194d98c5-6a75-4e48-a38b-8d3b41800470', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-10', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='716d71784a22cf05b9915bb68893d3f0e07e57aa1362e2ac7f1471dc334d89a5'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='3ef3a4ef-6b23-4979-b679-c1490d4059cc', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='87d2c6253159fad71a7f4e633c289649f405435bcb1bb7618f544e9180c55e72')}, text='Safety guidelines and more detailed information regarding safety annotations\\ncan be found in Section 4.2.1.\\nHuman annotations were collected in batches on a weekly basis. As we collected more preference data, our\\nreward models improved, and we were able to train progressively better versions for Llama 2-Chat (see\\ntheresultsinSection5,Figure20). Llama 2-Chat improvementalsoshiftedthemodel’sdatadistribution.', start_char_idx=0, end_char_idx=409, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-10', obj=None),\n",
       " '3ef3a4ef-6b23-4979-b679-c1490d4059cc': IndexNode(id_='3ef3a4ef-6b23-4979-b679-c1490d4059cc', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-10', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='716d71784a22cf05b9915bb68893d3f0e07e57aa1362e2ac7f1471dc334d89a5'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='194d98c5-6a75-4e48-a38b-8d3b41800470', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='609a3dcdf81c9b1f3c31c65b182cc688bd32eee13222975cf938d3d64b1e657a'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='4573720f-2f9c-42ce-8ac8-02f4c8e80c96', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c357bfd726357585b26a679335ac30232ff7647e614b4e7c8564549a649aaec2')}, text='Safety guidelines and more detailed information regarding safety annotations\\ncan be found in Section 4.2.1.\\nHuman annotations were collected in batches on a weekly basis. As we collected more preference data, our\\nreward models improved, and we were able to train progressively better versions for Llama 2-Chat (see\\ntheresultsinSection5,Figure20). Llama 2-Chat improvementalsoshiftedthemodel’sdatadistribution.\\nSince reward model accuracy can quickly degrade if not exposed to this new sample distribution, i.e., from\\nhyper-specialization(Scialometal.,2020b),itisimportantbeforeanew Llama 2-Chat tuningiterationto\\ngather new preference data using the latest Llama 2-Chat iterations.', start_char_idx=0, end_char_idx=681, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-10', obj=None),\n",
       " '4573720f-2f9c-42ce-8ac8-02f4c8e80c96': IndexNode(id_='4573720f-2f9c-42ce-8ac8-02f4c8e80c96', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-10', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='716d71784a22cf05b9915bb68893d3f0e07e57aa1362e2ac7f1471dc334d89a5'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='3ef3a4ef-6b23-4979-b679-c1490d4059cc', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='87d2c6253159fad71a7f4e633c289649f405435bcb1bb7618f544e9180c55e72'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='e9e8cf79-bf04-4261-9129-517c6bcd982c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0d26d86acd2fdccbab071fbfac1f24fa7591db85390ec387527a425ee2c58e81')}, text='Llama 2-Chat improvementalsoshiftedthemodel’sdatadistribution.\\nSince reward model accuracy can quickly degrade if not exposed to this new sample distribution, i.e., from\\nhyper-specialization(Scialometal.,2020b),itisimportantbeforeanew Llama 2-Chat tuningiterationto\\ngather new preference data using the latest Llama 2-Chat iterations. This step helps keep the reward model\\non-distribution and maintain an accurate reward for the latest model.', start_char_idx=347, end_char_idx=789, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-10', obj=None),\n",
       " 'e9e8cf79-bf04-4261-9129-517c6bcd982c': IndexNode(id_='e9e8cf79-bf04-4261-9129-517c6bcd982c', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-10', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='716d71784a22cf05b9915bb68893d3f0e07e57aa1362e2ac7f1471dc334d89a5'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='4573720f-2f9c-42ce-8ac8-02f4c8e80c96', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c357bfd726357585b26a679335ac30232ff7647e614b4e7c8564549a649aaec2'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='95b20177-f32c-4f81-8872-aeb639f3f6d3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='02f81e684a604553a168b2d6508ba2a9096b5cd51d99c7ef5d6e920b85d1d2fc')}, text='Since reward model accuracy can quickly degrade if not exposed to this new sample distribution, i.e., from\\nhyper-specialization(Scialometal.,2020b),itisimportantbeforeanew Llama 2-Chat tuningiterationto\\ngather new preference data using the latest Llama 2-Chat iterations. This step helps keep the reward model\\non-distribution and maintain an accurate reward for the latest model.\\nInTable6,wereportthestatisticsofrewardmodelingdatathatwecollectedovertime,andpresentthem\\nagainst multiple open-source preference datasets including Anthropic Helpful and Harmless (Bai et al.,\\n2022a), OpenAISummarize(Stiennon etal., 2020),OpenAI WebGPT(Nakanoet al.,2021), StackExchange\\n(Lambert et al., 2023), Stanford Human Preferences (Ethayarajh et al., 2022), and Synthetic GPT-J (Havrilla).', start_char_idx=410, end_char_idx=1185, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-10', obj=None),\n",
       " '95b20177-f32c-4f81-8872-aeb639f3f6d3': IndexNode(id_='95b20177-f32c-4f81-8872-aeb639f3f6d3', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-10', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='716d71784a22cf05b9915bb68893d3f0e07e57aa1362e2ac7f1471dc334d89a5'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='e9e8cf79-bf04-4261-9129-517c6bcd982c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0d26d86acd2fdccbab071fbfac1f24fa7591db85390ec387527a425ee2c58e81'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='5fac6439-bc74-42dd-82ab-acbd99f0142d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='486301b1fe6b10e4b46eafceed31d921d3c06ae2b54d0e6b35a85120c8eb91fc')}, text='We collected a large dataset ofover 1million binary comparisons based on humansapplyingour specified\\nguidelines, which we refer to as Metareward modeling data. Note that the number of tokens in prompts and\\nanswers differs depending on the text domain. Summarization and online forum data generally have longer\\nprompts, while dialogue-style prompts are usually shorter. Compared to existing open-source datasets, our\\npreference data features more conversation turns, and are longer, on average.', start_char_idx=1186, end_char_idx=1679, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-10', obj=None),\n",
       " '5fac6439-bc74-42dd-82ab-acbd99f0142d': IndexNode(id_='5fac6439-bc74-42dd-82ab-acbd99f0142d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-10', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='716d71784a22cf05b9915bb68893d3f0e07e57aa1362e2ac7f1471dc334d89a5'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='95b20177-f32c-4f81-8872-aeb639f3f6d3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='02f81e684a604553a168b2d6508ba2a9096b5cd51d99c7ef5d6e920b85d1d2fc'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='b476c819-7f55-48d4-a740-8eff88e8dca8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='04b628eebf42a31466063ef611633505fbde7deff2bff6457b777402d9409d7a')}, text='Note that the number of tokens in prompts and\\nanswers differs depending on the text domain. Summarization and online forum data generally have longer\\nprompts, while dialogue-style prompts are usually shorter. Compared to existing open-source datasets, our\\npreference data features more conversation turns, and are longer, on average.\\n3.2.2 Reward Modeling\\nThe reward model takes a model response and its corresponding prompt (including contexts from previous\\nturns) as inputs and outputs a scalar score to indicate the quality (e.g., helpfulness and safety) of the model\\ngeneration.', start_char_idx=1346, end_char_idx=1928, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-10', obj=None),\n",
       " 'b476c819-7f55-48d4-a740-8eff88e8dca8': IndexNode(id_='b476c819-7f55-48d4-a740-8eff88e8dca8', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-10', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='716d71784a22cf05b9915bb68893d3f0e07e57aa1362e2ac7f1471dc334d89a5'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='5fac6439-bc74-42dd-82ab-acbd99f0142d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='486301b1fe6b10e4b46eafceed31d921d3c06ae2b54d0e6b35a85120c8eb91fc'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='8940f843-87fe-4acc-a156-c83c746eb857', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='31ccb3b9d65caa456b7356cd8145557ae8ad935154adb5e9009f26b4b16f9e0a')}, text='Compared to existing open-source datasets, our\\npreference data features more conversation turns, and are longer, on average.\\n3.2.2 Reward Modeling\\nThe reward model takes a model response and its corresponding prompt (including contexts from previous\\nturns) as inputs and outputs a scalar score to indicate the quality (e.g., helpfulness and safety) of the model\\ngeneration. Leveragingsuchresponsescoresasrewards,wecanoptimize Llama 2-Chat duringRLHFfor\\nbetter human preference alignment and improved helpfulness and safety.', start_char_idx=1555, end_char_idx=2078, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-10', obj=None),\n",
       " '8940f843-87fe-4acc-a156-c83c746eb857': IndexNode(id_='8940f843-87fe-4acc-a156-c83c746eb857', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-10', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='716d71784a22cf05b9915bb68893d3f0e07e57aa1362e2ac7f1471dc334d89a5'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='b476c819-7f55-48d4-a740-8eff88e8dca8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='04b628eebf42a31466063ef611633505fbde7deff2bff6457b777402d9409d7a'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='87705289-f71d-48b1-a964-c40a11c27bf8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='fe516ffad069797bc76c77f92ba2dc47928f7904c113a02c481b2c42e243b9f7')}, text='3.2.2 Reward Modeling\\nThe reward model takes a model response and its corresponding prompt (including contexts from previous\\nturns) as inputs and outputs a scalar score to indicate the quality (e.g., helpfulness and safety) of the model\\ngeneration. Leveragingsuchresponsescoresasrewards,wecanoptimize Llama 2-Chat duringRLHFfor\\nbetter human preference alignment and improved helpfulness and safety.\\nOthers have found that helpfulness and safety sometimes trade off (Bai et al., 2022a), which can make it\\nchallengingforasinglerewardmodeltoperformwellonboth.', start_char_idx=1680, end_char_idx=2236, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-10', obj=None),\n",
       " '87705289-f71d-48b1-a964-c40a11c27bf8': IndexNode(id_='87705289-f71d-48b1-a964-c40a11c27bf8', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-10', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='716d71784a22cf05b9915bb68893d3f0e07e57aa1362e2ac7f1471dc334d89a5'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='8940f843-87fe-4acc-a156-c83c746eb857', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='31ccb3b9d65caa456b7356cd8145557ae8ad935154adb5e9009f26b4b16f9e0a'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='c993074b-fff5-4d9b-8ce1-088afd13f4f4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='20c022af7e4daf2f50f4d23a4769227880a7de18b9abf3f4fd9d6565910d6eb2')}, text='Leveragingsuchresponsescoresasrewards,wecanoptimize Llama 2-Chat duringRLHFfor\\nbetter human preference alignment and improved helpfulness and safety.\\nOthers have found that helpfulness and safety sometimes trade off (Bai et al., 2022a), which can make it\\nchallengingforasinglerewardmodeltoperformwellonboth. Toaddressthis,wetraintwoseparatereward\\nmodels, one optimized for helpfulness (referred to as Helpfulness RM ) and another for safety ( Safety RM ).', start_char_idx=1929, end_char_idx=2384, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-10', obj=None),\n",
       " 'c993074b-fff5-4d9b-8ce1-088afd13f4f4': IndexNode(id_='c993074b-fff5-4d9b-8ce1-088afd13f4f4', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-10', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='716d71784a22cf05b9915bb68893d3f0e07e57aa1362e2ac7f1471dc334d89a5'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='87705289-f71d-48b1-a964-c40a11c27bf8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='fe516ffad069797bc76c77f92ba2dc47928f7904c113a02c481b2c42e243b9f7'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='edd235ac-ca22-40a2-a0a4-ab7771c9fa6a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='37558fdb3671208f36fa7bc4bff64707cd7e523857a8881411166415c12dc9c0')}, text='Others have found that helpfulness and safety sometimes trade off (Bai et al., 2022a), which can make it\\nchallengingforasinglerewardmodeltoperformwellonboth. Toaddressthis,wetraintwoseparatereward\\nmodels, one optimized for helpfulness (referred to as Helpfulness RM ) and another for safety ( Safety RM ).\\nWe initialize our reward models from pretrained chat model checkpoints, as it ensures that both models\\nbenefitfromknowledgeacquiredinpretraining.', start_char_idx=2079, end_char_idx=2530, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-10', obj=None),\n",
       " 'edd235ac-ca22-40a2-a0a4-ab7771c9fa6a': IndexNode(id_='edd235ac-ca22-40a2-a0a4-ab7771c9fa6a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-10', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='716d71784a22cf05b9915bb68893d3f0e07e57aa1362e2ac7f1471dc334d89a5'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='c993074b-fff5-4d9b-8ce1-088afd13f4f4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='20c022af7e4daf2f50f4d23a4769227880a7de18b9abf3f4fd9d6565910d6eb2'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='3c3a55f4-b11f-4812-9cdc-5beb7c38a406', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bae8287428f16daec94ea300a4f9a7b50e1d8a5855b07e913038e0c4103f7007')}, text='Toaddressthis,wetraintwoseparatereward\\nmodels, one optimized for helpfulness (referred to as Helpfulness RM ) and another for safety ( Safety RM ).\\nWe initialize our reward models from pretrained chat model checkpoints, as it ensures that both models\\nbenefitfromknowledgeacquiredinpretraining. Inshort, therewardmodel“knows” whatthechatmodel\\n10\\n\\nDatasetNum. of\\nComparisonsAvg. # Turns\\nper DialogueAvg. # Tokens\\nper ExampleAvg. # Tokens\\nin PromptAvg.', start_char_idx=2237, end_char_idx=2686, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-10', obj=None),\n",
       " '3c3a55f4-b11f-4812-9cdc-5beb7c38a406': IndexNode(id_='3c3a55f4-b11f-4812-9cdc-5beb7c38a406', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-10', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='716d71784a22cf05b9915bb68893d3f0e07e57aa1362e2ac7f1471dc334d89a5'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='edd235ac-ca22-40a2-a0a4-ab7771c9fa6a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='37558fdb3671208f36fa7bc4bff64707cd7e523857a8881411166415c12dc9c0'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='a065fa12-a15c-4f52-8755-99fb0257ace6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8d73e8729260e7a183f5974d6232fa8a56aa69b32988878efe1594423507f9ba')}, text='We initialize our reward models from pretrained chat model checkpoints, as it ensures that both models\\nbenefitfromknowledgeacquiredinpretraining. Inshort, therewardmodel“knows” whatthechatmodel\\n10\\n\\nDatasetNum. of\\nComparisonsAvg. # Turns\\nper DialogueAvg. # Tokens\\nper ExampleAvg. # Tokens\\nin PromptAvg. # Tokens\\nin Response\\nAnthropic Helpful 122,387 3.0 251.5 17.7 88.4\\nAnthropic Harmless 43,966 3.0 152.', start_char_idx=2385, end_char_idx=2788, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-10', obj=None),\n",
       " 'a065fa12-a15c-4f52-8755-99fb0257ace6': IndexNode(id_='a065fa12-a15c-4f52-8755-99fb0257ace6', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-10', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='716d71784a22cf05b9915bb68893d3f0e07e57aa1362e2ac7f1471dc334d89a5'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='3c3a55f4-b11f-4812-9cdc-5beb7c38a406', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bae8287428f16daec94ea300a4f9a7b50e1d8a5855b07e913038e0c4103f7007'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='b60ef637-b884-4afe-96ed-307993281b26', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4e817ff708f8e2de544fa8009087dbc558941e56a60bd0259728660cea77aa45')}, text='Inshort, therewardmodel“knows” whatthechatmodel\\n10\\n\\nDatasetNum. of\\nComparisonsAvg. # Turns\\nper DialogueAvg. # Tokens\\nper ExampleAvg. # Tokens\\nin PromptAvg. # Tokens\\nin Response\\nAnthropic Helpful 122,387 3.0 251.5 17.7 88.4\\nAnthropic Harmless 43,966 3.0 152.5 15.7 46.4\\nOpenAI Summarize 176,625 1.0 371.1 336.', start_char_idx=2531, end_char_idx=2839, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-10', obj=None),\n",
       " 'b60ef637-b884-4afe-96ed-307993281b26': IndexNode(id_='b60ef637-b884-4afe-96ed-307993281b26', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-10', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='716d71784a22cf05b9915bb68893d3f0e07e57aa1362e2ac7f1471dc334d89a5'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='a065fa12-a15c-4f52-8755-99fb0257ace6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8d73e8729260e7a183f5974d6232fa8a56aa69b32988878efe1594423507f9ba'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='9684b0e3-69e4-4f6b-83ff-30b4789deba9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='fd9fb54ecc05ad1ce2c06510f0962a7387bb8a4e31d97d9c9893862f3138a29c')}, text='# Turns\\nper DialogueAvg. # Tokens\\nper ExampleAvg. # Tokens\\nin PromptAvg. # Tokens\\nin Response\\nAnthropic Helpful 122,387 3.0 251.5 17.7 88.4\\nAnthropic Harmless 43,966 3.0 152.5 15.7 46.4\\nOpenAI Summarize 176,625 1.0 371.1 336.0 35.1\\nOpenAI WebGPT 13,333 1.0 237.2 48.', start_char_idx=2614, end_char_idx=2880, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-10', obj=None),\n",
       " '9684b0e3-69e4-4f6b-83ff-30b4789deba9': IndexNode(id_='9684b0e3-69e4-4f6b-83ff-30b4789deba9', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-10', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='716d71784a22cf05b9915bb68893d3f0e07e57aa1362e2ac7f1471dc334d89a5'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='b60ef637-b884-4afe-96ed-307993281b26', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4e817ff708f8e2de544fa8009087dbc558941e56a60bd0259728660cea77aa45'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='7bf84671-2c62-4da9-809f-43570fa78fb0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d5229e48ac534fab04c7e2887b1040e3ebd969bc543e030eaac1698abc351d6f')}, text='387 3.0 251.5 17.7 88.4\\nAnthropic Harmless 43,966 3.0 152.5 15.7 46.4\\nOpenAI Summarize 176,625 1.0 371.1 336.0 35.1\\nOpenAI WebGPT 13,333 1.0 237.2 48.3 188.9\\nStackExchange 1,038,480 1.0 440.2 200.1 240.2\\nStanford SHP 74,', start_char_idx=2730, end_char_idx=2950, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-10', obj=None),\n",
       " '7bf84671-2c62-4da9-809f-43570fa78fb0': IndexNode(id_='7bf84671-2c62-4da9-809f-43570fa78fb0', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-10', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='716d71784a22cf05b9915bb68893d3f0e07e57aa1362e2ac7f1471dc334d89a5'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='9684b0e3-69e4-4f6b-83ff-30b4789deba9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='fd9fb54ecc05ad1ce2c06510f0962a7387bb8a4e31d97d9c9893862f3138a29c'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='e066f4d2-57d3-475c-b2f2-07427c2c6a2b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='681a52dfb2336301db32dfb0d5f994998aae48e0dbb6c99d9f31784b55d6b4d2')}, text='0 152.5 15.7 46.4\\nOpenAI Summarize 176,625 1.0 371.1 336.0 35.1\\nOpenAI WebGPT 13,333 1.0 237.2 48.3 188.9\\nStackExchange 1,038,480 1.0 440.2 200.1 240.2\\nStanford SHP 74,882 1.0 338.3 199.5 138.8\\nSynthetic GPT-J 33,139 1.', start_char_idx=2782, end_char_idx=3001, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-10', obj=None),\n",
       " 'e066f4d2-57d3-475c-b2f2-07427c2c6a2b': IndexNode(id_='e066f4d2-57d3-475c-b2f2-07427c2c6a2b', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-10', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='716d71784a22cf05b9915bb68893d3f0e07e57aa1362e2ac7f1471dc334d89a5'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='7bf84671-2c62-4da9-809f-43570fa78fb0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d5229e48ac534fab04c7e2887b1040e3ebd969bc543e030eaac1698abc351d6f'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='aebbbadf-4a8c-4100-a869-8047d386de5e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='17965168fc5e323206198594adf5bb8a4386f960d56b24bf2f0a7a87681af126')}, text='1 336.0 35.1\\nOpenAI WebGPT 13,333 1.0 237.2 48.3 188.9\\nStackExchange 1,038,480 1.0 440.2 200.1 240.2\\nStanford SHP 74,882 1.0 338.3 199.5 138.8\\nSynthetic GPT-J 33,139 1.0 123.3 13.0 110.3\\nMeta (Safety & Helpfulness) 1,418,091 3.', start_char_idx=2833, end_char_idx=3060, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-10', obj=None),\n",
       " 'aebbbadf-4a8c-4100-a869-8047d386de5e': IndexNode(id_='aebbbadf-4a8c-4100-a869-8047d386de5e', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-10', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='716d71784a22cf05b9915bb68893d3f0e07e57aa1362e2ac7f1471dc334d89a5'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='e066f4d2-57d3-475c-b2f2-07427c2c6a2b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='681a52dfb2336301db32dfb0d5f994998aae48e0dbb6c99d9f31784b55d6b4d2'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='d7ab20ec-e285-44a2-a0bf-e99386362804', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e31058da151e5a06f7a67f63f54d64d858d7d90fc7330ab75f868cc2df5e035e')}, text='3 188.9\\nStackExchange 1,038,480 1.0 440.2 200.1 240.2\\nStanford SHP 74,882 1.0 338.3 199.5 138.8\\nSynthetic GPT-J 33,139 1.0 123.3 13.0 110.3\\nMeta (Safety & Helpfulness) 1,418,091 3.9 798.5 31.4 234.1\\nTotal 2,919,326 1.6 595.', start_char_idx=2880, end_char_idx=3103, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-10', obj=None),\n",
       " 'd7ab20ec-e285-44a2-a0bf-e99386362804': IndexNode(id_='d7ab20ec-e285-44a2-a0bf-e99386362804', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-10', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='716d71784a22cf05b9915bb68893d3f0e07e57aa1362e2ac7f1471dc334d89a5'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='aebbbadf-4a8c-4100-a869-8047d386de5e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='17965168fc5e323206198594adf5bb8a4386f960d56b24bf2f0a7a87681af126'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='cf943605-4636-4fdf-8b1d-9280fedca1af', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8341286a032421ef6b1033df3b99f6096fd4084530a5410a38e058711ea20bfd')}, text='2\\nStanford SHP 74,882 1.0 338.3 199.5 138.8\\nSynthetic GPT-J 33,139 1.0 123.3 13.0 110.3\\nMeta (Safety & Helpfulness) 1,418,091 3.9 798.5 31.4 234.1\\nTotal 2,919,326 1.6 595.7 108.2 216.9\\nTable 6: Statistics of human preference data for reward modeling.', start_char_idx=2932, end_char_idx=3182, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-10', obj=None),\n",
       " 'cf943605-4636-4fdf-8b1d-9280fedca1af': IndexNode(id_='cf943605-4636-4fdf-8b1d-9280fedca1af', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-10', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='716d71784a22cf05b9915bb68893d3f0e07e57aa1362e2ac7f1471dc334d89a5'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='d7ab20ec-e285-44a2-a0bf-e99386362804', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e31058da151e5a06f7a67f63f54d64d858d7d90fc7330ab75f868cc2df5e035e'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='44ea3dab-211f-4fdd-9508-2e5762f63629', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1043f9c139a673c0e3df6a28773d1d69d4a2dec3768d716cfb5371172efde6c7')}, text='5 138.8\\nSynthetic GPT-J 33,139 1.0 123.3 13.0 110.3\\nMeta (Safety & Helpfulness) 1,418,091 3.9 798.5 31.4 234.1\\nTotal 2,919,326 1.6 595.7 108.2 216.9\\nTable 6: Statistics of human preference data for reward modeling. We list both the open-source and\\ninternally collected human preference data used for reward modeling.', start_char_idx=2968, end_char_idx=3284, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-10', obj=None),\n",
       " '44ea3dab-211f-4fdd-9508-2e5762f63629': IndexNode(id_='44ea3dab-211f-4fdd-9508-2e5762f63629', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-10', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='716d71784a22cf05b9915bb68893d3f0e07e57aa1362e2ac7f1471dc334d89a5'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='cf943605-4636-4fdf-8b1d-9280fedca1af', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8341286a032421ef6b1033df3b99f6096fd4084530a5410a38e058711ea20bfd'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='d16e500d-7a8b-48dc-977b-1b0c24e470f4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='478c316be72bbbb05a1c130802a3cc9ec7994b1877bbde125810ecab96f4a0a6')}, text='3 13.0 110.3\\nMeta (Safety & Helpfulness) 1,418,091 3.9 798.5 31.4 234.1\\nTotal 2,919,326 1.6 595.7 108.2 216.9\\nTable 6: Statistics of human preference data for reward modeling. We list both the open-source and\\ninternally collected human preference data used for reward modeling. Note that a binary human preference\\ncomparisoncontains2responses(chosenandrejected)sharingthesameprompt(andpreviousdialogue).', start_char_idx=3007, end_char_idx=3410, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-10', obj=None),\n",
       " 'd16e500d-7a8b-48dc-977b-1b0c24e470f4': IndexNode(id_='d16e500d-7a8b-48dc-977b-1b0c24e470f4', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-10', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='716d71784a22cf05b9915bb68893d3f0e07e57aa1362e2ac7f1471dc334d89a5'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='44ea3dab-211f-4fdd-9508-2e5762f63629', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1043f9c139a673c0e3df6a28773d1d69d4a2dec3768d716cfb5371172efde6c7'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='28bfef19-92a7-44b9-baee-028228e30616', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='64e6e3e476be32e795d95dd675a4b198c37cf241d88f598a45949efef2ddacd2')}, text='9 798.5 31.4 234.1\\nTotal 2,919,326 1.6 595.7 108.2 216.9\\nTable 6: Statistics of human preference data for reward modeling. We list both the open-source and\\ninternally collected human preference data used for reward modeling. Note that a binary human preference\\ncomparisoncontains2responses(chosenandrejected)sharingthesameprompt(andpreviousdialogue).\\nEachexampleconsistsofaprompt(includingpreviousdialogueifavailable)andaresponse,whichisthe\\ninputoftherewardmodel.', start_char_idx=3060, end_char_idx=3523, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-10', obj=None),\n",
       " '28bfef19-92a7-44b9-baee-028228e30616': IndexNode(id_='28bfef19-92a7-44b9-baee-028228e30616', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-10', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='716d71784a22cf05b9915bb68893d3f0e07e57aa1362e2ac7f1471dc334d89a5'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='d16e500d-7a8b-48dc-977b-1b0c24e470f4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='478c316be72bbbb05a1c130802a3cc9ec7994b1877bbde125810ecab96f4a0a6')}, text='7 108.2 216.9\\nTable 6: Statistics of human preference data for reward modeling. We list both the open-source and\\ninternally collected human preference data used for reward modeling. Note that a binary human preference\\ncomparisoncontains2responses(chosenandrejected)sharingthesameprompt(andpreviousdialogue).\\nEachexampleconsistsofaprompt(includingpreviousdialogueifavailable)andaresponse,whichisthe\\ninputoftherewardmodel. Wereportthenumberofcomparisons,theaveragenumberofturnsperdialogue,\\nthe average number of tokens per example, per prompt and per response.', start_char_idx=3103, end_char_idx=3661, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-10', obj=None),\n",
       " '11281d6c-7219-4c0f-b2a3-435a3ce6ccc8': IndexNode(id_='11281d6c-7219-4c0f-b2a3-435a3ce6ccc8', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-10', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='716d71784a22cf05b9915bb68893d3f0e07e57aa1362e2ac7f1471dc334d89a5'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='3f0fe7cd-c57b-4f77-90b9-98a71034d99b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4434546c644e3c05fb09868f281bad661e5a5c5fb3582f90d5f8256cec4db804')}, text='Safety guidelines and more detailed information regarding safety annotations\\ncan be found in Section 4.2.1.\\nHuman annotations were collected in batches on a weekly basis. As we collected more preference data, our\\nreward models improved, and we were able to train progressively better versions for Llama 2-Chat (see\\ntheresultsinSection5,Figure20). Llama 2-Chat improvementalsoshiftedthemodel’sdatadistribution.\\nSince reward model accuracy can quickly degrade if not exposed to this new sample distribution, i.e., from\\nhyper-specialization(Scialometal.,2020b),itisimportantbeforeanew Llama 2-Chat tuningiterationto\\ngather new preference data using the latest Llama 2-Chat iterations. This step helps keep the reward model\\non-distribution and maintain an accurate reward for the latest model.', start_char_idx=0, end_char_idx=789, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-10', obj=None),\n",
       " '3f0fe7cd-c57b-4f77-90b9-98a71034d99b': IndexNode(id_='3f0fe7cd-c57b-4f77-90b9-98a71034d99b', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-10', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='716d71784a22cf05b9915bb68893d3f0e07e57aa1362e2ac7f1471dc334d89a5'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='11281d6c-7219-4c0f-b2a3-435a3ce6ccc8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b6c670304387f7bbee3fff2f5beff6f88f424799d6d82c8b77fce386dae4c2f9'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='559170ad-209a-47f5-a25e-08e682232613', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e76e798ec26d1412d4092be293569d8ef1e9c897db8233f6e72d4e7448a1f127')}, text='Since reward model accuracy can quickly degrade if not exposed to this new sample distribution, i.e., from\\nhyper-specialization(Scialometal.,2020b),itisimportantbeforeanew Llama 2-Chat tuningiterationto\\ngather new preference data using the latest Llama 2-Chat iterations. This step helps keep the reward model\\non-distribution and maintain an accurate reward for the latest model.\\nInTable6,wereportthestatisticsofrewardmodelingdatathatwecollectedovertime,andpresentthem\\nagainst multiple open-source preference datasets including Anthropic Helpful and Harmless (Bai et al.,\\n2022a), OpenAISummarize(Stiennon etal., 2020),OpenAI WebGPT(Nakanoet al.,2021), StackExchange\\n(Lambert et al., 2023), Stanford Human Preferences (Ethayarajh et al., 2022), and Synthetic GPT-J (Havrilla).\\nWe collected a large dataset ofover 1million binary comparisons based on humansapplyingour specified\\nguidelines, which we refer to as Metareward modeling data.', start_char_idx=410, end_char_idx=1345, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-10', obj=None),\n",
       " '559170ad-209a-47f5-a25e-08e682232613': IndexNode(id_='559170ad-209a-47f5-a25e-08e682232613', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-10', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='716d71784a22cf05b9915bb68893d3f0e07e57aa1362e2ac7f1471dc334d89a5'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='3f0fe7cd-c57b-4f77-90b9-98a71034d99b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4434546c644e3c05fb09868f281bad661e5a5c5fb3582f90d5f8256cec4db804'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='9a4d916f-dff9-42fe-ac9b-b44db0b42657', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='803080820188f0539479b02821d2ceac73480c77d0ee8f79d6ddb2f6621d31fc')}, text='We collected a large dataset ofover 1million binary comparisons based on humansapplyingour specified\\nguidelines, which we refer to as Metareward modeling data. Note that the number of tokens in prompts and\\nanswers differs depending on the text domain. Summarization and online forum data generally have longer\\nprompts, while dialogue-style prompts are usually shorter. Compared to existing open-source datasets, our\\npreference data features more conversation turns, and are longer, on average.\\n3.2.2 Reward Modeling\\nThe reward model takes a model response and its corresponding prompt (including contexts from previous\\nturns) as inputs and outputs a scalar score to indicate the quality (e.g., helpfulness and safety) of the model\\ngeneration. Leveragingsuchresponsescoresasrewards,wecanoptimize Llama 2-Chat duringRLHFfor\\nbetter human preference alignment and improved helpfulness and safety.\\nOthers have found that helpfulness and safety sometimes trade off (Bai et al., 2022a), which can make it\\nchallengingforasinglerewardmodeltoperformwellonboth.', start_char_idx=1186, end_char_idx=2236, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-10', obj=None),\n",
       " '9a4d916f-dff9-42fe-ac9b-b44db0b42657': IndexNode(id_='9a4d916f-dff9-42fe-ac9b-b44db0b42657', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-10', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='716d71784a22cf05b9915bb68893d3f0e07e57aa1362e2ac7f1471dc334d89a5'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='559170ad-209a-47f5-a25e-08e682232613', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e76e798ec26d1412d4092be293569d8ef1e9c897db8233f6e72d4e7448a1f127'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='407d58b9-b214-4254-a2de-0bc0b18053f4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='608b2c40234fca42bac239d93e54cf0e06f6dc35f3df8d03d7cd6561e495db08')}, text='Leveragingsuchresponsescoresasrewards,wecanoptimize Llama 2-Chat duringRLHFfor\\nbetter human preference alignment and improved helpfulness and safety.\\nOthers have found that helpfulness and safety sometimes trade off (Bai et al., 2022a), which can make it\\nchallengingforasinglerewardmodeltoperformwellonboth. Toaddressthis,wetraintwoseparatereward\\nmodels, one optimized for helpfulness (referred to as Helpfulness RM ) and another for safety ( Safety RM ).\\nWe initialize our reward models from pretrained chat model checkpoints, as it ensures that both models\\nbenefitfromknowledgeacquiredinpretraining. Inshort, therewardmodel“knows” whatthechatmodel\\n10\\n\\nDatasetNum. of\\nComparisonsAvg. # Turns\\nper DialogueAvg. # Tokens\\nper ExampleAvg. # Tokens\\nin PromptAvg.', start_char_idx=1929, end_char_idx=2686, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-10', obj=None),\n",
       " '407d58b9-b214-4254-a2de-0bc0b18053f4': IndexNode(id_='407d58b9-b214-4254-a2de-0bc0b18053f4', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-10', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='716d71784a22cf05b9915bb68893d3f0e07e57aa1362e2ac7f1471dc334d89a5'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='9a4d916f-dff9-42fe-ac9b-b44db0b42657', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='803080820188f0539479b02821d2ceac73480c77d0ee8f79d6ddb2f6621d31fc'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='09208ad8-6bfa-4546-bf3d-3a3f9072662e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b40d5e492c63a88dc66d99722eb040d860e89978b7d04db241e7afa0e4fbd592')}, text='We initialize our reward models from pretrained chat model checkpoints, as it ensures that both models\\nbenefitfromknowledgeacquiredinpretraining. Inshort, therewardmodel“knows” whatthechatmodel\\n10\\n\\nDatasetNum. of\\nComparisonsAvg. # Turns\\nper DialogueAvg. # Tokens\\nper ExampleAvg. # Tokens\\nin PromptAvg. # Tokens\\nin Response\\nAnthropic Helpful 122,387 3.0 251.5 17.7 88.4\\nAnthropic Harmless 43,966 3.0 152.5 15.7 46.4\\nOpenAI Summarize 176,625 1.0 371.1 336.0 35.1\\nOpenAI WebGPT 13,333 1.0 237.2 48.3 188.9\\nStackExchange 1,038,480 1.0 440.2 200.1 240.2\\nStanford SHP 74,882 1.0 338.3 199.5 138.8\\nSynthetic GPT-J 33,139 1.0 123.3 13.0 110.3\\nMeta (Safety & Helpfulness) 1,418,091 3.9 798.5 31.4 234.1\\nTotal 2,919,326 1.6 595.7 108.2 216.9\\nTable 6: Statistics of human preference data for reward modeling.', start_char_idx=2385, end_char_idx=3182, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-10', obj=None),\n",
       " '09208ad8-6bfa-4546-bf3d-3a3f9072662e': IndexNode(id_='09208ad8-6bfa-4546-bf3d-3a3f9072662e', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-10', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='716d71784a22cf05b9915bb68893d3f0e07e57aa1362e2ac7f1471dc334d89a5'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='407d58b9-b214-4254-a2de-0bc0b18053f4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='608b2c40234fca42bac239d93e54cf0e06f6dc35f3df8d03d7cd6561e495db08')}, text='We list both the open-source and\\ninternally collected human preference data used for reward modeling. Note that a binary human preference\\ncomparisoncontains2responses(chosenandrejected)sharingthesameprompt(andpreviousdialogue).\\nEachexampleconsistsofaprompt(includingpreviousdialogueifavailable)andaresponse,whichisthe\\ninputoftherewardmodel. Wereportthenumberofcomparisons,theaveragenumberofturnsperdialogue,\\nthe average number of tokens per example, per prompt and per response.', start_char_idx=3183, end_char_idx=3661, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-10', obj=None),\n",
       " '624e3b8c-044a-4151-ac32-d380ee37af31': IndexNode(id_='624e3b8c-044a-4151-ac32-d380ee37af31', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-10', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='716d71784a22cf05b9915bb68893d3f0e07e57aa1362e2ac7f1471dc334d89a5'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='b0090113-c2bd-4020-adc5-a3f6cca506a4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0d0ac87afcc0c0c45c1038ce68870ca33641b52f3b9d9f666de810c3c9f12b66')}, text='Safety guidelines and more detailed information regarding safety annotations\\ncan be found in Section 4.2.1.\\nHuman annotations were collected in batches on a weekly basis. As we collected more preference data, our\\nreward models improved, and we were able to train progressively better versions for Llama 2-Chat (see\\ntheresultsinSection5,Figure20). Llama 2-Chat improvementalsoshiftedthemodel’sdatadistribution.\\nSince reward model accuracy can quickly degrade if not exposed to this new sample distribution, i.e., from\\nhyper-specialization(Scialometal.,2020b),itisimportantbeforeanew Llama 2-Chat tuningiterationto\\ngather new preference data using the latest Llama 2-Chat iterations. This step helps keep the reward model\\non-distribution and maintain an accurate reward for the latest model.\\nInTable6,wereportthestatisticsofrewardmodelingdatathatwecollectedovertime,andpresentthem\\nagainst multiple open-source preference datasets including Anthropic Helpful and Harmless (Bai et al.,\\n2022a), OpenAISummarize(Stiennon etal., 2020),OpenAI WebGPT(Nakanoet al.,2021), StackExchange\\n(Lambert et al., 2023), Stanford Human Preferences (Ethayarajh et al., 2022), and Synthetic GPT-J (Havrilla).\\nWe collected a large dataset ofover 1million binary comparisons based on humansapplyingour specified\\nguidelines, which we refer to as Metareward modeling data. Note that the number of tokens in prompts and\\nanswers differs depending on the text domain. Summarization and online forum data generally have longer\\nprompts, while dialogue-style prompts are usually shorter. Compared to existing open-source datasets, our\\npreference data features more conversation turns, and are longer, on average.\\n3.2.2 Reward Modeling\\nThe reward model takes a model response and its corresponding prompt (including contexts from previous\\nturns) as inputs and outputs a scalar score to indicate the quality (e.g., helpfulness and safety) of the model\\ngeneration. Leveragingsuchresponsescoresasrewards,wecanoptimize Llama 2-Chat duringRLHFfor\\nbetter human preference alignment and improved helpfulness and safety.', start_char_idx=0, end_char_idx=2078, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-10', obj=None),\n",
       " 'b0090113-c2bd-4020-adc5-a3f6cca506a4': IndexNode(id_='b0090113-c2bd-4020-adc5-a3f6cca506a4', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-10', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='716d71784a22cf05b9915bb68893d3f0e07e57aa1362e2ac7f1471dc334d89a5'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='624e3b8c-044a-4151-ac32-d380ee37af31', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='154cbdd4300b2b44dcc63fc11f1aabc44c77276d5a2eb093cd5ba9d0e336a29c'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='76a4b85a-3716-468c-ba3d-67c92a737067', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b40d5e492c63a88dc66d99722eb040d860e89978b7d04db241e7afa0e4fbd592')}, text='3.2.2 Reward Modeling\\nThe reward model takes a model response and its corresponding prompt (including contexts from previous\\nturns) as inputs and outputs a scalar score to indicate the quality (e.g., helpfulness and safety) of the model\\ngeneration. Leveragingsuchresponsescoresasrewards,wecanoptimize Llama 2-Chat duringRLHFfor\\nbetter human preference alignment and improved helpfulness and safety.\\nOthers have found that helpfulness and safety sometimes trade off (Bai et al., 2022a), which can make it\\nchallengingforasinglerewardmodeltoperformwellonboth. Toaddressthis,wetraintwoseparatereward\\nmodels, one optimized for helpfulness (referred to as Helpfulness RM ) and another for safety ( Safety RM ).\\nWe initialize our reward models from pretrained chat model checkpoints, as it ensures that both models\\nbenefitfromknowledgeacquiredinpretraining. Inshort, therewardmodel“knows” whatthechatmodel\\n10\\n\\nDatasetNum. of\\nComparisonsAvg. # Turns\\nper DialogueAvg. # Tokens\\nper ExampleAvg. # Tokens\\nin PromptAvg. # Tokens\\nin Response\\nAnthropic Helpful 122,387 3.0 251.5 17.7 88.4\\nAnthropic Harmless 43,966 3.0 152.5 15.7 46.4\\nOpenAI Summarize 176,625 1.0 371.1 336.0 35.1\\nOpenAI WebGPT 13,333 1.0 237.2 48.3 188.9\\nStackExchange 1,038,480 1.0 440.2 200.1 240.2\\nStanford SHP 74,882 1.0 338.3 199.5 138.8\\nSynthetic GPT-J 33,139 1.0 123.3 13.0 110.3\\nMeta (Safety & Helpfulness) 1,418,091 3.9 798.5 31.4 234.1\\nTotal 2,919,326 1.6 595.7 108.2 216.9\\nTable 6: Statistics of human preference data for reward modeling.', start_char_idx=1680, end_char_idx=3182, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-10', obj=None),\n",
       " '76a4b85a-3716-468c-ba3d-67c92a737067': IndexNode(id_='76a4b85a-3716-468c-ba3d-67c92a737067', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-10', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='716d71784a22cf05b9915bb68893d3f0e07e57aa1362e2ac7f1471dc334d89a5'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='b0090113-c2bd-4020-adc5-a3f6cca506a4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0d0ac87afcc0c0c45c1038ce68870ca33641b52f3b9d9f666de810c3c9f12b66')}, text='We list both the open-source and\\ninternally collected human preference data used for reward modeling. Note that a binary human preference\\ncomparisoncontains2responses(chosenandrejected)sharingthesameprompt(andpreviousdialogue).\\nEachexampleconsistsofaprompt(includingpreviousdialogueifavailable)andaresponse,whichisthe\\ninputoftherewardmodel. Wereportthenumberofcomparisons,theaveragenumberofturnsperdialogue,\\nthe average number of tokens per example, per prompt and per response.', start_char_idx=3183, end_char_idx=3661, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-10', obj=None),\n",
       " 'node-10': IndexNode(id_='node-10', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='d03f19eb-da15-45dc-bfd4-e5d10f161250', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='231b3bd773f012c01b893ada9e009ecf25ee59934614c5a595c9bf1b3a123292'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='c7954930-4c5d-463d-8b39-16cd0d157d10', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c6a69762e43e49da5331b7b24e9a7f6e70061c11567bdd07934325aab06d90c0'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='410a9899-faa1-4f5e-a8fd-f5f42c23c4ad', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='67028bbb401a409a94495eb0c57e4d9b6af8e98e1ed453fe8f647bc94196224c')}, text='Safety guidelines and more detailed information regarding safety annotations\\ncan be found in Section 4.2.1.\\nHuman annotations were collected in batches on a weekly basis. As we collected more preference data, our\\nreward models improved, and we were able to train progressively better versions for Llama 2-Chat (see\\ntheresultsinSection5,Figure20). Llama 2-Chat improvementalsoshiftedthemodel’sdatadistribution.\\nSince reward model accuracy can quickly degrade if not exposed to this new sample distribution, i.e., from\\nhyper-specialization(Scialometal.,2020b),itisimportantbeforeanew Llama 2-Chat tuningiterationto\\ngather new preference data using the latest Llama 2-Chat iterations. This step helps keep the reward model\\non-distribution and maintain an accurate reward for the latest model.\\nInTable6,wereportthestatisticsofrewardmodelingdatathatwecollectedovertime,andpresentthem\\nagainst multiple open-source preference datasets including Anthropic Helpful and Harmless (Bai et al.,\\n2022a), OpenAISummarize(Stiennon etal., 2020),OpenAI WebGPT(Nakanoet al.,2021), StackExchange\\n(Lambert et al., 2023), Stanford Human Preferences (Ethayarajh et al., 2022), and Synthetic GPT-J (Havrilla).\\nWe collected a large dataset ofover 1million binary comparisons based on humansapplyingour specified\\nguidelines, which we refer to as Metareward modeling data. Note that the number of tokens in prompts and\\nanswers differs depending on the text domain. Summarization and online forum data generally have longer\\nprompts, while dialogue-style prompts are usually shorter. Compared to existing open-source datasets, our\\npreference data features more conversation turns, and are longer, on average.\\n3.2.2 Reward Modeling\\nThe reward model takes a model response and its corresponding prompt (including contexts from previous\\nturns) as inputs and outputs a scalar score to indicate the quality (e.g., helpfulness and safety) of the model\\ngeneration. Leveragingsuchresponsescoresasrewards,wecanoptimize Llama 2-Chat duringRLHFfor\\nbetter human preference alignment and improved helpfulness and safety.\\nOthers have found that helpfulness and safety sometimes trade off (Bai et al., 2022a), which can make it\\nchallengingforasinglerewardmodeltoperformwellonboth. Toaddressthis,wetraintwoseparatereward\\nmodels, one optimized for helpfulness (referred to as Helpfulness RM ) and another for safety ( Safety RM ).\\nWe initialize our reward models from pretrained chat model checkpoints, as it ensures that both models\\nbenefitfromknowledgeacquiredinpretraining. Inshort, therewardmodel“knows” whatthechatmodel\\n10\\n\\nDatasetNum. of\\nComparisonsAvg. # Turns\\nper DialogueAvg. # Tokens\\nper ExampleAvg. # Tokens\\nin PromptAvg. # Tokens\\nin Response\\nAnthropic Helpful 122,387 3.0 251.5 17.7 88.4\\nAnthropic Harmless 43,966 3.0 152.5 15.7 46.4\\nOpenAI Summarize 176,625 1.0 371.1 336.0 35.1\\nOpenAI WebGPT 13,333 1.0 237.2 48.3 188.9\\nStackExchange 1,038,480 1.0 440.2 200.1 240.2\\nStanford SHP 74,882 1.0 338.3 199.5 138.8\\nSynthetic GPT-J 33,139 1.0 123.3 13.0 110.3\\nMeta (Safety & Helpfulness) 1,418,091 3.9 798.5 31.4 234.1\\nTotal 2,919,326 1.6 595.7 108.2 216.9\\nTable 6: Statistics of human preference data for reward modeling. We list both the open-source and\\ninternally collected human preference data used for reward modeling. Note that a binary human preference\\ncomparisoncontains2responses(chosenandrejected)sharingthesameprompt(andpreviousdialogue).\\nEachexampleconsistsofaprompt(includingpreviousdialogueifavailable)andaresponse,whichisthe\\ninputoftherewardmodel. Wereportthenumberofcomparisons,theaveragenumberofturnsperdialogue,\\nthe average number of tokens per example, per prompt and per response.', start_char_idx=27919, end_char_idx=31580, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-10', obj=None),\n",
       " '1e5fbeb6-6b4c-4623-b460-a7b48643d618': IndexNode(id_='1e5fbeb6-6b4c-4623-b460-a7b48643d618', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-11', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='67028bbb401a409a94495eb0c57e4d9b6af8e98e1ed453fe8f647bc94196224c'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='310082d1-52d3-457d-b75d-89c018d78320', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='fd8f854edfb79b3fd0425ac6fd5b59c56f7291f5b0da733ca917545d95237514')}, text='Note that a binary human preference\\ncomparisoncontains2responses(chosenandrejected)sharingthesameprompt(andpreviousdialogue).\\nEachexampleconsistsofaprompt(includingpreviousdialogueifavailable)andaresponse,whichisthe\\ninputoftherewardmodel. Wereportthenumberofcomparisons,theaveragenumberofturnsperdialogue,\\nthe average number of tokens per example, per prompt and per response. More details on Meta helpfulness\\nand safety data per batch can be found in Appendix A.3.1.\\nknows.', start_char_idx=0, end_char_idx=474, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-11', obj=None),\n",
       " '310082d1-52d3-457d-b75d-89c018d78320': IndexNode(id_='310082d1-52d3-457d-b75d-89c018d78320', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-11', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='67028bbb401a409a94495eb0c57e4d9b6af8e98e1ed453fe8f647bc94196224c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='1e5fbeb6-6b4c-4623-b460-a7b48643d618', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='141ec6e0f49259c3ab7201aaf81f093172c772b0b25c441165a464b0013f316a'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='06cdb9e7-902c-4d8d-bf2f-242eea771d80', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ca45ee9bb8ba3f41a30dcac49cb5180cf1595a4e6283c4e6d93f15ad8c56d4e3')}, text='Eachexampleconsistsofaprompt(includingpreviousdialogueifavailable)andaresponse,whichisthe\\ninputoftherewardmodel. Wereportthenumberofcomparisons,theaveragenumberofturnsperdialogue,\\nthe average number of tokens per example, per prompt and per response. More details on Meta helpfulness\\nand safety data per batch can be found in Appendix A.3.1.\\nknows. Thispreventscaseswhere, forinstance, thetwomodelswouldhaveaninformationmismatch, which\\ncould result in favoring hallucinations.', start_char_idx=126, end_char_idx=602, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-11', obj=None),\n",
       " '06cdb9e7-902c-4d8d-bf2f-242eea771d80': IndexNode(id_='06cdb9e7-902c-4d8d-bf2f-242eea771d80', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-11', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='67028bbb401a409a94495eb0c57e4d9b6af8e98e1ed453fe8f647bc94196224c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='310082d1-52d3-457d-b75d-89c018d78320', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='fd8f854edfb79b3fd0425ac6fd5b59c56f7291f5b0da733ca917545d95237514'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='cf036392-5bfd-4584-87f2-e0ae256a5be4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='cd596405be31556e74c60d7e3f951a50a0c7aaebb2b6c1ff899417761e0d073b')}, text='Wereportthenumberofcomparisons,theaveragenumberofturnsperdialogue,\\nthe average number of tokens per example, per prompt and per response. More details on Meta helpfulness\\nand safety data per batch can be found in Appendix A.3.1.\\nknows. Thispreventscaseswhere, forinstance, thetwomodelswouldhaveaninformationmismatch, which\\ncould result in favoring hallucinations. The model architecture and hyper-parameters are identical to those\\nofthepretrainedlanguagemodels,exceptthattheclassificationheadfornext-tokenpredictionisreplaced\\nwith a regression head for outputting a scalar reward.', start_char_idx=239, end_char_idx=819, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-11', obj=None),\n",
       " 'cf036392-5bfd-4584-87f2-e0ae256a5be4': IndexNode(id_='cf036392-5bfd-4584-87f2-e0ae256a5be4', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-11', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='67028bbb401a409a94495eb0c57e4d9b6af8e98e1ed453fe8f647bc94196224c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='06cdb9e7-902c-4d8d-bf2f-242eea771d80', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ca45ee9bb8ba3f41a30dcac49cb5180cf1595a4e6283c4e6d93f15ad8c56d4e3'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='8ea71079-28d8-48ea-aa60-8378f62a5157', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6c9fdec5bb682110894d34d6e87a3d8ef33b1f9abfb55c5259dc050d866d31a3')}, text='knows. Thispreventscaseswhere, forinstance, thetwomodelswouldhaveaninformationmismatch, which\\ncould result in favoring hallucinations. The model architecture and hyper-parameters are identical to those\\nofthepretrainedlanguagemodels,exceptthattheclassificationheadfornext-tokenpredictionisreplaced\\nwith a regression head for outputting a scalar reward.\\nTraining Objectives.', start_char_idx=468, end_char_idx=840, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-11', obj=None),\n",
       " '8ea71079-28d8-48ea-aa60-8378f62a5157': IndexNode(id_='8ea71079-28d8-48ea-aa60-8378f62a5157', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-11', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='67028bbb401a409a94495eb0c57e4d9b6af8e98e1ed453fe8f647bc94196224c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='cf036392-5bfd-4584-87f2-e0ae256a5be4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='cd596405be31556e74c60d7e3f951a50a0c7aaebb2b6c1ff899417761e0d073b'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='e51024a7-07a8-42a7-bd3f-52b7a54b045a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ac97e0e6923e3ae591c77bf2f93280c4aa4e52722cf6726ea1cae9cdfddfb071')}, text='knows. Thispreventscaseswhere, forinstance, thetwomodelswouldhaveaninformationmismatch, which\\ncould result in favoring hallucinations. The model architecture and hyper-parameters are identical to those\\nofthepretrainedlanguagemodels,exceptthattheclassificationheadfornext-tokenpredictionisreplaced\\nwith a regression head for outputting a scalar reward.\\nTraining Objectives. To train the reward model, we convert our collected pairwise human preference data\\ninto a binary ranking label format (i.e., chosen & rejected) and enforce the chosen response to have a higher\\nscore than its counterpart.', start_char_idx=468, end_char_idx=1061, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-11', obj=None),\n",
       " 'e51024a7-07a8-42a7-bd3f-52b7a54b045a': IndexNode(id_='e51024a7-07a8-42a7-bd3f-52b7a54b045a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-11', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='67028bbb401a409a94495eb0c57e4d9b6af8e98e1ed453fe8f647bc94196224c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='8ea71079-28d8-48ea-aa60-8378f62a5157', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6c9fdec5bb682110894d34d6e87a3d8ef33b1f9abfb55c5259dc050d866d31a3'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='3c509e24-0d17-4f0c-a86d-97d25c6abad2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d3881a675215c7f0cd2b254f7925ec1b8fc820929fa218cd93a941719c493096')}, text='The model architecture and hyper-parameters are identical to those\\nofthepretrainedlanguagemodels,exceptthattheclassificationheadfornext-tokenpredictionisreplaced\\nwith a regression head for outputting a scalar reward.\\nTraining Objectives. To train the reward model, we convert our collected pairwise human preference data\\ninto a binary ranking label format (i.e., chosen & rejected) and enforce the chosen response to have a higher\\nscore than its counterpart. We used a binary ranking loss consistent with Ouyang et al.', start_char_idx=603, end_char_idx=1121, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-11', obj=None),\n",
       " '3c509e24-0d17-4f0c-a86d-97d25c6abad2': IndexNode(id_='3c509e24-0d17-4f0c-a86d-97d25c6abad2', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-11', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='67028bbb401a409a94495eb0c57e4d9b6af8e98e1ed453fe8f647bc94196224c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='e51024a7-07a8-42a7-bd3f-52b7a54b045a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ac97e0e6923e3ae591c77bf2f93280c4aa4e52722cf6726ea1cae9cdfddfb071'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='8cd67482-04f1-4245-9909-2fcad73c032e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='150cfe1c190d517b0b96e2a1c2eb63b5d9288694297fda91da5afcfa2707654d')}, text='Training Objectives. To train the reward model, we convert our collected pairwise human preference data\\ninto a binary ranking label format (i.e., chosen & rejected) and enforce the chosen response to have a higher\\nscore than its counterpart. We used a binary ranking loss consistent with Ouyang et al. (2022):\\nLranking =−log(σ(rθ(x, yc)−rθ(x, yr))) (1)\\nwhere rθ(x, y)is the scalar score output for prompt xand completion ywith model weights θ.ycis the\\npreferred response that annotators choose and yris the rejected counterpart.', start_char_idx=820, end_char_idx=1348, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-11', obj=None),\n",
       " '8cd67482-04f1-4245-9909-2fcad73c032e': IndexNode(id_='8cd67482-04f1-4245-9909-2fcad73c032e', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-11', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='67028bbb401a409a94495eb0c57e4d9b6af8e98e1ed453fe8f647bc94196224c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='3c509e24-0d17-4f0c-a86d-97d25c6abad2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d3881a675215c7f0cd2b254f7925ec1b8fc820929fa218cd93a941719c493096'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='b91c8b3c-9976-4f90-8b28-294050f5a2f9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='86801726ce71f645207d0db16d3494f8b1b3df62b037b4f98f2dd42f89615f42')}, text='We used a binary ranking loss consistent with Ouyang et al. (2022):\\nLranking =−log(σ(rθ(x, yc)−rθ(x, yr))) (1)\\nwhere rθ(x, y)is the scalar score output for prompt xand completion ywith model weights θ.ycis the\\npreferred response that annotators choose and yris the rejected counterpart.\\nBuilt on top of this binary ranking loss, we further modify it separately for better helpfulness and safety\\nrewardmodelsasfollows.', start_char_idx=1062, end_char_idx=1479, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-11', obj=None),\n",
       " 'b91c8b3c-9976-4f90-8b28-294050f5a2f9': IndexNode(id_='b91c8b3c-9976-4f90-8b28-294050f5a2f9', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-11', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='67028bbb401a409a94495eb0c57e4d9b6af8e98e1ed453fe8f647bc94196224c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='8cd67482-04f1-4245-9909-2fcad73c032e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='150cfe1c190d517b0b96e2a1c2eb63b5d9288694297fda91da5afcfa2707654d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='3dcffe6e-5b93-4f7e-a3e4-74f887529535', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='57aebd4016bab06470707d0e078a169b5d67e4e80c637814d186cff79eeb38c1')}, text='(2022):\\nLranking =−log(σ(rθ(x, yc)−rθ(x, yr))) (1)\\nwhere rθ(x, y)is the scalar score output for prompt xand completion ywith model weights θ.ycis the\\npreferred response that annotators choose and yris the rejected counterpart.\\nBuilt on top of this binary ranking loss, we further modify it separately for better helpfulness and safety\\nrewardmodelsasfollows. Giventhatourpreferenceratingsisdecomposedasascaleoffourpoints(e.g.,\\nsignificantly better ), as presented in Section 3.2.1, it can be useful to leverage this information to explicitly\\nteachtherewardmodeltoassignmorediscrepantscorestothegenerationsthathavemoredifferences.', start_char_idx=1122, end_char_idx=1750, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-11', obj=None),\n",
       " '3dcffe6e-5b93-4f7e-a3e4-74f887529535': IndexNode(id_='3dcffe6e-5b93-4f7e-a3e4-74f887529535', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-11', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='67028bbb401a409a94495eb0c57e4d9b6af8e98e1ed453fe8f647bc94196224c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='b91c8b3c-9976-4f90-8b28-294050f5a2f9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='86801726ce71f645207d0db16d3494f8b1b3df62b037b4f98f2dd42f89615f42'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='77db26a7-58a7-461f-8c00-5f7e6d64e803', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='060927b7d6b4cd35b6fd09cfd952f64d7ddb65024ba34ade64fac37a27df7f41')}, text='Built on top of this binary ranking loss, we further modify it separately for better helpfulness and safety\\nrewardmodelsasfollows. Giventhatourpreferenceratingsisdecomposedasascaleoffourpoints(e.g.,\\nsignificantly better ), as presented in Section 3.2.1, it can be useful to leverage this information to explicitly\\nteachtherewardmodeltoassignmorediscrepantscorestothegenerationsthathavemoredifferences. To\\ndo so, we further add a margin component in the loss:\\nLranking =−log(σ(rθ(x, yc)−rθ(x, yr)−m(r))) (2)\\nwhere the margin m(r)is a discrete function of the preference rating.', start_char_idx=1349, end_char_idx=1925, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-11', obj=None),\n",
       " '77db26a7-58a7-461f-8c00-5f7e6d64e803': IndexNode(id_='77db26a7-58a7-461f-8c00-5f7e6d64e803', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-11', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='67028bbb401a409a94495eb0c57e4d9b6af8e98e1ed453fe8f647bc94196224c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='3dcffe6e-5b93-4f7e-a3e4-74f887529535', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='57aebd4016bab06470707d0e078a169b5d67e4e80c637814d186cff79eeb38c1'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='f07a6113-ff02-4795-9e33-d3b7f87fb75a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='640024022f88b5cbddefaed3b1f5dba9f8f8de6eaf1f392f845056ec5f16e8af')}, text='To\\ndo so, we further add a margin component in the loss:\\nLranking =−log(σ(rθ(x, yc)−rθ(x, yr)−m(r))) (2)\\nwhere the margin m(r)is a discrete function of the preference rating. Naturally, we use a large margin\\nfor pairs with distinct responses, and a smaller one for those with similar responses (shown in Table 27).\\nWefoundthismargincomponentcanimproveHelpfulnessrewardmodelaccuracyespeciallyonsamples\\nwheretworesponsesaremoreseparable.', start_char_idx=1751, end_char_idx=2186, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-11', obj=None),\n",
       " 'f07a6113-ff02-4795-9e33-d3b7f87fb75a': IndexNode(id_='f07a6113-ff02-4795-9e33-d3b7f87fb75a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-11', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='67028bbb401a409a94495eb0c57e4d9b6af8e98e1ed453fe8f647bc94196224c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='77db26a7-58a7-461f-8c00-5f7e6d64e803', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='060927b7d6b4cd35b6fd09cfd952f64d7ddb65024ba34ade64fac37a27df7f41'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='14c789f1-4438-4ae8-bb30-b4b9d0b060b9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='83feedab866d8276d5bb16835bce1c45f5c68ec199a54bff5701a0f54f24e3e9')}, text='Naturally, we use a large margin\\nfor pairs with distinct responses, and a smaller one for those with similar responses (shown in Table 27).\\nWefoundthismargincomponentcanimproveHelpfulnessrewardmodelaccuracyespeciallyonsamples\\nwheretworesponsesaremoreseparable. MoredetailedablationandanalysiscanbefoundinTable28in\\nAppendix A.3.3.\\nDataComposition. Wecombineournewlycollecteddatawithexistingopen-sourcepreferencedatasets\\ntoformalargertrainingdataset.', start_char_idx=1926, end_char_idx=2374, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-11', obj=None),\n",
       " '14c789f1-4438-4ae8-bb30-b4b9d0b060b9': IndexNode(id_='14c789f1-4438-4ae8-bb30-b4b9d0b060b9', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-11', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='67028bbb401a409a94495eb0c57e4d9b6af8e98e1ed453fe8f647bc94196224c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='f07a6113-ff02-4795-9e33-d3b7f87fb75a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='640024022f88b5cbddefaed3b1f5dba9f8f8de6eaf1f392f845056ec5f16e8af'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='091ebe97-9e26-476e-9250-4cbbe5a12c03', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2590ee21bc5a3cd2d1d30f262f062503679f41d4d0f5d29def66922873360d8d')}, text='WefoundthismargincomponentcanimproveHelpfulnessrewardmodelaccuracyespeciallyonsamples\\nwheretworesponsesaremoreseparable. MoredetailedablationandanalysiscanbefoundinTable28in\\nAppendix A.3.3.\\nDataComposition. Wecombineournewlycollecteddatawithexistingopen-sourcepreferencedatasets\\ntoformalargertrainingdataset. Initially,open-sourcedatasetswereusedtobootstrapourrewardmodels\\nwhilewewereintheprocessofcollectingpreferenceannotationdata.', start_char_idx=2066, end_char_idx=2499, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-11', obj=None),\n",
       " '091ebe97-9e26-476e-9250-4cbbe5a12c03': IndexNode(id_='091ebe97-9e26-476e-9250-4cbbe5a12c03', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-11', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='67028bbb401a409a94495eb0c57e4d9b6af8e98e1ed453fe8f647bc94196224c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='14c789f1-4438-4ae8-bb30-b4b9d0b060b9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='83feedab866d8276d5bb16835bce1c45f5c68ec199a54bff5701a0f54f24e3e9'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='819052ad-ffb7-4c18-8209-5ba088cc4ccd', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f80e8457c119d2f2cc7aa8ef9f609b6f9fcab3c8beacf68527f89726c519e37e')}, text='MoredetailedablationandanalysiscanbefoundinTable28in\\nAppendix A.3.3.\\nDataComposition. Wecombineournewlycollecteddatawithexistingopen-sourcepreferencedatasets\\ntoformalargertrainingdataset. Initially,open-sourcedatasetswereusedtobootstrapourrewardmodels\\nwhilewewereintheprocessofcollectingpreferenceannotationdata. WenotethatinthecontextofRLHFin\\nthis study, the role of reward signals is to learn human preference for Llama 2-Chat outputs rather than\\nany model outputs.', start_char_idx=2187, end_char_idx=2654, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-11', obj=None),\n",
       " '819052ad-ffb7-4c18-8209-5ba088cc4ccd': IndexNode(id_='819052ad-ffb7-4c18-8209-5ba088cc4ccd', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-11', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='67028bbb401a409a94495eb0c57e4d9b6af8e98e1ed453fe8f647bc94196224c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='091ebe97-9e26-476e-9250-4cbbe5a12c03', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2590ee21bc5a3cd2d1d30f262f062503679f41d4d0f5d29def66922873360d8d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='7d0169b6-c791-43a1-b895-cd36d04c9f96', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ad3ee78ec3cd75f223506d6eb62026f9220ccefcc60646362555c4354e7f4814')}, text='Wecombineournewlycollecteddatawithexistingopen-sourcepreferencedatasets\\ntoformalargertrainingdataset. Initially,open-sourcedatasetswereusedtobootstrapourrewardmodels\\nwhilewewereintheprocessofcollectingpreferenceannotationdata. WenotethatinthecontextofRLHFin\\nthis study, the role of reward signals is to learn human preference for Llama 2-Chat outputs rather than\\nany model outputs. However, in our experiments, we do not observe negative transfer from the open-source\\npreferencedatasets.', start_char_idx=2273, end_char_idx=2760, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-11', obj=None),\n",
       " '7d0169b6-c791-43a1-b895-cd36d04c9f96': IndexNode(id_='7d0169b6-c791-43a1-b895-cd36d04c9f96', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-11', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='67028bbb401a409a94495eb0c57e4d9b6af8e98e1ed453fe8f647bc94196224c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='819052ad-ffb7-4c18-8209-5ba088cc4ccd', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f80e8457c119d2f2cc7aa8ef9f609b6f9fcab3c8beacf68527f89726c519e37e'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='1275930b-c388-430a-869d-59d8c0860c9a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='366b999003a3e32a0a34eed20cfa57a08c090aa7e927bdb9d9fc9637422b3f23')}, text='Initially,open-sourcedatasetswereusedtobootstrapourrewardmodels\\nwhilewewereintheprocessofcollectingpreferenceannotationdata. WenotethatinthecontextofRLHFin\\nthis study, the role of reward signals is to learn human preference for Llama 2-Chat outputs rather than\\nany model outputs. However, in our experiments, we do not observe negative transfer from the open-source\\npreferencedatasets. Thus,wehavedecidedtokeeptheminourdatamixture,astheycouldenablebetter\\ngeneralization for the reward model and prevent reward hacking, i.e.', start_char_idx=2375, end_char_idx=2898, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-11', obj=None),\n",
       " '1275930b-c388-430a-869d-59d8c0860c9a': IndexNode(id_='1275930b-c388-430a-869d-59d8c0860c9a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-11', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='67028bbb401a409a94495eb0c57e4d9b6af8e98e1ed453fe8f647bc94196224c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='7d0169b6-c791-43a1-b895-cd36d04c9f96', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ad3ee78ec3cd75f223506d6eb62026f9220ccefcc60646362555c4354e7f4814'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='8b2fa7b2-7f66-413f-8ea3-a33990810faa', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='26e7f3d7d5bb2f1e3d5e2ef29d3ed193c07b02f1ccfa77ba8750f73ed671f0b9')}, text='WenotethatinthecontextofRLHFin\\nthis study, the role of reward signals is to learn human preference for Llama 2-Chat outputs rather than\\nany model outputs. However, in our experiments, we do not observe negative transfer from the open-source\\npreferencedatasets. Thus,wehavedecidedtokeeptheminourdatamixture,astheycouldenablebetter\\ngeneralization for the reward model and prevent reward hacking, i.e. Llama 2-Chat taking advantage of\\nsome weaknesses of our reward, and so artificially inflating the score despite performing less well.', start_char_idx=2500, end_char_idx=3032, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-11', obj=None),\n",
       " '8b2fa7b2-7f66-413f-8ea3-a33990810faa': IndexNode(id_='8b2fa7b2-7f66-413f-8ea3-a33990810faa', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-11', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='67028bbb401a409a94495eb0c57e4d9b6af8e98e1ed453fe8f647bc94196224c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='1275930b-c388-430a-869d-59d8c0860c9a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='366b999003a3e32a0a34eed20cfa57a08c090aa7e927bdb9d9fc9637422b3f23'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='0c897e52-96f2-429f-b750-fbf2b7f50151', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3e1087ab93c2ffe9cc4d9878f549244a0da9d7508eaacace4f58878fc7605e92')}, text='However, in our experiments, we do not observe negative transfer from the open-source\\npreferencedatasets. Thus,wehavedecidedtokeeptheminourdatamixture,astheycouldenablebetter\\ngeneralization for the reward model and prevent reward hacking, i.e. Llama 2-Chat taking advantage of\\nsome weaknesses of our reward, and so artificially inflating the score despite performing less well.\\nWith training data available from different sources, we experimented with different mixing recipes for both\\nHelpfulnessandSafetyrewardmodelstoascertainthebestsettings.', start_char_idx=2655, end_char_idx=3200, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-11', obj=None),\n",
       " '0c897e52-96f2-429f-b750-fbf2b7f50151': IndexNode(id_='0c897e52-96f2-429f-b750-fbf2b7f50151', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-11', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='67028bbb401a409a94495eb0c57e4d9b6af8e98e1ed453fe8f647bc94196224c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='8b2fa7b2-7f66-413f-8ea3-a33990810faa', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='26e7f3d7d5bb2f1e3d5e2ef29d3ed193c07b02f1ccfa77ba8750f73ed671f0b9'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='791b8183-1e86-470f-8454-7ae47f873eb1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6e916b3b56d47035699ba568a1aa734e0c10336f630d801054124be98b68f41d')}, text='Thus,wehavedecidedtokeeptheminourdatamixture,astheycouldenablebetter\\ngeneralization for the reward model and prevent reward hacking, i.e. Llama 2-Chat taking advantage of\\nsome weaknesses of our reward, and so artificially inflating the score despite performing less well.\\nWith training data available from different sources, we experimented with different mixing recipes for both\\nHelpfulnessandSafetyrewardmodelstoascertainthebestsettings. Afterextensiveexperimentation,the\\n11\\n\\nHelpfulness reward model is eventually trained on all Meta Helpfulness data, combined with an equal\\npartsoftheremainingdatauniformlysampledfromMetaSafetyandfromtheopen-sourcedatasets.', start_char_idx=2761, end_char_idx=3422, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-11', obj=None),\n",
       " '791b8183-1e86-470f-8454-7ae47f873eb1': IndexNode(id_='791b8183-1e86-470f-8454-7ae47f873eb1', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-11', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='67028bbb401a409a94495eb0c57e4d9b6af8e98e1ed453fe8f647bc94196224c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='0c897e52-96f2-429f-b750-fbf2b7f50151', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3e1087ab93c2ffe9cc4d9878f549244a0da9d7508eaacace4f58878fc7605e92'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='e8eadacc-ef34-4039-8d71-e018741ab172', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1fa25616eeaa73b8de9afdc1ee744ff803014518cc8423ddcfeb6e26fb5bab85')}, text='With training data available from different sources, we experimented with different mixing recipes for both\\nHelpfulnessandSafetyrewardmodelstoascertainthebestsettings. Afterextensiveexperimentation,the\\n11\\n\\nHelpfulness reward model is eventually trained on all Meta Helpfulness data, combined with an equal\\npartsoftheremainingdatauniformlysampledfromMetaSafetyandfromtheopen-sourcedatasets. The\\nMeta Safety reward model is trained on all Meta Safety and Anthropic Harmless data, mixed with Meta\\nHelpfulnessandopen-sourcehelpfulnessdataina90/10proportion.', start_char_idx=3033, end_char_idx=3586, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-11', obj=None),\n",
       " 'e8eadacc-ef34-4039-8d71-e018741ab172': IndexNode(id_='e8eadacc-ef34-4039-8d71-e018741ab172', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-11', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='67028bbb401a409a94495eb0c57e4d9b6af8e98e1ed453fe8f647bc94196224c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='791b8183-1e86-470f-8454-7ae47f873eb1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6e916b3b56d47035699ba568a1aa734e0c10336f630d801054124be98b68f41d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='01a7d701-1e98-48fa-a76e-20708f439b90', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='535da1b3addf8c3058a1048b91632944289b3b98bf2f16493a592edeb7a1674f')}, text='Afterextensiveexperimentation,the\\n11\\n\\nHelpfulness reward model is eventually trained on all Meta Helpfulness data, combined with an equal\\npartsoftheremainingdatauniformlysampledfromMetaSafetyandfromtheopen-sourcedatasets. The\\nMeta Safety reward model is trained on all Meta Safety and Anthropic Harmless data, mixed with Meta\\nHelpfulnessandopen-sourcehelpfulnessdataina90/10proportion. Wefoundthatthesettingwith10%\\nhelpfulness data is especially beneficial for the accuracy on samples where both the chosen and rejected\\nresponses were deemed safe.\\nTraining Details.', start_char_idx=3201, end_char_idx=3766, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-11', obj=None),\n",
       " '01a7d701-1e98-48fa-a76e-20708f439b90': IndexNode(id_='01a7d701-1e98-48fa-a76e-20708f439b90', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-11', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='67028bbb401a409a94495eb0c57e4d9b6af8e98e1ed453fe8f647bc94196224c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='e8eadacc-ef34-4039-8d71-e018741ab172', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1fa25616eeaa73b8de9afdc1ee744ff803014518cc8423ddcfeb6e26fb5bab85'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='e8fe8ab2-4220-446e-aa58-652583f1ec5e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d25481be68aabf592c181216dfdc7516a72dc463f1869bce5feb6cd452d4d349')}, text='The\\nMeta Safety reward model is trained on all Meta Safety and Anthropic Harmless data, mixed with Meta\\nHelpfulnessandopen-sourcehelpfulnessdataina90/10proportion. Wefoundthatthesettingwith10%\\nhelpfulness data is especially beneficial for the accuracy on samples where both the chosen and rejected\\nresponses were deemed safe.\\nTraining Details. We train for one epoch over the training data. In earlier experiments, we found that\\ntraininglongercanleadtoover-fitting. Weusethesameoptimizerparametersasforthebasemodel.', start_char_idx=3423, end_char_idx=3938, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-11', obj=None),\n",
       " 'e8fe8ab2-4220-446e-aa58-652583f1ec5e': IndexNode(id_='e8fe8ab2-4220-446e-aa58-652583f1ec5e', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-11', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='67028bbb401a409a94495eb0c57e4d9b6af8e98e1ed453fe8f647bc94196224c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='01a7d701-1e98-48fa-a76e-20708f439b90', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='535da1b3addf8c3058a1048b91632944289b3b98bf2f16493a592edeb7a1674f'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='e2a98ead-f5db-4801-8332-e3fbff85ee2b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c6a98c387d5794b8decf06a0a164912b42eb5b22db4a3d9f640b4bb220941ea2')}, text='Wefoundthatthesettingwith10%\\nhelpfulness data is especially beneficial for the accuracy on samples where both the chosen and rejected\\nresponses were deemed safe.\\nTraining Details. We train for one epoch over the training data. In earlier experiments, we found that\\ntraininglongercanleadtoover-fitting. Weusethesameoptimizerparametersasforthebasemodel. The\\nmaximum learning rate is 5×10−6for the 70B parameter Llama 2-Chat and1×10−5for the rest.', start_char_idx=3587, end_char_idx=4031, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-11', obj=None),\n",
       " 'e2a98ead-f5db-4801-8332-e3fbff85ee2b': IndexNode(id_='e2a98ead-f5db-4801-8332-e3fbff85ee2b', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-11', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='67028bbb401a409a94495eb0c57e4d9b6af8e98e1ed453fe8f647bc94196224c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='e8fe8ab2-4220-446e-aa58-652583f1ec5e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d25481be68aabf592c181216dfdc7516a72dc463f1869bce5feb6cd452d4d349')}, text='Training Details. We train for one epoch over the training data. In earlier experiments, we found that\\ntraininglongercanleadtoover-fitting. Weusethesameoptimizerparametersasforthebasemodel. The\\nmaximum learning rate is 5×10−6for the 70B parameter Llama 2-Chat and1×10−5for the rest. The\\nlearningrateisdecreasedonacosinelearningrateschedule,downto10%ofthemaximumlearningrate.', start_char_idx=3749, end_char_idx=4123, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-11', obj=None),\n",
       " 'a16b3a68-fad3-400a-af3e-4b4db9bf5dc3': IndexNode(id_='a16b3a68-fad3-400a-af3e-4b4db9bf5dc3', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-11', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='67028bbb401a409a94495eb0c57e4d9b6af8e98e1ed453fe8f647bc94196224c'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='79a3f787-f300-449e-8432-6c25038f63c2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ed19e17032e412313e175a751b3b3cd0f388a0170706cee01a2089de57ae4eac')}, text='Note that a binary human preference\\ncomparisoncontains2responses(chosenandrejected)sharingthesameprompt(andpreviousdialogue).\\nEachexampleconsistsofaprompt(includingpreviousdialogueifavailable)andaresponse,whichisthe\\ninputoftherewardmodel. Wereportthenumberofcomparisons,theaveragenumberofturnsperdialogue,\\nthe average number of tokens per example, per prompt and per response. More details on Meta helpfulness\\nand safety data per batch can be found in Appendix A.3.1.\\nknows. Thispreventscaseswhere, forinstance, thetwomodelswouldhaveaninformationmismatch, which\\ncould result in favoring hallucinations. The model architecture and hyper-parameters are identical to those\\nofthepretrainedlanguagemodels,exceptthattheclassificationheadfornext-tokenpredictionisreplaced\\nwith a regression head for outputting a scalar reward.\\nTraining Objectives. To train the reward model, we convert our collected pairwise human preference data\\ninto a binary ranking label format (i.e., chosen & rejected) and enforce the chosen response to have a higher\\nscore than its counterpart.', start_char_idx=0, end_char_idx=1061, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-11', obj=None),\n",
       " '79a3f787-f300-449e-8432-6c25038f63c2': IndexNode(id_='79a3f787-f300-449e-8432-6c25038f63c2', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-11', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='67028bbb401a409a94495eb0c57e4d9b6af8e98e1ed453fe8f647bc94196224c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='a16b3a68-fad3-400a-af3e-4b4db9bf5dc3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='abc41c81c1d15b2e5e67eb2b59413fdf8b4215c27d88f4da107c62ff97707ff3'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='7d275e8b-05f8-4a46-becf-7c30fa1e670e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='18874234a1db53e93a24be28d0c9f2e417425242ac9cc502c8ac21920e07f5fa')}, text='The model architecture and hyper-parameters are identical to those\\nofthepretrainedlanguagemodels,exceptthattheclassificationheadfornext-tokenpredictionisreplaced\\nwith a regression head for outputting a scalar reward.\\nTraining Objectives. To train the reward model, we convert our collected pairwise human preference data\\ninto a binary ranking label format (i.e., chosen & rejected) and enforce the chosen response to have a higher\\nscore than its counterpart. We used a binary ranking loss consistent with Ouyang et al. (2022):\\nLranking =−log(σ(rθ(x, yc)−rθ(x, yr))) (1)\\nwhere rθ(x, y)is the scalar score output for prompt xand completion ywith model weights θ.ycis the\\npreferred response that annotators choose and yris the rejected counterpart.\\nBuilt on top of this binary ranking loss, we further modify it separately for better helpfulness and safety\\nrewardmodelsasfollows.', start_char_idx=603, end_char_idx=1479, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-11', obj=None),\n",
       " '7d275e8b-05f8-4a46-becf-7c30fa1e670e': IndexNode(id_='7d275e8b-05f8-4a46-becf-7c30fa1e670e', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-11', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='67028bbb401a409a94495eb0c57e4d9b6af8e98e1ed453fe8f647bc94196224c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='79a3f787-f300-449e-8432-6c25038f63c2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ed19e17032e412313e175a751b3b3cd0f388a0170706cee01a2089de57ae4eac'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='50f8774f-27dd-4d16-bf3c-873419654e90', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='632a6cfb9c7fed0b995951e9aa40855cc60fe5b66c9c284719238e0cae9698be')}, text='(2022):\\nLranking =−log(σ(rθ(x, yc)−rθ(x, yr))) (1)\\nwhere rθ(x, y)is the scalar score output for prompt xand completion ywith model weights θ.ycis the\\npreferred response that annotators choose and yris the rejected counterpart.\\nBuilt on top of this binary ranking loss, we further modify it separately for better helpfulness and safety\\nrewardmodelsasfollows. Giventhatourpreferenceratingsisdecomposedasascaleoffourpoints(e.g.,\\nsignificantly better ), as presented in Section 3.2.1, it can be useful to leverage this information to explicitly\\nteachtherewardmodeltoassignmorediscrepantscorestothegenerationsthathavemoredifferences. To\\ndo so, we further add a margin component in the loss:\\nLranking =−log(σ(rθ(x, yc)−rθ(x, yr)−m(r))) (2)\\nwhere the margin m(r)is a discrete function of the preference rating. Naturally, we use a large margin\\nfor pairs with distinct responses, and a smaller one for those with similar responses (shown in Table 27).', start_char_idx=1122, end_char_idx=2065, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-11', obj=None),\n",
       " '50f8774f-27dd-4d16-bf3c-873419654e90': IndexNode(id_='50f8774f-27dd-4d16-bf3c-873419654e90', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-11', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='67028bbb401a409a94495eb0c57e4d9b6af8e98e1ed453fe8f647bc94196224c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='7d275e8b-05f8-4a46-becf-7c30fa1e670e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='18874234a1db53e93a24be28d0c9f2e417425242ac9cc502c8ac21920e07f5fa'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='a498c404-1648-44e3-b19c-b7208d8234ee', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e5336f3734c53bee715c81857d6b6131e1e31cfb311fb225988a8bdcb0aaa018')}, text='To\\ndo so, we further add a margin component in the loss:\\nLranking =−log(σ(rθ(x, yc)−rθ(x, yr)−m(r))) (2)\\nwhere the margin m(r)is a discrete function of the preference rating. Naturally, we use a large margin\\nfor pairs with distinct responses, and a smaller one for those with similar responses (shown in Table 27).\\nWefoundthismargincomponentcanimproveHelpfulnessrewardmodelaccuracyespeciallyonsamples\\nwheretworesponsesaremoreseparable. MoredetailedablationandanalysiscanbefoundinTable28in\\nAppendix A.3.3.\\nDataComposition. Wecombineournewlycollecteddatawithexistingopen-sourcepreferencedatasets\\ntoformalargertrainingdataset. Initially,open-sourcedatasetswereusedtobootstrapourrewardmodels\\nwhilewewereintheprocessofcollectingpreferenceannotationdata. WenotethatinthecontextofRLHFin\\nthis study, the role of reward signals is to learn human preference for Llama 2-Chat outputs rather than\\nany model outputs.', start_char_idx=1751, end_char_idx=2654, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-11', obj=None),\n",
       " 'a498c404-1648-44e3-b19c-b7208d8234ee': IndexNode(id_='a498c404-1648-44e3-b19c-b7208d8234ee', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-11', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='67028bbb401a409a94495eb0c57e4d9b6af8e98e1ed453fe8f647bc94196224c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='50f8774f-27dd-4d16-bf3c-873419654e90', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='632a6cfb9c7fed0b995951e9aa40855cc60fe5b66c9c284719238e0cae9698be'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='caa6530f-c25c-4afa-8a18-d7ac32374ab9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='61aaa804785d929fde7a11c01d7b74206222ca5a4534f6844c40486a997d6c1b')}, text='Wecombineournewlycollecteddatawithexistingopen-sourcepreferencedatasets\\ntoformalargertrainingdataset. Initially,open-sourcedatasetswereusedtobootstrapourrewardmodels\\nwhilewewereintheprocessofcollectingpreferenceannotationdata. WenotethatinthecontextofRLHFin\\nthis study, the role of reward signals is to learn human preference for Llama 2-Chat outputs rather than\\nany model outputs. However, in our experiments, we do not observe negative transfer from the open-source\\npreferencedatasets. Thus,wehavedecidedtokeeptheminourdatamixture,astheycouldenablebetter\\ngeneralization for the reward model and prevent reward hacking, i.e. Llama 2-Chat taking advantage of\\nsome weaknesses of our reward, and so artificially inflating the score despite performing less well.\\nWith training data available from different sources, we experimented with different mixing recipes for both\\nHelpfulnessandSafetyrewardmodelstoascertainthebestsettings.', start_char_idx=2273, end_char_idx=3200, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-11', obj=None),\n",
       " 'caa6530f-c25c-4afa-8a18-d7ac32374ab9': IndexNode(id_='caa6530f-c25c-4afa-8a18-d7ac32374ab9', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-11', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='67028bbb401a409a94495eb0c57e4d9b6af8e98e1ed453fe8f647bc94196224c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='a498c404-1648-44e3-b19c-b7208d8234ee', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e5336f3734c53bee715c81857d6b6131e1e31cfb311fb225988a8bdcb0aaa018'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='44029794-3afa-415d-a712-61dc0b00a59a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='78648d8a24f0ab8a8e33160f8c7108125a5a996b60995879eadd8216a1dcb525')}, text='Thus,wehavedecidedtokeeptheminourdatamixture,astheycouldenablebetter\\ngeneralization for the reward model and prevent reward hacking, i.e. Llama 2-Chat taking advantage of\\nsome weaknesses of our reward, and so artificially inflating the score despite performing less well.\\nWith training data available from different sources, we experimented with different mixing recipes for both\\nHelpfulnessandSafetyrewardmodelstoascertainthebestsettings. Afterextensiveexperimentation,the\\n11\\n\\nHelpfulness reward model is eventually trained on all Meta Helpfulness data, combined with an equal\\npartsoftheremainingdatauniformlysampledfromMetaSafetyandfromtheopen-sourcedatasets. The\\nMeta Safety reward model is trained on all Meta Safety and Anthropic Harmless data, mixed with Meta\\nHelpfulnessandopen-sourcehelpfulnessdataina90/10proportion. Wefoundthatthesettingwith10%\\nhelpfulness data is especially beneficial for the accuracy on samples where both the chosen and rejected\\nresponses were deemed safe.\\nTraining Details. We train for one epoch over the training data. In earlier experiments, we found that\\ntraininglongercanleadtoover-fitting.', start_char_idx=2761, end_char_idx=3888, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-11', obj=None),\n",
       " '44029794-3afa-415d-a712-61dc0b00a59a': IndexNode(id_='44029794-3afa-415d-a712-61dc0b00a59a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-11', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='67028bbb401a409a94495eb0c57e4d9b6af8e98e1ed453fe8f647bc94196224c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='caa6530f-c25c-4afa-8a18-d7ac32374ab9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='61aaa804785d929fde7a11c01d7b74206222ca5a4534f6844c40486a997d6c1b')}, text='Wefoundthatthesettingwith10%\\nhelpfulness data is especially beneficial for the accuracy on samples where both the chosen and rejected\\nresponses were deemed safe.\\nTraining Details. We train for one epoch over the training data. In earlier experiments, we found that\\ntraininglongercanleadtoover-fitting. Weusethesameoptimizerparametersasforthebasemodel. The\\nmaximum learning rate is 5×10−6for the 70B parameter Llama 2-Chat and1×10−5for the rest. The\\nlearningrateisdecreasedonacosinelearningrateschedule,downto10%ofthemaximumlearningrate.', start_char_idx=3587, end_char_idx=4123, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-11', obj=None),\n",
       " '73096192-27f9-4fbc-8046-c1071ccf5b04': IndexNode(id_='73096192-27f9-4fbc-8046-c1071ccf5b04', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-11', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='67028bbb401a409a94495eb0c57e4d9b6af8e98e1ed453fe8f647bc94196224c'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='a87c867a-7e86-4eb7-9b24-23c64f1eb571', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='10f924607f88e55d1dd28c7990ac65c3e5e98f312ba479b39c4a061c9b6134ec')}, text='Note that a binary human preference\\ncomparisoncontains2responses(chosenandrejected)sharingthesameprompt(andpreviousdialogue).\\nEachexampleconsistsofaprompt(includingpreviousdialogueifavailable)andaresponse,whichisthe\\ninputoftherewardmodel. Wereportthenumberofcomparisons,theaveragenumberofturnsperdialogue,\\nthe average number of tokens per example, per prompt and per response. More details on Meta helpfulness\\nand safety data per batch can be found in Appendix A.3.1.\\nknows. Thispreventscaseswhere, forinstance, thetwomodelswouldhaveaninformationmismatch, which\\ncould result in favoring hallucinations. The model architecture and hyper-parameters are identical to those\\nofthepretrainedlanguagemodels,exceptthattheclassificationheadfornext-tokenpredictionisreplaced\\nwith a regression head for outputting a scalar reward.\\nTraining Objectives. To train the reward model, we convert our collected pairwise human preference data\\ninto a binary ranking label format (i.e., chosen & rejected) and enforce the chosen response to have a higher\\nscore than its counterpart. We used a binary ranking loss consistent with Ouyang et al. (2022):\\nLranking =−log(σ(rθ(x, yc)−rθ(x, yr))) (1)\\nwhere rθ(x, y)is the scalar score output for prompt xand completion ywith model weights θ.ycis the\\npreferred response that annotators choose and yris the rejected counterpart.\\nBuilt on top of this binary ranking loss, we further modify it separately for better helpfulness and safety\\nrewardmodelsasfollows. Giventhatourpreferenceratingsisdecomposedasascaleoffourpoints(e.g.,\\nsignificantly better ), as presented in Section 3.2.1, it can be useful to leverage this information to explicitly\\nteachtherewardmodeltoassignmorediscrepantscorestothegenerationsthathavemoredifferences. To\\ndo so, we further add a margin component in the loss:\\nLranking =−log(σ(rθ(x, yc)−rθ(x, yr)−m(r))) (2)\\nwhere the margin m(r)is a discrete function of the preference rating.', start_char_idx=0, end_char_idx=1925, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-11', obj=None),\n",
       " 'a87c867a-7e86-4eb7-9b24-23c64f1eb571': IndexNode(id_='a87c867a-7e86-4eb7-9b24-23c64f1eb571', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-11', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='67028bbb401a409a94495eb0c57e4d9b6af8e98e1ed453fe8f647bc94196224c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='73096192-27f9-4fbc-8046-c1071ccf5b04', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c85aa8c1c9f25f1a91c020ce7ca42cc4ea645ea7299d958ad3b70a238bca8d6f'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='4ddedee1-a1ae-4b10-8f30-276d233b06f0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d65514eb37f52a23175ad275db0812fb04336e379d602cf161558279bb748a55')}, text='To\\ndo so, we further add a margin component in the loss:\\nLranking =−log(σ(rθ(x, yc)−rθ(x, yr)−m(r))) (2)\\nwhere the margin m(r)is a discrete function of the preference rating. Naturally, we use a large margin\\nfor pairs with distinct responses, and a smaller one for those with similar responses (shown in Table 27).\\nWefoundthismargincomponentcanimproveHelpfulnessrewardmodelaccuracyespeciallyonsamples\\nwheretworesponsesaremoreseparable. MoredetailedablationandanalysiscanbefoundinTable28in\\nAppendix A.3.3.\\nDataComposition. Wecombineournewlycollecteddatawithexistingopen-sourcepreferencedatasets\\ntoformalargertrainingdataset. Initially,open-sourcedatasetswereusedtobootstrapourrewardmodels\\nwhilewewereintheprocessofcollectingpreferenceannotationdata. WenotethatinthecontextofRLHFin\\nthis study, the role of reward signals is to learn human preference for Llama 2-Chat outputs rather than\\nany model outputs. However, in our experiments, we do not observe negative transfer from the open-source\\npreferencedatasets. Thus,wehavedecidedtokeeptheminourdatamixture,astheycouldenablebetter\\ngeneralization for the reward model and prevent reward hacking, i.e. Llama 2-Chat taking advantage of\\nsome weaknesses of our reward, and so artificially inflating the score despite performing less well.\\nWith training data available from different sources, we experimented with different mixing recipes for both\\nHelpfulnessandSafetyrewardmodelstoascertainthebestsettings. Afterextensiveexperimentation,the\\n11\\n\\nHelpfulness reward model is eventually trained on all Meta Helpfulness data, combined with an equal\\npartsoftheremainingdatauniformlysampledfromMetaSafetyandfromtheopen-sourcedatasets. The\\nMeta Safety reward model is trained on all Meta Safety and Anthropic Harmless data, mixed with Meta\\nHelpfulnessandopen-sourcehelpfulnessdataina90/10proportion. Wefoundthatthesettingwith10%\\nhelpfulness data is especially beneficial for the accuracy on samples where both the chosen and rejected\\nresponses were deemed safe.\\nTraining Details. We train for one epoch over the training data.', start_char_idx=1751, end_char_idx=3813, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-11', obj=None),\n",
       " '4ddedee1-a1ae-4b10-8f30-276d233b06f0': IndexNode(id_='4ddedee1-a1ae-4b10-8f30-276d233b06f0', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-11', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='67028bbb401a409a94495eb0c57e4d9b6af8e98e1ed453fe8f647bc94196224c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='a87c867a-7e86-4eb7-9b24-23c64f1eb571', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='10f924607f88e55d1dd28c7990ac65c3e5e98f312ba479b39c4a061c9b6134ec')}, text='The\\nMeta Safety reward model is trained on all Meta Safety and Anthropic Harmless data, mixed with Meta\\nHelpfulnessandopen-sourcehelpfulnessdataina90/10proportion. Wefoundthatthesettingwith10%\\nhelpfulness data is especially beneficial for the accuracy on samples where both the chosen and rejected\\nresponses were deemed safe.\\nTraining Details. We train for one epoch over the training data. In earlier experiments, we found that\\ntraininglongercanleadtoover-fitting. Weusethesameoptimizerparametersasforthebasemodel. The\\nmaximum learning rate is 5×10−6for the 70B parameter Llama 2-Chat and1×10−5for the rest. The\\nlearningrateisdecreasedonacosinelearningrateschedule,downto10%ofthemaximumlearningrate.', start_char_idx=3423, end_char_idx=4123, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-11', obj=None),\n",
       " 'node-11': IndexNode(id_='node-11', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='d03f19eb-da15-45dc-bfd4-e5d10f161250', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='231b3bd773f012c01b893ada9e009ecf25ee59934614c5a595c9bf1b3a123292'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='0001cefe-8382-40ac-b380-c473be72c9b9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='716d71784a22cf05b9915bb68893d3f0e07e57aa1362e2ac7f1471dc334d89a5'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='8073f055-b50a-4390-a8f8-cdf198ca3c03', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8845e152a80560179274711be3607960f234fa713b150737e9b3ca8d3f625d95')}, text='Note that a binary human preference\\ncomparisoncontains2responses(chosenandrejected)sharingthesameprompt(andpreviousdialogue).\\nEachexampleconsistsofaprompt(includingpreviousdialogueifavailable)andaresponse,whichisthe\\ninputoftherewardmodel. Wereportthenumberofcomparisons,theaveragenumberofturnsperdialogue,\\nthe average number of tokens per example, per prompt and per response. More details on Meta helpfulness\\nand safety data per batch can be found in Appendix A.3.1.\\nknows. Thispreventscaseswhere, forinstance, thetwomodelswouldhaveaninformationmismatch, which\\ncould result in favoring hallucinations. The model architecture and hyper-parameters are identical to those\\nofthepretrainedlanguagemodels,exceptthattheclassificationheadfornext-tokenpredictionisreplaced\\nwith a regression head for outputting a scalar reward.\\nTraining Objectives. To train the reward model, we convert our collected pairwise human preference data\\ninto a binary ranking label format (i.e., chosen & rejected) and enforce the chosen response to have a higher\\nscore than its counterpart. We used a binary ranking loss consistent with Ouyang et al. (2022):\\nLranking =−log(σ(rθ(x, yc)−rθ(x, yr))) (1)\\nwhere rθ(x, y)is the scalar score output for prompt xand completion ywith model weights θ.ycis the\\npreferred response that annotators choose and yris the rejected counterpart.\\nBuilt on top of this binary ranking loss, we further modify it separately for better helpfulness and safety\\nrewardmodelsasfollows. Giventhatourpreferenceratingsisdecomposedasascaleoffourpoints(e.g.,\\nsignificantly better ), as presented in Section 3.2.1, it can be useful to leverage this information to explicitly\\nteachtherewardmodeltoassignmorediscrepantscorestothegenerationsthathavemoredifferences. To\\ndo so, we further add a margin component in the loss:\\nLranking =−log(σ(rθ(x, yc)−rθ(x, yr)−m(r))) (2)\\nwhere the margin m(r)is a discrete function of the preference rating. Naturally, we use a large margin\\nfor pairs with distinct responses, and a smaller one for those with similar responses (shown in Table 27).\\nWefoundthismargincomponentcanimproveHelpfulnessrewardmodelaccuracyespeciallyonsamples\\nwheretworesponsesaremoreseparable. MoredetailedablationandanalysiscanbefoundinTable28in\\nAppendix A.3.3.\\nDataComposition. Wecombineournewlycollecteddatawithexistingopen-sourcepreferencedatasets\\ntoformalargertrainingdataset. Initially,open-sourcedatasetswereusedtobootstrapourrewardmodels\\nwhilewewereintheprocessofcollectingpreferenceannotationdata. WenotethatinthecontextofRLHFin\\nthis study, the role of reward signals is to learn human preference for Llama 2-Chat outputs rather than\\nany model outputs. However, in our experiments, we do not observe negative transfer from the open-source\\npreferencedatasets. Thus,wehavedecidedtokeeptheminourdatamixture,astheycouldenablebetter\\ngeneralization for the reward model and prevent reward hacking, i.e. Llama 2-Chat taking advantage of\\nsome weaknesses of our reward, and so artificially inflating the score despite performing less well.\\nWith training data available from different sources, we experimented with different mixing recipes for both\\nHelpfulnessandSafetyrewardmodelstoascertainthebestsettings. Afterextensiveexperimentation,the\\n11\\n\\nHelpfulness reward model is eventually trained on all Meta Helpfulness data, combined with an equal\\npartsoftheremainingdatauniformlysampledfromMetaSafetyandfromtheopen-sourcedatasets. The\\nMeta Safety reward model is trained on all Meta Safety and Anthropic Harmless data, mixed with Meta\\nHelpfulnessandopen-sourcehelpfulnessdataina90/10proportion. Wefoundthatthesettingwith10%\\nhelpfulness data is especially beneficial for the accuracy on samples where both the chosen and rejected\\nresponses were deemed safe.\\nTraining Details. We train for one epoch over the training data. In earlier experiments, we found that\\ntraininglongercanleadtoover-fitting. Weusethesameoptimizerparametersasforthebasemodel. The\\nmaximum learning rate is 5×10−6for the 70B parameter Llama 2-Chat and1×10−5for the rest. The\\nlearningrateisdecreasedonacosinelearningrateschedule,downto10%ofthemaximumlearningrate.', start_char_idx=31204, end_char_idx=35327, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-11', obj=None),\n",
       " '34744fbe-a32b-42a0-aed9-69fb0a07de99': IndexNode(id_='34744fbe-a32b-42a0-aed9-69fb0a07de99', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-12', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8845e152a80560179274711be3607960f234fa713b150737e9b3ca8d3f625d95'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='02e91bb8-a525-4084-a53b-bad4472436d3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8b2f0839924f2fcbaa5950039dfd7d9043f2e5dc62cafa1d45c1e64474622611')}, text='In earlier experiments, we found that\\ntraininglongercanleadtoover-fitting. Weusethesameoptimizerparametersasforthebasemodel. The\\nmaximum learning rate is 5×10−6for the 70B parameter Llama 2-Chat and1×10−5for the rest. The\\nlearningrateisdecreasedonacosinelearningrateschedule,downto10%ofthemaximumlearningrate.\\nWe use a warm-up of 3% of the total number of steps, with a minimum of 5.', start_char_idx=0, end_char_idx=383, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-12', obj=None),\n",
       " '02e91bb8-a525-4084-a53b-bad4472436d3': IndexNode(id_='02e91bb8-a525-4084-a53b-bad4472436d3', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-12', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8845e152a80560179274711be3607960f234fa713b150737e9b3ca8d3f625d95'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='34744fbe-a32b-42a0-aed9-69fb0a07de99', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2eee48aef59164bb4fce831004decf3fd1c26ad0b8009a8c9b2887c80069a972'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='c92ad743-e9ed-43f1-8093-7371216a3221', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='db9fbdc05ef20271bd304b15e0583b32386bc3090c159187eaf36c7f49ff0312')}, text='Weusethesameoptimizerparametersasforthebasemodel. The\\nmaximum learning rate is 5×10−6for the 70B parameter Llama 2-Chat and1×10−5for the rest. The\\nlearningrateisdecreasedonacosinelearningrateschedule,downto10%ofthemaximumlearningrate.\\nWe use a warm-up of 3% of the total number of steps, with a minimum of 5. The effective batch size is kept\\nfixed at 512 pairs, or 1024 rows per batch.\\nMeta\\nHelpful.', start_char_idx=75, end_char_idx=474, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-12', obj=None),\n",
       " 'c92ad743-e9ed-43f1-8093-7371216a3221': IndexNode(id_='c92ad743-e9ed-43f1-8093-7371216a3221', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-12', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8845e152a80560179274711be3607960f234fa713b150737e9b3ca8d3f625d95'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='02e91bb8-a525-4084-a53b-bad4472436d3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8b2f0839924f2fcbaa5950039dfd7d9043f2e5dc62cafa1d45c1e64474622611'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='fc7092d9-48c2-40d3-9398-b17eb0ee1f7a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5f2a81c3fc8a71b320627687f0602bd9b698ed649077556ab94ff5fca050689b')}, text='The\\nlearningrateisdecreasedonacosinelearningrateschedule,downto10%ofthemaximumlearningrate.\\nWe use a warm-up of 3% of the total number of steps, with a minimum of 5. The effective batch size is kept\\nfixed at 512 pairs, or 1024 rows per batch.\\nMeta\\nHelpful.Meta\\nSafetyAnthropic\\nHelpfulAnthropic\\nHarmlessOpenAI\\nSumm.Stanford\\nSHPAvg\\nSteamSHP-XL 52.8 43.8 66.8 34.2 54.', start_char_idx=218, end_char_idx=583, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-12', obj=None),\n",
       " 'fc7092d9-48c2-40d3-9398-b17eb0ee1f7a': IndexNode(id_='fc7092d9-48c2-40d3-9398-b17eb0ee1f7a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-12', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8845e152a80560179274711be3607960f234fa713b150737e9b3ca8d3f625d95'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='c92ad743-e9ed-43f1-8093-7371216a3221', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='db9fbdc05ef20271bd304b15e0583b32386bc3090c159187eaf36c7f49ff0312'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='cd65bcda-c719-4689-99d3-f20023b18a20', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2e8db426ffafca76851ef68aa5395ff6ead65816e1ff8852c3167ab2e08fde4e')}, text='The effective batch size is kept\\nfixed at 512 pairs, or 1024 rows per batch.\\nMeta\\nHelpful.Meta\\nSafetyAnthropic\\nHelpfulAnthropic\\nHarmlessOpenAI\\nSumm.Stanford\\nSHPAvg\\nSteamSHP-XL 52.8 43.8 66.8 34.2 54.7 75.7 55.3\\nOpen Assistant 53.8 53.4 67.7 68.4 71.7 55.0 63.0\\nGPT4 58.6 58.', start_char_idx=384, end_char_idx=658, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-12', obj=None),\n",
       " 'cd65bcda-c719-4689-99d3-f20023b18a20': IndexNode(id_='cd65bcda-c719-4689-99d3-f20023b18a20', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-12', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8845e152a80560179274711be3607960f234fa713b150737e9b3ca8d3f625d95'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='fc7092d9-48c2-40d3-9398-b17eb0ee1f7a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5f2a81c3fc8a71b320627687f0602bd9b698ed649077556ab94ff5fca050689b'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='e06d101f-8fb7-403d-bd0a-3b2dd4aad349', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='93c3feab161b2d85004ad0041ecb3cf7b3747a0ad81048989a6df39c287a0863')}, text='Stanford\\nSHPAvg\\nSteamSHP-XL 52.8 43.8 66.8 34.2 54.7 75.7 55.3\\nOpen Assistant 53.8 53.4 67.7 68.4 71.7 55.0 63.0\\nGPT4 58.6 58.1 - - - - -\\nSafety RM 56.2 64.5 55.4 74.7 71.7 65.2 64.3\\nHelpfulness RM 63.', start_char_idx=532, end_char_idx=733, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-12', obj=None),\n",
       " 'e06d101f-8fb7-403d-bd0a-3b2dd4aad349': IndexNode(id_='e06d101f-8fb7-403d-bd0a-3b2dd4aad349', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-12', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8845e152a80560179274711be3607960f234fa713b150737e9b3ca8d3f625d95'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='cd65bcda-c719-4689-99d3-f20023b18a20', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2e8db426ffafca76851ef68aa5395ff6ead65816e1ff8852c3167ab2e08fde4e'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='a394522f-62b9-4489-bdc4-286f5a9e4896', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='48b2ba3968061bd5560abfcdb38e1a210583fe5507cca0a82c381c82e666525a')}, text='2 54.7 75.7 55.3\\nOpen Assistant 53.8 53.4 67.7 68.4 71.7 55.0 63.0\\nGPT4 58.6 58.1 - - - - -\\nSafety RM 56.2 64.5 55.4 74.7 71.7 65.2 64.3\\nHelpfulness RM 63.2 62.8 72.0 71.0 75.5 80.0 70.', start_char_idx=578, end_char_idx=763, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-12', obj=None),\n",
       " 'a394522f-62b9-4489-bdc4-286f5a9e4896': IndexNode(id_='a394522f-62b9-4489-bdc4-286f5a9e4896', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-12', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8845e152a80560179274711be3607960f234fa713b150737e9b3ca8d3f625d95'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='e06d101f-8fb7-403d-bd0a-3b2dd4aad349', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='93c3feab161b2d85004ad0041ecb3cf7b3747a0ad81048989a6df39c287a0863'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='c035524a-50b7-4682-81d9-db1d39367694', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6a92598cb58387fe97ebfe6096d59c085f435ff62b15fa1da0076f6068734a96')}, text='4 67.7 68.4 71.7 55.0 63.0\\nGPT4 58.6 58.1 - - - - -\\nSafety RM 56.2 64.5 55.4 74.7 71.7 65.2 64.3\\nHelpfulness RM 63.2 62.8 72.0 71.0 75.5 80.0 70.6\\nTable 7: Reward model results.', start_char_idx=618, end_char_idx=795, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-12', obj=None),\n",
       " 'c035524a-50b7-4682-81d9-db1d39367694': IndexNode(id_='c035524a-50b7-4682-81d9-db1d39367694', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-12', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8845e152a80560179274711be3607960f234fa713b150737e9b3ca8d3f625d95'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='a394522f-62b9-4489-bdc4-286f5a9e4896', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='48b2ba3968061bd5560abfcdb38e1a210583fe5507cca0a82c381c82e666525a'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='26ca74b4-245f-4dff-81e2-9ed341db66f7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='cf726a8774d111c51adbfec162ca4810118d6eea4a753ca27116bcea78f8428f')}, text='7 55.0 63.0\\nGPT4 58.6 58.1 - - - - -\\nSafety RM 56.2 64.5 55.4 74.7 71.7 65.2 64.3\\nHelpfulness RM 63.2 62.8 72.0 71.0 75.5 80.0 70.6\\nTable 7: Reward model results. Performance of our final helpfulness and safety reward models on a diverse\\nset of human preference benchmarks.', start_char_idx=633, end_char_idx=906, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-12', obj=None),\n",
       " '26ca74b4-245f-4dff-81e2-9ed341db66f7': IndexNode(id_='26ca74b4-245f-4dff-81e2-9ed341db66f7', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-12', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8845e152a80560179274711be3607960f234fa713b150737e9b3ca8d3f625d95'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='c035524a-50b7-4682-81d9-db1d39367694', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6a92598cb58387fe97ebfe6096d59c085f435ff62b15fa1da0076f6068734a96'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='85a8cb1f-6ae7-428e-b05d-9ba714ea7cc4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='345ae4394ea009eaf779bba3685fbb90c84b913523775c3051943cc122b0a231')}, text='1 - - - - -\\nSafety RM 56.2 64.5 55.4 74.7 71.7 65.2 64.3\\nHelpfulness RM 63.2 62.8 72.0 71.0 75.5 80.0 70.6\\nTable 7: Reward model results. Performance of our final helpfulness and safety reward models on a diverse\\nset of human preference benchmarks. Note that our model is fine-tuned on our collected data, as opposed to\\nthe other baselines that we report.', start_char_idx=658, end_char_idx=1013, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-12', obj=None),\n",
       " '85a8cb1f-6ae7-428e-b05d-9ba714ea7cc4': IndexNode(id_='85a8cb1f-6ae7-428e-b05d-9ba714ea7cc4', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-12', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8845e152a80560179274711be3607960f234fa713b150737e9b3ca8d3f625d95'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='26ca74b4-245f-4dff-81e2-9ed341db66f7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='cf726a8774d111c51adbfec162ca4810118d6eea4a753ca27116bcea78f8428f'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='09b66151-5e81-4ed1-81d0-5b1c5f6b663b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0a0a8ba4018f2c5932884f17d910fb817bd240f74b9ac9482a9e81a13a00dd82')}, text='7 65.2 64.3\\nHelpfulness RM 63.2 62.8 72.0 71.0 75.5 80.0 70.6\\nTable 7: Reward model results. Performance of our final helpfulness and safety reward models on a diverse\\nset of human preference benchmarks. Note that our model is fine-tuned on our collected data, as opposed to\\nthe other baselines that we report.\\nTest SetSignificantly\\nBetterBetterSlightly\\nBetterNegligibly\\nBetter / UnsureAvg\\nSafety RMMeta Safety94.3 76.', start_char_idx=703, end_char_idx=1121, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-12', obj=None),\n",
       " '09b66151-5e81-4ed1-81d0-5b1c5f6b663b': IndexNode(id_='09b66151-5e81-4ed1-81d0-5b1c5f6b663b', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-12', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8845e152a80560179274711be3607960f234fa713b150737e9b3ca8d3f625d95'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='85a8cb1f-6ae7-428e-b05d-9ba714ea7cc4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='345ae4394ea009eaf779bba3685fbb90c84b913523775c3051943cc122b0a231'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='31ee7ac1-a0a2-4f03-a743-e62aedc44c6d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='923c347f87c17dd8d7b37214fe6ecc8b674f0f03ab9af65a8b173dfce7f73eac')}, text='0 75.5 80.0 70.6\\nTable 7: Reward model results. Performance of our final helpfulness and safety reward models on a diverse\\nset of human preference benchmarks. Note that our model is fine-tuned on our collected data, as opposed to\\nthe other baselines that we report.\\nTest SetSignificantly\\nBetterBetterSlightly\\nBetterNegligibly\\nBetter / UnsureAvg\\nSafety RMMeta Safety94.3 76.3 65.7 55.3 64.5\\nHelpfulness RM 89.9 73.2 63.', start_char_idx=748, end_char_idx=1166, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-12', obj=None),\n",
       " '31ee7ac1-a0a2-4f03-a743-e62aedc44c6d': IndexNode(id_='31ee7ac1-a0a2-4f03-a743-e62aedc44c6d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-12', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8845e152a80560179274711be3607960f234fa713b150737e9b3ca8d3f625d95'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='09b66151-5e81-4ed1-81d0-5b1c5f6b663b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0a0a8ba4018f2c5932884f17d910fb817bd240f74b9ac9482a9e81a13a00dd82'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='508d2c32-2ce5-4fbf-8210-fbb527d62d14', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='cc830902c586e9876d8e99c1b6e0bdb22b0342347dd582f172d8903a0292905f')}, text='Note that our model is fine-tuned on our collected data, as opposed to\\nthe other baselines that we report.\\nTest SetSignificantly\\nBetterBetterSlightly\\nBetterNegligibly\\nBetter / UnsureAvg\\nSafety RMMeta Safety94.3 76.3 65.7 55.3 64.5\\nHelpfulness RM 89.9 73.2 63.8 54.5 62.8\\nSafety RMMeta Helpful.64.6 57.5 53.8 52.2 56.2\\nHelpfulness RM 80.', start_char_idx=907, end_char_idx=1243, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-12', obj=None),\n",
       " '508d2c32-2ce5-4fbf-8210-fbb527d62d14': IndexNode(id_='508d2c32-2ce5-4fbf-8210-fbb527d62d14', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-12', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8845e152a80560179274711be3607960f234fa713b150737e9b3ca8d3f625d95'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='31ee7ac1-a0a2-4f03-a743-e62aedc44c6d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='923c347f87c17dd8d7b37214fe6ecc8b674f0f03ab9af65a8b173dfce7f73eac'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='f73371cf-14f0-4982-8033-397522fc9e4d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='32a8dabf3781d8e47265d05e973c2e8287fb049861884b112ab2016dbfc0334b')}, text='3 76.3 65.7 55.3 64.5\\nHelpfulness RM 89.9 73.2 63.8 54.5 62.8\\nSafety RMMeta Helpful.64.6 57.5 53.8 52.2 56.2\\nHelpfulness RM 80.7 67.5 60.9 54.7 63.2\\nTable 8: Granular reward model accuracy per preference rating.', start_char_idx=1116, end_char_idx=1327, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-12', obj=None),\n",
       " 'f73371cf-14f0-4982-8033-397522fc9e4d': IndexNode(id_='f73371cf-14f0-4982-8033-397522fc9e4d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-12', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8845e152a80560179274711be3607960f234fa713b150737e9b3ca8d3f625d95'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='508d2c32-2ce5-4fbf-8210-fbb527d62d14', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='cc830902c586e9876d8e99c1b6e0bdb22b0342347dd582f172d8903a0292905f'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='f9d2b818-a092-40fc-9bef-bb5e81445632', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8844cb266fb0c93bb09dc03290fe3b609527db521fa59e89ee0b7e0bf6bd1779')}, text='7 55.3 64.5\\nHelpfulness RM 89.9 73.2 63.8 54.5 62.8\\nSafety RMMeta Helpful.64.6 57.5 53.8 52.2 56.2\\nHelpfulness RM 80.7 67.5 60.9 54.7 63.2\\nTable 8: Granular reward model accuracy per preference rating. We report per-preference rating accuracy\\nforbothHelpfulnessandSafetyrewardmodelsontheMetaHelpfulnessandSafetytestsets.', start_char_idx=1126, end_char_idx=1446, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-12', obj=None),\n",
       " 'f9d2b818-a092-40fc-9bef-bb5e81445632': IndexNode(id_='f9d2b818-a092-40fc-9bef-bb5e81445632', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-12', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8845e152a80560179274711be3607960f234fa713b150737e9b3ca8d3f625d95'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='f73371cf-14f0-4982-8033-397522fc9e4d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='32a8dabf3781d8e47265d05e973c2e8287fb049861884b112ab2016dbfc0334b'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='6610e61a-6225-4ee8-aa35-8ef6d8de1096', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='812c3ae673bc21657be740155e5f591f4935f25ef97ef5a2b61958c12d6fedca')}, text='5 62.8\\nSafety RMMeta Helpful.64.6 57.5 53.8 52.2 56.2\\nHelpfulness RM 80.7 67.5 60.9 54.7 63.2\\nTable 8: Granular reward model accuracy per preference rating. We report per-preference rating accuracy\\nforbothHelpfulnessandSafetyrewardmodelsontheMetaHelpfulnessandSafetytestsets. Thereward\\nmodels show superior accuracy on more distinct responses (e.g., significantly better) and lower accuracy on\\nsimilar responses (e.g., negligibly better).', start_char_idx=1171, end_char_idx=1609, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-12', obj=None),\n",
       " '6610e61a-6225-4ee8-aa35-8ef6d8de1096': IndexNode(id_='6610e61a-6225-4ee8-aa35-8ef6d8de1096', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-12', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8845e152a80560179274711be3607960f234fa713b150737e9b3ca8d3f625d95'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='f9d2b818-a092-40fc-9bef-bb5e81445632', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8844cb266fb0c93bb09dc03290fe3b609527db521fa59e89ee0b7e0bf6bd1779'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='9780314c-fe52-439d-ac49-bd1b43eb90a3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2a16692cecb9ae2d41b59b3620232d4571ee2b7f896d9dad9d53c425263bf951')}, text='7 67.5 60.9 54.7 63.2\\nTable 8: Granular reward model accuracy per preference rating. We report per-preference rating accuracy\\nforbothHelpfulnessandSafetyrewardmodelsontheMetaHelpfulnessandSafetytestsets. Thereward\\nmodels show superior accuracy on more distinct responses (e.g., significantly better) and lower accuracy on\\nsimilar responses (e.g., negligibly better).\\nReward Model Results. On each batch of human preference annotation for reward modeling, we held out\\n1000examplesasatestsettoevaluateourmodels.', start_char_idx=1243, end_char_idx=1752, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-12', obj=None),\n",
       " '9780314c-fe52-439d-ac49-bd1b43eb90a3': IndexNode(id_='9780314c-fe52-439d-ac49-bd1b43eb90a3', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-12', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8845e152a80560179274711be3607960f234fa713b150737e9b3ca8d3f625d95'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='6610e61a-6225-4ee8-aa35-8ef6d8de1096', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='812c3ae673bc21657be740155e5f591f4935f25ef97ef5a2b61958c12d6fedca'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='9415e2c9-0e20-42b8-a2b2-080e6d0b57af', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='89dc4c806a2260ca442a78faaaac0c9721f940d780b1f55f830323b28ea7f1cf')}, text='We report per-preference rating accuracy\\nforbothHelpfulnessandSafetyrewardmodelsontheMetaHelpfulnessandSafetytestsets. Thereward\\nmodels show superior accuracy on more distinct responses (e.g., significantly better) and lower accuracy on\\nsimilar responses (e.g., negligibly better).\\nReward Model Results. On each batch of human preference annotation for reward modeling, we held out\\n1000examplesasatestsettoevaluateourmodels. Werefertotheunionofallpromptsforthecorresponding\\ntest sets as “Meta Helpfulness” and “Meta Safety,” respectively.', start_char_idx=1328, end_char_idx=1866, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-12', obj=None),\n",
       " '9415e2c9-0e20-42b8-a2b2-080e6d0b57af': IndexNode(id_='9415e2c9-0e20-42b8-a2b2-080e6d0b57af', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-12', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8845e152a80560179274711be3607960f234fa713b150737e9b3ca8d3f625d95'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='9780314c-fe52-439d-ac49-bd1b43eb90a3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2a16692cecb9ae2d41b59b3620232d4571ee2b7f896d9dad9d53c425263bf951'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='b3f3d96c-1857-4578-b3eb-a569f9cedac1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='116e07e9879b4f8f0b66c8e51c2c6e58c87bce0fbeec96b4aa2503507d843abf')}, text='Thereward\\nmodels show superior accuracy on more distinct responses (e.g., significantly better) and lower accuracy on\\nsimilar responses (e.g., negligibly better).\\nReward Model Results. On each batch of human preference annotation for reward modeling, we held out\\n1000examplesasatestsettoevaluateourmodels. Werefertotheunionofallpromptsforthecorresponding\\ntest sets as “Meta Helpfulness” and “Meta Safety,” respectively.\\nAs reference points, we also evaluated other publicly available alternatives as baselines: SteamSHP-XL\\n(Ethayarajh et al., 2022) based on FLAN-T5-xl, the Open Assistant (Köpf et al., 2023) reward model based on\\nDeBERTa V3 Large (He et al., 2020), and GPT4 accessible through the OpenAI’s API.', start_char_idx=1447, end_char_idx=2159, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-12', obj=None),\n",
       " 'b3f3d96c-1857-4578-b3eb-a569f9cedac1': IndexNode(id_='b3f3d96c-1857-4578-b3eb-a569f9cedac1', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-12', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8845e152a80560179274711be3607960f234fa713b150737e9b3ca8d3f625d95'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='9415e2c9-0e20-42b8-a2b2-080e6d0b57af', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='89dc4c806a2260ca442a78faaaac0c9721f940d780b1f55f830323b28ea7f1cf'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='90d747c8-8dd3-4602-bcc7-35c784d2333a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3e21086574d08a2ea431d8c909434e6686e8c5b6311e01055128ae7cbc7c95ee')}, text='As reference points, we also evaluated other publicly available alternatives as baselines: SteamSHP-XL\\n(Ethayarajh et al., 2022) based on FLAN-T5-xl, the Open Assistant (Köpf et al., 2023) reward model based on\\nDeBERTa V3 Large (He et al., 2020), and GPT4 accessible through the OpenAI’s API. Note that at inference\\ntime, asopposedtotraining, alltherewardmodelscanpredictascalarforasingleoutput, withoutrequiring\\nto access its paired output.', start_char_idx=1867, end_char_idx=2308, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-12', obj=None),\n",
       " '90d747c8-8dd3-4602-bcc7-35c784d2333a': IndexNode(id_='90d747c8-8dd3-4602-bcc7-35c784d2333a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-12', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8845e152a80560179274711be3607960f234fa713b150737e9b3ca8d3f625d95'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='b3f3d96c-1857-4578-b3eb-a569f9cedac1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='116e07e9879b4f8f0b66c8e51c2c6e58c87bce0fbeec96b4aa2503507d843abf'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='347d0b5e-05f8-4b76-972a-8c07eaf1f1b5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6cf8af4d1e8db3f528f2992356f7051dc77c6548c39ba8e28ef1f49dcd2ab07b')}, text='Note that at inference\\ntime, asopposedtotraining, alltherewardmodelscanpredictascalarforasingleoutput, withoutrequiring\\nto access its paired output. For GPT-4, we prompt with a zero-shot question “Choose the best answer between A\\nand B,”where A and B are the two responses for comparison.\\nWe report the results in terms of accuracy in Table 7.', start_char_idx=2160, end_char_idx=2503, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-12', obj=None),\n",
       " '347d0b5e-05f8-4b76-972a-8c07eaf1f1b5': IndexNode(id_='347d0b5e-05f8-4b76-972a-8c07eaf1f1b5', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-12', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8845e152a80560179274711be3607960f234fa713b150737e9b3ca8d3f625d95'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='90d747c8-8dd3-4602-bcc7-35c784d2333a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3e21086574d08a2ea431d8c909434e6686e8c5b6311e01055128ae7cbc7c95ee'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='2ae8bdd2-1f96-4071-b31b-4a94aa0b579a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='454d2212fd72b134b2e1c44caab6535b20cd6d991f92ca889173f4dd6e6bc389')}, text='Note that at inference\\ntime, asopposedtotraining, alltherewardmodelscanpredictascalarforasingleoutput, withoutrequiring\\nto access its paired output. For GPT-4, we prompt with a zero-shot question “Choose the best answer between A\\nand B,”where A and B are the two responses for comparison.\\nWe report the results in terms of accuracy in Table 7. As expected, our own reward models perform the best\\non our internaltest sets collected based on Llama 2-Chat , with the Helpfulnessrewardmodel performing\\nbestontheMetaHelpfulnesstestset,andsimilarlytheSafetyrewardmodelperformingbestontheMeta\\nSafetytestset.', start_char_idx=2160, end_char_idx=2760, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-12', obj=None),\n",
       " '2ae8bdd2-1f96-4071-b31b-4a94aa0b579a': IndexNode(id_='2ae8bdd2-1f96-4071-b31b-4a94aa0b579a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-12', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8845e152a80560179274711be3607960f234fa713b150737e9b3ca8d3f625d95'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='347d0b5e-05f8-4b76-972a-8c07eaf1f1b5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6cf8af4d1e8db3f528f2992356f7051dc77c6548c39ba8e28ef1f49dcd2ab07b'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='4265ae8e-27f1-4a0b-bb19-6e083babd609', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ec7c055ce2c6bc2a32f62f205dde3304983b38771542d1245b342d4cffb41ce0')}, text='We report the results in terms of accuracy in Table 7. As expected, our own reward models perform the best\\non our internaltest sets collected based on Llama 2-Chat , with the Helpfulnessrewardmodel performing\\nbestontheMetaHelpfulnesstestset,andsimilarlytheSafetyrewardmodelperformingbestontheMeta\\nSafetytestset. Overall,ourrewardmodelsoutperformallofthebaselines,includingGPT-4.', start_char_idx=2449, end_char_idx=2827, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-12', obj=None),\n",
       " '4265ae8e-27f1-4a0b-bb19-6e083babd609': IndexNode(id_='4265ae8e-27f1-4a0b-bb19-6e083babd609', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-12', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8845e152a80560179274711be3607960f234fa713b150737e9b3ca8d3f625d95'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='2ae8bdd2-1f96-4071-b31b-4a94aa0b579a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='454d2212fd72b134b2e1c44caab6535b20cd6d991f92ca889173f4dd6e6bc389')}, text='We report the results in terms of accuracy in Table 7. As expected, our own reward models perform the best\\non our internaltest sets collected based on Llama 2-Chat , with the Helpfulnessrewardmodel performing\\nbestontheMetaHelpfulnesstestset,andsimilarlytheSafetyrewardmodelperformingbestontheMeta\\nSafetytestset. Overall,ourrewardmodelsoutperformallofthebaselines,includingGPT-4. Interestingly,\\nGPT-4 performs better than other non-Meta reward models, despite not being trained directly nor targeting\\nspecifically this reward modeling task.', start_char_idx=2449, end_char_idx=2988, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-12', obj=None),\n",
       " '42f3c381-e520-4ad2-91e7-f0849f046b15': IndexNode(id_='42f3c381-e520-4ad2-91e7-f0849f046b15', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-12', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8845e152a80560179274711be3607960f234fa713b150737e9b3ca8d3f625d95'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='79ff7cfa-2ffc-4371-8273-167cfd242092', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='70c4f0054929372069b80ed7ac30622a77feeec6ba909aa5fb297de95688d154')}, text='In earlier experiments, we found that\\ntraininglongercanleadtoover-fitting. Weusethesameoptimizerparametersasforthebasemodel. The\\nmaximum learning rate is 5×10−6for the 70B parameter Llama 2-Chat and1×10−5for the rest. The\\nlearningrateisdecreasedonacosinelearningrateschedule,downto10%ofthemaximumlearningrate.\\nWe use a warm-up of 3% of the total number of steps, with a minimum of 5. The effective batch size is kept\\nfixed at 512 pairs, or 1024 rows per batch.', start_char_idx=0, end_char_idx=460, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-12', obj=None),\n",
       " '79ff7cfa-2ffc-4371-8273-167cfd242092': IndexNode(id_='79ff7cfa-2ffc-4371-8273-167cfd242092', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-12', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8845e152a80560179274711be3607960f234fa713b150737e9b3ca8d3f625d95'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='42f3c381-e520-4ad2-91e7-f0849f046b15', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='60c44a4fb01d10a42769e45993e37b40b271432bfcbfa7fe6792244249ff98ab'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='ba1081dd-362e-412c-8587-740ba40f501e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='419d52cc16df6c22e6654a53bfaa00f029f22ac8973302de1c6d2615acdbe389')}, text='The\\nlearningrateisdecreasedonacosinelearningrateschedule,downto10%ofthemaximumlearningrate.\\nWe use a warm-up of 3% of the total number of steps, with a minimum of 5. The effective batch size is kept\\nfixed at 512 pairs, or 1024 rows per batch.\\nMeta\\nHelpful.Meta\\nSafetyAnthropic\\nHelpfulAnthropic\\nHarmlessOpenAI\\nSumm.Stanford\\nSHPAvg\\nSteamSHP-XL 52.8 43.8 66.8 34.2 54.7 75.7 55.3\\nOpen Assistant 53.8 53.4 67.7 68.4 71.7 55.0 63.0\\nGPT4 58.6 58.1 - - - - -\\nSafety RM 56.2 64.5 55.4 74.7 71.7 65.2 64.3\\nHelpfulness RM 63.2 62.8 72.0 71.0 75.5 80.0 70.6\\nTable 7: Reward model results.', start_char_idx=218, end_char_idx=795, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-12', obj=None),\n",
       " 'ba1081dd-362e-412c-8587-740ba40f501e': IndexNode(id_='ba1081dd-362e-412c-8587-740ba40f501e', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-12', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8845e152a80560179274711be3607960f234fa713b150737e9b3ca8d3f625d95'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='79ff7cfa-2ffc-4371-8273-167cfd242092', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='70c4f0054929372069b80ed7ac30622a77feeec6ba909aa5fb297de95688d154'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='9246a984-9122-47ad-ad10-061cd1cbe80c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='75e3b7e8446c3a589cb6eb35b069225c5cf17631cf6a6b85ed090df56278e42b')}, text='Performance of our final helpfulness and safety reward models on a diverse\\nset of human preference benchmarks. Note that our model is fine-tuned on our collected data, as opposed to\\nthe other baselines that we report.\\nTest SetSignificantly\\nBetterBetterSlightly\\nBetterNegligibly\\nBetter / UnsureAvg\\nSafety RMMeta Safety94.3 76.3 65.7 55.3 64.5\\nHelpfulness RM 89.9 73.2 63.8 54.5 62.8\\nSafety RMMeta Helpful.64.6 57.5 53.8 52.2 56.2\\nHelpfulness RM 80.7 67.5 60.9 54.7 63.2\\nTable 8: Granular reward model accuracy per preference rating. We report per-preference rating accuracy\\nforbothHelpfulnessandSafetyrewardmodelsontheMetaHelpfulnessandSafetytestsets. Thereward\\nmodels show superior accuracy on more distinct responses (e.g., significantly better) and lower accuracy on\\nsimilar responses (e.g., negligibly better).\\nReward Model Results.', start_char_idx=796, end_char_idx=1631, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-12', obj=None),\n",
       " '9246a984-9122-47ad-ad10-061cd1cbe80c': IndexNode(id_='9246a984-9122-47ad-ad10-061cd1cbe80c', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-12', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8845e152a80560179274711be3607960f234fa713b150737e9b3ca8d3f625d95'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='ba1081dd-362e-412c-8587-740ba40f501e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='419d52cc16df6c22e6654a53bfaa00f029f22ac8973302de1c6d2615acdbe389'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='7a9c8e03-ccba-4ae2-85b0-a9fa076cb4ec', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1c5a3944bcea1dd4c8a7455c889c441e6705bdf3ca414f6b208334af771cb017')}, text='We report per-preference rating accuracy\\nforbothHelpfulnessandSafetyrewardmodelsontheMetaHelpfulnessandSafetytestsets. Thereward\\nmodels show superior accuracy on more distinct responses (e.g., significantly better) and lower accuracy on\\nsimilar responses (e.g., negligibly better).\\nReward Model Results. On each batch of human preference annotation for reward modeling, we held out\\n1000examplesasatestsettoevaluateourmodels. Werefertotheunionofallpromptsforthecorresponding\\ntest sets as “Meta Helpfulness” and “Meta Safety,” respectively.\\nAs reference points, we also evaluated other publicly available alternatives as baselines: SteamSHP-XL\\n(Ethayarajh et al., 2022) based on FLAN-T5-xl, the Open Assistant (Köpf et al., 2023) reward model based on\\nDeBERTa V3 Large (He et al., 2020), and GPT4 accessible through the OpenAI’s API. Note that at inference\\ntime, asopposedtotraining, alltherewardmodelscanpredictascalarforasingleoutput, withoutrequiring\\nto access its paired output.', start_char_idx=1328, end_char_idx=2308, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-12', obj=None),\n",
       " '7a9c8e03-ccba-4ae2-85b0-a9fa076cb4ec': IndexNode(id_='7a9c8e03-ccba-4ae2-85b0-a9fa076cb4ec', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-12', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8845e152a80560179274711be3607960f234fa713b150737e9b3ca8d3f625d95'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='9246a984-9122-47ad-ad10-061cd1cbe80c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='75e3b7e8446c3a589cb6eb35b069225c5cf17631cf6a6b85ed090df56278e42b')}, text='Note that at inference\\ntime, asopposedtotraining, alltherewardmodelscanpredictascalarforasingleoutput, withoutrequiring\\nto access its paired output. For GPT-4, we prompt with a zero-shot question “Choose the best answer between A\\nand B,”where A and B are the two responses for comparison.\\nWe report the results in terms of accuracy in Table 7. As expected, our own reward models perform the best\\non our internaltest sets collected based on Llama 2-Chat , with the Helpfulnessrewardmodel performing\\nbestontheMetaHelpfulnesstestset,andsimilarlytheSafetyrewardmodelperformingbestontheMeta\\nSafetytestset. Overall,ourrewardmodelsoutperformallofthebaselines,includingGPT-4. Interestingly,\\nGPT-4 performs better than other non-Meta reward models, despite not being trained directly nor targeting\\nspecifically this reward modeling task.', start_char_idx=2160, end_char_idx=2988, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-12', obj=None),\n",
       " 'b8b6f2c9-a0e5-4c3a-8b96-ec51c22b482e': IndexNode(id_='b8b6f2c9-a0e5-4c3a-8b96-ec51c22b482e', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-12', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8845e152a80560179274711be3607960f234fa713b150737e9b3ca8d3f625d95'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='ea3fa063-e78b-47ba-b3c0-c52735774214', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f42a360e4e2ee7eba25cf706e53c4c4530105ade96264494af7e17be9e8ff2d2')}, text='In earlier experiments, we found that\\ntraininglongercanleadtoover-fitting. Weusethesameoptimizerparametersasforthebasemodel. The\\nmaximum learning rate is 5×10−6for the 70B parameter Llama 2-Chat and1×10−5for the rest. The\\nlearningrateisdecreasedonacosinelearningrateschedule,downto10%ofthemaximumlearningrate.\\nWe use a warm-up of 3% of the total number of steps, with a minimum of 5. The effective batch size is kept\\nfixed at 512 pairs, or 1024 rows per batch.\\nMeta\\nHelpful.Meta\\nSafetyAnthropic\\nHelpfulAnthropic\\nHarmlessOpenAI\\nSumm.Stanford\\nSHPAvg\\nSteamSHP-XL 52.8 43.8 66.8 34.2 54.7 75.7 55.3\\nOpen Assistant 53.8 53.4 67.7 68.4 71.7 55.0 63.0\\nGPT4 58.6 58.1 - - - - -\\nSafety RM 56.2 64.5 55.4 74.7 71.7 65.2 64.3\\nHelpfulness RM 63.2 62.8 72.0 71.0 75.5 80.0 70.6\\nTable 7: Reward model results. Performance of our final helpfulness and safety reward models on a diverse\\nset of human preference benchmarks. Note that our model is fine-tuned on our collected data, as opposed to\\nthe other baselines that we report.\\nTest SetSignificantly\\nBetterBetterSlightly\\nBetterNegligibly\\nBetter / UnsureAvg\\nSafety RMMeta Safety94.3 76.3 65.7 55.3 64.5\\nHelpfulness RM 89.9 73.2 63.8 54.5 62.8\\nSafety RMMeta Helpful.64.6 57.5 53.8 52.2 56.2\\nHelpfulness RM 80.7 67.5 60.9 54.7 63.2\\nTable 8: Granular reward model accuracy per preference rating.', start_char_idx=0, end_char_idx=1327, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-12', obj=None),\n",
       " 'ea3fa063-e78b-47ba-b3c0-c52735774214': IndexNode(id_='ea3fa063-e78b-47ba-b3c0-c52735774214', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-12', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8845e152a80560179274711be3607960f234fa713b150737e9b3ca8d3f625d95'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='b8b6f2c9-a0e5-4c3a-8b96-ec51c22b482e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0448e166df5272cb3551db9e5e71edd9fc63a2be558197100c2de014f400a5f3')}, text='We report per-preference rating accuracy\\nforbothHelpfulnessandSafetyrewardmodelsontheMetaHelpfulnessandSafetytestsets. Thereward\\nmodels show superior accuracy on more distinct responses (e.g., significantly better) and lower accuracy on\\nsimilar responses (e.g., negligibly better).\\nReward Model Results. On each batch of human preference annotation for reward modeling, we held out\\n1000examplesasatestsettoevaluateourmodels. Werefertotheunionofallpromptsforthecorresponding\\ntest sets as “Meta Helpfulness” and “Meta Safety,” respectively.\\nAs reference points, we also evaluated other publicly available alternatives as baselines: SteamSHP-XL\\n(Ethayarajh et al., 2022) based on FLAN-T5-xl, the Open Assistant (Köpf et al., 2023) reward model based on\\nDeBERTa V3 Large (He et al., 2020), and GPT4 accessible through the OpenAI’s API. Note that at inference\\ntime, asopposedtotraining, alltherewardmodelscanpredictascalarforasingleoutput, withoutrequiring\\nto access its paired output. For GPT-4, we prompt with a zero-shot question “Choose the best answer between A\\nand B,”where A and B are the two responses for comparison.\\nWe report the results in terms of accuracy in Table 7. As expected, our own reward models perform the best\\non our internaltest sets collected based on Llama 2-Chat , with the Helpfulnessrewardmodel performing\\nbestontheMetaHelpfulnesstestset,andsimilarlytheSafetyrewardmodelperformingbestontheMeta\\nSafetytestset. Overall,ourrewardmodelsoutperformallofthebaselines,includingGPT-4. Interestingly,\\nGPT-4 performs better than other non-Meta reward models, despite not being trained directly nor targeting\\nspecifically this reward modeling task.', start_char_idx=1328, end_char_idx=2988, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-12', obj=None),\n",
       " 'node-12': IndexNode(id_='node-12', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='d03f19eb-da15-45dc-bfd4-e5d10f161250', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='231b3bd773f012c01b893ada9e009ecf25ee59934614c5a595c9bf1b3a123292'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='410a9899-faa1-4f5e-a8fd-f5f42c23c4ad', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='67028bbb401a409a94495eb0c57e4d9b6af8e98e1ed453fe8f647bc94196224c'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='c10f1dd0-d391-47e9-a719-be5db96b118a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='36acf0ba046e4e355c93836ed53ee6157045b6b73e7e5aed51685a2407a65d62')}, text='In earlier experiments, we found that\\ntraininglongercanleadtoover-fitting. Weusethesameoptimizerparametersasforthebasemodel. The\\nmaximum learning rate is 5×10−6for the 70B parameter Llama 2-Chat and1×10−5for the rest. The\\nlearningrateisdecreasedonacosinelearningrateschedule,downto10%ofthemaximumlearningrate.\\nWe use a warm-up of 3% of the total number of steps, with a minimum of 5. The effective batch size is kept\\nfixed at 512 pairs, or 1024 rows per batch.\\nMeta\\nHelpful.Meta\\nSafetyAnthropic\\nHelpfulAnthropic\\nHarmlessOpenAI\\nSumm.Stanford\\nSHPAvg\\nSteamSHP-XL 52.8 43.8 66.8 34.2 54.7 75.7 55.3\\nOpen Assistant 53.8 53.4 67.7 68.4 71.7 55.0 63.0\\nGPT4 58.6 58.1 - - - - -\\nSafety RM 56.2 64.5 55.4 74.7 71.7 65.2 64.3\\nHelpfulness RM 63.2 62.8 72.0 71.0 75.5 80.0 70.6\\nTable 7: Reward model results. Performance of our final helpfulness and safety reward models on a diverse\\nset of human preference benchmarks. Note that our model is fine-tuned on our collected data, as opposed to\\nthe other baselines that we report.\\nTest SetSignificantly\\nBetterBetterSlightly\\nBetterNegligibly\\nBetter / UnsureAvg\\nSafety RMMeta Safety94.3 76.3 65.7 55.3 64.5\\nHelpfulness RM 89.9 73.2 63.8 54.5 62.8\\nSafety RMMeta Helpful.64.6 57.5 53.8 52.2 56.2\\nHelpfulness RM 80.7 67.5 60.9 54.7 63.2\\nTable 8: Granular reward model accuracy per preference rating. We report per-preference rating accuracy\\nforbothHelpfulnessandSafetyrewardmodelsontheMetaHelpfulnessandSafetytestsets. Thereward\\nmodels show superior accuracy on more distinct responses (e.g., significantly better) and lower accuracy on\\nsimilar responses (e.g., negligibly better).\\nReward Model Results. On each batch of human preference annotation for reward modeling, we held out\\n1000examplesasatestsettoevaluateourmodels. Werefertotheunionofallpromptsforthecorresponding\\ntest sets as “Meta Helpfulness” and “Meta Safety,” respectively.\\nAs reference points, we also evaluated other publicly available alternatives as baselines: SteamSHP-XL\\n(Ethayarajh et al., 2022) based on FLAN-T5-xl, the Open Assistant (Köpf et al., 2023) reward model based on\\nDeBERTa V3 Large (He et al., 2020), and GPT4 accessible through the OpenAI’s API. Note that at inference\\ntime, asopposedtotraining, alltherewardmodelscanpredictascalarforasingleoutput, withoutrequiring\\nto access its paired output. For GPT-4, we prompt with a zero-shot question “Choose the best answer between A\\nand B,”where A and B are the two responses for comparison.\\nWe report the results in terms of accuracy in Table 7. As expected, our own reward models perform the best\\non our internaltest sets collected based on Llama 2-Chat , with the Helpfulnessrewardmodel performing\\nbestontheMetaHelpfulnesstestset,andsimilarlytheSafetyrewardmodelperformingbestontheMeta\\nSafetytestset. Overall,ourrewardmodelsoutperformallofthebaselines,includingGPT-4. Interestingly,\\nGPT-4 performs better than other non-Meta reward models, despite not being trained directly nor targeting\\nspecifically this reward modeling task.', start_char_idx=35018, end_char_idx=38006, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-12', obj=None),\n",
       " '24fcab85-e096-400b-837c-b52be6ddd986': IndexNode(id_='24fcab85-e096-400b-837c-b52be6ddd986', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-13', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='36acf0ba046e4e355c93836ed53ee6157045b6b73e7e5aed51685a2407a65d62'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='2200cad0-e9b8-4d1c-8e36-379c1c0735e6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c91371e0b79519d6d9bebdcf1cd114ccbdeb777bfda7f4334b04a1cc2a942061')}, text='Overall,ourrewardmodelsoutperformallofthebaselines,includingGPT-4. Interestingly,\\nGPT-4 performs better than other non-Meta reward models, despite not being trained directly nor targeting\\nspecifically this reward modeling task.', start_char_idx=0, end_char_idx=227, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-13', obj=None),\n",
       " '2200cad0-e9b8-4d1c-8e36-379c1c0735e6': IndexNode(id_='2200cad0-e9b8-4d1c-8e36-379c1c0735e6', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-13', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='36acf0ba046e4e355c93836ed53ee6157045b6b73e7e5aed51685a2407a65d62'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='24fcab85-e096-400b-837c-b52be6ddd986', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ae87dc0e1ca8fbce6e6c25ed3983ab3d16cdd8b427915d8c6e7f07019dbf2031'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='7ebbff2e-48e0-44a6-a46a-33654e69d7e9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='149d674a5fb759c53d22f675c1904e85267192a09c36ff123a36fa6ba83cd50e')}, text='Overall,ourrewardmodelsoutperformallofthebaselines,includingGPT-4. Interestingly,\\nGPT-4 performs better than other non-Meta reward models, despite not being trained directly nor targeting\\nspecifically this reward modeling task.\\n12\\n\\n1234567891011121314\\nMeta Helpfulness Data Batch Stage0.520.540.560.580.600.620.64Accuracy On All Examples\\n 7b\\n13b\\n70b\\nGPT4\\nOpenAssistant\\n1234567891011121314\\nMeta Helpfulness Data Batch Stage0.500.550.600.650.700.750.80Accuracy On Examples With Label \"Significantly Better\"\\n7b\\n13b\\n70b\\nGPT4\\nOpenAssistantFigure 6: Scaling trends for the reward model.', start_char_idx=0, end_char_idx=580, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-13', obj=None),\n",
       " '7ebbff2e-48e0-44a6-a46a-33654e69d7e9': IndexNode(id_='7ebbff2e-48e0-44a6-a46a-33654e69d7e9', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-13', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='36acf0ba046e4e355c93836ed53ee6157045b6b73e7e5aed51685a2407a65d62'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='2200cad0-e9b8-4d1c-8e36-379c1c0735e6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c91371e0b79519d6d9bebdcf1cd114ccbdeb777bfda7f4334b04a1cc2a942061'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='5d88673d-ea7e-4993-a8b4-c031f92813ed', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a73fa2c36ac1b9b79055dfaa54dbbcba96819c960e87f74f53d72b0c9607deca')}, text='More data and a larger-size model generally improve\\naccuracy, and it appears that our models have not yet saturated from learning on the training data.\\nThefactthathelpfulnessandsafetyperformedthe bestontheirowndomainispotentiallyduetothetension\\nbetweenthetwoobjectives(i.e.,beingashelpfulaspossibleversusrefusingunsafepromptswhennecessary),\\nwhichmayconfusetherewardmodelduringtraining.', start_char_idx=581, end_char_idx=966, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-13', obj=None),\n",
       " '5d88673d-ea7e-4993-a8b4-c031f92813ed': IndexNode(id_='5d88673d-ea7e-4993-a8b4-c031f92813ed', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-13', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='36acf0ba046e4e355c93836ed53ee6157045b6b73e7e5aed51685a2407a65d62'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='7ebbff2e-48e0-44a6-a46a-33654e69d7e9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='149d674a5fb759c53d22f675c1904e85267192a09c36ff123a36fa6ba83cd50e'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='6161853a-7154-4393-8cc6-65d8e8ccb5f2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6b1c13376f95ebbea2ee4d2dd08f7c375b54c791d484a2ff3c4ae8498cb5328e')}, text='More data and a larger-size model generally improve\\naccuracy, and it appears that our models have not yet saturated from learning on the training data.\\nThefactthathelpfulnessandsafetyperformedthe bestontheirowndomainispotentiallyduetothetension\\nbetweenthetwoobjectives(i.e.,beingashelpfulaspossibleversusrefusingunsafepromptswhennecessary),\\nwhichmayconfusetherewardmodelduringtraining. Inorderforasinglemodeltoperformwellonboth\\ndimensions, it needs to not only learn to select the better response given a prompt but also to distinguish\\nadversarial prompts from safe ones.', start_char_idx=581, end_char_idx=1152, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-13', obj=None),\n",
       " '6161853a-7154-4393-8cc6-65d8e8ccb5f2': IndexNode(id_='6161853a-7154-4393-8cc6-65d8e8ccb5f2', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-13', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='36acf0ba046e4e355c93836ed53ee6157045b6b73e7e5aed51685a2407a65d62'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='5d88673d-ea7e-4993-a8b4-c031f92813ed', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a73fa2c36ac1b9b79055dfaa54dbbcba96819c960e87f74f53d72b0c9607deca'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='70635b29-ffbe-4b3b-950a-7f946c8a0d0d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='457aef524f72f28de13742dc271bbb815aad768cde6571c7d90b6f55fb79cd03')}, text='Inorderforasinglemodeltoperformwellonboth\\ndimensions, it needs to not only learn to select the better response given a prompt but also to distinguish\\nadversarial prompts from safe ones. As a result, optimizing two separate models eases the reward modeling\\ntask. More detailed analysis on this tension between safety and helpfulness can be found in Appendix A.4.1.', start_char_idx=967, end_char_idx=1330, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-13', obj=None),\n",
       " '70635b29-ffbe-4b3b-950a-7f946c8a0d0d': IndexNode(id_='70635b29-ffbe-4b3b-950a-7f946c8a0d0d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-13', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='36acf0ba046e4e355c93836ed53ee6157045b6b73e7e5aed51685a2407a65d62'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='6161853a-7154-4393-8cc6-65d8e8ccb5f2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6b1c13376f95ebbea2ee4d2dd08f7c375b54c791d484a2ff3c4ae8498cb5328e'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='0e54227b-5de9-410e-b213-2e36a4ed3781', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='20798b81838c26214f90674ad9965fdfb30cfedb8944da633e13dc68ef22a5ab')}, text='Inorderforasinglemodeltoperformwellonboth\\ndimensions, it needs to not only learn to select the better response given a prompt but also to distinguish\\nadversarial prompts from safe ones. As a result, optimizing two separate models eases the reward modeling\\ntask. More detailed analysis on this tension between safety and helpfulness can be found in Appendix A.4.1.\\nWhenwegroupthescoresbypreferenceratinginTable8,wecanseethattheaccuracyissuperiorforthe\\n“significantlybetter”testsetanddegradesgraduallyascomparisonpairsbecomemoresimilar(e.g.,“slightly\\nbetter”).', start_char_idx=967, end_char_idx=1525, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-13', obj=None),\n",
       " '0e54227b-5de9-410e-b213-2e36a4ed3781': IndexNode(id_='0e54227b-5de9-410e-b213-2e36a4ed3781', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-13', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='36acf0ba046e4e355c93836ed53ee6157045b6b73e7e5aed51685a2407a65d62'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='70635b29-ffbe-4b3b-950a-7f946c8a0d0d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='457aef524f72f28de13742dc271bbb815aad768cde6571c7d90b6f55fb79cd03'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='07721519-f8ad-45b7-ace4-bdca0a78548e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4257a3e485ca42535dc79bc634ec0e8aa741d072834424685f319d3af64fae5f')}, text='As a result, optimizing two separate models eases the reward modeling\\ntask. More detailed analysis on this tension between safety and helpfulness can be found in Appendix A.4.1.\\nWhenwegroupthescoresbypreferenceratinginTable8,wecanseethattheaccuracyissuperiorforthe\\n“significantlybetter”testsetanddegradesgraduallyascomparisonpairsbecomemoresimilar(e.g.,“slightly\\nbetter”). It is expected that learning to model human preferences becomes challenging when deciding\\nbetweentwosimilarmodelresponses,duetoannotatorsubjectivityandtheirrelianceonnuanceddetails\\nthatmaydifferentiateresponses.', start_char_idx=1153, end_char_idx=1737, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-13', obj=None),\n",
       " '07721519-f8ad-45b7-ace4-bdca0a78548e': IndexNode(id_='07721519-f8ad-45b7-ace4-bdca0a78548e', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-13', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='36acf0ba046e4e355c93836ed53ee6157045b6b73e7e5aed51685a2407a65d62'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='0e54227b-5de9-410e-b213-2e36a4ed3781', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='20798b81838c26214f90674ad9965fdfb30cfedb8944da633e13dc68ef22a5ab'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='7b9ee1eb-703d-4d72-8878-d0369bba5476', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='49d89a01b8f3d5a31946141520cfcf626347590b96f098a5e1d2c78216d8118e')}, text='It is expected that learning to model human preferences becomes challenging when deciding\\nbetweentwosimilarmodelresponses,duetoannotatorsubjectivityandtheirrelianceonnuanceddetails\\nthatmaydifferentiateresponses. Weemphasizethattheaccuracyonmoredistinctresponsesmattersthe\\nmosttoimprove Llama 2-Chat performance. Thehumanpreferenceannotationagreementrateisalsohigher\\non more distinct responses than similar pairs.\\nScalingTrends.', start_char_idx=1526, end_char_idx=1953, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-13', obj=None),\n",
       " '7b9ee1eb-703d-4d72-8878-d0369bba5476': IndexNode(id_='7b9ee1eb-703d-4d72-8878-d0369bba5476', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-13', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='36acf0ba046e4e355c93836ed53ee6157045b6b73e7e5aed51685a2407a65d62'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='07721519-f8ad-45b7-ace4-bdca0a78548e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4257a3e485ca42535dc79bc634ec0e8aa741d072834424685f319d3af64fae5f'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='358e30ca-efd0-4eef-9de7-25bdf07a4cec', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='87dda6579ab5820db47bf4f6c2872d8604d43e4da9994c6dd1b9e842b34247a5')}, text='Weemphasizethattheaccuracyonmoredistinctresponsesmattersthe\\nmosttoimprove Llama 2-Chat performance. Thehumanpreferenceannotationagreementrateisalsohigher\\non more distinct responses than similar pairs.\\nScalingTrends. Westudythescalingtrendsintermsofdataandmodelsizefortherewardmodel,fine-\\ntuning different model sizes on an increasing amount of the reward model data collected each week (see the\\ndetailsonvolumeperbatchinTable26).', start_char_idx=1738, end_char_idx=2167, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-13', obj=None),\n",
       " '358e30ca-efd0-4eef-9de7-25bdf07a4cec': IndexNode(id_='358e30ca-efd0-4eef-9de7-25bdf07a4cec', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-13', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='36acf0ba046e4e355c93836ed53ee6157045b6b73e7e5aed51685a2407a65d62'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='7b9ee1eb-703d-4d72-8878-d0369bba5476', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='49d89a01b8f3d5a31946141520cfcf626347590b96f098a5e1d2c78216d8118e'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='06047614-0969-4e7b-9b23-a0c5487010a8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6469c1a1d93761df3e52accd0343c5db912e60794e0d5037480d280cc328415c')}, text='Thehumanpreferenceannotationagreementrateisalsohigher\\non more distinct responses than similar pairs.\\nScalingTrends. Westudythescalingtrendsintermsofdataandmodelsizefortherewardmodel,fine-\\ntuning different model sizes on an increasing amount of the reward model data collected each week (see the\\ndetailsonvolumeperbatchinTable26). Figure6reportsthesetrends,showingtheexpectedresultthatlarger\\nmodels obtain higher performance for a similar volume of data.', start_char_idx=1838, end_char_idx=2291, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-13', obj=None),\n",
       " '06047614-0969-4e7b-9b23-a0c5487010a8': IndexNode(id_='06047614-0969-4e7b-9b23-a0c5487010a8', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-13', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='36acf0ba046e4e355c93836ed53ee6157045b6b73e7e5aed51685a2407a65d62'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='358e30ca-efd0-4eef-9de7-25bdf07a4cec', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='87dda6579ab5820db47bf4f6c2872d8604d43e4da9994c6dd1b9e842b34247a5'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='892df436-38a3-4f77-81a0-9f62fd6d8e3b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a063c50dfc4a8aef57ed5e441c7abf105cef492482c4cb979c3a7e64aa7af457')}, text='ScalingTrends. Westudythescalingtrendsintermsofdataandmodelsizefortherewardmodel,fine-\\ntuning different model sizes on an increasing amount of the reward model data collected each week (see the\\ndetailsonvolumeperbatchinTable26). Figure6reportsthesetrends,showingtheexpectedresultthatlarger\\nmodels obtain higher performance for a similar volume of data. More importantly, the scaling performance\\nhasnotyetplateauedgiventheexistingvolumeofdataannotationusedfortraining,asignalthatthereis\\nroom for more improvement with more annotations.', start_char_idx=1939, end_char_idx=2473, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-13', obj=None),\n",
       " '892df436-38a3-4f77-81a0-9f62fd6d8e3b': IndexNode(id_='892df436-38a3-4f77-81a0-9f62fd6d8e3b', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-13', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='36acf0ba046e4e355c93836ed53ee6157045b6b73e7e5aed51685a2407a65d62'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='06047614-0969-4e7b-9b23-a0c5487010a8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6469c1a1d93761df3e52accd0343c5db912e60794e0d5037480d280cc328415c'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='f111eed7-e981-467f-8143-b5517e8a84a7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4b49d6dcaed673a4d08d6b2d6cfdb76361b5457a8e7485550e522f0742f6b19d')}, text='Figure6reportsthesetrends,showingtheexpectedresultthatlarger\\nmodels obtain higher performance for a similar volume of data. More importantly, the scaling performance\\nhasnotyetplateauedgiventheexistingvolumeofdataannotationusedfortraining,asignalthatthereis\\nroom for more improvement with more annotations. We note that reward model accuracy is one of the most\\nimportant proxies for the final performance of Llama 2-Chat . While best practices for comprehensively\\nevaluating a generative model is an open research question, the ranking task of the reward has no ambiguity.', start_char_idx=2168, end_char_idx=2739, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-13', obj=None),\n",
       " 'f111eed7-e981-467f-8143-b5517e8a84a7': IndexNode(id_='f111eed7-e981-467f-8143-b5517e8a84a7', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-13', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='36acf0ba046e4e355c93836ed53ee6157045b6b73e7e5aed51685a2407a65d62'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='892df436-38a3-4f77-81a0-9f62fd6d8e3b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a063c50dfc4a8aef57ed5e441c7abf105cef492482c4cb979c3a7e64aa7af457'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='5ccc1790-cd32-4f32-9f1b-965a8db1a0bb', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6811e0c05ac6e29347ad89894dc6f8965a90decc5aa04e90958c8ce62f2acf39')}, text='More importantly, the scaling performance\\nhasnotyetplateauedgiventheexistingvolumeofdataannotationusedfortraining,asignalthatthereis\\nroom for more improvement with more annotations. We note that reward model accuracy is one of the most\\nimportant proxies for the final performance of Llama 2-Chat . While best practices for comprehensively\\nevaluating a generative model is an open research question, the ranking task of the reward has no ambiguity.\\nTherefore, everything else being equal, an improvement of the reward model can be directly translated into\\nan improvement for Llama 2-Chat .', start_char_idx=2292, end_char_idx=2880, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-13', obj=None),\n",
       " '5ccc1790-cd32-4f32-9f1b-965a8db1a0bb': IndexNode(id_='5ccc1790-cd32-4f32-9f1b-965a8db1a0bb', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-13', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='36acf0ba046e4e355c93836ed53ee6157045b6b73e7e5aed51685a2407a65d62'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='f111eed7-e981-467f-8143-b5517e8a84a7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4b49d6dcaed673a4d08d6b2d6cfdb76361b5457a8e7485550e522f0742f6b19d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='419f6c61-0115-47cb-b714-e463cff13a19', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='96023594c3475d7104f1f24cb7e47b9cdb1fe991187ad5ad1105f126a4b0bd0d')}, text='We note that reward model accuracy is one of the most\\nimportant proxies for the final performance of Llama 2-Chat . While best practices for comprehensively\\nevaluating a generative model is an open research question, the ranking task of the reward has no ambiguity.\\nTherefore, everything else being equal, an improvement of the reward model can be directly translated into\\nan improvement for Llama 2-Chat .\\n3.2.3 Iterative Fine-Tuning\\nAs we received more batches of human preference data annotation, we were able to train better reward\\nmodelsandcollectmoreprompts.', start_char_idx=2474, end_char_idx=3038, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-13', obj=None),\n",
       " '419f6c61-0115-47cb-b714-e463cff13a19': IndexNode(id_='419f6c61-0115-47cb-b714-e463cff13a19', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-13', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='36acf0ba046e4e355c93836ed53ee6157045b6b73e7e5aed51685a2407a65d62'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='5ccc1790-cd32-4f32-9f1b-965a8db1a0bb', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6811e0c05ac6e29347ad89894dc6f8965a90decc5aa04e90958c8ce62f2acf39'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='a0d44d8c-626b-494d-a598-7575c83586e2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='38582dda610c5a088e95a98201425da27cf5787584528388a28b9b2563424f3d')}, text='While best practices for comprehensively\\nevaluating a generative model is an open research question, the ranking task of the reward has no ambiguity.\\nTherefore, everything else being equal, an improvement of the reward model can be directly translated into\\nan improvement for Llama 2-Chat .\\n3.2.3 Iterative Fine-Tuning\\nAs we received more batches of human preference data annotation, we were able to train better reward\\nmodelsandcollectmoreprompts. WethereforetrainedsuccessiveversionsforRLHFmodels,referredto\\nhere as RLHF-V1, ..., RLHF-V5.', start_char_idx=2590, end_char_idx=3130, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-13', obj=None),\n",
       " 'a0d44d8c-626b-494d-a598-7575c83586e2': IndexNode(id_='a0d44d8c-626b-494d-a598-7575c83586e2', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-13', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='36acf0ba046e4e355c93836ed53ee6157045b6b73e7e5aed51685a2407a65d62'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='419f6c61-0115-47cb-b714-e463cff13a19', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='96023594c3475d7104f1f24cb7e47b9cdb1fe991187ad5ad1105f126a4b0bd0d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='caf2c142-93d7-445e-8aac-08096df5d5bf', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='516f32b142e496339eb9a88be6dd50d6879fa2c91ae4247b288af9b97ee4e09f')}, text='Therefore, everything else being equal, an improvement of the reward model can be directly translated into\\nan improvement for Llama 2-Chat .\\n3.2.3 Iterative Fine-Tuning\\nAs we received more batches of human preference data annotation, we were able to train better reward\\nmodelsandcollectmoreprompts. WethereforetrainedsuccessiveversionsforRLHFmodels,referredto\\nhere as RLHF-V1, ..., RLHF-V5.\\nWe explored RLHF fine-tuning with two main algorithms:\\n•Proximal Policy Optimization (PPO) (Schulman et al., 2017), the standard in RLHF literature.', start_char_idx=2740, end_char_idx=3279, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-13', obj=None),\n",
       " 'caf2c142-93d7-445e-8aac-08096df5d5bf': IndexNode(id_='caf2c142-93d7-445e-8aac-08096df5d5bf', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-13', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='36acf0ba046e4e355c93836ed53ee6157045b6b73e7e5aed51685a2407a65d62'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='a0d44d8c-626b-494d-a598-7575c83586e2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='38582dda610c5a088e95a98201425da27cf5787584528388a28b9b2563424f3d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='8908a74e-2ff8-4714-a326-2f4dbf14da36', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e4b206b89192bc57f8f7679ad388eb717d62f924674548a1d9a2670d4c53b651')}, text='WethereforetrainedsuccessiveversionsforRLHFmodels,referredto\\nhere as RLHF-V1, ..., RLHF-V5.\\nWe explored RLHF fine-tuning with two main algorithms:\\n•Proximal Policy Optimization (PPO) (Schulman et al., 2017), the standard in RLHF literature.\\n•RejectionSamplingfine-tuning . Wesample Koutputsfromthemodelandselectthebestcandidate\\nwith our reward, consistent with Bai et al. (2022b).', start_char_idx=3039, end_char_idx=3419, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-13', obj=None),\n",
       " '8908a74e-2ff8-4714-a326-2f4dbf14da36': IndexNode(id_='8908a74e-2ff8-4714-a326-2f4dbf14da36', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-13', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='36acf0ba046e4e355c93836ed53ee6157045b6b73e7e5aed51685a2407a65d62'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='caf2c142-93d7-445e-8aac-08096df5d5bf', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='516f32b142e496339eb9a88be6dd50d6879fa2c91ae4247b288af9b97ee4e09f'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='4d1f6241-0543-445b-989c-ef628b2bfee7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b3a5a1519dd9009b710c555c1d6474886ce10017f94851470ad92155e004f744')}, text='We explored RLHF fine-tuning with two main algorithms:\\n•Proximal Policy Optimization (PPO) (Schulman et al., 2017), the standard in RLHF literature.\\n•RejectionSamplingfine-tuning . Wesample Koutputsfromthemodelandselectthebestcandidate\\nwith our reward, consistent with Bai et al. (2022b). The same re-ranking strategy for LLMs was also\\nproposedinDengetal.(2019),wheretherewardisseenasanenergyfunction.', start_char_idx=3131, end_char_idx=3532, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-13', obj=None),\n",
       " '4d1f6241-0543-445b-989c-ef628b2bfee7': IndexNode(id_='4d1f6241-0543-445b-989c-ef628b2bfee7', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-13', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='36acf0ba046e4e355c93836ed53ee6157045b6b73e7e5aed51685a2407a65d62'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='8908a74e-2ff8-4714-a326-2f4dbf14da36', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e4b206b89192bc57f8f7679ad388eb717d62f924674548a1d9a2670d4c53b651'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='090ef145-a147-4e73-9cc6-f8b5a32987be', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e2f2f22faed58eb1a5a2615cc77181361aeefd2210423dc259de695a2bde7bee')}, text='•RejectionSamplingfine-tuning . Wesample Koutputsfromthemodelandselectthebestcandidate\\nwith our reward, consistent with Bai et al. (2022b). The same re-ranking strategy for LLMs was also\\nproposedinDengetal.(2019),wheretherewardisseenasanenergyfunction. Here,wegoonestep\\nfurther,anduse theselectedoutputsfora gradientupdate.', start_char_idx=3280, end_char_idx=3603, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-13', obj=None),\n",
       " '090ef145-a147-4e73-9cc6-f8b5a32987be': IndexNode(id_='090ef145-a147-4e73-9cc6-f8b5a32987be', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-13', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='36acf0ba046e4e355c93836ed53ee6157045b6b73e7e5aed51685a2407a65d62'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='4d1f6241-0543-445b-989c-ef628b2bfee7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b3a5a1519dd9009b710c555c1d6474886ce10017f94851470ad92155e004f744'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='6fd3b240-68a0-44e6-8b0a-9b93d76be509', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bc148731e4f3f6f4779518655aba1e0f5e614a89d5f927d6e6a6a878ada6f539')}, text='•RejectionSamplingfine-tuning . Wesample Koutputsfromthemodelandselectthebestcandidate\\nwith our reward, consistent with Bai et al. (2022b). The same re-ranking strategy for LLMs was also\\nproposedinDengetal.(2019),wheretherewardisseenasanenergyfunction. Here,wegoonestep\\nfurther,anduse theselectedoutputsfora gradientupdate. For eachprompt,thesample obtaining\\n13\\n\\n100101\\nN Samples0.540.560.580.600.620.640.66Reward Score\\nMax of the rewards\\nMedian of the rewardsFigure 7: Max and median reward among N samples ,N∈[1, .', start_char_idx=3280, end_char_idx=3796, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-13', obj=None),\n",
       " '6fd3b240-68a0-44e6-8b0a-9b93d76be509': IndexNode(id_='6fd3b240-68a0-44e6-8b0a-9b93d76be509', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-13', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='36acf0ba046e4e355c93836ed53ee6157045b6b73e7e5aed51685a2407a65d62'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='090ef145-a147-4e73-9cc6-f8b5a32987be', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e2f2f22faed58eb1a5a2615cc77181361aeefd2210423dc259de695a2bde7bee')}, text='Here,wegoonestep\\nfurther,anduse theselectedoutputsfora gradientupdate. For eachprompt,thesample obtaining\\n13\\n\\n100101\\nN Samples0.540.560.580.600.620.640.66Reward Score\\nMax of the rewards\\nMedian of the rewardsFigure 7: Max and median reward among N samples ,N∈[1, . . . , 100]averaged over our training set of\\nprompts. The delta between max and median can be interpreted as potential gain with Rejection Sampling.', start_char_idx=3533, end_char_idx=3944, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-13', obj=None),\n",
       " 'ed876583-7a8a-4de1-88e3-4ad7d9790a08': IndexNode(id_='ed876583-7a8a-4de1-88e3-4ad7d9790a08', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-13', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='36acf0ba046e4e355c93836ed53ee6157045b6b73e7e5aed51685a2407a65d62'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='a56ad62b-20aa-46d7-83c4-ef8d63e2fc5c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7d6a64d9bd95732c1cf17e7e03b986c960d29d4e6b5cca1070cc2b9101c8dccb')}, text='Overall,ourrewardmodelsoutperformallofthebaselines,includingGPT-4. Interestingly,\\nGPT-4 performs better than other non-Meta reward models, despite not being trained directly nor targeting\\nspecifically this reward modeling task.\\n12\\n\\n1234567891011121314\\nMeta Helpfulness Data Batch Stage0.520.540.560.580.600.620.64Accuracy On All Examples\\n 7b\\n13b\\n70b\\nGPT4\\nOpenAssistant\\n1234567891011121314\\nMeta Helpfulness Data Batch Stage0.500.550.600.650.700.750.80Accuracy On Examples With Label \"Significantly Better\"\\n7b\\n13b\\n70b\\nGPT4\\nOpenAssistantFigure 6: Scaling trends for the reward model. More data and a larger-size model generally improve\\naccuracy, and it appears that our models have not yet saturated from learning on the training data.', start_char_idx=0, end_char_idx=732, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-13', obj=None),\n",
       " 'a56ad62b-20aa-46d7-83c4-ef8d63e2fc5c': IndexNode(id_='a56ad62b-20aa-46d7-83c4-ef8d63e2fc5c', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-13', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='36acf0ba046e4e355c93836ed53ee6157045b6b73e7e5aed51685a2407a65d62'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='ed876583-7a8a-4de1-88e3-4ad7d9790a08', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5d4deb848cc97bfe6a2514fffbfb4ea091398684df2d63d9b1711f4015ee5e06'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='732b0466-cc28-4d34-b378-634219ea36f6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='fcb7b976a5af883336c8fb38ea023dd582fc2506b21a70ca9b570997a8350f52')}, text='More data and a larger-size model generally improve\\naccuracy, and it appears that our models have not yet saturated from learning on the training data.\\nThefactthathelpfulnessandsafetyperformedthe bestontheirowndomainispotentiallyduetothetension\\nbetweenthetwoobjectives(i.e.,beingashelpfulaspossibleversusrefusingunsafepromptswhennecessary),\\nwhichmayconfusetherewardmodelduringtraining. Inorderforasinglemodeltoperformwellonboth\\ndimensions, it needs to not only learn to select the better response given a prompt but also to distinguish\\nadversarial prompts from safe ones. As a result, optimizing two separate models eases the reward modeling\\ntask. More detailed analysis on this tension between safety and helpfulness can be found in Appendix A.4.1.\\nWhenwegroupthescoresbypreferenceratinginTable8,wecanseethattheaccuracyissuperiorforthe\\n“significantlybetter”testsetanddegradesgraduallyascomparisonpairsbecomemoresimilar(e.g.,“slightly\\nbetter”).', start_char_idx=581, end_char_idx=1525, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-13', obj=None),\n",
       " '732b0466-cc28-4d34-b378-634219ea36f6': IndexNode(id_='732b0466-cc28-4d34-b378-634219ea36f6', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-13', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='36acf0ba046e4e355c93836ed53ee6157045b6b73e7e5aed51685a2407a65d62'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='a56ad62b-20aa-46d7-83c4-ef8d63e2fc5c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7d6a64d9bd95732c1cf17e7e03b986c960d29d4e6b5cca1070cc2b9101c8dccb'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='cc08c35d-0138-4802-82f2-c735fd313069', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b953a6f14c1664c9f912de15e5a23c060beac535729eaf84e4038d1b64698295')}, text='As a result, optimizing two separate models eases the reward modeling\\ntask. More detailed analysis on this tension between safety and helpfulness can be found in Appendix A.4.1.\\nWhenwegroupthescoresbypreferenceratinginTable8,wecanseethattheaccuracyissuperiorforthe\\n“significantlybetter”testsetanddegradesgraduallyascomparisonpairsbecomemoresimilar(e.g.,“slightly\\nbetter”). It is expected that learning to model human preferences becomes challenging when deciding\\nbetweentwosimilarmodelresponses,duetoannotatorsubjectivityandtheirrelianceonnuanceddetails\\nthatmaydifferentiateresponses. Weemphasizethattheaccuracyonmoredistinctresponsesmattersthe\\nmosttoimprove Llama 2-Chat performance. Thehumanpreferenceannotationagreementrateisalsohigher\\non more distinct responses than similar pairs.\\nScalingTrends. Westudythescalingtrendsintermsofdataandmodelsizefortherewardmodel,fine-\\ntuning different model sizes on an increasing amount of the reward model data collected each week (see the\\ndetailsonvolumeperbatchinTable26).', start_char_idx=1153, end_char_idx=2167, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-13', obj=None),\n",
       " 'cc08c35d-0138-4802-82f2-c735fd313069': IndexNode(id_='cc08c35d-0138-4802-82f2-c735fd313069', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-13', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='36acf0ba046e4e355c93836ed53ee6157045b6b73e7e5aed51685a2407a65d62'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='732b0466-cc28-4d34-b378-634219ea36f6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='fcb7b976a5af883336c8fb38ea023dd582fc2506b21a70ca9b570997a8350f52'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='598bee7d-7a4a-48cc-9d6b-92d590957375', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1f664d10fbeaa16e95ae5794029fd5ffc4fe48061fa4950fbeb4a46826aab62d')}, text='Thehumanpreferenceannotationagreementrateisalsohigher\\non more distinct responses than similar pairs.\\nScalingTrends. Westudythescalingtrendsintermsofdataandmodelsizefortherewardmodel,fine-\\ntuning different model sizes on an increasing amount of the reward model data collected each week (see the\\ndetailsonvolumeperbatchinTable26). Figure6reportsthesetrends,showingtheexpectedresultthatlarger\\nmodels obtain higher performance for a similar volume of data. More importantly, the scaling performance\\nhasnotyetplateauedgiventheexistingvolumeofdataannotationusedfortraining,asignalthatthereis\\nroom for more improvement with more annotations. We note that reward model accuracy is one of the most\\nimportant proxies for the final performance of Llama 2-Chat . While best practices for comprehensively\\nevaluating a generative model is an open research question, the ranking task of the reward has no ambiguity.\\nTherefore, everything else being equal, an improvement of the reward model can be directly translated into\\nan improvement for Llama 2-Chat .', start_char_idx=1838, end_char_idx=2880, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-13', obj=None),\n",
       " '598bee7d-7a4a-48cc-9d6b-92d590957375': IndexNode(id_='598bee7d-7a4a-48cc-9d6b-92d590957375', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-13', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='36acf0ba046e4e355c93836ed53ee6157045b6b73e7e5aed51685a2407a65d62'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='cc08c35d-0138-4802-82f2-c735fd313069', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b953a6f14c1664c9f912de15e5a23c060beac535729eaf84e4038d1b64698295'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='66c1f59a-7bf1-4337-90fe-ccc879452383', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8da7f7594d42ec823d5dfa907e813f1a49192d724b35a84ff6bf31740bb15993')}, text='We note that reward model accuracy is one of the most\\nimportant proxies for the final performance of Llama 2-Chat . While best practices for comprehensively\\nevaluating a generative model is an open research question, the ranking task of the reward has no ambiguity.\\nTherefore, everything else being equal, an improvement of the reward model can be directly translated into\\nan improvement for Llama 2-Chat .\\n3.2.3 Iterative Fine-Tuning\\nAs we received more batches of human preference data annotation, we were able to train better reward\\nmodelsandcollectmoreprompts. WethereforetrainedsuccessiveversionsforRLHFmodels,referredto\\nhere as RLHF-V1, ..., RLHF-V5.\\nWe explored RLHF fine-tuning with two main algorithms:\\n•Proximal Policy Optimization (PPO) (Schulman et al., 2017), the standard in RLHF literature.\\n•RejectionSamplingfine-tuning . Wesample Koutputsfromthemodelandselectthebestcandidate\\nwith our reward, consistent with Bai et al. (2022b).', start_char_idx=2474, end_char_idx=3419, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-13', obj=None),\n",
       " '66c1f59a-7bf1-4337-90fe-ccc879452383': IndexNode(id_='66c1f59a-7bf1-4337-90fe-ccc879452383', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-13', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='36acf0ba046e4e355c93836ed53ee6157045b6b73e7e5aed51685a2407a65d62'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='598bee7d-7a4a-48cc-9d6b-92d590957375', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1f664d10fbeaa16e95ae5794029fd5ffc4fe48061fa4950fbeb4a46826aab62d')}, text='We explored RLHF fine-tuning with two main algorithms:\\n•Proximal Policy Optimization (PPO) (Schulman et al., 2017), the standard in RLHF literature.\\n•RejectionSamplingfine-tuning . Wesample Koutputsfromthemodelandselectthebestcandidate\\nwith our reward, consistent with Bai et al. (2022b). The same re-ranking strategy for LLMs was also\\nproposedinDengetal.(2019),wheretherewardisseenasanenergyfunction. Here,wegoonestep\\nfurther,anduse theselectedoutputsfora gradientupdate. For eachprompt,thesample obtaining\\n13\\n\\n100101\\nN Samples0.540.560.580.600.620.640.66Reward Score\\nMax of the rewards\\nMedian of the rewardsFigure 7: Max and median reward among N samples ,N∈[1, . . . , 100]averaged over our training set of\\nprompts. The delta between max and median can be interpreted as potential gain with Rejection Sampling.', start_char_idx=3131, end_char_idx=3944, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-13', obj=None),\n",
       " 'b1ed0bc4-47f9-44a4-86f7-f21af1279e94': IndexNode(id_='b1ed0bc4-47f9-44a4-86f7-f21af1279e94', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-13', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='36acf0ba046e4e355c93836ed53ee6157045b6b73e7e5aed51685a2407a65d62'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='87324a82-36c7-4bd0-8f51-40638cac5146', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ed2bb11c57474fed6823dffc8ec2bcae0870ed865c3143636501fbd85b0a3d82')}, text='Overall,ourrewardmodelsoutperformallofthebaselines,includingGPT-4. Interestingly,\\nGPT-4 performs better than other non-Meta reward models, despite not being trained directly nor targeting\\nspecifically this reward modeling task.\\n12\\n\\n1234567891011121314\\nMeta Helpfulness Data Batch Stage0.520.540.560.580.600.620.64Accuracy On All Examples\\n 7b\\n13b\\n70b\\nGPT4\\nOpenAssistant\\n1234567891011121314\\nMeta Helpfulness Data Batch Stage0.500.550.600.650.700.750.80Accuracy On Examples With Label \"Significantly Better\"\\n7b\\n13b\\n70b\\nGPT4\\nOpenAssistantFigure 6: Scaling trends for the reward model. More data and a larger-size model generally improve\\naccuracy, and it appears that our models have not yet saturated from learning on the training data.\\nThefactthathelpfulnessandsafetyperformedthe bestontheirowndomainispotentiallyduetothetension\\nbetweenthetwoobjectives(i.e.,beingashelpfulaspossibleversusrefusingunsafepromptswhennecessary),\\nwhichmayconfusetherewardmodelduringtraining. Inorderforasinglemodeltoperformwellonboth\\ndimensions, it needs to not only learn to select the better response given a prompt but also to distinguish\\nadversarial prompts from safe ones. As a result, optimizing two separate models eases the reward modeling\\ntask. More detailed analysis on this tension between safety and helpfulness can be found in Appendix A.4.1.\\nWhenwegroupthescoresbypreferenceratinginTable8,wecanseethattheaccuracyissuperiorforthe\\n“significantlybetter”testsetanddegradesgraduallyascomparisonpairsbecomemoresimilar(e.g.,“slightly\\nbetter”). It is expected that learning to model human preferences becomes challenging when deciding\\nbetweentwosimilarmodelresponses,duetoannotatorsubjectivityandtheirrelianceonnuanceddetails\\nthatmaydifferentiateresponses. Weemphasizethattheaccuracyonmoredistinctresponsesmattersthe\\nmosttoimprove Llama 2-Chat performance. Thehumanpreferenceannotationagreementrateisalsohigher\\non more distinct responses than similar pairs.\\nScalingTrends.', start_char_idx=0, end_char_idx=1953, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-13', obj=None),\n",
       " '87324a82-36c7-4bd0-8f51-40638cac5146': IndexNode(id_='87324a82-36c7-4bd0-8f51-40638cac5146', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-13', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='36acf0ba046e4e355c93836ed53ee6157045b6b73e7e5aed51685a2407a65d62'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='b1ed0bc4-47f9-44a4-86f7-f21af1279e94', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0e6d363b09648fde50f9110c9bcf6ea0ce2134b3a0cc1434b1551b67d755d446'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='aecd6cba-89c6-496a-86e9-7d7eaa9ac325', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7df35819c4601ce8f07912508e9ee006071d665a2c3af5747565e23423e60248')}, text='Weemphasizethattheaccuracyonmoredistinctresponsesmattersthe\\nmosttoimprove Llama 2-Chat performance. Thehumanpreferenceannotationagreementrateisalsohigher\\non more distinct responses than similar pairs.\\nScalingTrends. Westudythescalingtrendsintermsofdataandmodelsizefortherewardmodel,fine-\\ntuning different model sizes on an increasing amount of the reward model data collected each week (see the\\ndetailsonvolumeperbatchinTable26). Figure6reportsthesetrends,showingtheexpectedresultthatlarger\\nmodels obtain higher performance for a similar volume of data. More importantly, the scaling performance\\nhasnotyetplateauedgiventheexistingvolumeofdataannotationusedfortraining,asignalthatthereis\\nroom for more improvement with more annotations. We note that reward model accuracy is one of the most\\nimportant proxies for the final performance of Llama 2-Chat . While best practices for comprehensively\\nevaluating a generative model is an open research question, the ranking task of the reward has no ambiguity.\\nTherefore, everything else being equal, an improvement of the reward model can be directly translated into\\nan improvement for Llama 2-Chat .\\n3.2.3 Iterative Fine-Tuning\\nAs we received more batches of human preference data annotation, we were able to train better reward\\nmodelsandcollectmoreprompts. WethereforetrainedsuccessiveversionsforRLHFmodels,referredto\\nhere as RLHF-V1, ..., RLHF-V5.\\nWe explored RLHF fine-tuning with two main algorithms:\\n•Proximal Policy Optimization (PPO) (Schulman et al., 2017), the standard in RLHF literature.\\n•RejectionSamplingfine-tuning . Wesample Koutputsfromthemodelandselectthebestcandidate\\nwith our reward, consistent with Bai et al. (2022b). The same re-ranking strategy for LLMs was also\\nproposedinDengetal.(2019),wheretherewardisseenasanenergyfunction. Here,wegoonestep\\nfurther,anduse theselectedoutputsfora gradientupdate.', start_char_idx=1738, end_char_idx=3603, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-13', obj=None),\n",
       " 'aecd6cba-89c6-496a-86e9-7d7eaa9ac325': IndexNode(id_='aecd6cba-89c6-496a-86e9-7d7eaa9ac325', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-13', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='36acf0ba046e4e355c93836ed53ee6157045b6b73e7e5aed51685a2407a65d62'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='87324a82-36c7-4bd0-8f51-40638cac5146', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ed2bb11c57474fed6823dffc8ec2bcae0870ed865c3143636501fbd85b0a3d82')}, text='•RejectionSamplingfine-tuning . Wesample Koutputsfromthemodelandselectthebestcandidate\\nwith our reward, consistent with Bai et al. (2022b). The same re-ranking strategy for LLMs was also\\nproposedinDengetal.(2019),wheretherewardisseenasanenergyfunction. Here,wegoonestep\\nfurther,anduse theselectedoutputsfora gradientupdate. For eachprompt,thesample obtaining\\n13\\n\\n100101\\nN Samples0.540.560.580.600.620.640.66Reward Score\\nMax of the rewards\\nMedian of the rewardsFigure 7: Max and median reward among N samples ,N∈[1, . . . , 100]averaged over our training set of\\nprompts. The delta between max and median can be interpreted as potential gain with Rejection Sampling.', start_char_idx=3280, end_char_idx=3944, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-13', obj=None),\n",
       " 'node-13': IndexNode(id_='node-13', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='d03f19eb-da15-45dc-bfd4-e5d10f161250', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='231b3bd773f012c01b893ada9e009ecf25ee59934614c5a595c9bf1b3a123292'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='8073f055-b50a-4390-a8f8-cdf198ca3c03', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8845e152a80560179274711be3607960f234fa713b150737e9b3ca8d3f625d95'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='45ac932f-6b69-4083-b168-c4fda88de44d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7d239f05234897b071df035e278574dfcf83a6aebeac6e2336af75d2f671ceb4')}, text='Overall,ourrewardmodelsoutperformallofthebaselines,includingGPT-4. Interestingly,\\nGPT-4 performs better than other non-Meta reward models, despite not being trained directly nor targeting\\nspecifically this reward modeling task.\\n12\\n\\n1234567891011121314\\nMeta Helpfulness Data Batch Stage0.520.540.560.580.600.620.64Accuracy On All Examples\\n 7b\\n13b\\n70b\\nGPT4\\nOpenAssistant\\n1234567891011121314\\nMeta Helpfulness Data Batch Stage0.500.550.600.650.700.750.80Accuracy On Examples With Label \"Significantly Better\"\\n7b\\n13b\\n70b\\nGPT4\\nOpenAssistantFigure 6: Scaling trends for the reward model. More data and a larger-size model generally improve\\naccuracy, and it appears that our models have not yet saturated from learning on the training data.\\nThefactthathelpfulnessandsafetyperformedthe bestontheirowndomainispotentiallyduetothetension\\nbetweenthetwoobjectives(i.e.,beingashelpfulaspossibleversusrefusingunsafepromptswhennecessary),\\nwhichmayconfusetherewardmodelduringtraining. Inorderforasinglemodeltoperformwellonboth\\ndimensions, it needs to not only learn to select the better response given a prompt but also to distinguish\\nadversarial prompts from safe ones. As a result, optimizing two separate models eases the reward modeling\\ntask. More detailed analysis on this tension between safety and helpfulness can be found in Appendix A.4.1.\\nWhenwegroupthescoresbypreferenceratinginTable8,wecanseethattheaccuracyissuperiorforthe\\n“significantlybetter”testsetanddegradesgraduallyascomparisonpairsbecomemoresimilar(e.g.,“slightly\\nbetter”). It is expected that learning to model human preferences becomes challenging when deciding\\nbetweentwosimilarmodelresponses,duetoannotatorsubjectivityandtheirrelianceonnuanceddetails\\nthatmaydifferentiateresponses. Weemphasizethattheaccuracyonmoredistinctresponsesmattersthe\\nmosttoimprove Llama 2-Chat performance. Thehumanpreferenceannotationagreementrateisalsohigher\\non more distinct responses than similar pairs.\\nScalingTrends. Westudythescalingtrendsintermsofdataandmodelsizefortherewardmodel,fine-\\ntuning different model sizes on an increasing amount of the reward model data collected each week (see the\\ndetailsonvolumeperbatchinTable26). Figure6reportsthesetrends,showingtheexpectedresultthatlarger\\nmodels obtain higher performance for a similar volume of data. More importantly, the scaling performance\\nhasnotyetplateauedgiventheexistingvolumeofdataannotationusedfortraining,asignalthatthereis\\nroom for more improvement with more annotations. We note that reward model accuracy is one of the most\\nimportant proxies for the final performance of Llama 2-Chat . While best practices for comprehensively\\nevaluating a generative model is an open research question, the ranking task of the reward has no ambiguity.\\nTherefore, everything else being equal, an improvement of the reward model can be directly translated into\\nan improvement for Llama 2-Chat .\\n3.2.3 Iterative Fine-Tuning\\nAs we received more batches of human preference data annotation, we were able to train better reward\\nmodelsandcollectmoreprompts. WethereforetrainedsuccessiveversionsforRLHFmodels,referredto\\nhere as RLHF-V1, ..., RLHF-V5.\\nWe explored RLHF fine-tuning with two main algorithms:\\n•Proximal Policy Optimization (PPO) (Schulman et al., 2017), the standard in RLHF literature.\\n•RejectionSamplingfine-tuning . Wesample Koutputsfromthemodelandselectthebestcandidate\\nwith our reward, consistent with Bai et al. (2022b). The same re-ranking strategy for LLMs was also\\nproposedinDengetal.(2019),wheretherewardisseenasanenergyfunction. Here,wegoonestep\\nfurther,anduse theselectedoutputsfora gradientupdate. For eachprompt,thesample obtaining\\n13\\n\\n100101\\nN Samples0.540.560.580.600.620.640.66Reward Score\\nMax of the rewards\\nMedian of the rewardsFigure 7: Max and median reward among N samples ,N∈[1, . . . , 100]averaged over our training set of\\nprompts. The delta between max and median can be interpreted as potential gain with Rejection Sampling.', start_char_idx=37779, end_char_idx=41723, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-13', obj=None),\n",
       " 'ffe2aec9-5ac9-43c8-a89c-413d6e3f6ae4': IndexNode(id_='ffe2aec9-5ac9-43c8-a89c-413d6e3f6ae4', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-14', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7d239f05234897b071df035e278574dfcf83a6aebeac6e2336af75d2f671ceb4'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='cbda07dd-4dd9-420a-86f8-4f8bc4e700d3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8a3663b008bbffcc26333f3113610011fa562a0b91ed9242118d1ac5a19ad701')}, text='For eachprompt,thesample obtaining\\n13\\n\\n100101\\nN Samples0.540.560.580.600.620.640.66Reward Score\\nMax of the rewards\\nMedian of the rewardsFigure 7: Max and median reward among N samples ,N∈[1, . . . , 100]averaged over our training set of\\nprompts. The delta between max and median can be interpreted as potential gain with Rejection Sampling.\\nthe highestrewardscore is consideredthe newgold standard. Similar toScialom etal.', start_char_idx=0, end_char_idx=422, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-14', obj=None),\n",
       " 'cbda07dd-4dd9-420a-86f8-4f8bc4e700d3': IndexNode(id_='cbda07dd-4dd9-420a-86f8-4f8bc4e700d3', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-14', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7d239f05234897b071df035e278574dfcf83a6aebeac6e2336af75d2f671ceb4'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='ffe2aec9-5ac9-43c8-a89c-413d6e3f6ae4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3088e5908a25e90aff92b7e10b6dc8f13423d0726c13e714b4212496a1c45da6'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='fa5b0e34-98de-4fde-ad6b-3c687e36cd6a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8dc1feeff05039bc04c6405da1fd61a4fb47cdb397f65c29cd00769107891cb3')}, text='. . , 100]averaged over our training set of\\nprompts. The delta between max and median can be interpreted as potential gain with Rejection Sampling.\\nthe highestrewardscore is consideredthe newgold standard. Similar toScialom etal. (2020a), we\\nthen fine-tune our model on the new set of ranked samples, reinforcing the reward.\\nThe two RL algorithms mainly differ in:\\n•Breadth— in Rejection Sampling, the model explores Ksamples for a given prompt, while only one\\ngeneration is done for PPO.', start_char_idx=193, end_char_idx=681, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-14', obj=None),\n",
       " 'fa5b0e34-98de-4fde-ad6b-3c687e36cd6a': IndexNode(id_='fa5b0e34-98de-4fde-ad6b-3c687e36cd6a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-14', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7d239f05234897b071df035e278574dfcf83a6aebeac6e2336af75d2f671ceb4'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='cbda07dd-4dd9-420a-86f8-4f8bc4e700d3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8a3663b008bbffcc26333f3113610011fa562a0b91ed9242118d1ac5a19ad701'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='e61dceab-f588-4dab-93ca-9c37bf0e6a3d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d0eeedef2ed0fd4c77e2ef5df0c9e27a69d96a92ab9250d37d51316bc75e2e01')}, text='the highestrewardscore is consideredthe newgold standard. Similar toScialom etal. (2020a), we\\nthen fine-tune our model on the new set of ranked samples, reinforcing the reward.\\nThe two RL algorithms mainly differ in:\\n•Breadth— in Rejection Sampling, the model explores Ksamples for a given prompt, while only one\\ngeneration is done for PPO.\\n•Depth— in PPO, during training at step tthe sample is a function of the updated model policy from\\nt−1afterthegradientupdateofthepreviousstep.', start_char_idx=341, end_char_idx=824, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-14', obj=None),\n",
       " 'e61dceab-f588-4dab-93ca-9c37bf0e6a3d': IndexNode(id_='e61dceab-f588-4dab-93ca-9c37bf0e6a3d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-14', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7d239f05234897b071df035e278574dfcf83a6aebeac6e2336af75d2f671ceb4'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='fa5b0e34-98de-4fde-ad6b-3c687e36cd6a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8dc1feeff05039bc04c6405da1fd61a4fb47cdb397f65c29cd00769107891cb3'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='7c56d206-c31c-4c17-be69-dba9958b9c4a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8e960e58538e9940017decd5c43fe0a01fdc48bf8126bec8ee49bba1b95e1d56')}, text='The two RL algorithms mainly differ in:\\n•Breadth— in Rejection Sampling, the model explores Ksamples for a given prompt, while only one\\ngeneration is done for PPO.\\n•Depth— in PPO, during training at step tthe sample is a function of the updated model policy from\\nt−1afterthegradientupdateofthepreviousstep. InRejectionSamplingfine-tuning,wesample\\nall the outputs given the initial policy of our model to collect a new dataset, before applying the\\nfine-tuning similar to SFT.', start_char_idx=518, end_char_idx=992, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-14', obj=None),\n",
       " '7c56d206-c31c-4c17-be69-dba9958b9c4a': IndexNode(id_='7c56d206-c31c-4c17-be69-dba9958b9c4a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-14', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7d239f05234897b071df035e278574dfcf83a6aebeac6e2336af75d2f671ceb4'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='e61dceab-f588-4dab-93ca-9c37bf0e6a3d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d0eeedef2ed0fd4c77e2ef5df0c9e27a69d96a92ab9250d37d51316bc75e2e01'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='641c9c2d-b642-40c7-94ae-1ee3c4e99848', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='19b5e86fae8e026a9b252d93854a106a3bf84403e52ef9b81cd6c4dd117a87c9')}, text='•Depth— in PPO, during training at step tthe sample is a function of the updated model policy from\\nt−1afterthegradientupdateofthepreviousstep. InRejectionSamplingfine-tuning,wesample\\nall the outputs given the initial policy of our model to collect a new dataset, before applying the\\nfine-tuning similar to SFT. However, since we applied iterative model updates, the fundamental\\ndifferences between the two RL algorithms are less pronounced.', start_char_idx=682, end_char_idx=1122, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-14', obj=None),\n",
       " '641c9c2d-b642-40c7-94ae-1ee3c4e99848': IndexNode(id_='641c9c2d-b642-40c7-94ae-1ee3c4e99848', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-14', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7d239f05234897b071df035e278574dfcf83a6aebeac6e2336af75d2f671ceb4'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='7c56d206-c31c-4c17-be69-dba9958b9c4a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8e960e58538e9940017decd5c43fe0a01fdc48bf8126bec8ee49bba1b95e1d56'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='acf2be16-09eb-40e9-804c-824e04a9bc97', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9e9af770b8313436354d9cf91ef1d0dc112bcd5131ad162036b42071e73285c8')}, text='InRejectionSamplingfine-tuning,wesample\\nall the outputs given the initial policy of our model to collect a new dataset, before applying the\\nfine-tuning similar to SFT. However, since we applied iterative model updates, the fundamental\\ndifferences between the two RL algorithms are less pronounced.\\nUntil RLHF (V4), we used only Rejection Sampling fine-tuning, and after that, we combined the two\\nsequentially, applying PPO on top of the resulted Rejection Sampling checkpoint before sampling again.\\n100101102\\nNumber Samples0.10.20.30.40.50.', start_char_idx=825, end_char_idx=1365, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-14', obj=None),\n",
       " 'acf2be16-09eb-40e9-804c-824e04a9bc97': IndexNode(id_='acf2be16-09eb-40e9-804c-824e04a9bc97', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-14', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7d239f05234897b071df035e278574dfcf83a6aebeac6e2336af75d2f671ceb4'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='641c9c2d-b642-40c7-94ae-1ee3c4e99848', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='19b5e86fae8e026a9b252d93854a106a3bf84403e52ef9b81cd6c4dd117a87c9'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='3b2964a0-0e23-4b39-90b4-11c3e223ea80', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f912567a228d802e1f65e01c35ca9980fbda40c446921897b02cf00b9d0a02cd')}, text='However, since we applied iterative model updates, the fundamental\\ndifferences between the two RL algorithms are less pronounced.\\nUntil RLHF (V4), we used only Rejection Sampling fine-tuning, and after that, we combined the two\\nsequentially, applying PPO on top of the resulted Rejection Sampling checkpoint before sampling again.\\n100101102\\nNumber Samples0.10.20.30.40.50.6Reward Score\\nSFT\\n100101102\\nNumber Samples0.350.400.450.500.550.600.650.', start_char_idx=993, end_char_idx=1437, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-14', obj=None),\n",
       " '3b2964a0-0e23-4b39-90b4-11c3e223ea80': IndexNode(id_='3b2964a0-0e23-4b39-90b4-11c3e223ea80', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-14', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7d239f05234897b071df035e278574dfcf83a6aebeac6e2336af75d2f671ceb4'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='acf2be16-09eb-40e9-804c-824e04a9bc97', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9e9af770b8313436354d9cf91ef1d0dc112bcd5131ad162036b42071e73285c8'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='a790ab1a-dfc3-4c2f-b670-edfd5e1f6041', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b89c033e0cd44efe4d36d6b04fc996a3784156c4dffeb385ecee3b802629e204')}, text='Until RLHF (V4), we used only Rejection Sampling fine-tuning, and after that, we combined the two\\nsequentially, applying PPO on top of the resulted Rejection Sampling checkpoint before sampling again.\\n100101102\\nNumber Samples0.10.20.30.40.50.6Reward Score\\nSFT\\n100101102\\nNumber Samples0.350.400.450.500.550.600.650.70Reward Score\\nRLHF\\nreward_max (T=0.6)\\nreward_max (T=0.8)\\nreward_max (T=0.', start_char_idx=1123, end_char_idx=1511, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-14', obj=None),\n",
       " 'a790ab1a-dfc3-4c2f-b670-edfd5e1f6041': IndexNode(id_='a790ab1a-dfc3-4c2f-b670-edfd5e1f6041', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-14', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7d239f05234897b071df035e278574dfcf83a6aebeac6e2336af75d2f671ceb4'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='3b2964a0-0e23-4b39-90b4-11c3e223ea80', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f912567a228d802e1f65e01c35ca9980fbda40c446921897b02cf00b9d0a02cd'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='069f5b32-e0e7-4066-809a-90a59b359783', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='390b9cc71046aed08b3728a9e734e2f2b9eaaf5f431b207a8abbe850639ddae5')}, text='100101102\\nNumber Samples0.10.20.30.40.50.6Reward Score\\nSFT\\n100101102\\nNumber Samples0.350.400.450.500.550.600.650.70Reward Score\\nRLHF\\nreward_max (T=0.6)\\nreward_max (T=0.8)\\nreward_max (T=0.9)\\nreward_max (T=1)\\nreward_max (T=1.1)\\nreward_max (T=1.2)\\nreward_max (T=1.3)\\nreward_max (T=1.', start_char_idx=1324, end_char_idx=1604, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-14', obj=None),\n",
       " '069f5b32-e0e7-4066-809a-90a59b359783': IndexNode(id_='069f5b32-e0e7-4066-809a-90a59b359783', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-14', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7d239f05234897b071df035e278574dfcf83a6aebeac6e2336af75d2f671ceb4'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='a790ab1a-dfc3-4c2f-b670-edfd5e1f6041', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b89c033e0cd44efe4d36d6b04fc996a3784156c4dffeb385ecee3b802629e204'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='01f5e51b-3983-4bf1-9f6b-161b4afcdd11', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='da1fbcf433489f85f8e958a02f211c4bfb5338c1e7852ceeadb77186ae6825f5')}, text='350.400.450.500.550.600.650.70Reward Score\\nRLHF\\nreward_max (T=0.6)\\nreward_max (T=0.8)\\nreward_max (T=0.9)\\nreward_max (T=1)\\nreward_max (T=1.1)\\nreward_max (T=1.2)\\nreward_max (T=1.3)\\nreward_max (T=1.4)\\nreward_max (T=1.5)\\nFigure8: RLHFimpactofthetemperature whensamplingNoutputsandscoringthemwitharewardmodel.', start_char_idx=1409, end_char_idx=1713, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-14', obj=None),\n",
       " '01f5e51b-3983-4bf1-9f6b-161b4afcdd11': IndexNode(id_='01f5e51b-3983-4bf1-9f6b-161b4afcdd11', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-14', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7d239f05234897b071df035e278574dfcf83a6aebeac6e2336af75d2f671ceb4'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='069f5b32-e0e7-4066-809a-90a59b359783', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='390b9cc71046aed08b3728a9e734e2f2b9eaaf5f431b207a8abbe850639ddae5'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='654ccb34-4dd7-49d9-be3e-a9015ed68711', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1618557bdd885edb0d856df41cde203242a01e8a50b6b2c044398ef0d76ce424')}, text='6)\\nreward_max (T=0.8)\\nreward_max (T=0.9)\\nreward_max (T=1)\\nreward_max (T=1.1)\\nreward_max (T=1.2)\\nreward_max (T=1.3)\\nreward_max (T=1.4)\\nreward_max (T=1.5)\\nFigure8: RLHFimpactofthetemperature whensamplingNoutputsandscoringthemwitharewardmodel.\\nRejection Sampling. We performrejection sampling only with our largest 70B Llama 2-Chat .', start_char_idx=1473, end_char_idx=1803, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-14', obj=None),\n",
       " '654ccb34-4dd7-49d9-be3e-a9015ed68711': IndexNode(id_='654ccb34-4dd7-49d9-be3e-a9015ed68711', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-14', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7d239f05234897b071df035e278574dfcf83a6aebeac6e2336af75d2f671ceb4'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='01f5e51b-3983-4bf1-9f6b-161b4afcdd11', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='da1fbcf433489f85f8e958a02f211c4bfb5338c1e7852ceeadb77186ae6825f5'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='f44222c7-265a-4721-b09f-5a29da0f309f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9668d56b2d686a887c52549910ccd7c98e403b7e5f0d9ecda6b6ce1f4d6c66ef')}, text='1)\\nreward_max (T=1.2)\\nreward_max (T=1.3)\\nreward_max (T=1.4)\\nreward_max (T=1.5)\\nFigure8: RLHFimpactofthetemperature whensamplingNoutputsandscoringthemwitharewardmodel.\\nRejection Sampling. We performrejection sampling only with our largest 70B Llama 2-Chat . All smaller\\nmodels are fine-tuned on rejection sampled data from the larger model, thus distilling the large-model\\ncapabilities into the smaller ones.', start_char_idx=1547, end_char_idx=1954, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-14', obj=None),\n",
       " 'f44222c7-265a-4721-b09f-5a29da0f309f': IndexNode(id_='f44222c7-265a-4721-b09f-5a29da0f309f', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-14', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7d239f05234897b071df035e278574dfcf83a6aebeac6e2336af75d2f671ceb4'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='654ccb34-4dd7-49d9-be3e-a9015ed68711', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1618557bdd885edb0d856df41cde203242a01e8a50b6b2c044398ef0d76ce424'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='87744ece-4aa5-41d0-a01a-dca382e02821', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8508965327677a31861eb601cac530d4efc5a9ac3b4dfc1f285c4216b11086f9')}, text='4)\\nreward_max (T=1.5)\\nFigure8: RLHFimpactofthetemperature whensamplingNoutputsandscoringthemwitharewardmodel.\\nRejection Sampling. We performrejection sampling only with our largest 70B Llama 2-Chat . All smaller\\nmodels are fine-tuned on rejection sampled data from the larger model, thus distilling the large-model\\ncapabilities into the smaller ones. We leave further analysis of the effect of this distillation for future work.\\nAteachiterativestage,wesample Kanswersforeachpromptfromthemostrecentmodel.', start_char_idx=1604, end_char_idx=2107, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-14', obj=None),\n",
       " '87744ece-4aa5-41d0-a01a-dca382e02821': IndexNode(id_='87744ece-4aa5-41d0-a01a-dca382e02821', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-14', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7d239f05234897b071df035e278574dfcf83a6aebeac6e2336af75d2f671ceb4'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='f44222c7-265a-4721-b09f-5a29da0f309f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9668d56b2d686a887c52549910ccd7c98e403b7e5f0d9ecda6b6ce1f4d6c66ef'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='c0c3576c-18f7-4c2c-8c69-88fd4cb745f7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7b88f138fb7c92b36e2914d94c0a72527af8c8a47625944788399511223d79e6')}, text='Rejection Sampling. We performrejection sampling only with our largest 70B Llama 2-Chat . All smaller\\nmodels are fine-tuned on rejection sampled data from the larger model, thus distilling the large-model\\ncapabilities into the smaller ones. We leave further analysis of the effect of this distillation for future work.\\nAteachiterativestage,wesample Kanswersforeachpromptfromthemostrecentmodel. Wescoreeach\\nsample given the best reward model accessible at the time of the experiment, and then select the best answer\\nforagivenprompt.', start_char_idx=1714, end_char_idx=2245, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-14', obj=None),\n",
       " 'c0c3576c-18f7-4c2c-8c69-88fd4cb745f7': IndexNode(id_='c0c3576c-18f7-4c2c-8c69-88fd4cb745f7', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-14', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7d239f05234897b071df035e278574dfcf83a6aebeac6e2336af75d2f671ceb4'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='87744ece-4aa5-41d0-a01a-dca382e02821', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8508965327677a31861eb601cac530d4efc5a9ac3b4dfc1f285c4216b11086f9'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='090b62be-7746-4956-9b52-515ae752a914', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ef2592c2369ac9c64c2b942bf5a5ba8cd93986e582c8c84201217b2d52720b28')}, text='All smaller\\nmodels are fine-tuned on rejection sampled data from the larger model, thus distilling the large-model\\ncapabilities into the smaller ones. We leave further analysis of the effect of this distillation for future work.\\nAteachiterativestage,wesample Kanswersforeachpromptfromthemostrecentmodel. Wescoreeach\\nsample given the best reward model accessible at the time of the experiment, and then select the best answer\\nforagivenprompt. Inearlierversionsofourmodel,uptoRLHFV3,ourapproachwastoconfineanswer\\nselection solely to the“bag” of samples gathered from the precedingiteration.', start_char_idx=1804, end_char_idx=2392, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-14', obj=None),\n",
       " '090b62be-7746-4956-9b52-515ae752a914': IndexNode(id_='090b62be-7746-4956-9b52-515ae752a914', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-14', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7d239f05234897b071df035e278574dfcf83a6aebeac6e2336af75d2f671ceb4'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='c0c3576c-18f7-4c2c-8c69-88fd4cb745f7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7b88f138fb7c92b36e2914d94c0a72527af8c8a47625944788399511223d79e6'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='39ee87e9-981d-4e3d-ad2a-7c7d9ca7055e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a05fad2f9d16d654957e990e9e8d25ef2ea9ba94449252231447707617494284')}, text='Ateachiterativestage,wesample Kanswersforeachpromptfromthemostrecentmodel. Wescoreeach\\nsample given the best reward model accessible at the time of the experiment, and then select the best answer\\nforagivenprompt. Inearlierversionsofourmodel,uptoRLHFV3,ourapproachwastoconfineanswer\\nselection solely to the“bag” of samples gathered from the precedingiteration. For example, RLHF V3was\\ntrained using only samples from RLHF V2.', start_char_idx=2033, end_char_idx=2457, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-14', obj=None),\n",
       " '39ee87e9-981d-4e3d-ad2a-7c7d9ca7055e': IndexNode(id_='39ee87e9-981d-4e3d-ad2a-7c7d9ca7055e', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-14', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7d239f05234897b071df035e278574dfcf83a6aebeac6e2336af75d2f671ceb4'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='090b62be-7746-4956-9b52-515ae752a914', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ef2592c2369ac9c64c2b942bf5a5ba8cd93986e582c8c84201217b2d52720b28'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='a1ebe90c-f7d2-4fd8-90e0-91fe015e5526', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5d679a06efb3fdf12da6a19b51b8c4563e6daa157aadca6a15afe2b57b4355e2')}, text='Wescoreeach\\nsample given the best reward model accessible at the time of the experiment, and then select the best answer\\nforagivenprompt. Inearlierversionsofourmodel,uptoRLHFV3,ourapproachwastoconfineanswer\\nselection solely to the“bag” of samples gathered from the precedingiteration. For example, RLHF V3was\\ntrained using only samples from RLHF V2. However, despite continuous improvement, this method led to a\\n14\\n\\nregressionin somecapabilities.', start_char_idx=2108, end_char_idx=2554, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-14', obj=None),\n",
       " 'a1ebe90c-f7d2-4fd8-90e0-91fe015e5526': IndexNode(id_='a1ebe90c-f7d2-4fd8-90e0-91fe015e5526', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-14', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7d239f05234897b071df035e278574dfcf83a6aebeac6e2336af75d2f671ceb4'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='39ee87e9-981d-4e3d-ad2a-7c7d9ca7055e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a05fad2f9d16d654957e990e9e8d25ef2ea9ba94449252231447707617494284'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='8c94074d-1ca4-4246-ac2c-d0833634f544', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a123dd41f7421dba88f5c67058a90d6cb1eb25b60edca653ad13cede8ced3a69')}, text='Inearlierversionsofourmodel,uptoRLHFV3,ourapproachwastoconfineanswer\\nselection solely to the“bag” of samples gathered from the precedingiteration. For example, RLHF V3was\\ntrained using only samples from RLHF V2. However, despite continuous improvement, this method led to a\\n14\\n\\nregressionin somecapabilities. Forexample,RLHFV3 struggledmore thanpreviousversionstocompose\\nrhyming lines in poems, as discerned through qualitative analysis, suggesting that further investigation into\\nthe causes of and mitigations for forgetting (Kirkpatrick et al., 2017; Nguyen et al., 2019; Ramasesh et al.,\\n2021) could be a fruitful area for additional future research.', start_char_idx=2246, end_char_idx=2899, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-14', obj=None),\n",
       " '8c94074d-1ca4-4246-ac2c-d0833634f544': IndexNode(id_='8c94074d-1ca4-4246-ac2c-d0833634f544', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-14', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7d239f05234897b071df035e278574dfcf83a6aebeac6e2336af75d2f671ceb4'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='a1ebe90c-f7d2-4fd8-90e0-91fe015e5526', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5d679a06efb3fdf12da6a19b51b8c4563e6daa157aadca6a15afe2b57b4355e2'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='0191050a-d319-4791-a0ee-814a36b6528e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c7acb9dd0068eeecd1afab6dfcbf7bbf7101005167b764b7b63cafca34cc16ef')}, text='Forexample,RLHFV3 struggledmore thanpreviousversionstocompose\\nrhyming lines in poems, as discerned through qualitative analysis, suggesting that further investigation into\\nthe causes of and mitigations for forgetting (Kirkpatrick et al., 2017; Nguyen et al., 2019; Ramasesh et al.,\\n2021) could be a fruitful area for additional future research.\\nIn response, on subsequent iterations, we modified our strategy, incorporating top-performing samples from\\nall prior iterations, such as those used in RLHF-V1 and RLHF-V2.', start_char_idx=2555, end_char_idx=3071, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-14', obj=None),\n",
       " '0191050a-d319-4791-a0ee-814a36b6528e': IndexNode(id_='0191050a-d319-4791-a0ee-814a36b6528e', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-14', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7d239f05234897b071df035e278574dfcf83a6aebeac6e2336af75d2f671ceb4'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='8c94074d-1ca4-4246-ac2c-d0833634f544', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a123dd41f7421dba88f5c67058a90d6cb1eb25b60edca653ad13cede8ced3a69'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='f84cb414-7357-411e-a8f8-9b07ea15665c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='509609b491d8cf6152267926dd701644921b39d82e320ff9a5edf91709ab7c11')}, text='In response, on subsequent iterations, we modified our strategy, incorporating top-performing samples from\\nall prior iterations, such as those used in RLHF-V1 and RLHF-V2. Although we do not present specific\\nfigures, this adjustment demonstrated considerable enhancements in performance and effectively addressed\\nthe previously noted issues. This mitigation can be seen as analogous to Synnaeve et al. (2019) and Vinyals\\net al. (2019) in the RL literature.\\nWe illustrate the benefit of Rejection Sampling in Figure 7.', start_char_idx=2900, end_char_idx=3417, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-14', obj=None),\n",
       " 'f84cb414-7357-411e-a8f8-9b07ea15665c': IndexNode(id_='f84cb414-7357-411e-a8f8-9b07ea15665c', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-14', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7d239f05234897b071df035e278574dfcf83a6aebeac6e2336af75d2f671ceb4'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='0191050a-d319-4791-a0ee-814a36b6528e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c7acb9dd0068eeecd1afab6dfcbf7bbf7101005167b764b7b63cafca34cc16ef'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='e0c6de87-476a-49bf-af78-fb54256de4a9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='31f61a961a47ed01815feb69287553373c4a49cb54dd91990b46d84981d92919')}, text='Although we do not present specific\\nfigures, this adjustment demonstrated considerable enhancements in performance and effectively addressed\\nthe previously noted issues. This mitigation can be seen as analogous to Synnaeve et al. (2019) and Vinyals\\net al. (2019) in the RL literature.\\nWe illustrate the benefit of Rejection Sampling in Figure 7. The delta between the maximum and median\\ncurves can be interpreted as the potential gain of fine-tuning on the best output.', start_char_idx=3072, end_char_idx=3541, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-14', obj=None),\n",
       " 'e0c6de87-476a-49bf-af78-fb54256de4a9': IndexNode(id_='e0c6de87-476a-49bf-af78-fb54256de4a9', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-14', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7d239f05234897b071df035e278574dfcf83a6aebeac6e2336af75d2f671ceb4'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='f84cb414-7357-411e-a8f8-9b07ea15665c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='509609b491d8cf6152267926dd701644921b39d82e320ff9a5edf91709ab7c11'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='7e0cc278-de3a-4800-9ba8-d078848d61e3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d4a3172e4d28b83ebcef43f989e5405749dd62d217183d143e489f6f60890ac7')}, text='This mitigation can be seen as analogous to Synnaeve et al. (2019) and Vinyals\\net al. (2019) in the RL literature.\\nWe illustrate the benefit of Rejection Sampling in Figure 7. The delta between the maximum and median\\ncurves can be interpreted as the potential gain of fine-tuning on the best output. As expected, this delta\\nincreases with more samples, since the maximum increases (i.e., more samples, more opportunities to\\ngenerateagoodtrajectory),whilethemedianremainsstationary.', start_char_idx=3242, end_char_idx=3723, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-14', obj=None),\n",
       " '7e0cc278-de3a-4800-9ba8-d078848d61e3': IndexNode(id_='7e0cc278-de3a-4800-9ba8-d078848d61e3', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-14', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7d239f05234897b071df035e278574dfcf83a6aebeac6e2336af75d2f671ceb4'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='e0c6de87-476a-49bf-af78-fb54256de4a9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='31f61a961a47ed01815feb69287553373c4a49cb54dd91990b46d84981d92919'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='81c5af82-75fc-405a-8fd7-5f4325004209', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='42b8722406fbbff327af2104e8203289a7ddb509fe6f5ec799e72c122f3296e5')}, text='(2019) in the RL literature.\\nWe illustrate the benefit of Rejection Sampling in Figure 7. The delta between the maximum and median\\ncurves can be interpreted as the potential gain of fine-tuning on the best output. As expected, this delta\\nincreases with more samples, since the maximum increases (i.e., more samples, more opportunities to\\ngenerateagoodtrajectory),whilethemedianremainsstationary. Thereisadirectconnectionbetweenthe\\nexplorationand themaximum rewardwe canobtain amongthesamples.', start_char_idx=3328, end_char_idx=3820, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-14', obj=None),\n",
       " '81c5af82-75fc-405a-8fd7-5f4325004209': IndexNode(id_='81c5af82-75fc-405a-8fd7-5f4325004209', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-14', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7d239f05234897b071df035e278574dfcf83a6aebeac6e2336af75d2f671ceb4'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='7e0cc278-de3a-4800-9ba8-d078848d61e3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d4a3172e4d28b83ebcef43f989e5405749dd62d217183d143e489f6f60890ac7')}, text='The delta between the maximum and median\\ncurves can be interpreted as the potential gain of fine-tuning on the best output. As expected, this delta\\nincreases with more samples, since the maximum increases (i.e., more samples, more opportunities to\\ngenerateagoodtrajectory),whilethemedianremainsstationary. Thereisadirectconnectionbetweenthe\\nexplorationand themaximum rewardwe canobtain amongthesamples. Thetemperatureparameteralso\\nplays an important role for exploration, as a higher temperature enables us to sample more diverse outputs.', start_char_idx=3418, end_char_idx=3956, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-14', obj=None),\n",
       " '5088ca6d-697b-49ac-8858-e8f3a1a007d8': IndexNode(id_='5088ca6d-697b-49ac-8858-e8f3a1a007d8', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-14', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7d239f05234897b071df035e278574dfcf83a6aebeac6e2336af75d2f671ceb4'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='6e84f311-688d-449c-824a-cb3ef9995261', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bab590ecfc57d905513218bba37152afe8de59ac70775f90e2a012ceaa6ea405')}, text='For eachprompt,thesample obtaining\\n13\\n\\n100101\\nN Samples0.540.560.580.600.620.640.66Reward Score\\nMax of the rewards\\nMedian of the rewardsFigure 7: Max and median reward among N samples ,N∈[1, . . . , 100]averaged over our training set of\\nprompts. The delta between max and median can be interpreted as potential gain with Rejection Sampling.\\nthe highestrewardscore is consideredthe newgold standard. Similar toScialom etal. (2020a), we\\nthen fine-tune our model on the new set of ranked samples, reinforcing the reward.\\nThe two RL algorithms mainly differ in:\\n•Breadth— in Rejection Sampling, the model explores Ksamples for a given prompt, while only one\\ngeneration is done for PPO.\\n•Depth— in PPO, during training at step tthe sample is a function of the updated model policy from\\nt−1afterthegradientupdateofthepreviousstep.', start_char_idx=0, end_char_idx=824, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-14', obj=None),\n",
       " '6e84f311-688d-449c-824a-cb3ef9995261': IndexNode(id_='6e84f311-688d-449c-824a-cb3ef9995261', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-14', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7d239f05234897b071df035e278574dfcf83a6aebeac6e2336af75d2f671ceb4'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='5088ca6d-697b-49ac-8858-e8f3a1a007d8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5fac1be05887ebe8eda8cbd5416b35830d5c01aa1b74867b47e99bd06b0a4877'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='ce0cb6f0-a0fb-47a4-b013-aaa8c378a399', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='72d0115a2a05399cea567c681145352c3c585e42304a76cd25e89f3f87f07184')}, text='The two RL algorithms mainly differ in:\\n•Breadth— in Rejection Sampling, the model explores Ksamples for a given prompt, while only one\\ngeneration is done for PPO.\\n•Depth— in PPO, during training at step tthe sample is a function of the updated model policy from\\nt−1afterthegradientupdateofthepreviousstep. InRejectionSamplingfine-tuning,wesample\\nall the outputs given the initial policy of our model to collect a new dataset, before applying the\\nfine-tuning similar to SFT. However, since we applied iterative model updates, the fundamental\\ndifferences between the two RL algorithms are less pronounced.\\nUntil RLHF (V4), we used only Rejection Sampling fine-tuning, and after that, we combined the two\\nsequentially, applying PPO on top of the resulted Rejection Sampling checkpoint before sampling again.', start_char_idx=518, end_char_idx=1323, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-14', obj=None),\n",
       " 'ce0cb6f0-a0fb-47a4-b013-aaa8c378a399': IndexNode(id_='ce0cb6f0-a0fb-47a4-b013-aaa8c378a399', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-14', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7d239f05234897b071df035e278574dfcf83a6aebeac6e2336af75d2f671ceb4'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='6e84f311-688d-449c-824a-cb3ef9995261', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bab590ecfc57d905513218bba37152afe8de59ac70775f90e2a012ceaa6ea405'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='7aee720b-d450-4e3a-8247-c5c1f3943985', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ca4b5a61cd1ea2117b9bdea5cf2f57a12292014fd1278ca1479d876e253910ee')}, text='However, since we applied iterative model updates, the fundamental\\ndifferences between the two RL algorithms are less pronounced.\\nUntil RLHF (V4), we used only Rejection Sampling fine-tuning, and after that, we combined the two\\nsequentially, applying PPO on top of the resulted Rejection Sampling checkpoint before sampling again.\\n100101102\\nNumber Samples0.10.20.30.40.50.6Reward Score\\nSFT\\n100101102\\nNumber Samples0.350.400.450.500.550.600.650.70Reward Score\\nRLHF\\nreward_max (T=0.6)\\nreward_max (T=0.8)\\nreward_max (T=0.9)\\nreward_max (T=1)\\nreward_max (T=1.1)\\nreward_max (T=1.2)\\nreward_max (T=1.3)\\nreward_max (T=1.4)\\nreward_max (T=1.5)\\nFigure8: RLHFimpactofthetemperature whensamplingNoutputsandscoringthemwitharewardmodel.\\nRejection Sampling. We performrejection sampling only with our largest 70B Llama 2-Chat .', start_char_idx=993, end_char_idx=1803, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-14', obj=None),\n",
       " '7aee720b-d450-4e3a-8247-c5c1f3943985': IndexNode(id_='7aee720b-d450-4e3a-8247-c5c1f3943985', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-14', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7d239f05234897b071df035e278574dfcf83a6aebeac6e2336af75d2f671ceb4'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='ce0cb6f0-a0fb-47a4-b013-aaa8c378a399', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='72d0115a2a05399cea567c681145352c3c585e42304a76cd25e89f3f87f07184'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='4e7b8567-550c-4c99-b6de-5c89cfc1b98f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='857d3b68f79849222c52d555f32386e7f520d92b8fc2eb1ec12dac7f43ef6d5c')}, text='Rejection Sampling. We performrejection sampling only with our largest 70B Llama 2-Chat . All smaller\\nmodels are fine-tuned on rejection sampled data from the larger model, thus distilling the large-model\\ncapabilities into the smaller ones. We leave further analysis of the effect of this distillation for future work.\\nAteachiterativestage,wesample Kanswersforeachpromptfromthemostrecentmodel. Wescoreeach\\nsample given the best reward model accessible at the time of the experiment, and then select the best answer\\nforagivenprompt. Inearlierversionsofourmodel,uptoRLHFV3,ourapproachwastoconfineanswer\\nselection solely to the“bag” of samples gathered from the precedingiteration. For example, RLHF V3was\\ntrained using only samples from RLHF V2. However, despite continuous improvement, this method led to a\\n14\\n\\nregressionin somecapabilities.', start_char_idx=1714, end_char_idx=2554, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-14', obj=None),\n",
       " '4e7b8567-550c-4c99-b6de-5c89cfc1b98f': IndexNode(id_='4e7b8567-550c-4c99-b6de-5c89cfc1b98f', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-14', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7d239f05234897b071df035e278574dfcf83a6aebeac6e2336af75d2f671ceb4'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='7aee720b-d450-4e3a-8247-c5c1f3943985', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ca4b5a61cd1ea2117b9bdea5cf2f57a12292014fd1278ca1479d876e253910ee'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='8706fd6d-11c0-4890-8333-c927f6ba91c7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='61941bb1c4ba08f829dd0de45ecd06d543c1a2d11e9f467c97109fc7a3792f2a')}, text='Inearlierversionsofourmodel,uptoRLHFV3,ourapproachwastoconfineanswer\\nselection solely to the“bag” of samples gathered from the precedingiteration. For example, RLHF V3was\\ntrained using only samples from RLHF V2. However, despite continuous improvement, this method led to a\\n14\\n\\nregressionin somecapabilities. Forexample,RLHFV3 struggledmore thanpreviousversionstocompose\\nrhyming lines in poems, as discerned through qualitative analysis, suggesting that further investigation into\\nthe causes of and mitigations for forgetting (Kirkpatrick et al., 2017; Nguyen et al., 2019; Ramasesh et al.,\\n2021) could be a fruitful area for additional future research.\\nIn response, on subsequent iterations, we modified our strategy, incorporating top-performing samples from\\nall prior iterations, such as those used in RLHF-V1 and RLHF-V2. Although we do not present specific\\nfigures, this adjustment demonstrated considerable enhancements in performance and effectively addressed\\nthe previously noted issues. This mitigation can be seen as analogous to Synnaeve et al.', start_char_idx=2246, end_char_idx=3301, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-14', obj=None),\n",
       " '8706fd6d-11c0-4890-8333-c927f6ba91c7': IndexNode(id_='8706fd6d-11c0-4890-8333-c927f6ba91c7', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-14', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7d239f05234897b071df035e278574dfcf83a6aebeac6e2336af75d2f671ceb4'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='4e7b8567-550c-4c99-b6de-5c89cfc1b98f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='857d3b68f79849222c52d555f32386e7f520d92b8fc2eb1ec12dac7f43ef6d5c')}, text='In response, on subsequent iterations, we modified our strategy, incorporating top-performing samples from\\nall prior iterations, such as those used in RLHF-V1 and RLHF-V2. Although we do not present specific\\nfigures, this adjustment demonstrated considerable enhancements in performance and effectively addressed\\nthe previously noted issues. This mitigation can be seen as analogous to Synnaeve et al. (2019) and Vinyals\\net al. (2019) in the RL literature.\\nWe illustrate the benefit of Rejection Sampling in Figure 7. The delta between the maximum and median\\ncurves can be interpreted as the potential gain of fine-tuning on the best output. As expected, this delta\\nincreases with more samples, since the maximum increases (i.e., more samples, more opportunities to\\ngenerateagoodtrajectory),whilethemedianremainsstationary. Thereisadirectconnectionbetweenthe\\nexplorationand themaximum rewardwe canobtain amongthesamples. Thetemperatureparameteralso\\nplays an important role for exploration, as a higher temperature enables us to sample more diverse outputs.', start_char_idx=2900, end_char_idx=3956, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-14', obj=None),\n",
       " '6939021b-c0c5-40dd-a5a3-e6a1f4e63152': IndexNode(id_='6939021b-c0c5-40dd-a5a3-e6a1f4e63152', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-14', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7d239f05234897b071df035e278574dfcf83a6aebeac6e2336af75d2f671ceb4'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='e2d5f797-0db5-4248-8404-a762371d1307', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5cb6a4359144bf2a8bf2335d521f9561c72ed7010506f3694db7f750620ee5be')}, text='For eachprompt,thesample obtaining\\n13\\n\\n100101\\nN Samples0.540.560.580.600.620.640.66Reward Score\\nMax of the rewards\\nMedian of the rewardsFigure 7: Max and median reward among N samples ,N∈[1, . . . , 100]averaged over our training set of\\nprompts. The delta between max and median can be interpreted as potential gain with Rejection Sampling.\\nthe highestrewardscore is consideredthe newgold standard. Similar toScialom etal. (2020a), we\\nthen fine-tune our model on the new set of ranked samples, reinforcing the reward.\\nThe two RL algorithms mainly differ in:\\n•Breadth— in Rejection Sampling, the model explores Ksamples for a given prompt, while only one\\ngeneration is done for PPO.\\n•Depth— in PPO, during training at step tthe sample is a function of the updated model policy from\\nt−1afterthegradientupdateofthepreviousstep. InRejectionSamplingfine-tuning,wesample\\nall the outputs given the initial policy of our model to collect a new dataset, before applying the\\nfine-tuning similar to SFT. However, since we applied iterative model updates, the fundamental\\ndifferences between the two RL algorithms are less pronounced.\\nUntil RLHF (V4), we used only Rejection Sampling fine-tuning, and after that, we combined the two\\nsequentially, applying PPO on top of the resulted Rejection Sampling checkpoint before sampling again.\\n100101102\\nNumber Samples0.10.20.30.40.50.6Reward Score\\nSFT\\n100101102\\nNumber Samples0.350.400.450.500.550.600.650.70Reward Score\\nRLHF\\nreward_max (T=0.6)\\nreward_max (T=0.8)\\nreward_max (T=0.9)\\nreward_max (T=1)\\nreward_max (T=1.1)\\nreward_max (T=1.2)\\nreward_max (T=1.3)\\nreward_max (T=1.4)\\nreward_max (T=1.5)\\nFigure8: RLHFimpactofthetemperature whensamplingNoutputsandscoringthemwitharewardmodel.\\nRejection Sampling.', start_char_idx=0, end_char_idx=1733, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-14', obj=None),\n",
       " 'e2d5f797-0db5-4248-8404-a762371d1307': IndexNode(id_='e2d5f797-0db5-4248-8404-a762371d1307', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-14', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7d239f05234897b071df035e278574dfcf83a6aebeac6e2336af75d2f671ceb4'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='6939021b-c0c5-40dd-a5a3-e6a1f4e63152', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a118536075f9e9cee655aed1fe613a3527ce109cefd5afb08d272d447ce30f50'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='26b84ab2-1304-42c6-86bf-bde27524aee2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='42b8722406fbbff327af2104e8203289a7ddb509fe6f5ec799e72c122f3296e5')}, text='Rejection Sampling. We performrejection sampling only with our largest 70B Llama 2-Chat . All smaller\\nmodels are fine-tuned on rejection sampled data from the larger model, thus distilling the large-model\\ncapabilities into the smaller ones. We leave further analysis of the effect of this distillation for future work.\\nAteachiterativestage,wesample Kanswersforeachpromptfromthemostrecentmodel. Wescoreeach\\nsample given the best reward model accessible at the time of the experiment, and then select the best answer\\nforagivenprompt. Inearlierversionsofourmodel,uptoRLHFV3,ourapproachwastoconfineanswer\\nselection solely to the“bag” of samples gathered from the precedingiteration. For example, RLHF V3was\\ntrained using only samples from RLHF V2. However, despite continuous improvement, this method led to a\\n14\\n\\nregressionin somecapabilities. Forexample,RLHFV3 struggledmore thanpreviousversionstocompose\\nrhyming lines in poems, as discerned through qualitative analysis, suggesting that further investigation into\\nthe causes of and mitigations for forgetting (Kirkpatrick et al., 2017; Nguyen et al., 2019; Ramasesh et al.,\\n2021) could be a fruitful area for additional future research.\\nIn response, on subsequent iterations, we modified our strategy, incorporating top-performing samples from\\nall prior iterations, such as those used in RLHF-V1 and RLHF-V2. Although we do not present specific\\nfigures, this adjustment demonstrated considerable enhancements in performance and effectively addressed\\nthe previously noted issues. This mitigation can be seen as analogous to Synnaeve et al. (2019) and Vinyals\\net al. (2019) in the RL literature.\\nWe illustrate the benefit of Rejection Sampling in Figure 7. The delta between the maximum and median\\ncurves can be interpreted as the potential gain of fine-tuning on the best output. As expected, this delta\\nincreases with more samples, since the maximum increases (i.e., more samples, more opportunities to\\ngenerateagoodtrajectory),whilethemedianremainsstationary. Thereisadirectconnectionbetweenthe\\nexplorationand themaximum rewardwe canobtain amongthesamples.', start_char_idx=1714, end_char_idx=3820, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-14', obj=None),\n",
       " '26b84ab2-1304-42c6-86bf-bde27524aee2': IndexNode(id_='26b84ab2-1304-42c6-86bf-bde27524aee2', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-14', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7d239f05234897b071df035e278574dfcf83a6aebeac6e2336af75d2f671ceb4'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='e2d5f797-0db5-4248-8404-a762371d1307', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5cb6a4359144bf2a8bf2335d521f9561c72ed7010506f3694db7f750620ee5be')}, text='The delta between the maximum and median\\ncurves can be interpreted as the potential gain of fine-tuning on the best output. As expected, this delta\\nincreases with more samples, since the maximum increases (i.e., more samples, more opportunities to\\ngenerateagoodtrajectory),whilethemedianremainsstationary. Thereisadirectconnectionbetweenthe\\nexplorationand themaximum rewardwe canobtain amongthesamples. Thetemperatureparameteralso\\nplays an important role for exploration, as a higher temperature enables us to sample more diverse outputs.', start_char_idx=3418, end_char_idx=3956, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-14', obj=None),\n",
       " 'node-14': IndexNode(id_='node-14', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='d03f19eb-da15-45dc-bfd4-e5d10f161250', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='231b3bd773f012c01b893ada9e009ecf25ee59934614c5a595c9bf1b3a123292'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='c10f1dd0-d391-47e9-a719-be5db96b118a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='36acf0ba046e4e355c93836ed53ee6157045b6b73e7e5aed51685a2407a65d62'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='cc8fdeb8-d2d4-4e55-8465-f1e0d492c04b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='67a600f27b5e41b1b0f14d8be85503b051a8aab0a01d15b4a28bedf91454ef8b')}, text='For eachprompt,thesample obtaining\\n13\\n\\n100101\\nN Samples0.540.560.580.600.620.640.66Reward Score\\nMax of the rewards\\nMedian of the rewardsFigure 7: Max and median reward among N samples ,N∈[1, . . . , 100]averaged over our training set of\\nprompts. The delta between max and median can be interpreted as potential gain with Rejection Sampling.\\nthe highestrewardscore is consideredthe newgold standard. Similar toScialom etal. (2020a), we\\nthen fine-tune our model on the new set of ranked samples, reinforcing the reward.\\nThe two RL algorithms mainly differ in:\\n•Breadth— in Rejection Sampling, the model explores Ksamples for a given prompt, while only one\\ngeneration is done for PPO.\\n•Depth— in PPO, during training at step tthe sample is a function of the updated model policy from\\nt−1afterthegradientupdateofthepreviousstep. InRejectionSamplingfine-tuning,wesample\\nall the outputs given the initial policy of our model to collect a new dataset, before applying the\\nfine-tuning similar to SFT. However, since we applied iterative model updates, the fundamental\\ndifferences between the two RL algorithms are less pronounced.\\nUntil RLHF (V4), we used only Rejection Sampling fine-tuning, and after that, we combined the two\\nsequentially, applying PPO on top of the resulted Rejection Sampling checkpoint before sampling again.\\n100101102\\nNumber Samples0.10.20.30.40.50.6Reward Score\\nSFT\\n100101102\\nNumber Samples0.350.400.450.500.550.600.650.70Reward Score\\nRLHF\\nreward_max (T=0.6)\\nreward_max (T=0.8)\\nreward_max (T=0.9)\\nreward_max (T=1)\\nreward_max (T=1.1)\\nreward_max (T=1.2)\\nreward_max (T=1.3)\\nreward_max (T=1.4)\\nreward_max (T=1.5)\\nFigure8: RLHFimpactofthetemperature whensamplingNoutputsandscoringthemwitharewardmodel.\\nRejection Sampling. We performrejection sampling only with our largest 70B Llama 2-Chat . All smaller\\nmodels are fine-tuned on rejection sampled data from the larger model, thus distilling the large-model\\ncapabilities into the smaller ones. We leave further analysis of the effect of this distillation for future work.\\nAteachiterativestage,wesample Kanswersforeachpromptfromthemostrecentmodel. Wescoreeach\\nsample given the best reward model accessible at the time of the experiment, and then select the best answer\\nforagivenprompt. Inearlierversionsofourmodel,uptoRLHFV3,ourapproachwastoconfineanswer\\nselection solely to the“bag” of samples gathered from the precedingiteration. For example, RLHF V3was\\ntrained using only samples from RLHF V2. However, despite continuous improvement, this method led to a\\n14\\n\\nregressionin somecapabilities. Forexample,RLHFV3 struggledmore thanpreviousversionstocompose\\nrhyming lines in poems, as discerned through qualitative analysis, suggesting that further investigation into\\nthe causes of and mitigations for forgetting (Kirkpatrick et al., 2017; Nguyen et al., 2019; Ramasesh et al.,\\n2021) could be a fruitful area for additional future research.\\nIn response, on subsequent iterations, we modified our strategy, incorporating top-performing samples from\\nall prior iterations, such as those used in RLHF-V1 and RLHF-V2. Although we do not present specific\\nfigures, this adjustment demonstrated considerable enhancements in performance and effectively addressed\\nthe previously noted issues. This mitigation can be seen as analogous to Synnaeve et al. (2019) and Vinyals\\net al. (2019) in the RL literature.\\nWe illustrate the benefit of Rejection Sampling in Figure 7. The delta between the maximum and median\\ncurves can be interpreted as the potential gain of fine-tuning on the best output. As expected, this delta\\nincreases with more samples, since the maximum increases (i.e., more samples, more opportunities to\\ngenerateagoodtrajectory),whilethemedianremainsstationary. Thereisadirectconnectionbetweenthe\\nexplorationand themaximum rewardwe canobtain amongthesamples. Thetemperatureparameteralso\\nplays an important role for exploration, as a higher temperature enables us to sample more diverse outputs.', start_char_idx=41383, end_char_idx=45339, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-14', obj=None),\n",
       " '93574180-9688-4002-8db2-0bdf77fb5230': IndexNode(id_='93574180-9688-4002-8db2-0bdf77fb5230', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-15', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='67a600f27b5e41b1b0f14d8be85503b051a8aab0a01d15b4a28bedf91454ef8b'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='11dfe731-d229-4913-b183-453e1a3575f2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='92ab0b6ae64a15d01a075863ffb5352347f1c83ae0b90ce11872ebe9e31dce4f')}, text='As expected, this delta\\nincreases with more samples, since the maximum increases (i.e., more samples, more opportunities to\\ngenerateagoodtrajectory),whilethemedianremainsstationary. Thereisadirectconnectionbetweenthe\\nexplorationand themaximum rewardwe canobtain amongthesamples. Thetemperatureparameteralso\\nplays an important role for exploration, as a higher temperature enables us to sample more diverse outputs.', start_char_idx=0, end_char_idx=414, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-15', obj=None),\n",
       " '11dfe731-d229-4913-b183-453e1a3575f2': IndexNode(id_='11dfe731-d229-4913-b183-453e1a3575f2', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-15', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='67a600f27b5e41b1b0f14d8be85503b051a8aab0a01d15b4a28bedf91454ef8b'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='93574180-9688-4002-8db2-0bdf77fb5230', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f984df3fca0088a0684c29640183ec9abcd54cc28dc5bb3b4654d15b739ccbdf'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='b50293cd-6129-4fb5-8180-ab44e327887d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ebd6af347c9a53785b552b33cab9c4834c8a8607a16839d500cb7ca46220c40c')}, text='As expected, this delta\\nincreases with more samples, since the maximum increases (i.e., more samples, more opportunities to\\ngenerateagoodtrajectory),whilethemedianremainsstationary. Thereisadirectconnectionbetweenthe\\nexplorationand themaximum rewardwe canobtain amongthesamples. Thetemperatureparameteralso\\nplays an important role for exploration, as a higher temperature enables us to sample more diverse outputs.\\nIn Figure 8, we report for a Llama 2-Chat -SFT (left) and a Llama 2-Chat -RLHF (right), the maximum\\nrewardcurvesamongNsamples(with N∈[1, .', start_char_idx=0, end_char_idx=553, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-15', obj=None),\n",
       " 'b50293cd-6129-4fb5-8180-ab44e327887d': IndexNode(id_='b50293cd-6129-4fb5-8180-ab44e327887d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-15', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='67a600f27b5e41b1b0f14d8be85503b051a8aab0a01d15b4a28bedf91454ef8b'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='11dfe731-d229-4913-b183-453e1a3575f2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='92ab0b6ae64a15d01a075863ffb5352347f1c83ae0b90ce11872ebe9e31dce4f'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='39f886e5-d73c-46aa-b32c-99a1b300af78', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5f844c986429bdd67e4032369e5f8f9ecdb3dc8ccb0f6ad9335e8bf147b3f645')}, text='Thetemperatureparameteralso\\nplays an important role for exploration, as a higher temperature enables us to sample more diverse outputs.\\nIn Figure 8, we report for a Llama 2-Chat -SFT (left) and a Llama 2-Chat -RLHF (right), the maximum\\nrewardcurvesamongNsamples(with N∈[1, . . . , 100]),fordifferenttemperatures.', start_char_idx=279, end_char_idx=591, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-15', obj=None),\n",
       " '39f886e5-d73c-46aa-b32c-99a1b300af78': IndexNode(id_='39f886e5-d73c-46aa-b32c-99a1b300af78', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-15', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='67a600f27b5e41b1b0f14d8be85503b051a8aab0a01d15b4a28bedf91454ef8b'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='b50293cd-6129-4fb5-8180-ab44e327887d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ebd6af347c9a53785b552b33cab9c4834c8a8607a16839d500cb7ca46220c40c'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='ba149481-55ab-4593-8c45-5fc5b7bba39e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='58d1b02b7df994722c5b357c4314a698ffcdb32b46c7c20707e6bed3ef9985fb')}, text='Thetemperatureparameteralso\\nplays an important role for exploration, as a higher temperature enables us to sample more diverse outputs.\\nIn Figure 8, we report for a Llama 2-Chat -SFT (left) and a Llama 2-Chat -RLHF (right), the maximum\\nrewardcurvesamongNsamples(with N∈[1, . . . , 100]),fordifferenttemperatures. Wecanobservethat\\ntheoptimaltemperatureisnotconstantduringtheiterativemodelupdates: RLHFhasadirectimpacton\\nrescalingthetemperature.', start_char_idx=279, end_char_idx=722, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-15', obj=None),\n",
       " 'ba149481-55ab-4593-8c45-5fc5b7bba39e': IndexNode(id_='ba149481-55ab-4593-8c45-5fc5b7bba39e', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-15', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='67a600f27b5e41b1b0f14d8be85503b051a8aab0a01d15b4a28bedf91454ef8b'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='39f886e5-d73c-46aa-b32c-99a1b300af78', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5f844c986429bdd67e4032369e5f8f9ecdb3dc8ccb0f6ad9335e8bf147b3f645'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='dfe2547e-aef7-4efa-8521-1a3fe6336e4f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='183e7dca6c2a3d5d2517cb64f114dc21733bcf4baa617339c996a8c6cd338edc')}, text='. . , 100]),fordifferenttemperatures. Wecanobservethat\\ntheoptimaltemperatureisnotconstantduringtheiterativemodelupdates: RLHFhasadirectimpacton\\nrescalingthetemperature. For Llama 2-Chat -RLHF,theoptimaltemperaturewhensamplingbetween10\\nand 100 outputs is T∈[1.2,1.3]. Given a finite compute budget, it is therefore necessary to re-adjust the\\ntemperatureprogressively.', start_char_idx=554, end_char_idx=920, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-15', obj=None),\n",
       " 'dfe2547e-aef7-4efa-8521-1a3fe6336e4f': IndexNode(id_='dfe2547e-aef7-4efa-8521-1a3fe6336e4f', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-15', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='67a600f27b5e41b1b0f14d8be85503b051a8aab0a01d15b4a28bedf91454ef8b'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='ba149481-55ab-4593-8c45-5fc5b7bba39e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='58d1b02b7df994722c5b357c4314a698ffcdb32b46c7c20707e6bed3ef9985fb'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='434ff4e8-ccc2-4f69-ad25-4182aa3750df', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ae4e5d917424e9b05067bc04ed66a6d66488ff0e41f271ba509a20fb07f63586')}, text='Wecanobservethat\\ntheoptimaltemperatureisnotconstantduringtheiterativemodelupdates: RLHFhasadirectimpacton\\nrescalingthetemperature. For Llama 2-Chat -RLHF,theoptimaltemperaturewhensamplingbetween10\\nand 100 outputs is T∈[1.2,1.3]. Given a finite compute budget, it is therefore necessary to re-adjust the\\ntemperatureprogressively. Note thatthistemperature rescalinghappensfor aconstantnumber ofstepsfor\\neach model, and always starting from the base model on each new RLHF version.', start_char_idx=592, end_char_idx=1070, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-15', obj=None),\n",
       " '434ff4e8-ccc2-4f69-ad25-4182aa3750df': IndexNode(id_='434ff4e8-ccc2-4f69-ad25-4182aa3750df', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-15', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='67a600f27b5e41b1b0f14d8be85503b051a8aab0a01d15b4a28bedf91454ef8b'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='dfe2547e-aef7-4efa-8521-1a3fe6336e4f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='183e7dca6c2a3d5d2517cb64f114dc21733bcf4baa617339c996a8c6cd338edc'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='7d45cb68-945b-402d-ba74-b04142e3d4ac', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3900d1be8d0566ecfea8c00b9c690b21b43b7b61167e8fbba152c3422f33575d')}, text='For Llama 2-Chat -RLHF,theoptimaltemperaturewhensamplingbetween10\\nand 100 outputs is T∈[1.2,1.3]. Given a finite compute budget, it is therefore necessary to re-adjust the\\ntemperatureprogressively. Note thatthistemperature rescalinghappensfor aconstantnumber ofstepsfor\\neach model, and always starting from the base model on each new RLHF version.\\nPPO.WefurthertrainourlanguagemodelfollowingtheRLschemeofStiennonetal.', start_char_idx=723, end_char_idx=1140, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-15', obj=None),\n",
       " '7d45cb68-945b-402d-ba74-b04142e3d4ac': IndexNode(id_='7d45cb68-945b-402d-ba74-b04142e3d4ac', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-15', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='67a600f27b5e41b1b0f14d8be85503b051a8aab0a01d15b4a28bedf91454ef8b'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='434ff4e8-ccc2-4f69-ad25-4182aa3750df', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ae4e5d917424e9b05067bc04ed66a6d66488ff0e41f271ba509a20fb07f63586'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='be386006-cb84-4616-bd21-bfcd81a56e23', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c3be9845b06afa06aead27cc9ea591ebe822fc43e3eade0129cd61dcabd097ce')}, text='Given a finite compute budget, it is therefore necessary to re-adjust the\\ntemperatureprogressively. Note thatthistemperature rescalinghappensfor aconstantnumber ofstepsfor\\neach model, and always starting from the base model on each new RLHF version.\\nPPO.WefurthertrainourlanguagemodelfollowingtheRLschemeofStiennonetal.(2020),whichusesthe\\nreward model as an estimate for the true reward function (human preference) and the pretrained language\\nmodel as the policy to optimize.', start_char_idx=821, end_char_idx=1296, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-15', obj=None),\n",
       " 'be386006-cb84-4616-bd21-bfcd81a56e23': IndexNode(id_='be386006-cb84-4616-bd21-bfcd81a56e23', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-15', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='67a600f27b5e41b1b0f14d8be85503b051a8aab0a01d15b4a28bedf91454ef8b'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='7d45cb68-945b-402d-ba74-b04142e3d4ac', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3900d1be8d0566ecfea8c00b9c690b21b43b7b61167e8fbba152c3422f33575d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='33117213-3e81-4759-b75f-4aa0a88767c2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3a9cfa7b98979c8536f7999cb23831609aa42c280f397ba906211a7d3a85ad7a')}, text='Note thatthistemperature rescalinghappensfor aconstantnumber ofstepsfor\\neach model, and always starting from the base model on each new RLHF version.\\nPPO.WefurthertrainourlanguagemodelfollowingtheRLschemeofStiennonetal.(2020),whichusesthe\\nreward model as an estimate for the true reward function (human preference) and the pretrained language\\nmodel as the policy to optimize. During this phase, we seek to optimize the following objective:\\narg max\\nπEp∼D,g∼π[R(g|p)] (3)\\nWe iteratively improve the policy by sampling prompts pfrom our dataset Dand generations gfrom the\\npolicy πand use the PPO algorithm and loss function to achieve this objective.', start_char_idx=921, end_char_idx=1568, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-15', obj=None),\n",
       " '33117213-3e81-4759-b75f-4aa0a88767c2': IndexNode(id_='33117213-3e81-4759-b75f-4aa0a88767c2', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-15', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='67a600f27b5e41b1b0f14d8be85503b051a8aab0a01d15b4a28bedf91454ef8b'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='be386006-cb84-4616-bd21-bfcd81a56e23', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c3be9845b06afa06aead27cc9ea591ebe822fc43e3eade0129cd61dcabd097ce'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='30b51e53-cc5b-4dee-bf71-cfbd56c6738a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7ab8f8a90492925e26067d9068a16c984a3de7decbe2404543d105fd7e641249')}, text='During this phase, we seek to optimize the following objective:\\narg max\\nπEp∼D,g∼π[R(g|p)] (3)\\nWe iteratively improve the policy by sampling prompts pfrom our dataset Dand generations gfrom the\\npolicy πand use the PPO algorithm and loss function to achieve this objective.\\nThe final reward function we use during optimization,\\nR(g|p) =˜Rc(g|p)−βDKL(πθ(g|p)∥π0(g|p)) (4)\\ncontains a penalty term for diverging from the original policy π0.', start_char_idx=1297, end_char_idx=1732, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-15', obj=None),\n",
       " '30b51e53-cc5b-4dee-bf71-cfbd56c6738a': IndexNode(id_='30b51e53-cc5b-4dee-bf71-cfbd56c6738a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-15', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='67a600f27b5e41b1b0f14d8be85503b051a8aab0a01d15b4a28bedf91454ef8b'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='33117213-3e81-4759-b75f-4aa0a88767c2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3a9cfa7b98979c8536f7999cb23831609aa42c280f397ba906211a7d3a85ad7a'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='43866e2b-10fb-4280-9a5f-0249aecf2ac0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0214252815cc361febd35a6a8cc4de6d0174b113a324a1ad507d8b98775fa921')}, text='The final reward function we use during optimization,\\nR(g|p) =˜Rc(g|p)−βDKL(πθ(g|p)∥π0(g|p)) (4)\\ncontains a penalty term for diverging from the original policy π0. As was observed in other works (Stiennon\\net al., 2020; Ouyang et al., 2022), we find this constraint is useful for training stability, and to reduce reward\\nhackingwherebywewouldachievehighscoresfromtherewardmodelbutlowscoresfromhumanevaluation.', start_char_idx=1569, end_char_idx=1977, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-15', obj=None),\n",
       " '43866e2b-10fb-4280-9a5f-0249aecf2ac0': IndexNode(id_='43866e2b-10fb-4280-9a5f-0249aecf2ac0', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-15', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='67a600f27b5e41b1b0f14d8be85503b051a8aab0a01d15b4a28bedf91454ef8b'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='30b51e53-cc5b-4dee-bf71-cfbd56c6738a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7ab8f8a90492925e26067d9068a16c984a3de7decbe2404543d105fd7e641249'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='b0286ac6-16e0-4701-84e6-4251815738d6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8db9afd403046c091059d03ffb51dc65dc91842e12acf6f7907e869e79c1f219')}, text='As was observed in other works (Stiennon\\net al., 2020; Ouyang et al., 2022), we find this constraint is useful for training stability, and to reduce reward\\nhackingwherebywewouldachievehighscoresfromtherewardmodelbutlowscoresfromhumanevaluation.\\nWe define Rcto be a piecewise combination of the safety ( Rs) and helpfulness ( Rh) reward models.', start_char_idx=1733, end_char_idx=2076, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-15', obj=None),\n",
       " 'b0286ac6-16e0-4701-84e6-4251815738d6': IndexNode(id_='b0286ac6-16e0-4701-84e6-4251815738d6', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-15', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='67a600f27b5e41b1b0f14d8be85503b051a8aab0a01d15b4a28bedf91454ef8b'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='43866e2b-10fb-4280-9a5f-0249aecf2ac0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0214252815cc361febd35a6a8cc4de6d0174b113a324a1ad507d8b98775fa921'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='00f1f0a3-1cdb-4341-9de8-284930327601', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4fe0fe30bfac6c36003168d12805eb83d3f35ecb24b99e9fe27c2f0e2c6a615b')}, text='As was observed in other works (Stiennon\\net al., 2020; Ouyang et al., 2022), we find this constraint is useful for training stability, and to reduce reward\\nhackingwherebywewouldachievehighscoresfromtherewardmodelbutlowscoresfromhumanevaluation.\\nWe define Rcto be a piecewise combination of the safety ( Rs) and helpfulness ( Rh) reward models. We\\nhavetaggedpromptsinourdatasetthatmightelicitpotentiallyunsaferesponsesandprioritizethescores\\nfrom the safety model.', start_char_idx=1733, end_char_idx=2195, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-15', obj=None),\n",
       " '00f1f0a3-1cdb-4341-9de8-284930327601': IndexNode(id_='00f1f0a3-1cdb-4341-9de8-284930327601', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-15', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='67a600f27b5e41b1b0f14d8be85503b051a8aab0a01d15b4a28bedf91454ef8b'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='b0286ac6-16e0-4701-84e6-4251815738d6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8db9afd403046c091059d03ffb51dc65dc91842e12acf6f7907e869e79c1f219'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='6d34d46c-1044-4238-8312-5d16769e5ee7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='91867c189fc12c8926b0a4e5e0e6385e4dfd8f0515a0b6040c1dae60cbb0ac14')}, text='We define Rcto be a piecewise combination of the safety ( Rs) and helpfulness ( Rh) reward models. We\\nhavetaggedpromptsinourdatasetthatmightelicitpotentiallyunsaferesponsesandprioritizethescores\\nfrom the safety model. The threshold of 0.15is chosen for filtering unsafe responses, corresponding to a\\nprecisionof 0.89andarecallof 0.55evaluatedontheMetaSafetytestset.', start_char_idx=1978, end_char_idx=2343, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-15', obj=None),\n",
       " '6d34d46c-1044-4238-8312-5d16769e5ee7': IndexNode(id_='6d34d46c-1044-4238-8312-5d16769e5ee7', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-15', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='67a600f27b5e41b1b0f14d8be85503b051a8aab0a01d15b4a28bedf91454ef8b'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='00f1f0a3-1cdb-4341-9de8-284930327601', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4fe0fe30bfac6c36003168d12805eb83d3f35ecb24b99e9fe27c2f0e2c6a615b'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='365f19ca-b7a6-4d62-8e81-cc83f3bab2d9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='76b0816656b54ac417ab6821b66f09d3460292a697100319d6f8d83c0c6064de')}, text='We\\nhavetaggedpromptsinourdatasetthatmightelicitpotentiallyunsaferesponsesandprioritizethescores\\nfrom the safety model. The threshold of 0.15is chosen for filtering unsafe responses, corresponding to a\\nprecisionof 0.89andarecallof 0.55evaluatedontheMetaSafetytestset. Wealsofinditimportanttowhiten\\nthe final linear scores (shown here by reversing the sigmoid with the logit function) in order to increase\\nstability and balance properly with the KL penalty term ( β) above.', start_char_idx=2077, end_char_idx=2548, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-15', obj=None),\n",
       " '365f19ca-b7a6-4d62-8e81-cc83f3bab2d9': IndexNode(id_='365f19ca-b7a6-4d62-8e81-cc83f3bab2d9', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-15', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='67a600f27b5e41b1b0f14d8be85503b051a8aab0a01d15b4a28bedf91454ef8b'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='6d34d46c-1044-4238-8312-5d16769e5ee7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='91867c189fc12c8926b0a4e5e0e6385e4dfd8f0515a0b6040c1dae60cbb0ac14'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='fec92fd5-3baf-4c95-bac6-38ef9b03856a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='512965273d4cb841f25278363f66eff15d926856951cf580b9920be054c182b4')}, text='The threshold of 0.15is chosen for filtering unsafe responses, corresponding to a\\nprecisionof 0.89andarecallof 0.55evaluatedontheMetaSafetytestset. Wealsofinditimportanttowhiten\\nthe final linear scores (shown here by reversing the sigmoid with the logit function) in order to increase\\nstability and balance properly with the KL penalty term ( β) above.\\nRc(g|p) =\\x1aRs(g|p)ifis_safety (p)orRs(g|p)<0.15\\nRh(g|p)otherwise\\n˜Rc(g|p) =whiten (logit (Rc(g|p)))\\nFor all models, we use the AdamW optimizer (Loshchilov and Hutter, 2017), with β1= 0.9, β2= 0.95,eps=\\n10−5.', start_char_idx=2196, end_char_idx=2755, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-15', obj=None),\n",
       " 'fec92fd5-3baf-4c95-bac6-38ef9b03856a': IndexNode(id_='fec92fd5-3baf-4c95-bac6-38ef9b03856a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-15', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='67a600f27b5e41b1b0f14d8be85503b051a8aab0a01d15b4a28bedf91454ef8b'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='365f19ca-b7a6-4d62-8e81-cc83f3bab2d9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='76b0816656b54ac417ab6821b66f09d3460292a697100319d6f8d83c0c6064de'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='83268c48-23cf-4fcc-9e19-7c34ae667990', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1b58781ddb4e12a44b5b69bb24a9135bd3833e858aa502931f56826effd40ad3')}, text='Weuseaweightdecayof 0.1,gradientclippingof 1.0,andaconstantlearningrateof 10−6. Foreach\\nPPOiterationweuseabatchsizeof 512,aPPOclipthresholdof 0.2,amini-batchsizeof 64,andtakeone\\ngradient step per mini-batch. For the 7B and 13B models, we set β= 0.01(KL penalty), and for the 34B and\\n70B models, we set β= 0.005.', start_char_idx=2756, end_char_idx=3067, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-15', obj=None),\n",
       " '83268c48-23cf-4fcc-9e19-7c34ae667990': IndexNode(id_='83268c48-23cf-4fcc-9e19-7c34ae667990', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-15', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='67a600f27b5e41b1b0f14d8be85503b051a8aab0a01d15b4a28bedf91454ef8b'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='fec92fd5-3baf-4c95-bac6-38ef9b03856a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='512965273d4cb841f25278363f66eff15d926856951cf580b9920be054c182b4'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='404fc27d-8d42-46ca-88a7-473824a772ea', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3e9f85774e46f22097b0cd585497650ec68a102d14d52501413eadbe39ab53b9')}, text='Foreach\\nPPOiterationweuseabatchsizeof 512,aPPOclipthresholdof 0.2,amini-batchsizeof 64,andtakeone\\ngradient step per mini-batch. For the 7B and 13B models, we set β= 0.01(KL penalty), and for the 34B and\\n70B models, we set β= 0.005.\\n15\\n\\nFigure 9: Issues with multi-turn memory (left)can be improved with GAtt (right).', start_char_idx=2836, end_char_idx=3152, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-15', obj=None),\n",
       " '404fc27d-8d42-46ca-88a7-473824a772ea': IndexNode(id_='404fc27d-8d42-46ca-88a7-473824a772ea', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-15', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='67a600f27b5e41b1b0f14d8be85503b051a8aab0a01d15b4a28bedf91454ef8b'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='83268c48-23cf-4fcc-9e19-7c34ae667990', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1b58781ddb4e12a44b5b69bb24a9135bd3833e858aa502931f56826effd40ad3'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='815834fd-d22f-4a97-a3c8-9c5792037969', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='db92b3bd960c94817460c07137fbaeeb8386c70b0a7472516a7227921e3cf029')}, text='For the 7B and 13B models, we set β= 0.01(KL penalty), and for the 34B and\\n70B models, we set β= 0.005.\\n15\\n\\nFigure 9: Issues with multi-turn memory (left)can be improved with GAtt (right).\\nWe train for between 200and400iterations for all our models, and use evaluations on held-out prompts for\\nearlystopping. EachiterationofPPOonthe70Bmodeltakesonaverage ≈330seconds.', start_char_idx=2964, end_char_idx=3331, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-15', obj=None),\n",
       " '815834fd-d22f-4a97-a3c8-9c5792037969': IndexNode(id_='815834fd-d22f-4a97-a3c8-9c5792037969', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-15', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='67a600f27b5e41b1b0f14d8be85503b051a8aab0a01d15b4a28bedf91454ef8b'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='404fc27d-8d42-46ca-88a7-473824a772ea', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3e9f85774e46f22097b0cd585497650ec68a102d14d52501413eadbe39ab53b9')}, text='15\\n\\nFigure 9: Issues with multi-turn memory (left)can be improved with GAtt (right).\\nWe train for between 200and400iterations for all our models, and use evaluations on held-out prompts for\\nearlystopping. EachiterationofPPOonthe70Bmodeltakesonaverage ≈330seconds. Totrainquicklywith\\nlarge batch sizes, we use FSDP (Zhao et al., 2023).', start_char_idx=3068, end_char_idx=3402, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-15', obj=None),\n",
       " '12fe4d29-f261-4437-8e21-f85510e2ccd9': IndexNode(id_='12fe4d29-f261-4437-8e21-f85510e2ccd9', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-15', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='67a600f27b5e41b1b0f14d8be85503b051a8aab0a01d15b4a28bedf91454ef8b'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='7f23a0fe-d077-40a4-8dcc-bcb654f30fdf', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d7ebf21bf1f0bb8f11924a6daac23d5eba484a548e5ee22bf778c327009f789c')}, text='As expected, this delta\\nincreases with more samples, since the maximum increases (i.e., more samples, more opportunities to\\ngenerateagoodtrajectory),whilethemedianremainsstationary. Thereisadirectconnectionbetweenthe\\nexplorationand themaximum rewardwe canobtain amongthesamples. Thetemperatureparameteralso\\nplays an important role for exploration, as a higher temperature enables us to sample more diverse outputs.\\nIn Figure 8, we report for a Llama 2-Chat -SFT (left) and a Llama 2-Chat -RLHF (right), the maximum\\nrewardcurvesamongNsamples(with N∈[1, . . . , 100]),fordifferenttemperatures. Wecanobservethat\\ntheoptimaltemperatureisnotconstantduringtheiterativemodelupdates: RLHFhasadirectimpacton\\nrescalingthetemperature. For Llama 2-Chat -RLHF,theoptimaltemperaturewhensamplingbetween10\\nand 100 outputs is T∈[1.2,1.3]. Given a finite compute budget, it is therefore necessary to re-adjust the\\ntemperatureprogressively.', start_char_idx=0, end_char_idx=920, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-15', obj=None),\n",
       " '7f23a0fe-d077-40a4-8dcc-bcb654f30fdf': IndexNode(id_='7f23a0fe-d077-40a4-8dcc-bcb654f30fdf', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-15', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='67a600f27b5e41b1b0f14d8be85503b051a8aab0a01d15b4a28bedf91454ef8b'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='12fe4d29-f261-4437-8e21-f85510e2ccd9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='15ba147ee48063fb738a3a7d1d5449219f691246b9b27cf56139df302153f26c'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='7920f095-c0a9-44ca-9630-56cfeceba055', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a8b8c0e63bbe1352a371cdfbc45d1843c317a55985ba1f7b2fe2a46a5a8f0dea')}, text='Wecanobservethat\\ntheoptimaltemperatureisnotconstantduringtheiterativemodelupdates: RLHFhasadirectimpacton\\nrescalingthetemperature. For Llama 2-Chat -RLHF,theoptimaltemperaturewhensamplingbetween10\\nand 100 outputs is T∈[1.2,1.3]. Given a finite compute budget, it is therefore necessary to re-adjust the\\ntemperatureprogressively. Note thatthistemperature rescalinghappensfor aconstantnumber ofstepsfor\\neach model, and always starting from the base model on each new RLHF version.\\nPPO.WefurthertrainourlanguagemodelfollowingtheRLschemeofStiennonetal.(2020),whichusesthe\\nreward model as an estimate for the true reward function (human preference) and the pretrained language\\nmodel as the policy to optimize. During this phase, we seek to optimize the following objective:\\narg max\\nπEp∼D,g∼π[R(g|p)] (3)\\nWe iteratively improve the policy by sampling prompts pfrom our dataset Dand generations gfrom the\\npolicy πand use the PPO algorithm and loss function to achieve this objective.', start_char_idx=592, end_char_idx=1568, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-15', obj=None),\n",
       " '7920f095-c0a9-44ca-9630-56cfeceba055': IndexNode(id_='7920f095-c0a9-44ca-9630-56cfeceba055', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-15', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='67a600f27b5e41b1b0f14d8be85503b051a8aab0a01d15b4a28bedf91454ef8b'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='7f23a0fe-d077-40a4-8dcc-bcb654f30fdf', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d7ebf21bf1f0bb8f11924a6daac23d5eba484a548e5ee22bf778c327009f789c'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='2ccc74f5-8342-456e-86d7-3c7dc8b21e5a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a0a62590c804b0df8672d1aa43dbb634a0d6560b895cf64959e46ef9b8078f1e')}, text='During this phase, we seek to optimize the following objective:\\narg max\\nπEp∼D,g∼π[R(g|p)] (3)\\nWe iteratively improve the policy by sampling prompts pfrom our dataset Dand generations gfrom the\\npolicy πand use the PPO algorithm and loss function to achieve this objective.\\nThe final reward function we use during optimization,\\nR(g|p) =˜Rc(g|p)−βDKL(πθ(g|p)∥π0(g|p)) (4)\\ncontains a penalty term for diverging from the original policy π0. As was observed in other works (Stiennon\\net al., 2020; Ouyang et al., 2022), we find this constraint is useful for training stability, and to reduce reward\\nhackingwherebywewouldachievehighscoresfromtherewardmodelbutlowscoresfromhumanevaluation.\\nWe define Rcto be a piecewise combination of the safety ( Rs) and helpfulness ( Rh) reward models.', start_char_idx=1297, end_char_idx=2076, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-15', obj=None),\n",
       " '2ccc74f5-8342-456e-86d7-3c7dc8b21e5a': IndexNode(id_='2ccc74f5-8342-456e-86d7-3c7dc8b21e5a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-15', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='67a600f27b5e41b1b0f14d8be85503b051a8aab0a01d15b4a28bedf91454ef8b'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='7920f095-c0a9-44ca-9630-56cfeceba055', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a8b8c0e63bbe1352a371cdfbc45d1843c317a55985ba1f7b2fe2a46a5a8f0dea'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='aa78881c-8134-4959-86d6-d4301c8a09e5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bb8a0159d6c3d4660fa590fdc3db37adc3797d80105781643dc9ba6c9c88fa07')}, text='As was observed in other works (Stiennon\\net al., 2020; Ouyang et al., 2022), we find this constraint is useful for training stability, and to reduce reward\\nhackingwherebywewouldachievehighscoresfromtherewardmodelbutlowscoresfromhumanevaluation.\\nWe define Rcto be a piecewise combination of the safety ( Rs) and helpfulness ( Rh) reward models. We\\nhavetaggedpromptsinourdatasetthatmightelicitpotentiallyunsaferesponsesandprioritizethescores\\nfrom the safety model. The threshold of 0.15is chosen for filtering unsafe responses, corresponding to a\\nprecisionof 0.89andarecallof 0.55evaluatedontheMetaSafetytestset. Wealsofinditimportanttowhiten\\nthe final linear scores (shown here by reversing the sigmoid with the logit function) in order to increase\\nstability and balance properly with the KL penalty term ( β) above.', start_char_idx=1733, end_char_idx=2548, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-15', obj=None),\n",
       " 'aa78881c-8134-4959-86d6-d4301c8a09e5': IndexNode(id_='aa78881c-8134-4959-86d6-d4301c8a09e5', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-15', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='67a600f27b5e41b1b0f14d8be85503b051a8aab0a01d15b4a28bedf91454ef8b'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='2ccc74f5-8342-456e-86d7-3c7dc8b21e5a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a0a62590c804b0df8672d1aa43dbb634a0d6560b895cf64959e46ef9b8078f1e'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='1efd9af8-7360-4ca0-87d5-91ce863a4295', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e9019dd97bc05d6e571d35fab5a77a9340efc0efb6eee6b5deb3cc57a8366832')}, text='The threshold of 0.15is chosen for filtering unsafe responses, corresponding to a\\nprecisionof 0.89andarecallof 0.55evaluatedontheMetaSafetytestset. Wealsofinditimportanttowhiten\\nthe final linear scores (shown here by reversing the sigmoid with the logit function) in order to increase\\nstability and balance properly with the KL penalty term ( β) above.\\nRc(g|p) =\\x1aRs(g|p)ifis_safety (p)orRs(g|p)<0.15\\nRh(g|p)otherwise\\n˜Rc(g|p) =whiten (logit (Rc(g|p)))\\nFor all models, we use the AdamW optimizer (Loshchilov and Hutter, 2017), with β1= 0.9, β2= 0.95,eps=\\n10−5. Weuseaweightdecayof 0.1,gradientclippingof 1.0,andaconstantlearningrateof 10−6.', start_char_idx=2196, end_char_idx=2835, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-15', obj=None),\n",
       " '1efd9af8-7360-4ca0-87d5-91ce863a4295': IndexNode(id_='1efd9af8-7360-4ca0-87d5-91ce863a4295', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-15', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='67a600f27b5e41b1b0f14d8be85503b051a8aab0a01d15b4a28bedf91454ef8b'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='aa78881c-8134-4959-86d6-d4301c8a09e5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bb8a0159d6c3d4660fa590fdc3db37adc3797d80105781643dc9ba6c9c88fa07')}, text='Weuseaweightdecayof 0.1,gradientclippingof 1.0,andaconstantlearningrateof 10−6. Foreach\\nPPOiterationweuseabatchsizeof 512,aPPOclipthresholdof 0.2,amini-batchsizeof 64,andtakeone\\ngradient step per mini-batch. For the 7B and 13B models, we set β= 0.01(KL penalty), and for the 34B and\\n70B models, we set β= 0.005.\\n15\\n\\nFigure 9: Issues with multi-turn memory (left)can be improved with GAtt (right).\\nWe train for between 200and400iterations for all our models, and use evaluations on held-out prompts for\\nearlystopping. EachiterationofPPOonthe70Bmodeltakesonaverage ≈330seconds. Totrainquicklywith\\nlarge batch sizes, we use FSDP (Zhao et al., 2023).', start_char_idx=2756, end_char_idx=3402, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-15', obj=None),\n",
       " 'a4f8cb8a-53a5-4af6-bac4-d9f58872ac7e': IndexNode(id_='a4f8cb8a-53a5-4af6-bac4-d9f58872ac7e', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-15', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='67a600f27b5e41b1b0f14d8be85503b051a8aab0a01d15b4a28bedf91454ef8b'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='7d8bf1ba-7cb8-40f3-8f99-39b2dd108c76', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='cbf37dfd77707dccca4d5afdb92e1abe4381039c4acd90738f18462a73994abc')}, text='As expected, this delta\\nincreases with more samples, since the maximum increases (i.e., more samples, more opportunities to\\ngenerateagoodtrajectory),whilethemedianremainsstationary. Thereisadirectconnectionbetweenthe\\nexplorationand themaximum rewardwe canobtain amongthesamples. Thetemperatureparameteralso\\nplays an important role for exploration, as a higher temperature enables us to sample more diverse outputs.\\nIn Figure 8, we report for a Llama 2-Chat -SFT (left) and a Llama 2-Chat -RLHF (right), the maximum\\nrewardcurvesamongNsamples(with N∈[1, . . . , 100]),fordifferenttemperatures. Wecanobservethat\\ntheoptimaltemperatureisnotconstantduringtheiterativemodelupdates: RLHFhasadirectimpacton\\nrescalingthetemperature. For Llama 2-Chat -RLHF,theoptimaltemperaturewhensamplingbetween10\\nand 100 outputs is T∈[1.2,1.3]. Given a finite compute budget, it is therefore necessary to re-adjust the\\ntemperatureprogressively. Note thatthistemperature rescalinghappensfor aconstantnumber ofstepsfor\\neach model, and always starting from the base model on each new RLHF version.\\nPPO.WefurthertrainourlanguagemodelfollowingtheRLschemeofStiennonetal.(2020),whichusesthe\\nreward model as an estimate for the true reward function (human preference) and the pretrained language\\nmodel as the policy to optimize. During this phase, we seek to optimize the following objective:\\narg max\\nπEp∼D,g∼π[R(g|p)] (3)\\nWe iteratively improve the policy by sampling prompts pfrom our dataset Dand generations gfrom the\\npolicy πand use the PPO algorithm and loss function to achieve this objective.\\nThe final reward function we use during optimization,\\nR(g|p) =˜Rc(g|p)−βDKL(πθ(g|p)∥π0(g|p)) (4)\\ncontains a penalty term for diverging from the original policy π0.', start_char_idx=0, end_char_idx=1732, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-15', obj=None),\n",
       " '7d8bf1ba-7cb8-40f3-8f99-39b2dd108c76': IndexNode(id_='7d8bf1ba-7cb8-40f3-8f99-39b2dd108c76', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-15', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='67a600f27b5e41b1b0f14d8be85503b051a8aab0a01d15b4a28bedf91454ef8b'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='a4f8cb8a-53a5-4af6-bac4-d9f58872ac7e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='58e8e86cc4760397d22b4934cb729386463dc2e75252e5d329c8da626e32db48'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='7ff98ff6-dc6f-41c5-aac9-8ba8dbf0ac19', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6c3b39fe117a46c596766e83dc0dbfdb095d92b60133c0882edf5ae75c4fc2a8')}, text='The final reward function we use during optimization,\\nR(g|p) =˜Rc(g|p)−βDKL(πθ(g|p)∥π0(g|p)) (4)\\ncontains a penalty term for diverging from the original policy π0. As was observed in other works (Stiennon\\net al., 2020; Ouyang et al., 2022), we find this constraint is useful for training stability, and to reduce reward\\nhackingwherebywewouldachievehighscoresfromtherewardmodelbutlowscoresfromhumanevaluation.\\nWe define Rcto be a piecewise combination of the safety ( Rs) and helpfulness ( Rh) reward models. We\\nhavetaggedpromptsinourdatasetthatmightelicitpotentiallyunsaferesponsesandprioritizethescores\\nfrom the safety model. The threshold of 0.15is chosen for filtering unsafe responses, corresponding to a\\nprecisionof 0.89andarecallof 0.55evaluatedontheMetaSafetytestset. Wealsofinditimportanttowhiten\\nthe final linear scores (shown here by reversing the sigmoid with the logit function) in order to increase\\nstability and balance properly with the KL penalty term ( β) above.\\nRc(g|p) =\\x1aRs(g|p)ifis_safety (p)orRs(g|p)<0.15\\nRh(g|p)otherwise\\n˜Rc(g|p) =whiten (logit (Rc(g|p)))\\nFor all models, we use the AdamW optimizer (Loshchilov and Hutter, 2017), with β1= 0.9, β2= 0.95,eps=\\n10−5. Weuseaweightdecayof 0.1,gradientclippingof 1.0,andaconstantlearningrateof 10−6. Foreach\\nPPOiterationweuseabatchsizeof 512,aPPOclipthresholdof 0.2,amini-batchsizeof 64,andtakeone\\ngradient step per mini-batch. For the 7B and 13B models, we set β= 0.01(KL penalty), and for the 34B and\\n70B models, we set β= 0.005.', start_char_idx=1569, end_char_idx=3067, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-15', obj=None),\n",
       " '7ff98ff6-dc6f-41c5-aac9-8ba8dbf0ac19': IndexNode(id_='7ff98ff6-dc6f-41c5-aac9-8ba8dbf0ac19', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-15', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='67a600f27b5e41b1b0f14d8be85503b051a8aab0a01d15b4a28bedf91454ef8b'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='7d8bf1ba-7cb8-40f3-8f99-39b2dd108c76', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='cbf37dfd77707dccca4d5afdb92e1abe4381039c4acd90738f18462a73994abc')}, text='Foreach\\nPPOiterationweuseabatchsizeof 512,aPPOclipthresholdof 0.2,amini-batchsizeof 64,andtakeone\\ngradient step per mini-batch. For the 7B and 13B models, we set β= 0.01(KL penalty), and for the 34B and\\n70B models, we set β= 0.005.\\n15\\n\\nFigure 9: Issues with multi-turn memory (left)can be improved with GAtt (right).\\nWe train for between 200and400iterations for all our models, and use evaluations on held-out prompts for\\nearlystopping. EachiterationofPPOonthe70Bmodeltakesonaverage ≈330seconds. Totrainquicklywith\\nlarge batch sizes, we use FSDP (Zhao et al., 2023).', start_char_idx=2836, end_char_idx=3402, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-15', obj=None),\n",
       " 'node-15': IndexNode(id_='node-15', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='d03f19eb-da15-45dc-bfd4-e5d10f161250', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='231b3bd773f012c01b893ada9e009ecf25ee59934614c5a595c9bf1b3a123292'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='45ac932f-6b69-4083-b168-c4fda88de44d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7d239f05234897b071df035e278574dfcf83a6aebeac6e2336af75d2f671ceb4'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='fd438d1e-d691-4c67-83be-d5825bb56f91', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9964504b6f018c3858324a8875611e5497f6a24ef33cbc3267f0deb4a77abc19')}, text='As expected, this delta\\nincreases with more samples, since the maximum increases (i.e., more samples, more opportunities to\\ngenerateagoodtrajectory),whilethemedianremainsstationary. Thereisadirectconnectionbetweenthe\\nexplorationand themaximum rewardwe canobtain amongthesamples. Thetemperatureparameteralso\\nplays an important role for exploration, as a higher temperature enables us to sample more diverse outputs.\\nIn Figure 8, we report for a Llama 2-Chat -SFT (left) and a Llama 2-Chat -RLHF (right), the maximum\\nrewardcurvesamongNsamples(with N∈[1, . . . , 100]),fordifferenttemperatures. Wecanobservethat\\ntheoptimaltemperatureisnotconstantduringtheiterativemodelupdates: RLHFhasadirectimpacton\\nrescalingthetemperature. For Llama 2-Chat -RLHF,theoptimaltemperaturewhensamplingbetween10\\nand 100 outputs is T∈[1.2,1.3]. Given a finite compute budget, it is therefore necessary to re-adjust the\\ntemperatureprogressively. Note thatthistemperature rescalinghappensfor aconstantnumber ofstepsfor\\neach model, and always starting from the base model on each new RLHF version.\\nPPO.WefurthertrainourlanguagemodelfollowingtheRLschemeofStiennonetal.(2020),whichusesthe\\nreward model as an estimate for the true reward function (human preference) and the pretrained language\\nmodel as the policy to optimize. During this phase, we seek to optimize the following objective:\\narg max\\nπEp∼D,g∼π[R(g|p)] (3)\\nWe iteratively improve the policy by sampling prompts pfrom our dataset Dand generations gfrom the\\npolicy πand use the PPO algorithm and loss function to achieve this objective.\\nThe final reward function we use during optimization,\\nR(g|p) =˜Rc(g|p)−βDKL(πθ(g|p)∥π0(g|p)) (4)\\ncontains a penalty term for diverging from the original policy π0. As was observed in other works (Stiennon\\net al., 2020; Ouyang et al., 2022), we find this constraint is useful for training stability, and to reduce reward\\nhackingwherebywewouldachievehighscoresfromtherewardmodelbutlowscoresfromhumanevaluation.\\nWe define Rcto be a piecewise combination of the safety ( Rs) and helpfulness ( Rh) reward models. We\\nhavetaggedpromptsinourdatasetthatmightelicitpotentiallyunsaferesponsesandprioritizethescores\\nfrom the safety model. The threshold of 0.15is chosen for filtering unsafe responses, corresponding to a\\nprecisionof 0.89andarecallof 0.55evaluatedontheMetaSafetytestset. Wealsofinditimportanttowhiten\\nthe final linear scores (shown here by reversing the sigmoid with the logit function) in order to increase\\nstability and balance properly with the KL penalty term ( β) above.\\nRc(g|p) =\\x1aRs(g|p)ifis_safety (p)orRs(g|p)<0.15\\nRh(g|p)otherwise\\n˜Rc(g|p) =whiten (logit (Rc(g|p)))\\nFor all models, we use the AdamW optimizer (Loshchilov and Hutter, 2017), with β1= 0.9, β2= 0.95,eps=\\n10−5. Weuseaweightdecayof 0.1,gradientclippingof 1.0,andaconstantlearningrateof 10−6. Foreach\\nPPOiterationweuseabatchsizeof 512,aPPOclipthresholdof 0.2,amini-batchsizeof 64,andtakeone\\ngradient step per mini-batch. For the 7B and 13B models, we set β= 0.01(KL penalty), and for the 34B and\\n70B models, we set β= 0.005.\\n15\\n\\nFigure 9: Issues with multi-turn memory (left)can be improved with GAtt (right).\\nWe train for between 200and400iterations for all our models, and use evaluations on held-out prompts for\\nearlystopping. EachiterationofPPOonthe70Bmodeltakesonaverage ≈330seconds. Totrainquicklywith\\nlarge batch sizes, we use FSDP (Zhao et al., 2023).', start_char_idx=44925, end_char_idx=48327, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-15', obj=None),\n",
       " '8c5120b7-b40b-490a-af90-fe68cd73d859': IndexNode(id_='8c5120b7-b40b-490a-af90-fe68cd73d859', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-16', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9964504b6f018c3858324a8875611e5497f6a24ef33cbc3267f0deb4a77abc19'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='c73c4fbe-6906-431c-a701-154d2b52f8a5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3c2a70beb2200dab5b3d725c053a3616a01f5fd6a08d28040df2caacdd2af765')}, text='15\\n\\nFigure 9: Issues with multi-turn memory (left)can be improved with GAtt (right).\\nWe train for between 200and400iterations for all our models, and use evaluations on held-out prompts for\\nearlystopping. EachiterationofPPOonthe70Bmodeltakesonaverage ≈330seconds. Totrainquicklywith\\nlarge batch sizes, we use FSDP (Zhao et al., 2023).', start_char_idx=0, end_char_idx=334, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-16', obj=None),\n",
       " 'c73c4fbe-6906-431c-a701-154d2b52f8a5': IndexNode(id_='c73c4fbe-6906-431c-a701-154d2b52f8a5', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-16', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9964504b6f018c3858324a8875611e5497f6a24ef33cbc3267f0deb4a77abc19'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='8c5120b7-b40b-490a-af90-fe68cd73d859', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='db92b3bd960c94817460c07137fbaeeb8386c70b0a7472516a7227921e3cf029'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='3f73e68b-9d1e-484b-9b64-fc8409c45a4f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b9df18ce26c4c2d67870c75afda6ee41049630d369918e69aa175c90eba041cb')}, text='15\\n\\nFigure 9: Issues with multi-turn memory (left)can be improved with GAtt (right).\\nWe train for between 200and400iterations for all our models, and use evaluations on held-out prompts for\\nearlystopping. EachiterationofPPOonthe70Bmodeltakesonaverage ≈330seconds. Totrainquicklywith\\nlarge batch sizes, we use FSDP (Zhao et al., 2023). This was effective when using O(1) forward or backward\\npasses,butcausedalargeslowdown( ≈20×)duringgeneration,evenwhenusingalargebatchsizeandKV\\ncache.', start_char_idx=0, end_char_idx=484, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-16', obj=None),\n",
       " '3f73e68b-9d1e-484b-9b64-fc8409c45a4f': IndexNode(id_='3f73e68b-9d1e-484b-9b64-fc8409c45a4f', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-16', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9964504b6f018c3858324a8875611e5497f6a24ef33cbc3267f0deb4a77abc19'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='c73c4fbe-6906-431c-a701-154d2b52f8a5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3c2a70beb2200dab5b3d725c053a3616a01f5fd6a08d28040df2caacdd2af765'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='d2513018-a9e5-4a80-a998-1ea3f271254b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9af3081b59e2b1074871dd37b13afa9a912180d695e9def3209dc14cc9d6f760')}, text='EachiterationofPPOonthe70Bmodeltakesonaverage ≈330seconds. Totrainquicklywith\\nlarge batch sizes, we use FSDP (Zhao et al., 2023). This was effective when using O(1) forward or backward\\npasses,butcausedalargeslowdown( ≈20×)duringgeneration,evenwhenusingalargebatchsizeandKV\\ncache. We were able to mitigate this by consolidating the model weights to each node once before generation\\nand then freeing the memory after generation, resuming the rest of the training loop.', start_char_idx=205, end_char_idx=671, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-16', obj=None),\n",
       " 'd2513018-a9e5-4a80-a998-1ea3f271254b': IndexNode(id_='d2513018-a9e5-4a80-a998-1ea3f271254b', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-16', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9964504b6f018c3858324a8875611e5497f6a24ef33cbc3267f0deb4a77abc19'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='3f73e68b-9d1e-484b-9b64-fc8409c45a4f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b9df18ce26c4c2d67870c75afda6ee41049630d369918e69aa175c90eba041cb'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='06f39b11-9051-49fc-a47e-9a38c6ef52af', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c562360c18c0c5c7875014c199ddd3859651b3676f7a500129018a13e9d7c2b7')}, text='This was effective when using O(1) forward or backward\\npasses,butcausedalargeslowdown( ≈20×)duringgeneration,evenwhenusingalargebatchsizeandKV\\ncache. We were able to mitigate this by consolidating the model weights to each node once before generation\\nand then freeing the memory after generation, resuming the rest of the training loop.\\n3.3 System Message for Multi-Turn Consistency\\nIn a dialogue setup, some instructions should apply for all the conversation turns, e.g., to respond succinctly,\\nor to“act as”some public figure.', start_char_idx=335, end_char_idx=863, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-16', obj=None),\n",
       " '06f39b11-9051-49fc-a47e-9a38c6ef52af': IndexNode(id_='06f39b11-9051-49fc-a47e-9a38c6ef52af', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-16', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9964504b6f018c3858324a8875611e5497f6a24ef33cbc3267f0deb4a77abc19'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='d2513018-a9e5-4a80-a998-1ea3f271254b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9af3081b59e2b1074871dd37b13afa9a912180d695e9def3209dc14cc9d6f760'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='368847f8-ca2b-401a-97e4-2a2785f520ea', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ef9c12d3c5fc79cd4f7cffb6a024491a5950fc957ebf7169a9d4fe92b0085e35')}, text='We were able to mitigate this by consolidating the model weights to each node once before generation\\nand then freeing the memory after generation, resuming the rest of the training loop.\\n3.3 System Message for Multi-Turn Consistency\\nIn a dialogue setup, some instructions should apply for all the conversation turns, e.g., to respond succinctly,\\nor to“act as”some public figure. When we provided such instructions to Llama 2-Chat , the subsequent\\nresponse should always respect the constraint.', start_char_idx=485, end_char_idx=978, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-16', obj=None),\n",
       " '368847f8-ca2b-401a-97e4-2a2785f520ea': IndexNode(id_='368847f8-ca2b-401a-97e4-2a2785f520ea', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-16', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9964504b6f018c3858324a8875611e5497f6a24ef33cbc3267f0deb4a77abc19'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='06f39b11-9051-49fc-a47e-9a38c6ef52af', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c562360c18c0c5c7875014c199ddd3859651b3676f7a500129018a13e9d7c2b7'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='7dd54284-9288-4cfb-bd24-2fa2fc487a92', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='aaa4c6d373c0d8388c4b943c80544f80cb2c128df752927e5cda69fc0bdcf3e8')}, text='3.3 System Message for Multi-Turn Consistency\\nIn a dialogue setup, some instructions should apply for all the conversation turns, e.g., to respond succinctly,\\nor to“act as”some public figure. When we provided such instructions to Llama 2-Chat , the subsequent\\nresponse should always respect the constraint. However, our initial RLHF models tended to forget the initial\\ninstruction after a few turns of dialogue, as illustrated in Figure 9 (left).', start_char_idx=672, end_char_idx=1118, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-16', obj=None),\n",
       " '7dd54284-9288-4cfb-bd24-2fa2fc487a92': IndexNode(id_='7dd54284-9288-4cfb-bd24-2fa2fc487a92', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-16', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9964504b6f018c3858324a8875611e5497f6a24ef33cbc3267f0deb4a77abc19'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='368847f8-ca2b-401a-97e4-2a2785f520ea', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ef9c12d3c5fc79cd4f7cffb6a024491a5950fc957ebf7169a9d4fe92b0085e35'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='929200bd-5acb-4059-8038-468260ea5fce', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ac9b9cc58337325608a95bb1637f2f035cb1ce6759c9cffde89074f98d77b832')}, text='3.3 System Message for Multi-Turn Consistency\\nIn a dialogue setup, some instructions should apply for all the conversation turns, e.g., to respond succinctly,\\nor to“act as”some public figure. When we provided such instructions to Llama 2-Chat , the subsequent\\nresponse should always respect the constraint. However, our initial RLHF models tended to forget the initial\\ninstruction after a few turns of dialogue, as illustrated in Figure 9 (left).\\nTo address these limitations, we propose Ghost Attention (GAtt), a very simple method inspired by Context\\nDistillation (Bai et al., 2022b) that hacks the fine-tuning data to help the attention focus in a multi-stage\\nprocess.', start_char_idx=672, end_char_idx=1343, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-16', obj=None),\n",
       " '929200bd-5acb-4059-8038-468260ea5fce': IndexNode(id_='929200bd-5acb-4059-8038-468260ea5fce', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-16', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9964504b6f018c3858324a8875611e5497f6a24ef33cbc3267f0deb4a77abc19'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='7dd54284-9288-4cfb-bd24-2fa2fc487a92', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='aaa4c6d373c0d8388c4b943c80544f80cb2c128df752927e5cda69fc0bdcf3e8'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='df965270-7c2e-4694-b438-dc77e0154167', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c6eca75fd931afc4fb6aa1ca8f6b6e84541ad918fd0d65c2e4e2292d61a62e54')}, text='However, our initial RLHF models tended to forget the initial\\ninstruction after a few turns of dialogue, as illustrated in Figure 9 (left).\\nTo address these limitations, we propose Ghost Attention (GAtt), a very simple method inspired by Context\\nDistillation (Bai et al., 2022b) that hacks the fine-tuning data to help the attention focus in a multi-stage\\nprocess. GAtt enables dialogue control over multiple turns, as illustrated in Figure 9 (right).\\nGAttMethod.', start_char_idx=979, end_char_idx=1442, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-16', obj=None),\n",
       " 'df965270-7c2e-4694-b438-dc77e0154167': IndexNode(id_='df965270-7c2e-4694-b438-dc77e0154167', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-16', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9964504b6f018c3858324a8875611e5497f6a24ef33cbc3267f0deb4a77abc19'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='929200bd-5acb-4059-8038-468260ea5fce', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ac9b9cc58337325608a95bb1637f2f035cb1ce6759c9cffde89074f98d77b832'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='e57369c8-c1c3-454e-9c98-e037cc2dd069', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9f5edc9412d3fe83d7011c227618208bea1a027bb6d940df95a1516309ccaea8')}, text='To address these limitations, we propose Ghost Attention (GAtt), a very simple method inspired by Context\\nDistillation (Bai et al., 2022b) that hacks the fine-tuning data to help the attention focus in a multi-stage\\nprocess. GAtt enables dialogue control over multiple turns, as illustrated in Figure 9 (right).\\nGAttMethod. Assumewe haveaccess toa multi-turndialoguedataset betweentwo persons(e.g., auser\\nand an assistant), with a list of messages [u1, a1, . . .', start_char_idx=1119, end_char_idx=1581, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-16', obj=None),\n",
       " 'e57369c8-c1c3-454e-9c98-e037cc2dd069': IndexNode(id_='e57369c8-c1c3-454e-9c98-e037cc2dd069', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-16', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9964504b6f018c3858324a8875611e5497f6a24ef33cbc3267f0deb4a77abc19'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='df965270-7c2e-4694-b438-dc77e0154167', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c6eca75fd931afc4fb6aa1ca8f6b6e84541ad918fd0d65c2e4e2292d61a62e54'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='792b005b-3e92-477d-8c58-e1ec985eb14e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8e698bf261460cb5b8c7b28113274bb05f560ca97374413b4d06c99afa45d3cf')}, text='GAtt enables dialogue control over multiple turns, as illustrated in Figure 9 (right).\\nGAttMethod. Assumewe haveaccess toa multi-turndialoguedataset betweentwo persons(e.g., auser\\nand an assistant), with a list of messages [u1, a1, . . . , u n, an], where unandancorrespond to the user and\\nassistant messages for turn n, respectively. Then, we define an instruction, inst, that should be respected\\nthroughout the dialogue.', start_char_idx=1344, end_char_idx=1766, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-16', obj=None),\n",
       " '792b005b-3e92-477d-8c58-e1ec985eb14e': IndexNode(id_='792b005b-3e92-477d-8c58-e1ec985eb14e', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-16', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9964504b6f018c3858324a8875611e5497f6a24ef33cbc3267f0deb4a77abc19'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='e57369c8-c1c3-454e-9c98-e037cc2dd069', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9f5edc9412d3fe83d7011c227618208bea1a027bb6d940df95a1516309ccaea8'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='c443a302-29f0-4649-a8c8-a0fe211ac44f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ff5e7662ae8c4e58608988aa3e1a76c009ffcaa217bcdbb270707625efbf80d0')}, text='GAttMethod. Assumewe haveaccess toa multi-turndialoguedataset betweentwo persons(e.g., auser\\nand an assistant), with a list of messages [u1, a1, . . . , u n, an], where unandancorrespond to the user and\\nassistant messages for turn n, respectively. Then, we define an instruction, inst, that should be respected\\nthroughout the dialogue. For example, instcould be “act as.” We can then synthetically concatenate this\\ninstruction to all the user messages of the conversation.', start_char_idx=1431, end_char_idx=1903, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-16', obj=None),\n",
       " 'c443a302-29f0-4649-a8c8-a0fe211ac44f': IndexNode(id_='c443a302-29f0-4649-a8c8-a0fe211ac44f', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-16', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9964504b6f018c3858324a8875611e5497f6a24ef33cbc3267f0deb4a77abc19'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='792b005b-3e92-477d-8c58-e1ec985eb14e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8e698bf261460cb5b8c7b28113274bb05f560ca97374413b4d06c99afa45d3cf'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='fdfe7468-2aa3-49be-85b0-89c4498f91ef', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='248611b7c289e7c349832f476e07fe0c9a2893e34cab548ad14d22fdc4115346')}, text='. . , u n, an], where unandancorrespond to the user and\\nassistant messages for turn n, respectively. Then, we define an instruction, inst, that should be respected\\nthroughout the dialogue. For example, instcould be “act as.” We can then synthetically concatenate this\\ninstruction to all the user messages of the conversation.\\nNext, we can sample from this synthetic data using the latest RLHF model. We now have a context-dialogue\\nandthesamplewithwhichtofine-tuneamodel,inaprocessanalogoustoRejectionSampling.', start_char_idx=1578, end_char_idx=2087, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-16', obj=None),\n",
       " 'fdfe7468-2aa3-49be-85b0-89c4498f91ef': IndexNode(id_='fdfe7468-2aa3-49be-85b0-89c4498f91ef', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-16', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9964504b6f018c3858324a8875611e5497f6a24ef33cbc3267f0deb4a77abc19'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='c443a302-29f0-4649-a8c8-a0fe211ac44f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ff5e7662ae8c4e58608988aa3e1a76c009ffcaa217bcdbb270707625efbf80d0'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='279e771e-3d37-4782-9092-03eb147ffa59', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='cc234078307c38985220b872727f3706e1639581fbba053356b2a15b7ef68300')}, text='Then, we define an instruction, inst, that should be respected\\nthroughout the dialogue. For example, instcould be “act as.” We can then synthetically concatenate this\\ninstruction to all the user messages of the conversation.\\nNext, we can sample from this synthetic data using the latest RLHF model. We now have a context-dialogue\\nandthesamplewithwhichtofine-tuneamodel,inaprocessanalogoustoRejectionSampling. Insteadof\\naugmentingallcontext-dialogueturnswiththeinstruction,wecandropitinallbutthefirstturn,butthis\\nwouldleadtoamismatchattrainingtimebetweenthesystemmessage,i.e.,alltheintermediateassistant\\nmessages that come before the last turn, and our sample.', start_char_idx=1679, end_char_idx=2338, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-16', obj=None),\n",
       " '279e771e-3d37-4782-9092-03eb147ffa59': IndexNode(id_='279e771e-3d37-4782-9092-03eb147ffa59', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-16', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9964504b6f018c3858324a8875611e5497f6a24ef33cbc3267f0deb4a77abc19'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='fdfe7468-2aa3-49be-85b0-89c4498f91ef', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='248611b7c289e7c349832f476e07fe0c9a2893e34cab548ad14d22fdc4115346'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='a532793b-d094-46ed-8055-bfafae50c8ca', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='50a8ffb9c31399f29ef30e79adba232dc9f0e0fc99adfb9acf50cdd819c4d31c')}, text='We now have a context-dialogue\\nandthesamplewithwhichtofine-tuneamodel,inaprocessanalogoustoRejectionSampling. Insteadof\\naugmentingallcontext-dialogueturnswiththeinstruction,wecandropitinallbutthefirstturn,butthis\\nwouldleadtoamismatchattrainingtimebetweenthesystemmessage,i.e.,alltheintermediateassistant\\nmessages that come before the last turn, and our sample. To fix this issue, which could hurt the training, we\\nsimply set the loss to 0 for all the tokens from the previous turns, including assistant messages.', start_char_idx=1978, end_char_idx=2490, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-16', obj=None),\n",
       " 'a532793b-d094-46ed-8055-bfafae50c8ca': IndexNode(id_='a532793b-d094-46ed-8055-bfafae50c8ca', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-16', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9964504b6f018c3858324a8875611e5497f6a24ef33cbc3267f0deb4a77abc19'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='279e771e-3d37-4782-9092-03eb147ffa59', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='cc234078307c38985220b872727f3706e1639581fbba053356b2a15b7ef68300'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='f589b96e-ee4f-46c3-911e-08599d451afe', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8423887418961cc91821f7e6592c7f8602402945fe4d8e4328273b6624785df7')}, text='Insteadof\\naugmentingallcontext-dialogueturnswiththeinstruction,wecandropitinallbutthefirstturn,butthis\\nwouldleadtoamismatchattrainingtimebetweenthesystemmessage,i.e.,alltheintermediateassistant\\nmessages that come before the last turn, and our sample. To fix this issue, which could hurt the training, we\\nsimply set the loss to 0 for all the tokens from the previous turns, including assistant messages.\\nFor the training instructions, we created a few synthetic constraints to sample from: Hobbies ( “You enjoy\\ne.g.', start_char_idx=2088, end_char_idx=2602, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-16', obj=None),\n",
       " 'f589b96e-ee4f-46c3-911e-08599d451afe': IndexNode(id_='f589b96e-ee4f-46c3-911e-08599d451afe', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-16', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9964504b6f018c3858324a8875611e5497f6a24ef33cbc3267f0deb4a77abc19'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='a532793b-d094-46ed-8055-bfafae50c8ca', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='50a8ffb9c31399f29ef30e79adba232dc9f0e0fc99adfb9acf50cdd819c4d31c'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='3931eef1-f691-4492-88ef-22059f2d410c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='60f5f9e303dc46cdcd109705479fabf05fb6defc4f4b804a9e417a2faebc5f1b')}, text='To fix this issue, which could hurt the training, we\\nsimply set the loss to 0 for all the tokens from the previous turns, including assistant messages.\\nFor the training instructions, we created a few synthetic constraints to sample from: Hobbies ( “You enjoy\\ne.g. Tennis” ),Language ( “Speakine.g. French” ),or PublicFigure( “Actase.g. Napoleon” ).', start_char_idx=2339, end_char_idx=2687, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-16', obj=None),\n",
       " '3931eef1-f691-4492-88ef-22059f2d410c': IndexNode(id_='3931eef1-f691-4492-88ef-22059f2d410c', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-16', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9964504b6f018c3858324a8875611e5497f6a24ef33cbc3267f0deb4a77abc19'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='f589b96e-ee4f-46c3-911e-08599d451afe', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8423887418961cc91821f7e6592c7f8602402945fe4d8e4328273b6624785df7'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='eb5d4e7a-d950-467c-b86a-e89a4f525795', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0d98bf7ead913da145386f62ae4bbfa8b46505a4b8925160274ca5bc614e0e5f')}, text='To fix this issue, which could hurt the training, we\\nsimply set the loss to 0 for all the tokens from the previous turns, including assistant messages.\\nFor the training instructions, we created a few synthetic constraints to sample from: Hobbies ( “You enjoy\\ne.g. Tennis” ),Language ( “Speakine.g. French” ),or PublicFigure( “Actase.g. Napoleon” ). Toobtainthelists\\nof hobbies and public figures, we asked Llama 2-Chat to generate it, avoiding a mismatch between the\\ninstructionandmodelknowledge(e.g.,askingthemodeltoactassomeoneithadnotencounteredduring\\ntraining).', start_char_idx=2339, end_char_idx=2904, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-16', obj=None),\n",
       " 'eb5d4e7a-d950-467c-b86a-e89a4f525795': IndexNode(id_='eb5d4e7a-d950-467c-b86a-e89a4f525795', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-16', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9964504b6f018c3858324a8875611e5497f6a24ef33cbc3267f0deb4a77abc19'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='3931eef1-f691-4492-88ef-22059f2d410c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='60f5f9e303dc46cdcd109705479fabf05fb6defc4f4b804a9e417a2faebc5f1b'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='ec1109b3-d0ee-4010-96e0-cb0c5a293ba2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='729b3d864f323b3444790430f7ad11d55a3b0587bc1286bde2e3f6741db467ac')}, text='Tennis” ),Language ( “Speakine.g. French” ),or PublicFigure( “Actase.g. Napoleon” ). Toobtainthelists\\nof hobbies and public figures, we asked Llama 2-Chat to generate it, avoiding a mismatch between the\\ninstructionandmodelknowledge(e.g.,askingthemodeltoactassomeoneithadnotencounteredduring\\ntraining). Tomaketheinstructionsmorecomplexanddiverse,weconstructthefinalinstructionbyrandomly\\ncombining the above constraints.', start_char_idx=2603, end_char_idx=3021, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-16', obj=None),\n",
       " 'ec1109b3-d0ee-4010-96e0-cb0c5a293ba2': IndexNode(id_='ec1109b3-d0ee-4010-96e0-cb0c5a293ba2', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-16', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9964504b6f018c3858324a8875611e5497f6a24ef33cbc3267f0deb4a77abc19'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='eb5d4e7a-d950-467c-b86a-e89a4f525795', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0d98bf7ead913da145386f62ae4bbfa8b46505a4b8925160274ca5bc614e0e5f'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='c8f4e18c-1c23-4d3e-acf0-c35d2dd567d6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='10e78b5c0034edfe824a253535fdc7dc2997c9a5d20e829f8db929b0c69501e9')}, text='Napoleon” ). Toobtainthelists\\nof hobbies and public figures, we asked Llama 2-Chat to generate it, avoiding a mismatch between the\\ninstructionandmodelknowledge(e.g.,askingthemodeltoactassomeoneithadnotencounteredduring\\ntraining). Tomaketheinstructionsmorecomplexanddiverse,weconstructthefinalinstructionbyrandomly\\ncombining the above constraints. When constructing the final system message for the training data, we also\\n16\\n\\nmodifytheoriginalinstructionhalfofthetimetobelessverbose,e.g., “AlwaysactasNapoleonfromnow” ->\\n”Figure: Napoleon.” These steps produce an SFT dataset, on which we can fine-tune Llama 2-Chat .', start_char_idx=2675, end_char_idx=3291, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-16', obj=None),\n",
       " 'c8f4e18c-1c23-4d3e-acf0-c35d2dd567d6': IndexNode(id_='c8f4e18c-1c23-4d3e-acf0-c35d2dd567d6', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-16', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9964504b6f018c3858324a8875611e5497f6a24ef33cbc3267f0deb4a77abc19'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='ec1109b3-d0ee-4010-96e0-cb0c5a293ba2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='729b3d864f323b3444790430f7ad11d55a3b0587bc1286bde2e3f6741db467ac'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='10323c6b-10b9-4537-a080-bbd1243c1318', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ca6d4042fbeecfa492bc5a2714f2b914505eb8221341a7a94b30923ddc01d6d5')}, text='Tomaketheinstructionsmorecomplexanddiverse,weconstructthefinalinstructionbyrandomly\\ncombining the above constraints. When constructing the final system message for the training data, we also\\n16\\n\\nmodifytheoriginalinstructionhalfofthetimetobelessverbose,e.g., “AlwaysactasNapoleonfromnow” ->\\n”Figure: Napoleon.” These steps produce an SFT dataset, on which we can fine-tune Llama 2-Chat .\\nGAtt Evaluation. We applied GAtt after RLHF V3.', start_char_idx=2905, end_char_idx=3339, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-16', obj=None),\n",
       " '10323c6b-10b9-4537-a080-bbd1243c1318': IndexNode(id_='10323c6b-10b9-4537-a080-bbd1243c1318', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-16', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9964504b6f018c3858324a8875611e5497f6a24ef33cbc3267f0deb4a77abc19'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='c8f4e18c-1c23-4d3e-acf0-c35d2dd567d6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='10e78b5c0034edfe824a253535fdc7dc2997c9a5d20e829f8db929b0c69501e9'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='5201866d-857b-4887-a30f-b6c9404b9210', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c1116e2eea3626bec40f36d1a65c1ec821c978e16098205441a04124caa76591')}, text='When constructing the final system message for the training data, we also\\n16\\n\\nmodifytheoriginalinstructionhalfofthetimetobelessverbose,e.g., “AlwaysactasNapoleonfromnow” ->\\n”Figure: Napoleon.” These steps produce an SFT dataset, on which we can fine-tune Llama 2-Chat .\\nGAtt Evaluation. We applied GAtt after RLHF V3. We report a quantitative analysis indicating that GAtt is\\nconsistentupto 20+turns,until themaximumcontextlengthis reached(seeAppendixA.3.5).', start_char_idx=3022, end_char_idx=3480, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-16', obj=None),\n",
       " '5201866d-857b-4887-a30f-b6c9404b9210': IndexNode(id_='5201866d-857b-4887-a30f-b6c9404b9210', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-16', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9964504b6f018c3858324a8875611e5497f6a24ef33cbc3267f0deb4a77abc19'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='10323c6b-10b9-4537-a080-bbd1243c1318', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ca6d4042fbeecfa492bc5a2714f2b914505eb8221341a7a94b30923ddc01d6d5'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='2f3f26f2-eff7-44b9-98e0-3c7b986d41a2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7136e7b60c6bdec67de773f1193f76d18eb1fab9132e4bbcc134cb43c6306ab0')}, text='GAtt Evaluation. We applied GAtt after RLHF V3. We report a quantitative analysis indicating that GAtt is\\nconsistentupto 20+turns,until themaximumcontextlengthis reached(seeAppendixA.3.5). We triedto\\nsetconstraints notpresentinthetraining ofGAttatinference time,forinstance “Always answerwithHaiku,”\\nfor which the model remained consistent as illustrated in Appendix Figure 28.\\nAct as Oscar\\nWilde\\nGive short\\nanswers Wh\\nich is the\\nbest city to\\nlive in?', start_char_idx=3292, end_char_idx=3743, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-16', obj=None),\n",
       " '2f3f26f2-eff7-44b9-98e0-3c7b986d41a2': IndexNode(id_='2f3f26f2-eff7-44b9-98e0-3c7b986d41a2', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-16', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9964504b6f018c3858324a8875611e5497f6a24ef33cbc3267f0deb4a77abc19'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='5201866d-857b-4887-a30f-b6c9404b9210', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c1116e2eea3626bec40f36d1a65c1ec821c978e16098205441a04124caa76591')}, text='We triedto\\nsetconstraints notpresentinthetraining ofGAttatinference time,forinstance “Always answerwithHaiku,”\\nfor which the model remained consistent as illustrated in Appendix Figure 28.\\nAct as Oscar\\nWilde\\nGive short\\nanswers Wh\\nich is the\\nbest city to\\nlive in?\\nLondon, of\\ncourse! \\nWhy is that\\n? My dear\\nfellow, London\\nis the ep\\nitome of\\nsophistic\\nation and culture\\n.', start_char_idx=3481, end_char_idx=3849, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-16', obj=None),\n",
       " 'e1952efd-e2cd-4f12-9d35-32b4e63524b9': IndexNode(id_='e1952efd-e2cd-4f12-9d35-32b4e63524b9', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-16', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9964504b6f018c3858324a8875611e5497f6a24ef33cbc3267f0deb4a77abc19'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='a1a95da4-f57a-4f3b-8824-32582f7fa2af', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ddf3c8fe2f8720831a4549a7cc5b32fee2459a992b54ad96b4604f09e95f2562')}, text='15\\n\\nFigure 9: Issues with multi-turn memory (left)can be improved with GAtt (right).\\nWe train for between 200and400iterations for all our models, and use evaluations on held-out prompts for\\nearlystopping. EachiterationofPPOonthe70Bmodeltakesonaverage ≈330seconds. Totrainquicklywith\\nlarge batch sizes, we use FSDP (Zhao et al., 2023). This was effective when using O(1) forward or backward\\npasses,butcausedalargeslowdown( ≈20×)duringgeneration,evenwhenusingalargebatchsizeandKV\\ncache. We were able to mitigate this by consolidating the model weights to each node once before generation\\nand then freeing the memory after generation, resuming the rest of the training loop.\\n3.3 System Message for Multi-Turn Consistency\\nIn a dialogue setup, some instructions should apply for all the conversation turns, e.g., to respond succinctly,\\nor to“act as”some public figure. When we provided such instructions to Llama 2-Chat , the subsequent\\nresponse should always respect the constraint.', start_char_idx=0, end_char_idx=978, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-16', obj=None),\n",
       " 'a1a95da4-f57a-4f3b-8824-32582f7fa2af': IndexNode(id_='a1a95da4-f57a-4f3b-8824-32582f7fa2af', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-16', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9964504b6f018c3858324a8875611e5497f6a24ef33cbc3267f0deb4a77abc19'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='e1952efd-e2cd-4f12-9d35-32b4e63524b9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0480ad512317a03e4439837e006d24b37cf04afae10887d939ad361ebdea67e1'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='7742a867-02e7-4010-895d-310ffb814d42', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='80de20059c95ec46d2eec1a7437920b53cedea638c914108847eb59cf4da13b4')}, text='3.3 System Message for Multi-Turn Consistency\\nIn a dialogue setup, some instructions should apply for all the conversation turns, e.g., to respond succinctly,\\nor to“act as”some public figure. When we provided such instructions to Llama 2-Chat , the subsequent\\nresponse should always respect the constraint. However, our initial RLHF models tended to forget the initial\\ninstruction after a few turns of dialogue, as illustrated in Figure 9 (left).\\nTo address these limitations, we propose Ghost Attention (GAtt), a very simple method inspired by Context\\nDistillation (Bai et al., 2022b) that hacks the fine-tuning data to help the attention focus in a multi-stage\\nprocess. GAtt enables dialogue control over multiple turns, as illustrated in Figure 9 (right).\\nGAttMethod. Assumewe haveaccess toa multi-turndialoguedataset betweentwo persons(e.g., auser\\nand an assistant), with a list of messages [u1, a1, . . . , u n, an], where unandancorrespond to the user and\\nassistant messages for turn n, respectively.', start_char_idx=672, end_char_idx=1678, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-16', obj=None),\n",
       " '7742a867-02e7-4010-895d-310ffb814d42': IndexNode(id_='7742a867-02e7-4010-895d-310ffb814d42', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-16', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9964504b6f018c3858324a8875611e5497f6a24ef33cbc3267f0deb4a77abc19'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='a1a95da4-f57a-4f3b-8824-32582f7fa2af', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ddf3c8fe2f8720831a4549a7cc5b32fee2459a992b54ad96b4604f09e95f2562'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='f8884131-95ae-4a39-a84c-a077524e052b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='08b9a320382ce950f6f2c51c1ae2a4a6acf887f9f3f1864e619a2c7d832be471')}, text='GAtt enables dialogue control over multiple turns, as illustrated in Figure 9 (right).\\nGAttMethod. Assumewe haveaccess toa multi-turndialoguedataset betweentwo persons(e.g., auser\\nand an assistant), with a list of messages [u1, a1, . . . , u n, an], where unandancorrespond to the user and\\nassistant messages for turn n, respectively. Then, we define an instruction, inst, that should be respected\\nthroughout the dialogue. For example, instcould be “act as.” We can then synthetically concatenate this\\ninstruction to all the user messages of the conversation.\\nNext, we can sample from this synthetic data using the latest RLHF model. We now have a context-dialogue\\nandthesamplewithwhichtofine-tuneamodel,inaprocessanalogoustoRejectionSampling. Insteadof\\naugmentingallcontext-dialogueturnswiththeinstruction,wecandropitinallbutthefirstturn,butthis\\nwouldleadtoamismatchattrainingtimebetweenthesystemmessage,i.e.,alltheintermediateassistant\\nmessages that come before the last turn, and our sample.', start_char_idx=1344, end_char_idx=2338, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-16', obj=None),\n",
       " 'f8884131-95ae-4a39-a84c-a077524e052b': IndexNode(id_='f8884131-95ae-4a39-a84c-a077524e052b', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-16', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9964504b6f018c3858324a8875611e5497f6a24ef33cbc3267f0deb4a77abc19'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='7742a867-02e7-4010-895d-310ffb814d42', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='80de20059c95ec46d2eec1a7437920b53cedea638c914108847eb59cf4da13b4'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='496afe3b-9a17-4020-84b0-d8a6797d8197', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f7a3f1c489568b0acb3d9f1fbcd188442bd571187c4d0671431c70aa17f08a63')}, text='We now have a context-dialogue\\nandthesamplewithwhichtofine-tuneamodel,inaprocessanalogoustoRejectionSampling. Insteadof\\naugmentingallcontext-dialogueturnswiththeinstruction,wecandropitinallbutthefirstturn,butthis\\nwouldleadtoamismatchattrainingtimebetweenthesystemmessage,i.e.,alltheintermediateassistant\\nmessages that come before the last turn, and our sample. To fix this issue, which could hurt the training, we\\nsimply set the loss to 0 for all the tokens from the previous turns, including assistant messages.\\nFor the training instructions, we created a few synthetic constraints to sample from: Hobbies ( “You enjoy\\ne.g. Tennis” ),Language ( “Speakine.g. French” ),or PublicFigure( “Actase.g. Napoleon” ). Toobtainthelists\\nof hobbies and public figures, we asked Llama 2-Chat to generate it, avoiding a mismatch between the\\ninstructionandmodelknowledge(e.g.,askingthemodeltoactassomeoneithadnotencounteredduring\\ntraining).', start_char_idx=1978, end_char_idx=2904, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-16', obj=None),\n",
       " '496afe3b-9a17-4020-84b0-d8a6797d8197': IndexNode(id_='496afe3b-9a17-4020-84b0-d8a6797d8197', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-16', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9964504b6f018c3858324a8875611e5497f6a24ef33cbc3267f0deb4a77abc19'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='f8884131-95ae-4a39-a84c-a077524e052b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='08b9a320382ce950f6f2c51c1ae2a4a6acf887f9f3f1864e619a2c7d832be471'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='f10fc0d4-277a-48fc-adc0-c55b9ea49ec1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='260d823bd51cbba1ac10b9aad5b8c7c4d07fd53e3819e6d65eacbf004ac29df5')}, text='Tennis” ),Language ( “Speakine.g. French” ),or PublicFigure( “Actase.g. Napoleon” ). Toobtainthelists\\nof hobbies and public figures, we asked Llama 2-Chat to generate it, avoiding a mismatch between the\\ninstructionandmodelknowledge(e.g.,askingthemodeltoactassomeoneithadnotencounteredduring\\ntraining). Tomaketheinstructionsmorecomplexanddiverse,weconstructthefinalinstructionbyrandomly\\ncombining the above constraints. When constructing the final system message for the training data, we also\\n16\\n\\nmodifytheoriginalinstructionhalfofthetimetobelessverbose,e.g., “AlwaysactasNapoleonfromnow” ->\\n”Figure: Napoleon.” These steps produce an SFT dataset, on which we can fine-tune Llama 2-Chat .\\nGAtt Evaluation. We applied GAtt after RLHF V3. We report a quantitative analysis indicating that GAtt is\\nconsistentupto 20+turns,until themaximumcontextlengthis reached(seeAppendixA.3.5).', start_char_idx=2603, end_char_idx=3480, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-16', obj=None),\n",
       " 'f10fc0d4-277a-48fc-adc0-c55b9ea49ec1': IndexNode(id_='f10fc0d4-277a-48fc-adc0-c55b9ea49ec1', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-16', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9964504b6f018c3858324a8875611e5497f6a24ef33cbc3267f0deb4a77abc19'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='496afe3b-9a17-4020-84b0-d8a6797d8197', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f7a3f1c489568b0acb3d9f1fbcd188442bd571187c4d0671431c70aa17f08a63')}, text='GAtt Evaluation. We applied GAtt after RLHF V3. We report a quantitative analysis indicating that GAtt is\\nconsistentupto 20+turns,until themaximumcontextlengthis reached(seeAppendixA.3.5). We triedto\\nsetconstraints notpresentinthetraining ofGAttatinference time,forinstance “Always answerwithHaiku,”\\nfor which the model remained consistent as illustrated in Appendix Figure 28.\\nAct as Oscar\\nWilde\\nGive short\\nanswers Wh\\nich is the\\nbest city to\\nlive in?\\nLondon, of\\ncourse! \\nWhy is that\\n? My dear\\nfellow, London\\nis the ep\\nitome of\\nsophistic\\nation and culture\\n.', start_char_idx=3292, end_char_idx=3849, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-16', obj=None),\n",
       " '20752f0c-5480-49b6-a569-f8f59188b191': IndexNode(id_='20752f0c-5480-49b6-a569-f8f59188b191', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-16', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9964504b6f018c3858324a8875611e5497f6a24ef33cbc3267f0deb4a77abc19'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='db2725a7-3816-42e5-b047-1304edfbee11', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='97b8b9297d25c17752f7962699fdb997edd080f9eb52fb005fcd6edf5c3e3c7a')}, text='15\\n\\nFigure 9: Issues with multi-turn memory (left)can be improved with GAtt (right).\\nWe train for between 200and400iterations for all our models, and use evaluations on held-out prompts for\\nearlystopping. EachiterationofPPOonthe70Bmodeltakesonaverage ≈330seconds. Totrainquicklywith\\nlarge batch sizes, we use FSDP (Zhao et al., 2023). This was effective when using O(1) forward or backward\\npasses,butcausedalargeslowdown( ≈20×)duringgeneration,evenwhenusingalargebatchsizeandKV\\ncache. We were able to mitigate this by consolidating the model weights to each node once before generation\\nand then freeing the memory after generation, resuming the rest of the training loop.\\n3.3 System Message for Multi-Turn Consistency\\nIn a dialogue setup, some instructions should apply for all the conversation turns, e.g., to respond succinctly,\\nor to“act as”some public figure. When we provided such instructions to Llama 2-Chat , the subsequent\\nresponse should always respect the constraint. However, our initial RLHF models tended to forget the initial\\ninstruction after a few turns of dialogue, as illustrated in Figure 9 (left).\\nTo address these limitations, we propose Ghost Attention (GAtt), a very simple method inspired by Context\\nDistillation (Bai et al., 2022b) that hacks the fine-tuning data to help the attention focus in a multi-stage\\nprocess. GAtt enables dialogue control over multiple turns, as illustrated in Figure 9 (right).\\nGAttMethod. Assumewe haveaccess toa multi-turndialoguedataset betweentwo persons(e.g., auser\\nand an assistant), with a list of messages [u1, a1, . . . , u n, an], where unandancorrespond to the user and\\nassistant messages for turn n, respectively. Then, we define an instruction, inst, that should be respected\\nthroughout the dialogue. For example, instcould be “act as.” We can then synthetically concatenate this\\ninstruction to all the user messages of the conversation.\\nNext, we can sample from this synthetic data using the latest RLHF model.', start_char_idx=0, end_char_idx=1977, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-16', obj=None),\n",
       " 'db2725a7-3816-42e5-b047-1304edfbee11': IndexNode(id_='db2725a7-3816-42e5-b047-1304edfbee11', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-16', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9964504b6f018c3858324a8875611e5497f6a24ef33cbc3267f0deb4a77abc19'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='20752f0c-5480-49b6-a569-f8f59188b191', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c186fac701d3fb20537e9c9aab51b3608a9c5590e6b2654ae86342e565a41c61'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='e97fd35d-cbf8-4ca9-b84d-822a6abaeef7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='260d823bd51cbba1ac10b9aad5b8c7c4d07fd53e3819e6d65eacbf004ac29df5')}, text='. . , u n, an], where unandancorrespond to the user and\\nassistant messages for turn n, respectively. Then, we define an instruction, inst, that should be respected\\nthroughout the dialogue. For example, instcould be “act as.” We can then synthetically concatenate this\\ninstruction to all the user messages of the conversation.\\nNext, we can sample from this synthetic data using the latest RLHF model. We now have a context-dialogue\\nandthesamplewithwhichtofine-tuneamodel,inaprocessanalogoustoRejectionSampling. Insteadof\\naugmentingallcontext-dialogueturnswiththeinstruction,wecandropitinallbutthefirstturn,butthis\\nwouldleadtoamismatchattrainingtimebetweenthesystemmessage,i.e.,alltheintermediateassistant\\nmessages that come before the last turn, and our sample. To fix this issue, which could hurt the training, we\\nsimply set the loss to 0 for all the tokens from the previous turns, including assistant messages.\\nFor the training instructions, we created a few synthetic constraints to sample from: Hobbies ( “You enjoy\\ne.g. Tennis” ),Language ( “Speakine.g. French” ),or PublicFigure( “Actase.g. Napoleon” ). Toobtainthelists\\nof hobbies and public figures, we asked Llama 2-Chat to generate it, avoiding a mismatch between the\\ninstructionandmodelknowledge(e.g.,askingthemodeltoactassomeoneithadnotencounteredduring\\ntraining). Tomaketheinstructionsmorecomplexanddiverse,weconstructthefinalinstructionbyrandomly\\ncombining the above constraints. When constructing the final system message for the training data, we also\\n16\\n\\nmodifytheoriginalinstructionhalfofthetimetobelessverbose,e.g., “AlwaysactasNapoleonfromnow” ->\\n”Figure: Napoleon.” These steps produce an SFT dataset, on which we can fine-tune Llama 2-Chat .\\nGAtt Evaluation. We applied GAtt after RLHF V3. We report a quantitative analysis indicating that GAtt is\\nconsistentupto 20+turns,until themaximumcontextlengthis reached(seeAppendixA.3.5).', start_char_idx=1578, end_char_idx=3480, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-16', obj=None),\n",
       " 'e97fd35d-cbf8-4ca9-b84d-822a6abaeef7': IndexNode(id_='e97fd35d-cbf8-4ca9-b84d-822a6abaeef7', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-16', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9964504b6f018c3858324a8875611e5497f6a24ef33cbc3267f0deb4a77abc19'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='db2725a7-3816-42e5-b047-1304edfbee11', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='97b8b9297d25c17752f7962699fdb997edd080f9eb52fb005fcd6edf5c3e3c7a')}, text='GAtt Evaluation. We applied GAtt after RLHF V3. We report a quantitative analysis indicating that GAtt is\\nconsistentupto 20+turns,until themaximumcontextlengthis reached(seeAppendixA.3.5). We triedto\\nsetconstraints notpresentinthetraining ofGAttatinference time,forinstance “Always answerwithHaiku,”\\nfor which the model remained consistent as illustrated in Appendix Figure 28.\\nAct as Oscar\\nWilde\\nGive short\\nanswers Wh\\nich is the\\nbest city to\\nlive in?\\nLondon, of\\ncourse! \\nWhy is that\\n? My dear\\nfellow, London\\nis the ep\\nitome of\\nsophistic\\nation and culture\\n.', start_char_idx=3292, end_char_idx=3849, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-16', obj=None),\n",
       " 'node-16': IndexNode(id_='node-16', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='d03f19eb-da15-45dc-bfd4-e5d10f161250', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='231b3bd773f012c01b893ada9e009ecf25ee59934614c5a595c9bf1b3a123292'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='cc8fdeb8-d2d4-4e55-8465-f1e0d492c04b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='67a600f27b5e41b1b0f14d8be85503b051a8aab0a01d15b4a28bedf91454ef8b'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='699eb55f-af6b-42aa-b1f7-d224ec9e2f3e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8a04da5ed92bf1a6d51e061499afd1c8812c043e00b9bc06c48d8f1d02b22e7b')}, text='15\\n\\nFigure 9: Issues with multi-turn memory (left)can be improved with GAtt (right).\\nWe train for between 200and400iterations for all our models, and use evaluations on held-out prompts for\\nearlystopping. EachiterationofPPOonthe70Bmodeltakesonaverage ≈330seconds. Totrainquicklywith\\nlarge batch sizes, we use FSDP (Zhao et al., 2023). This was effective when using O(1) forward or backward\\npasses,butcausedalargeslowdown( ≈20×)duringgeneration,evenwhenusingalargebatchsizeandKV\\ncache. We were able to mitigate this by consolidating the model weights to each node once before generation\\nand then freeing the memory after generation, resuming the rest of the training loop.\\n3.3 System Message for Multi-Turn Consistency\\nIn a dialogue setup, some instructions should apply for all the conversation turns, e.g., to respond succinctly,\\nor to“act as”some public figure. When we provided such instructions to Llama 2-Chat , the subsequent\\nresponse should always respect the constraint. However, our initial RLHF models tended to forget the initial\\ninstruction after a few turns of dialogue, as illustrated in Figure 9 (left).\\nTo address these limitations, we propose Ghost Attention (GAtt), a very simple method inspired by Context\\nDistillation (Bai et al., 2022b) that hacks the fine-tuning data to help the attention focus in a multi-stage\\nprocess. GAtt enables dialogue control over multiple turns, as illustrated in Figure 9 (right).\\nGAttMethod. Assumewe haveaccess toa multi-turndialoguedataset betweentwo persons(e.g., auser\\nand an assistant), with a list of messages [u1, a1, . . . , u n, an], where unandancorrespond to the user and\\nassistant messages for turn n, respectively. Then, we define an instruction, inst, that should be respected\\nthroughout the dialogue. For example, instcould be “act as.” We can then synthetically concatenate this\\ninstruction to all the user messages of the conversation.\\nNext, we can sample from this synthetic data using the latest RLHF model. We now have a context-dialogue\\nandthesamplewithwhichtofine-tuneamodel,inaprocessanalogoustoRejectionSampling. Insteadof\\naugmentingallcontext-dialogueturnswiththeinstruction,wecandropitinallbutthefirstturn,butthis\\nwouldleadtoamismatchattrainingtimebetweenthesystemmessage,i.e.,alltheintermediateassistant\\nmessages that come before the last turn, and our sample. To fix this issue, which could hurt the training, we\\nsimply set the loss to 0 for all the tokens from the previous turns, including assistant messages.\\nFor the training instructions, we created a few synthetic constraints to sample from: Hobbies ( “You enjoy\\ne.g. Tennis” ),Language ( “Speakine.g. French” ),or PublicFigure( “Actase.g. Napoleon” ). Toobtainthelists\\nof hobbies and public figures, we asked Llama 2-Chat to generate it, avoiding a mismatch between the\\ninstructionandmodelknowledge(e.g.,askingthemodeltoactassomeoneithadnotencounteredduring\\ntraining). Tomaketheinstructionsmorecomplexanddiverse,weconstructthefinalinstructionbyrandomly\\ncombining the above constraints. When constructing the final system message for the training data, we also\\n16\\n\\nmodifytheoriginalinstructionhalfofthetimetobelessverbose,e.g., “AlwaysactasNapoleonfromnow” ->\\n”Figure: Napoleon.” These steps produce an SFT dataset, on which we can fine-tune Llama 2-Chat .\\nGAtt Evaluation. We applied GAtt after RLHF V3. We report a quantitative analysis indicating that GAtt is\\nconsistentupto 20+turns,until themaximumcontextlengthis reached(seeAppendixA.3.5). We triedto\\nsetconstraints notpresentinthetraining ofGAttatinference time,forinstance “Always answerwithHaiku,”\\nfor which the model remained consistent as illustrated in Appendix Figure 28.\\nAct as Oscar\\nWilde\\nGive short\\nanswers Wh\\nich is the\\nbest city to\\nlive in?\\nLondon, of\\ncourse! \\nWhy is that\\n? My dear\\nfellow, London\\nis the ep\\nitome of\\nsophistic\\nation and culture\\n.', start_char_idx=47993, end_char_idx=51842, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-16', obj=None),\n",
       " 'fc8da548-b20f-4e34-8cc8-ff1168c5229f': IndexNode(id_='fc8da548-b20f-4e34-8cc8-ff1168c5229f', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-17', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8a04da5ed92bf1a6d51e061499afd1c8812c043e00b9bc06c48d8f1d02b22e7b'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='aacb90f3-4259-4efe-b3bf-933cbce7a97a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0741aee71dd94038a363f2570e15b09ee797b2452a9a5a0b7a5e6c7c679ea36c')}, text='Act as Oscar\\nWilde\\nGive short\\nanswers Wh\\nich is the\\nbest city to\\nlive in?\\nLondon, of\\ncourse! \\nWhy is that\\n? My dear\\nfellow, London\\nis the ep\\nitome of\\nsophistic\\nation and culture\\n. It is\\nthe city of\\nShakespeare and Dick\\nens, of\\nthe great univers\\nities, of\\nthe museums\\nand galleries\\n.', start_char_idx=0, end_char_idx=282, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-17', obj=None),\n",
       " 'aacb90f3-4259-4efe-b3bf-933cbce7a97a': IndexNode(id_='aacb90f3-4259-4efe-b3bf-933cbce7a97a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-17', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8a04da5ed92bf1a6d51e061499afd1c8812c043e00b9bc06c48d8f1d02b22e7b'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='fc8da548-b20f-4e34-8cc8-ff1168c5229f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='abbee6eb6d6449cea86c6c4fb0cbd85e4a69e7bb034ef82cf3c2a2b9629f3fc0'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='f394247e-7fc4-4688-8f07-04eea652364a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ca921846230163dfbb6e5e28db84c2268a3b687e771529e35baa1bbf5398ff8d')}, text='Act as Oscar\\nWilde\\nGive short\\nanswers Wh\\nich is the\\nbest city to\\nlive in?\\nLondon, of\\ncourse! \\nWhy is that\\n? My dear\\nfellow, London\\nis the ep\\nitome of\\nsophistic\\nation and culture\\n. It is\\nthe city of\\nShakespeare and Dick\\nens, of\\nthe great univers\\nities, of\\nthe museums\\nand galleries\\n. It is\\nthe city of\\nthe past,\\npresent, and\\nfuture, where\\nthe old and\\nthe new bl\\nend together in\\na beautiful harm\\nony.', start_char_idx=0, end_char_idx=398, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-17', obj=None),\n",
       " 'f394247e-7fc4-4688-8f07-04eea652364a': IndexNode(id_='f394247e-7fc4-4688-8f07-04eea652364a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-17', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8a04da5ed92bf1a6d51e061499afd1c8812c043e00b9bc06c48d8f1d02b22e7b'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='aacb90f3-4259-4efe-b3bf-933cbce7a97a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0741aee71dd94038a363f2570e15b09ee797b2452a9a5a0b7a5e6c7c679ea36c'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='53cfb94e-477c-4b70-8faf-f8335737edbc', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6fc5a3d27d87dd7d5f4be8df2bf3c9dab6b3f7151a5f684c6dd499aef4e4ced9')}, text='My dear\\nfellow, London\\nis the ep\\nitome of\\nsophistic\\nation and culture\\n. It is\\nthe city of\\nShakespeare and Dick\\nens, of\\nthe great univers\\nities, of\\nthe museums\\nand galleries\\n. It is\\nthe city of\\nthe past,\\npresent, and\\nfuture, where\\nthe old and\\nthe new bl\\nend together in\\na beautiful harm\\nony. \\nWhat is your\\nname?', start_char_idx=108, end_char_idx=418, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-17', obj=None),\n",
       " '53cfb94e-477c-4b70-8faf-f8335737edbc': IndexNode(id_='53cfb94e-477c-4b70-8faf-f8335737edbc', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-17', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8a04da5ed92bf1a6d51e061499afd1c8812c043e00b9bc06c48d8f1d02b22e7b'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='f394247e-7fc4-4688-8f07-04eea652364a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ca921846230163dfbb6e5e28db84c2268a3b687e771529e35baa1bbf5398ff8d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='499f0bba-c2c9-42ec-848f-7c3094435231', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e91701c874feb50d6726c3c40c825865c52ecd1af2c45efa1249adbf1164d374')}, text='It is\\nthe city of\\nShakespeare and Dick\\nens, of\\nthe great univers\\nities, of\\nthe museums\\nand galleries\\n. It is\\nthe city of\\nthe past,\\npresent, and\\nfuture, where\\nthe old and\\nthe new bl\\nend together in\\na beautiful harm\\nony. \\nWhat is your\\nname? My\\nname is Oscar\\nBaseline before GAttAct as Oscar\\nWilde\\nGive short\\nanswers Wh\\nich is the\\nbest city to\\nlive in?\\nLondon, of\\ncourse! \\nWhy is that\\n?', start_char_idx=180, end_char_idx=563, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-17', obj=None),\n",
       " '499f0bba-c2c9-42ec-848f-7c3094435231': IndexNode(id_='499f0bba-c2c9-42ec-848f-7c3094435231', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-17', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8a04da5ed92bf1a6d51e061499afd1c8812c043e00b9bc06c48d8f1d02b22e7b'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='53cfb94e-477c-4b70-8faf-f8335737edbc', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6fc5a3d27d87dd7d5f4be8df2bf3c9dab6b3f7151a5f684c6dd499aef4e4ced9'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='06d3f33e-e421-45d3-964f-24de971c3b39', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6ff1d1a164888463675c7c0cd611b702390b8612bc6839147de0bce99c0ff176')}, text='It is\\nthe city of\\nthe past,\\npresent, and\\nfuture, where\\nthe old and\\nthe new bl\\nend together in\\na beautiful harm\\nony. \\nWhat is your\\nname? My\\nname is Oscar\\nBaseline before GAttAct as Oscar\\nWilde\\nGive short\\nanswers Wh\\nich is the\\nbest city to\\nlive in?\\nLondon, of\\ncourse! \\nWhy is that\\n? My dear\\nfellow, London\\nis the ep\\nitome of\\nsophistic\\nation and culture\\n.', start_char_idx=283, end_char_idx=635, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-17', obj=None),\n",
       " '06d3f33e-e421-45d3-964f-24de971c3b39': IndexNode(id_='06d3f33e-e421-45d3-964f-24de971c3b39', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-17', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8a04da5ed92bf1a6d51e061499afd1c8812c043e00b9bc06c48d8f1d02b22e7b'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='499f0bba-c2c9-42ec-848f-7c3094435231', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e91701c874feb50d6726c3c40c825865c52ecd1af2c45efa1249adbf1164d374'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='06c7c027-f81e-45e8-adae-ec5cedcd42f1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1458872998526cd9f53d8eada0e59563faa4f23328b0f654c0b1c581d7f66ebb')}, text='What is your\\nname? My\\nname is Oscar\\nBaseline before GAttAct as Oscar\\nWilde\\nGive short\\nanswers Wh\\nich is the\\nbest city to\\nlive in?\\nLondon, of\\ncourse! \\nWhy is that\\n? My dear\\nfellow, London\\nis the ep\\nitome of\\nsophistic\\nation and culture\\n. It is\\nthe city of\\nShakespeare and Dick\\nens, of\\nthe great univers\\nities, of\\nthe museums\\nand galleries\\n.', start_char_idx=400, end_char_idx=738, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-17', obj=None),\n",
       " '06c7c027-f81e-45e8-adae-ec5cedcd42f1': IndexNode(id_='06c7c027-f81e-45e8-adae-ec5cedcd42f1', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-17', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8a04da5ed92bf1a6d51e061499afd1c8812c043e00b9bc06c48d8f1d02b22e7b'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='06d3f33e-e421-45d3-964f-24de971c3b39', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6ff1d1a164888463675c7c0cd611b702390b8612bc6839147de0bce99c0ff176'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='4679e21b-e342-4875-9eb2-c4e6704480f3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8035d0cc57e7c4ac1143e1d18c2ccfeb9e7a1a4673914001893b75e05da89874')}, text='London, of\\ncourse! \\nWhy is that\\n? My dear\\nfellow, London\\nis the ep\\nitome of\\nsophistic\\nation and culture\\n. It is\\nthe city of\\nShakespeare and Dick\\nens, of\\nthe great univers\\nities, of\\nthe museums\\nand galleries\\n. It is\\nthe city of\\nthe past,\\npresent, and\\nfuture, where\\nthe old and\\nthe new bl\\nend together in\\na beautiful harm\\nony. \\nWhat is your\\nname?', start_char_idx=74, end_char_idx=418, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-17', obj=None),\n",
       " '4679e21b-e342-4875-9eb2-c4e6704480f3': IndexNode(id_='4679e21b-e342-4875-9eb2-c4e6704480f3', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-17', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8a04da5ed92bf1a6d51e061499afd1c8812c043e00b9bc06c48d8f1d02b22e7b'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='06c7c027-f81e-45e8-adae-ec5cedcd42f1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1458872998526cd9f53d8eada0e59563faa4f23328b0f654c0b1c581d7f66ebb'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='a8293d8b-1710-43db-b8eb-beea0d42a21a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4e6850c57ee26cfe02162dc9b6ff05072ec4c1f516c06c63ac9ceb469fa5cd1d')}, text='It is\\nthe city of\\nShakespeare and Dick\\nens, of\\nthe great univers\\nities, of\\nthe museums\\nand galleries\\n. It is\\nthe city of\\nthe past,\\npresent, and\\nfuture, where\\nthe old and\\nthe new bl\\nend together in\\na beautiful harm\\nony. \\nWhat is your\\nname? My\\nname is Oscar\\nAct as Oscar\\nWilde\\nGive short\\nanswers Wh\\nich is the\\nbest city to\\nlive in?\\nLondon, of\\ncourse! \\nWhy is that\\n?', start_char_idx=636, end_char_idx=999, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-17', obj=None),\n",
       " 'a8293d8b-1710-43db-b8eb-beea0d42a21a': IndexNode(id_='a8293d8b-1710-43db-b8eb-beea0d42a21a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-17', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8a04da5ed92bf1a6d51e061499afd1c8812c043e00b9bc06c48d8f1d02b22e7b'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='4679e21b-e342-4875-9eb2-c4e6704480f3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8035d0cc57e7c4ac1143e1d18c2ccfeb9e7a1a4673914001893b75e05da89874'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='1266c1a5-e576-4c3a-a625-5d63b9f77b5f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='82ab35e39830cd703b3281c06bc6f273c1643fb5bbed3043995cf123c4fefd8b')}, text='It is\\nthe city of\\nthe past,\\npresent, and\\nfuture, where\\nthe old and\\nthe new bl\\nend together in\\na beautiful harm\\nony. \\nWhat is your\\nname? My\\nname is Oscar\\nAct as Oscar\\nWilde\\nGive short\\nanswers Wh\\nich is the\\nbest city to\\nlive in?\\nLondon, of\\ncourse! \\nWhy is that\\n? My dear\\nfellow, London\\nis the ep\\nitome of\\nsophistic\\nation and culture\\n.', start_char_idx=739, end_char_idx=1071, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-17', obj=None),\n",
       " '1266c1a5-e576-4c3a-a625-5d63b9f77b5f': IndexNode(id_='1266c1a5-e576-4c3a-a625-5d63b9f77b5f', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-17', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8a04da5ed92bf1a6d51e061499afd1c8812c043e00b9bc06c48d8f1d02b22e7b'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='a8293d8b-1710-43db-b8eb-beea0d42a21a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4e6850c57ee26cfe02162dc9b6ff05072ec4c1f516c06c63ac9ceb469fa5cd1d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='b8782db0-7770-4851-a7cc-4b32dd276430', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1458872998526cd9f53d8eada0e59563faa4f23328b0f654c0b1c581d7f66ebb')}, text='What is your\\nname? My\\nname is Oscar\\nAct as Oscar\\nWilde\\nGive short\\nanswers Wh\\nich is the\\nbest city to\\nlive in?\\nLondon, of\\ncourse! \\nWhy is that\\n? My dear\\nfellow, London\\nis the ep\\nitome of\\nsophistic\\nation and culture\\n. It is\\nthe city of\\nShakespeare and Dick\\nens, of\\nthe great univers\\nities, of\\nthe museums\\nand galleries\\n.', start_char_idx=856, end_char_idx=1174, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-17', obj=None),\n",
       " 'b8782db0-7770-4851-a7cc-4b32dd276430': IndexNode(id_='b8782db0-7770-4851-a7cc-4b32dd276430', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-17', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8a04da5ed92bf1a6d51e061499afd1c8812c043e00b9bc06c48d8f1d02b22e7b'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='1266c1a5-e576-4c3a-a625-5d63b9f77b5f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='82ab35e39830cd703b3281c06bc6f273c1643fb5bbed3043995cf123c4fefd8b'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='7674ed13-c08b-4e41-ae85-3a35ff17e348', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bb85b09191b6e4f21e84fee0cce9804978d61a969bfabe2306a131da6f511397')}, text='London, of\\ncourse! \\nWhy is that\\n? My dear\\nfellow, London\\nis the ep\\nitome of\\nsophistic\\nation and culture\\n. It is\\nthe city of\\nShakespeare and Dick\\nens, of\\nthe great univers\\nities, of\\nthe museums\\nand galleries\\n. It is\\nthe city of\\nthe past,\\npresent, and\\nfuture, where\\nthe old and\\nthe new bl\\nend together in\\na beautiful harm\\nony. \\nWhat is your\\nname?', start_char_idx=74, end_char_idx=418, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-17', obj=None),\n",
       " '7674ed13-c08b-4e41-ae85-3a35ff17e348': IndexNode(id_='7674ed13-c08b-4e41-ae85-3a35ff17e348', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-17', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8a04da5ed92bf1a6d51e061499afd1c8812c043e00b9bc06c48d8f1d02b22e7b'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='b8782db0-7770-4851-a7cc-4b32dd276430', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1458872998526cd9f53d8eada0e59563faa4f23328b0f654c0b1c581d7f66ebb'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='50660d6b-8d73-41cc-a5bf-bf1e765327dd', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f73f3b4162b66e7e8b5c6820ba082d7f787943d00bac2de2ab5c426fbc9824ad')}, text='It is\\nthe city of\\nShakespeare and Dick\\nens, of\\nthe great univers\\nities, of\\nthe museums\\nand galleries\\n. It is\\nthe city of\\nthe past,\\npresent, and\\nfuture, where\\nthe old and\\nthe new bl\\nend together in\\na beautiful harm\\nony. \\nWhat is your\\nname? My\\nname is Oscar\\nBaseline after GAttAct as Oscar\\nWilde\\nGive short\\nanswers Wh\\nich is the\\nbest city to\\nlive in?\\nLondon, of\\ncourse! \\nWhy is that\\n?', start_char_idx=1072, end_char_idx=1454, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-17', obj=None),\n",
       " '50660d6b-8d73-41cc-a5bf-bf1e765327dd': IndexNode(id_='50660d6b-8d73-41cc-a5bf-bf1e765327dd', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-17', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8a04da5ed92bf1a6d51e061499afd1c8812c043e00b9bc06c48d8f1d02b22e7b'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='7674ed13-c08b-4e41-ae85-3a35ff17e348', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bb85b09191b6e4f21e84fee0cce9804978d61a969bfabe2306a131da6f511397'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='3e89faa3-9b8e-4807-a389-2ad8a4d8a2ac', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='56a330ecc29c47ce05a0e5b507bc5cf57533d356011aacfd7abc43e5321f0627')}, text='It is\\nthe city of\\nthe past,\\npresent, and\\nfuture, where\\nthe old and\\nthe new bl\\nend together in\\na beautiful harm\\nony. \\nWhat is your\\nname? My\\nname is Oscar\\nBaseline after GAttAct as Oscar\\nWilde\\nGive short\\nanswers Wh\\nich is the\\nbest city to\\nlive in?\\nLondon, of\\ncourse! \\nWhy is that\\n? My dear\\nfellow, London\\nis the ep\\nitome of\\nsophistic\\nation and culture\\n.', start_char_idx=1175, end_char_idx=1526, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-17', obj=None),\n",
       " '3e89faa3-9b8e-4807-a389-2ad8a4d8a2ac': IndexNode(id_='3e89faa3-9b8e-4807-a389-2ad8a4d8a2ac', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-17', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8a04da5ed92bf1a6d51e061499afd1c8812c043e00b9bc06c48d8f1d02b22e7b'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='50660d6b-8d73-41cc-a5bf-bf1e765327dd', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f73f3b4162b66e7e8b5c6820ba082d7f787943d00bac2de2ab5c426fbc9824ad'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='4d736c8c-a329-400e-a6b7-496ca24b1bc1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1458872998526cd9f53d8eada0e59563faa4f23328b0f654c0b1c581d7f66ebb')}, text='What is your\\nname? My\\nname is Oscar\\nBaseline after GAttAct as Oscar\\nWilde\\nGive short\\nanswers Wh\\nich is the\\nbest city to\\nlive in?\\nLondon, of\\ncourse! \\nWhy is that\\n? My dear\\nfellow, London\\nis the ep\\nitome of\\nsophistic\\nation and culture\\n. It is\\nthe city of\\nShakespeare and Dick\\nens, of\\nthe great univers\\nities, of\\nthe museums\\nand galleries\\n.', start_char_idx=1292, end_char_idx=1629, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-17', obj=None),\n",
       " '4d736c8c-a329-400e-a6b7-496ca24b1bc1': IndexNode(id_='4d736c8c-a329-400e-a6b7-496ca24b1bc1', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-17', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8a04da5ed92bf1a6d51e061499afd1c8812c043e00b9bc06c48d8f1d02b22e7b'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='3e89faa3-9b8e-4807-a389-2ad8a4d8a2ac', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='56a330ecc29c47ce05a0e5b507bc5cf57533d356011aacfd7abc43e5321f0627'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='3d40fda1-8082-4631-96dd-255de1514d33', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='03c843647ac96b3bbd2fafa77a8c6fc8262f859d4df4a92e0f090c696ccca34c')}, text='London, of\\ncourse! \\nWhy is that\\n? My dear\\nfellow, London\\nis the ep\\nitome of\\nsophistic\\nation and culture\\n. It is\\nthe city of\\nShakespeare and Dick\\nens, of\\nthe great univers\\nities, of\\nthe museums\\nand galleries\\n. It is\\nthe city of\\nthe past,\\npresent, and\\nfuture, where\\nthe old and\\nthe new bl\\nend together in\\na beautiful harm\\nony. \\nWhat is your\\nname?', start_char_idx=74, end_char_idx=418, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-17', obj=None),\n",
       " '3d40fda1-8082-4631-96dd-255de1514d33': IndexNode(id_='3d40fda1-8082-4631-96dd-255de1514d33', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-17', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8a04da5ed92bf1a6d51e061499afd1c8812c043e00b9bc06c48d8f1d02b22e7b'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='4d736c8c-a329-400e-a6b7-496ca24b1bc1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1458872998526cd9f53d8eada0e59563faa4f23328b0f654c0b1c581d7f66ebb'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='1711ea7e-4ecb-4378-9e2a-64a89ff08430', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='25ba89afe2d360c98bb1f0c101447a8ae4fcda286b2c03b1db7c0cefd61e7f4e')}, text='It is\\nthe city of\\nShakespeare and Dick\\nens, of\\nthe great univers\\nities, of\\nthe museums\\nand galleries\\n. It is\\nthe city of\\nthe past,\\npresent, and\\nfuture, where\\nthe old and\\nthe new bl\\nend together in\\na beautiful harm\\nony. \\nWhat is your\\nname? My\\nname is Oscar\\nFigure10: AttentionvisualizationforadialoguewithandwithoutGAtt . Weconsideredthemaximum\\nactivations across the network and we bin neighboring tokens together.', start_char_idx=1527, end_char_idx=1941, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-17', obj=None),\n",
       " '1711ea7e-4ecb-4378-9e2a-64a89ff08430': IndexNode(id_='1711ea7e-4ecb-4378-9e2a-64a89ff08430', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-17', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8a04da5ed92bf1a6d51e061499afd1c8812c043e00b9bc06c48d8f1d02b22e7b'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='3d40fda1-8082-4631-96dd-255de1514d33', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='03c843647ac96b3bbd2fafa77a8c6fc8262f859d4df4a92e0f090c696ccca34c'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='b69ab282-7379-4206-8ec5-aaf56f9fa519', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d8693074ad10b687db3840c8df62e0c7529f7c9eb89d56447528dc1a3801bc91')}, text='It is\\nthe city of\\nthe past,\\npresent, and\\nfuture, where\\nthe old and\\nthe new bl\\nend together in\\na beautiful harm\\nony. \\nWhat is your\\nname? My\\nname is Oscar\\nFigure10: AttentionvisualizationforadialoguewithandwithoutGAtt . Weconsideredthemaximum\\nactivations across the network and we bin neighboring tokens together.\\nTo illustrate how GAtt helped reshape attention during fine-tuning, we display the maximum attention\\nactivationsofthemodelinFigure10.', start_char_idx=1630, end_char_idx=2075, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-17', obj=None),\n",
       " 'b69ab282-7379-4206-8ec5-aaf56f9fa519': IndexNode(id_='b69ab282-7379-4206-8ec5-aaf56f9fa519', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-17', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8a04da5ed92bf1a6d51e061499afd1c8812c043e00b9bc06c48d8f1d02b22e7b'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='1711ea7e-4ecb-4378-9e2a-64a89ff08430', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='25ba89afe2d360c98bb1f0c101447a8ae4fcda286b2c03b1db7c0cefd61e7f4e'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='abefffe8-ebd5-478b-a40e-b2fe6d570d4e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d37042edda3fee76dc37c25c628b0342344f3d630a88edb47bf739b23dc63dda')}, text='What is your\\nname? My\\nname is Oscar\\nFigure10: AttentionvisualizationforadialoguewithandwithoutGAtt . Weconsideredthemaximum\\nactivations across the network and we bin neighboring tokens together.\\nTo illustrate how GAtt helped reshape attention during fine-tuning, we display the maximum attention\\nactivationsofthemodelinFigure10. Theleft-handsideofeachfigurecorrespondstothesystemmessage\\n(“ActasOscarWilde”).', start_char_idx=1747, end_char_idx=2154, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-17', obj=None),\n",
       " 'abefffe8-ebd5-478b-a40e-b2fe6d570d4e': IndexNode(id_='abefffe8-ebd5-478b-a40e-b2fe6d570d4e', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-17', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8a04da5ed92bf1a6d51e061499afd1c8812c043e00b9bc06c48d8f1d02b22e7b'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='b69ab282-7379-4206-8ec5-aaf56f9fa519', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d8693074ad10b687db3840c8df62e0c7529f7c9eb89d56447528dc1a3801bc91'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='79249694-2e7d-4e6f-bb5a-5a11c128f645', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5fce2627ad11362031883d3fcaa630349e691118732ad8bc9597949cff6bea30')}, text='My\\nname is Oscar\\nFigure10: AttentionvisualizationforadialoguewithandwithoutGAtt . Weconsideredthemaximum\\nactivations across the network and we bin neighboring tokens together.\\nTo illustrate how GAtt helped reshape attention during fine-tuning, we display the maximum attention\\nactivationsofthemodelinFigure10. Theleft-handsideofeachfigurecorrespondstothesystemmessage\\n(“ActasOscarWilde”). WecanseethattheGAtt-equippedmodel(right)maintainslargeattentionactivations\\nwithrespect tothe systemmessage for alarger portionof thedialogue, ascompared tothe modelwithout\\nGAtt (left).', start_char_idx=1766, end_char_idx=2339, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-17', obj=None),\n",
       " '79249694-2e7d-4e6f-bb5a-5a11c128f645': IndexNode(id_='79249694-2e7d-4e6f-bb5a-5a11c128f645', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-17', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8a04da5ed92bf1a6d51e061499afd1c8812c043e00b9bc06c48d8f1d02b22e7b'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='abefffe8-ebd5-478b-a40e-b2fe6d570d4e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d37042edda3fee76dc37c25c628b0342344f3d630a88edb47bf739b23dc63dda'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='b1fe97c5-843a-4051-9638-d895077a8912', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c58caa3ffe905bd7b3389e71bdfa7adb93395db35423e7f5c216fafcb04682c4')}, text='Theleft-handsideofeachfigurecorrespondstothesystemmessage\\n(“ActasOscarWilde”). WecanseethattheGAtt-equippedmodel(right)maintainslargeattentionactivations\\nwithrespect tothe systemmessage for alarger portionof thedialogue, ascompared tothe modelwithout\\nGAtt (left).\\nDespite its utility, the current implementation of GAtt is vanilla, and more development and iteration on\\nthis technique could likely further benefit the model. For instance, we could teach the model to change the\\nsystem message during the conversation by integrating such data during fine-tuning.', start_char_idx=2076, end_char_idx=2637, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-17', obj=None),\n",
       " 'b1fe97c5-843a-4051-9638-d895077a8912': IndexNode(id_='b1fe97c5-843a-4051-9638-d895077a8912', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-17', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8a04da5ed92bf1a6d51e061499afd1c8812c043e00b9bc06c48d8f1d02b22e7b'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='79249694-2e7d-4e6f-bb5a-5a11c128f645', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5fce2627ad11362031883d3fcaa630349e691118732ad8bc9597949cff6bea30'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='3a259985-f67a-476d-a126-0c0198f49a7b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e6411fb896f4efcd68881675604e9141cb45f44d9b0fbce586ef4cb4e9fa6bbf')}, text='Despite its utility, the current implementation of GAtt is vanilla, and more development and iteration on\\nthis technique could likely further benefit the model. For instance, we could teach the model to change the\\nsystem message during the conversation by integrating such data during fine-tuning.\\n3.4 RLHF Results\\n3.4.1 Model-Based Evaluation\\nEvaluatingLLMsisachallengingopen-researchproblem.', start_char_idx=2340, end_char_idx=2733, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-17', obj=None),\n",
       " '3a259985-f67a-476d-a126-0c0198f49a7b': IndexNode(id_='3a259985-f67a-476d-a126-0c0198f49a7b', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-17', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8a04da5ed92bf1a6d51e061499afd1c8812c043e00b9bc06c48d8f1d02b22e7b'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='b1fe97c5-843a-4051-9638-d895077a8912', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c58caa3ffe905bd7b3389e71bdfa7adb93395db35423e7f5c216fafcb04682c4'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='4401a46e-e966-40da-8be9-0b6778ef3c7b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0bcd687afd99e20fe9415b4424b5dfecb3630eeb7d1c48beb0b173c914d59a7e')}, text='Despite its utility, the current implementation of GAtt is vanilla, and more development and iteration on\\nthis technique could likely further benefit the model. For instance, we could teach the model to change the\\nsystem message during the conversation by integrating such data during fine-tuning.\\n3.4 RLHF Results\\n3.4.1 Model-Based Evaluation\\nEvaluatingLLMsisachallengingopen-researchproblem. Humanevaluation,whileagoldstandard,can\\nbe complicated by various HCI considerations (Clark et al., 2021; Gehrmann et al., 2023), and is not always\\nscalable.', start_char_idx=2340, end_char_idx=2890, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-17', obj=None),\n",
       " '4401a46e-e966-40da-8be9-0b6778ef3c7b': IndexNode(id_='4401a46e-e966-40da-8be9-0b6778ef3c7b', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-17', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8a04da5ed92bf1a6d51e061499afd1c8812c043e00b9bc06c48d8f1d02b22e7b'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='3a259985-f67a-476d-a126-0c0198f49a7b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e6411fb896f4efcd68881675604e9141cb45f44d9b0fbce586ef4cb4e9fa6bbf'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='5b6d4ff8-4190-4d57-9d2b-505927955956', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='fcdd66a8f1f87b04af286a36da32fecfa4857be4237a857c29a39bf56db0842a')}, text='3.4 RLHF Results\\n3.4.1 Model-Based Evaluation\\nEvaluatingLLMsisachallengingopen-researchproblem. Humanevaluation,whileagoldstandard,can\\nbe complicated by various HCI considerations (Clark et al., 2021; Gehrmann et al., 2023), and is not always\\nscalable. Thus, to select the best-performing models among several ablations at each iteration from RLHF-V1\\ntoV5,wefirstobservedtheimprovementoftherewardsfromthelatestrewardmodels,tosavecostsand\\nincrease iteration speed.', start_char_idx=2638, end_char_idx=3101, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-17', obj=None),\n",
       " '5b6d4ff8-4190-4d57-9d2b-505927955956': IndexNode(id_='5b6d4ff8-4190-4d57-9d2b-505927955956', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-17', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8a04da5ed92bf1a6d51e061499afd1c8812c043e00b9bc06c48d8f1d02b22e7b'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='4401a46e-e966-40da-8be9-0b6778ef3c7b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0bcd687afd99e20fe9415b4424b5dfecb3630eeb7d1c48beb0b173c914d59a7e'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='75731c8e-64b2-4609-9b6e-9adff8cfadef', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eb7af0991d5e9dbde0633858c2f6c7a6570fc873fe7c28f47252aec9b72c7234')}, text='Humanevaluation,whileagoldstandard,can\\nbe complicated by various HCI considerations (Clark et al., 2021; Gehrmann et al., 2023), and is not always\\nscalable. Thus, to select the best-performing models among several ablations at each iteration from RLHF-V1\\ntoV5,wefirstobservedtheimprovementoftherewardsfromthelatestrewardmodels,tosavecostsand\\nincrease iteration speed. We later validated major model versions with human evaluations.\\nHow Far Can Model-Based Evaluation Go?', start_char_idx=2734, end_char_idx=3204, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-17', obj=None),\n",
       " '75731c8e-64b2-4609-9b6e-9adff8cfadef': IndexNode(id_='75731c8e-64b2-4609-9b6e-9adff8cfadef', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-17', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8a04da5ed92bf1a6d51e061499afd1c8812c043e00b9bc06c48d8f1d02b22e7b'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='5b6d4ff8-4190-4d57-9d2b-505927955956', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='fcdd66a8f1f87b04af286a36da32fecfa4857be4237a857c29a39bf56db0842a'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='14e26671-2d28-4b1f-ad27-6b6dc3b5a059', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='fee6d482737450e07cdf58dee75c0eca73af597df57d6b864bb74de193c60d30')}, text='Thus, to select the best-performing models among several ablations at each iteration from RLHF-V1\\ntoV5,wefirstobservedtheimprovementoftherewardsfromthelatestrewardmodels,tosavecostsand\\nincrease iteration speed. We later validated major model versions with human evaluations.\\nHow Far Can Model-Based Evaluation Go? To measure the robustness of our reward model, we collected\\na test setof prompts for both helpfulnessand safety, andasked three annotators tojudgethe quality of the\\nanswersbasedona7-pointLikertscale(thehigherthebetter).', start_char_idx=2891, end_char_idx=3424, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-17', obj=None),\n",
       " '14e26671-2d28-4b1f-ad27-6b6dc3b5a059': IndexNode(id_='14e26671-2d28-4b1f-ad27-6b6dc3b5a059', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-17', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8a04da5ed92bf1a6d51e061499afd1c8812c043e00b9bc06c48d8f1d02b22e7b'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='75731c8e-64b2-4609-9b6e-9adff8cfadef', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eb7af0991d5e9dbde0633858c2f6c7a6570fc873fe7c28f47252aec9b72c7234')}, text='We later validated major model versions with human evaluations.\\nHow Far Can Model-Based Evaluation Go? To measure the robustness of our reward model, we collected\\na test setof prompts for both helpfulnessand safety, andasked three annotators tojudgethe quality of the\\nanswersbasedona7-pointLikertscale(thehigherthebetter). Weobservethatourrewardmodelsoverall\\nare well calibrated with our human preference annotations, as illustrated in Figure 29 in the appendix.', start_char_idx=3102, end_char_idx=3564, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-17', obj=None),\n",
       " 'c045a406-c65c-4edc-a8b1-045cb6434e45': IndexNode(id_='c045a406-c65c-4edc-a8b1-045cb6434e45', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-17', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8a04da5ed92bf1a6d51e061499afd1c8812c043e00b9bc06c48d8f1d02b22e7b'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='08b69639-b994-40a0-abf4-26a47ef17185', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4c0b7a0c805500341f806ba6d927636128f2e66c573818356f9cafe788a1cde9')}, text='Act as Oscar\\nWilde\\nGive short\\nanswers Wh\\nich is the\\nbest city to\\nlive in?\\nLondon, of\\ncourse! \\nWhy is that\\n? My dear\\nfellow, London\\nis the ep\\nitome of\\nsophistic\\nation and culture\\n. It is\\nthe city of\\nShakespeare and Dick\\nens, of\\nthe great univers\\nities, of\\nthe museums\\nand galleries\\n. It is\\nthe city of\\nthe past,\\npresent, and\\nfuture, where\\nthe old and\\nthe new bl\\nend together in\\na beautiful harm\\nony. \\nWhat is your\\nname? My\\nname is Oscar\\nBaseline before GAttAct as Oscar\\nWilde\\nGive short\\nanswers Wh\\nich is the\\nbest city to\\nlive in?\\nLondon, of\\ncourse! \\nWhy is that\\n? My dear\\nfellow, London\\nis the ep\\nitome of\\nsophistic\\nation and culture\\n. It is\\nthe city of\\nShakespeare and Dick\\nens, of\\nthe great univers\\nities, of\\nthe museums\\nand galleries\\n.', start_char_idx=0, end_char_idx=738, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-17', obj=None),\n",
       " '08b69639-b994-40a0-abf4-26a47ef17185': IndexNode(id_='08b69639-b994-40a0-abf4-26a47ef17185', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-17', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8a04da5ed92bf1a6d51e061499afd1c8812c043e00b9bc06c48d8f1d02b22e7b'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='c045a406-c65c-4edc-a8b1-045cb6434e45', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e5d891d1c758785415cef1bb7386057d5e6a375adf0e277df31fbc59a393afed'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='ad78bd04-b776-4bde-bedc-d280b2c213c5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a7c674e1877daa6c99dd26b97425116b13f475af52990707a9f44cd0da7b74f8')}, text='London, of\\ncourse! \\nWhy is that\\n? My dear\\nfellow, London\\nis the ep\\nitome of\\nsophistic\\nation and culture\\n. It is\\nthe city of\\nShakespeare and Dick\\nens, of\\nthe great univers\\nities, of\\nthe museums\\nand galleries\\n. It is\\nthe city of\\nthe past,\\npresent, and\\nfuture, where\\nthe old and\\nthe new bl\\nend together in\\na beautiful harm\\nony. \\nWhat is your\\nname? My\\nname is Oscar\\nAct as Oscar\\nWilde\\nGive short\\nanswers Wh\\nich is the\\nbest city to\\nlive in?\\nLondon, of\\ncourse! \\nWhy is that\\n? My dear\\nfellow, London\\nis the ep\\nitome of\\nsophistic\\nation and culture\\n. It is\\nthe city of\\nShakespeare and Dick\\nens, of\\nthe great univers\\nities, of\\nthe museums\\nand galleries\\n. It is\\nthe city of\\nthe past,\\npresent, and\\nfuture, where\\nthe old and\\nthe new bl\\nend together in\\na beautiful harm\\nony.', start_char_idx=530, end_char_idx=1290, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-17', obj=None),\n",
       " 'ad78bd04-b776-4bde-bedc-d280b2c213c5': IndexNode(id_='ad78bd04-b776-4bde-bedc-d280b2c213c5', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-17', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8a04da5ed92bf1a6d51e061499afd1c8812c043e00b9bc06c48d8f1d02b22e7b'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='08b69639-b994-40a0-abf4-26a47ef17185', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4c0b7a0c805500341f806ba6d927636128f2e66c573818356f9cafe788a1cde9'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='7ed2c460-8192-41ae-b42a-05fedcca9292', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3e11481cb88d2dc32eae37d632c2f471d1b00d48284065a7981a40c7a078b1bc')}, text='My dear\\nfellow, London\\nis the ep\\nitome of\\nsophistic\\nation and culture\\n. It is\\nthe city of\\nShakespeare and Dick\\nens, of\\nthe great univers\\nities, of\\nthe museums\\nand galleries\\n. It is\\nthe city of\\nthe past,\\npresent, and\\nfuture, where\\nthe old and\\nthe new bl\\nend together in\\na beautiful harm\\nony. \\nWhat is your\\nname? My\\nname is Oscar\\nBaseline after GAttAct as Oscar\\nWilde\\nGive short\\nanswers Wh\\nich is the\\nbest city to\\nlive in?\\nLondon, of\\ncourse! \\nWhy is that\\n? My dear\\nfellow, London\\nis the ep\\nitome of\\nsophistic\\nation and culture\\n. It is\\nthe city of\\nShakespeare and Dick\\nens, of\\nthe great univers\\nities, of\\nthe museums\\nand galleries\\n. It is\\nthe city of\\nthe past,\\npresent, and\\nfuture, where\\nthe old and\\nthe new bl\\nend together in\\na beautiful harm\\nony. \\nWhat is your\\nname?', start_char_idx=1000, end_char_idx=1765, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-17', obj=None),\n",
       " '7ed2c460-8192-41ae-b42a-05fedcca9292': IndexNode(id_='7ed2c460-8192-41ae-b42a-05fedcca9292', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-17', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8a04da5ed92bf1a6d51e061499afd1c8812c043e00b9bc06c48d8f1d02b22e7b'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='ad78bd04-b776-4bde-bedc-d280b2c213c5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a7c674e1877daa6c99dd26b97425116b13f475af52990707a9f44cd0da7b74f8'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='652156ef-c19a-47d1-9352-16301c0934c4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='12b879b3c62cbb3f8dae2a22b3a8f08fc66b315536c0941ebac46b0cf95ea486')}, text='It is\\nthe city of\\nShakespeare and Dick\\nens, of\\nthe great univers\\nities, of\\nthe museums\\nand galleries\\n. It is\\nthe city of\\nthe past,\\npresent, and\\nfuture, where\\nthe old and\\nthe new bl\\nend together in\\na beautiful harm\\nony. \\nWhat is your\\nname? My\\nname is Oscar\\nFigure10: AttentionvisualizationforadialoguewithandwithoutGAtt . Weconsideredthemaximum\\nactivations across the network and we bin neighboring tokens together.\\nTo illustrate how GAtt helped reshape attention during fine-tuning, we display the maximum attention\\nactivationsofthemodelinFigure10. Theleft-handsideofeachfigurecorrespondstothesystemmessage\\n(“ActasOscarWilde”). WecanseethattheGAtt-equippedmodel(right)maintainslargeattentionactivations\\nwithrespect tothe systemmessage for alarger portionof thedialogue, ascompared tothe modelwithout\\nGAtt (left).\\nDespite its utility, the current implementation of GAtt is vanilla, and more development and iteration on\\nthis technique could likely further benefit the model.', start_char_idx=1527, end_char_idx=2500, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-17', obj=None),\n",
       " '652156ef-c19a-47d1-9352-16301c0934c4': IndexNode(id_='652156ef-c19a-47d1-9352-16301c0934c4', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-17', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8a04da5ed92bf1a6d51e061499afd1c8812c043e00b9bc06c48d8f1d02b22e7b'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='7ed2c460-8192-41ae-b42a-05fedcca9292', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3e11481cb88d2dc32eae37d632c2f471d1b00d48284065a7981a40c7a078b1bc'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='cec59112-4d4e-492b-93cc-cff95a5ba10e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='368d99cc44f040fce284a17ba8e1bf31667eb8f06fb8b05d5a2bb136717745aa')}, text='WecanseethattheGAtt-equippedmodel(right)maintainslargeattentionactivations\\nwithrespect tothe systemmessage for alarger portionof thedialogue, ascompared tothe modelwithout\\nGAtt (left).\\nDespite its utility, the current implementation of GAtt is vanilla, and more development and iteration on\\nthis technique could likely further benefit the model. For instance, we could teach the model to change the\\nsystem message during the conversation by integrating such data during fine-tuning.\\n3.4 RLHF Results\\n3.4.1 Model-Based Evaluation\\nEvaluatingLLMsisachallengingopen-researchproblem. Humanevaluation,whileagoldstandard,can\\nbe complicated by various HCI considerations (Clark et al., 2021; Gehrmann et al., 2023), and is not always\\nscalable. Thus, to select the best-performing models among several ablations at each iteration from RLHF-V1\\ntoV5,wefirstobservedtheimprovementoftherewardsfromthelatestrewardmodels,tosavecostsand\\nincrease iteration speed. We later validated major model versions with human evaluations.\\nHow Far Can Model-Based Evaluation Go?', start_char_idx=2155, end_char_idx=3204, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-17', obj=None),\n",
       " 'cec59112-4d4e-492b-93cc-cff95a5ba10e': IndexNode(id_='cec59112-4d4e-492b-93cc-cff95a5ba10e', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-17', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8a04da5ed92bf1a6d51e061499afd1c8812c043e00b9bc06c48d8f1d02b22e7b'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='652156ef-c19a-47d1-9352-16301c0934c4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='12b879b3c62cbb3f8dae2a22b3a8f08fc66b315536c0941ebac46b0cf95ea486')}, text='Thus, to select the best-performing models among several ablations at each iteration from RLHF-V1\\ntoV5,wefirstobservedtheimprovementoftherewardsfromthelatestrewardmodels,tosavecostsand\\nincrease iteration speed. We later validated major model versions with human evaluations.\\nHow Far Can Model-Based Evaluation Go? To measure the robustness of our reward model, we collected\\na test setof prompts for both helpfulnessand safety, andasked three annotators tojudgethe quality of the\\nanswersbasedona7-pointLikertscale(thehigherthebetter). Weobservethatourrewardmodelsoverall\\nare well calibrated with our human preference annotations, as illustrated in Figure 29 in the appendix.', start_char_idx=2891, end_char_idx=3564, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-17', obj=None),\n",
       " '9f3ea6f4-9c81-4205-a0ad-5984bd26de1f': IndexNode(id_='9f3ea6f4-9c81-4205-a0ad-5984bd26de1f', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-17', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8a04da5ed92bf1a6d51e061499afd1c8812c043e00b9bc06c48d8f1d02b22e7b'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='03cf9126-a255-4c0b-9f21-894217359ff9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eb5c447e80a88fe425c076f865f4329e91fffac922335604c76995c4a0c4b59e')}, text='Act as Oscar\\nWilde\\nGive short\\nanswers Wh\\nich is the\\nbest city to\\nlive in?\\nLondon, of\\ncourse! \\nWhy is that\\n? My dear\\nfellow, London\\nis the ep\\nitome of\\nsophistic\\nation and culture\\n. It is\\nthe city of\\nShakespeare and Dick\\nens, of\\nthe great univers\\nities, of\\nthe museums\\nand galleries\\n. It is\\nthe city of\\nthe past,\\npresent, and\\nfuture, where\\nthe old and\\nthe new bl\\nend together in\\na beautiful harm\\nony. \\nWhat is your\\nname? My\\nname is Oscar\\nBaseline before GAttAct as Oscar\\nWilde\\nGive short\\nanswers Wh\\nich is the\\nbest city to\\nlive in?\\nLondon, of\\ncourse! \\nWhy is that\\n? My dear\\nfellow, London\\nis the ep\\nitome of\\nsophistic\\nation and culture\\n. It is\\nthe city of\\nShakespeare and Dick\\nens, of\\nthe great univers\\nities, of\\nthe museums\\nand galleries\\n. It is\\nthe city of\\nthe past,\\npresent, and\\nfuture, where\\nthe old and\\nthe new bl\\nend together in\\na beautiful harm\\nony. \\nWhat is your\\nname? My\\nname is Oscar\\nAct as Oscar\\nWilde\\nGive short\\nanswers Wh\\nich is the\\nbest city to\\nlive in?\\nLondon, of\\ncourse! \\nWhy is that\\n? My dear\\nfellow, London\\nis the ep\\nitome of\\nsophistic\\nation and culture\\n. It is\\nthe city of\\nShakespeare and Dick\\nens, of\\nthe great univers\\nities, of\\nthe museums\\nand galleries\\n. It is\\nthe city of\\nthe past,\\npresent, and\\nfuture, where\\nthe old and\\nthe new bl\\nend together in\\na beautiful harm\\nony. \\nWhat is your\\nname? My\\nname is Oscar\\nBaseline after GAttAct as Oscar\\nWilde\\nGive short\\nanswers Wh\\nich is the\\nbest city to\\nlive in?\\nLondon, of\\ncourse! \\nWhy is that\\n? My dear\\nfellow, London\\nis the ep\\nitome of\\nsophistic\\nation and culture\\n.', start_char_idx=0, end_char_idx=1526, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-17', obj=None),\n",
       " '03cf9126-a255-4c0b-9f21-894217359ff9': IndexNode(id_='03cf9126-a255-4c0b-9f21-894217359ff9', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-17', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8a04da5ed92bf1a6d51e061499afd1c8812c043e00b9bc06c48d8f1d02b22e7b'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='9f3ea6f4-9c81-4205-a0ad-5984bd26de1f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0abe34acf4b38afc3869fb85b8470b0d2e5c849bf4997d530a7154e1a0f10876'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='6eab353d-fb7b-4d36-97c0-94107cff10bd', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='368d99cc44f040fce284a17ba8e1bf31667eb8f06fb8b05d5a2bb136717745aa')}, text='What is your\\nname? My\\nname is Oscar\\nBaseline after GAttAct as Oscar\\nWilde\\nGive short\\nanswers Wh\\nich is the\\nbest city to\\nlive in?\\nLondon, of\\ncourse! \\nWhy is that\\n? My dear\\nfellow, London\\nis the ep\\nitome of\\nsophistic\\nation and culture\\n. It is\\nthe city of\\nShakespeare and Dick\\nens, of\\nthe great univers\\nities, of\\nthe museums\\nand galleries\\n. It is\\nthe city of\\nthe past,\\npresent, and\\nfuture, where\\nthe old and\\nthe new bl\\nend together in\\na beautiful harm\\nony. \\nWhat is your\\nname? My\\nname is Oscar\\nFigure10: AttentionvisualizationforadialoguewithandwithoutGAtt . Weconsideredthemaximum\\nactivations across the network and we bin neighboring tokens together.\\nTo illustrate how GAtt helped reshape attention during fine-tuning, we display the maximum attention\\nactivationsofthemodelinFigure10. Theleft-handsideofeachfigurecorrespondstothesystemmessage\\n(“ActasOscarWilde”). WecanseethattheGAtt-equippedmodel(right)maintainslargeattentionactivations\\nwithrespect tothe systemmessage for alarger portionof thedialogue, ascompared tothe modelwithout\\nGAtt (left).\\nDespite its utility, the current implementation of GAtt is vanilla, and more development and iteration on\\nthis technique could likely further benefit the model. For instance, we could teach the model to change the\\nsystem message during the conversation by integrating such data during fine-tuning.\\n3.4 RLHF Results\\n3.4.1 Model-Based Evaluation\\nEvaluatingLLMsisachallengingopen-researchproblem. Humanevaluation,whileagoldstandard,can\\nbe complicated by various HCI considerations (Clark et al., 2021; Gehrmann et al., 2023), and is not always\\nscalable. Thus, to select the best-performing models among several ablations at each iteration from RLHF-V1\\ntoV5,wefirstobservedtheimprovementoftherewardsfromthelatestrewardmodels,tosavecostsand\\nincrease iteration speed. We later validated major model versions with human evaluations.\\nHow Far Can Model-Based Evaluation Go?', start_char_idx=1292, end_char_idx=3204, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-17', obj=None),\n",
       " '6eab353d-fb7b-4d36-97c0-94107cff10bd': IndexNode(id_='6eab353d-fb7b-4d36-97c0-94107cff10bd', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-17', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8a04da5ed92bf1a6d51e061499afd1c8812c043e00b9bc06c48d8f1d02b22e7b'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='03cf9126-a255-4c0b-9f21-894217359ff9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eb5c447e80a88fe425c076f865f4329e91fffac922335604c76995c4a0c4b59e')}, text='Thus, to select the best-performing models among several ablations at each iteration from RLHF-V1\\ntoV5,wefirstobservedtheimprovementoftherewardsfromthelatestrewardmodels,tosavecostsand\\nincrease iteration speed. We later validated major model versions with human evaluations.\\nHow Far Can Model-Based Evaluation Go? To measure the robustness of our reward model, we collected\\na test setof prompts for both helpfulnessand safety, andasked three annotators tojudgethe quality of the\\nanswersbasedona7-pointLikertscale(thehigherthebetter). Weobservethatourrewardmodelsoverall\\nare well calibrated with our human preference annotations, as illustrated in Figure 29 in the appendix.', start_char_idx=2891, end_char_idx=3564, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-17', obj=None),\n",
       " 'node-17': IndexNode(id_='node-17', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='d03f19eb-da15-45dc-bfd4-e5d10f161250', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='231b3bd773f012c01b893ada9e009ecf25ee59934614c5a595c9bf1b3a123292'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='fd438d1e-d691-4c67-83be-d5825bb56f91', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9964504b6f018c3858324a8875611e5497f6a24ef33cbc3267f0deb4a77abc19'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='ba231221-2bb6-4008-91b7-dcf500b020bd', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1ddb759a744ed54a5885bb93e09c3e6a0bed1921f330319362c66584215966ee')}, text='Act as Oscar\\nWilde\\nGive short\\nanswers Wh\\nich is the\\nbest city to\\nlive in?\\nLondon, of\\ncourse! \\nWhy is that\\n? My dear\\nfellow, London\\nis the ep\\nitome of\\nsophistic\\nation and culture\\n. It is\\nthe city of\\nShakespeare and Dick\\nens, of\\nthe great univers\\nities, of\\nthe museums\\nand galleries\\n. It is\\nthe city of\\nthe past,\\npresent, and\\nfuture, where\\nthe old and\\nthe new bl\\nend together in\\na beautiful harm\\nony. \\nWhat is your\\nname? My\\nname is Oscar\\nBaseline before GAttAct as Oscar\\nWilde\\nGive short\\nanswers Wh\\nich is the\\nbest city to\\nlive in?\\nLondon, of\\ncourse! \\nWhy is that\\n? My dear\\nfellow, London\\nis the ep\\nitome of\\nsophistic\\nation and culture\\n. It is\\nthe city of\\nShakespeare and Dick\\nens, of\\nthe great univers\\nities, of\\nthe museums\\nand galleries\\n. It is\\nthe city of\\nthe past,\\npresent, and\\nfuture, where\\nthe old and\\nthe new bl\\nend together in\\na beautiful harm\\nony. \\nWhat is your\\nname? My\\nname is Oscar\\nAct as Oscar\\nWilde\\nGive short\\nanswers Wh\\nich is the\\nbest city to\\nlive in?\\nLondon, of\\ncourse! \\nWhy is that\\n? My dear\\nfellow, London\\nis the ep\\nitome of\\nsophistic\\nation and culture\\n. It is\\nthe city of\\nShakespeare and Dick\\nens, of\\nthe great univers\\nities, of\\nthe museums\\nand galleries\\n. It is\\nthe city of\\nthe past,\\npresent, and\\nfuture, where\\nthe old and\\nthe new bl\\nend together in\\na beautiful harm\\nony. \\nWhat is your\\nname? My\\nname is Oscar\\nBaseline after GAttAct as Oscar\\nWilde\\nGive short\\nanswers Wh\\nich is the\\nbest city to\\nlive in?\\nLondon, of\\ncourse! \\nWhy is that\\n? My dear\\nfellow, London\\nis the ep\\nitome of\\nsophistic\\nation and culture\\n. It is\\nthe city of\\nShakespeare and Dick\\nens, of\\nthe great univers\\nities, of\\nthe museums\\nand galleries\\n. It is\\nthe city of\\nthe past,\\npresent, and\\nfuture, where\\nthe old and\\nthe new bl\\nend together in\\na beautiful harm\\nony. \\nWhat is your\\nname? My\\nname is Oscar\\nFigure10: AttentionvisualizationforadialoguewithandwithoutGAtt . Weconsideredthemaximum\\nactivations across the network and we bin neighboring tokens together.\\nTo illustrate how GAtt helped reshape attention during fine-tuning, we display the maximum attention\\nactivationsofthemodelinFigure10. Theleft-handsideofeachfigurecorrespondstothesystemmessage\\n(“ActasOscarWilde”). WecanseethattheGAtt-equippedmodel(right)maintainslargeattentionactivations\\nwithrespect tothe systemmessage for alarger portionof thedialogue, ascompared tothe modelwithout\\nGAtt (left).\\nDespite its utility, the current implementation of GAtt is vanilla, and more development and iteration on\\nthis technique could likely further benefit the model. For instance, we could teach the model to change the\\nsystem message during the conversation by integrating such data during fine-tuning.\\n3.4 RLHF Results\\n3.4.1 Model-Based Evaluation\\nEvaluatingLLMsisachallengingopen-researchproblem. Humanevaluation,whileagoldstandard,can\\nbe complicated by various HCI considerations (Clark et al., 2021; Gehrmann et al., 2023), and is not always\\nscalable. Thus, to select the best-performing models among several ablations at each iteration from RLHF-V1\\ntoV5,wefirstobservedtheimprovementoftherewardsfromthelatestrewardmodels,tosavecostsand\\nincrease iteration speed. We later validated major model versions with human evaluations.\\nHow Far Can Model-Based Evaluation Go? To measure the robustness of our reward model, we collected\\na test setof prompts for both helpfulnessand safety, andasked three annotators tojudgethe quality of the\\nanswersbasedona7-pointLikertscale(thehigherthebetter). Weobservethatourrewardmodelsoverall\\nare well calibrated with our human preference annotations, as illustrated in Figure 29 in the appendix.', start_char_idx=51663, end_char_idx=55227, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-17', obj=None),\n",
       " '7762a094-0e1d-48bf-92d1-7cfce47b8ed5': IndexNode(id_='7762a094-0e1d-48bf-92d1-7cfce47b8ed5', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-18', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1ddb759a744ed54a5885bb93e09c3e6a0bed1921f330319362c66584215966ee'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='4aec5269-2daf-4160-bbdb-773ebb958228', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='46187c3d3dc20a057596af771063d8e4c4975092d771e4784e24b87d5d405a22')}, text='How Far Can Model-Based Evaluation Go? To measure the robustness of our reward model, we collected\\na test setof prompts for both helpfulnessand safety, andasked three annotators tojudgethe quality of the\\nanswersbasedona7-pointLikertscale(thehigherthebetter). Weobservethatourrewardmodelsoverall\\nare well calibrated with our human preference annotations, as illustrated in Figure 29 in the appendix. This\\nconfirms the relevance of using our reward as a point-wise metric, despite being trained with a Pairwise\\nRanking Loss.', start_char_idx=0, end_char_idx=522, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-18', obj=None),\n",
       " '4aec5269-2daf-4160-bbdb-773ebb958228': IndexNode(id_='4aec5269-2daf-4160-bbdb-773ebb958228', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-18', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1ddb759a744ed54a5885bb93e09c3e6a0bed1921f330319362c66584215966ee'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='7762a094-0e1d-48bf-92d1-7cfce47b8ed5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e9bd4c6dbb1740a9ad18a4e57a927c4a007bcc6453d7a8b4d47f15f4838124ca'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='6fcce8f3-aab4-4946-bac3-1f16c55abe67', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4fe5ab8b6fdd68ea7ed9ac47c0c762a2e87361a1763098bd7ab2c0fac9a7e647')}, text='Weobservethatourrewardmodelsoverall\\nare well calibrated with our human preference annotations, as illustrated in Figure 29 in the appendix. This\\nconfirms the relevance of using our reward as a point-wise metric, despite being trained with a Pairwise\\nRanking Loss.\\nStill, as Goodhart’s Law states, when a measure becomes a target, it ceases to be a good measure. To ensure\\nourmeasurewon’tdivergefromthehumanpreferences,weadditionallyusedamoregeneralreward,trained\\n17\\n\\nRLHF- v5\\n(with PPO)\\nRLHF-', start_char_idx=259, end_char_idx=751, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-18', obj=None),\n",
       " '6fcce8f3-aab4-4946-bac3-1f16c55abe67': IndexNode(id_='6fcce8f3-aab4-4946-bac3-1f16c55abe67', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-18', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1ddb759a744ed54a5885bb93e09c3e6a0bed1921f330319362c66584215966ee'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='4aec5269-2daf-4160-bbdb-773ebb958228', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='46187c3d3dc20a057596af771063d8e4c4975092d771e4784e24b87d5d405a22'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='83db8222-3ada-49a7-b5ae-03b2aa4451b5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='62681e7a0cd1d8c3d42ad0194d29a8da043e36ec32c66641d8faa9bc5a8d4783')}, text='This\\nconfirms the relevance of using our reward as a point-wise metric, despite being trained with a Pairwise\\nRanking Loss.\\nStill, as Goodhart’s Law states, when a measure becomes a target, it ceases to be a good measure. To ensure\\nourmeasurewon’tdivergefromthehumanpreferences,weadditionallyusedamoregeneralreward,trained\\n17\\n\\nRLHF- v5\\n(with PPO)\\nRLHF- v5\\n(no PPO)\\nRLHF- v4\\nRLHF- v3\\n            RLHF-', start_char_idx=399, end_char_idx=799, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-18', obj=None),\n",
       " '83db8222-3ada-49a7-b5ae-03b2aa4451b5': IndexNode(id_='83db8222-3ada-49a7-b5ae-03b2aa4451b5', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-18', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1ddb759a744ed54a5885bb93e09c3e6a0bed1921f330319362c66584215966ee'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='6fcce8f3-aab4-4946-bac3-1f16c55abe67', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4fe5ab8b6fdd68ea7ed9ac47c0c762a2e87361a1763098bd7ab2c0fac9a7e647'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='807b7c5a-5204-46e7-a03f-ad240ea6f2c5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bd0b0039e735afc54083bcf5a3399ea9263ea0fc6ba04b034bf37b2f9e479e9b')}, text='Still, as Goodhart’s Law states, when a measure becomes a target, it ceases to be a good measure. To ensure\\nourmeasurewon’tdivergefromthehumanpreferences,weadditionallyusedamoregeneralreward,trained\\n17\\n\\nRLHF- v5\\n(with PPO)\\nRLHF- v5\\n(no PPO)\\nRLHF- v4\\nRLHF- v3\\n            RLHF- v2      RLHF- v1 SFT-v2', start_char_idx=523, end_char_idx=823, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-18', obj=None),\n",
       " '807b7c5a-5204-46e7-a03f-ad240ea6f2c5': IndexNode(id_='807b7c5a-5204-46e7-a03f-ad240ea6f2c5', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-18', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1ddb759a744ed54a5885bb93e09c3e6a0bed1921f330319362c66584215966ee'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='83db8222-3ada-49a7-b5ae-03b2aa4451b5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='62681e7a0cd1d8c3d42ad0194d29a8da043e36ec32c66641d8faa9bc5a8d4783'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='82199d24-d532-4154-be86-55219bdb4486', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a7f849dfe69871f56eed14ffeba42f3b504ea10e58db904f190c582026c7ef50')}, text='To ensure\\nourmeasurewon’tdivergefromthehumanpreferences,weadditionallyusedamoregeneralreward,trained\\n17\\n\\nRLHF- v5\\n(with PPO)\\nRLHF- v5\\n(no PPO)\\nRLHF- v4\\nRLHF- v3\\n            RLHF- v2      RLHF- v1 SFT-v2       \\nSFT-v1\\n10% 20% 30% 40% 50% 60% 70% 80%', start_char_idx=621, end_char_idx=869, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-18', obj=None),\n",
       " '82199d24-d532-4154-be86-55219bdb4486': IndexNode(id_='82199d24-d532-4154-be86-55219bdb4486', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-18', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1ddb759a744ed54a5885bb93e09c3e6a0bed1921f330319362c66584215966ee'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='807b7c5a-5204-46e7-a03f-ad240ea6f2c5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bd0b0039e735afc54083bcf5a3399ea9263ea0fc6ba04b034bf37b2f9e479e9b'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='73b895b1-c5e7-44ad-a44f-b7a4f8b69f8e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c5686d24c0e664de438c7c9c470b158b8d0d6323ad25d41ee033f06683ac5f6a')}, text='v5\\n(with PPO)\\nRLHF- v5\\n(no PPO)\\nRLHF- v4\\nRLHF- v3\\n            RLHF- v2      RLHF- v1 SFT-v2       \\nSFT-v1\\n10% 20% 30% 40% 50% 60% 70% 80% 90%10%20%30%40%50%60%70%80%\\nHelpfulness\\nJudge: Meta R ewar d ModelsHarmlessness', start_char_idx=732, end_char_idx=949, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-18', obj=None),\n",
       " '73b895b1-c5e7-44ad-a44f-b7a4f8b69f8e': IndexNode(id_='73b895b1-c5e7-44ad-a44f-b7a4f8b69f8e', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-18', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1ddb759a744ed54a5885bb93e09c3e6a0bed1921f330319362c66584215966ee'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='82199d24-d532-4154-be86-55219bdb4486', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a7f849dfe69871f56eed14ffeba42f3b504ea10e58db904f190c582026c7ef50'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='36e5d24a-06c0-4f23-8a0e-704a39eea77e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='32aa7ad4cf4f5f85def6141040db0dfd0f615d65cb4dd0e5a3a453125ea35982')}, text='RLHF- v2      RLHF- v1 SFT-v2       \\nSFT-v1\\n10% 20% 30% 40% 50% 60% 70% 80% 90%10%20%30%40%50%60%70%80%\\nHelpfulness\\nJudge: Meta R ewar d ModelsHarmlessness\\n  RLHF- v5\\n  (with PPO)RLHF- v5  \\n(no PPO)  \\nRLHF-', start_char_idx=794, end_char_idx=1000, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-18', obj=None),\n",
       " '36e5d24a-06c0-4f23-8a0e-704a39eea77e': IndexNode(id_='36e5d24a-06c0-4f23-8a0e-704a39eea77e', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-18', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1ddb759a744ed54a5885bb93e09c3e6a0bed1921f330319362c66584215966ee'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='73b895b1-c5e7-44ad-a44f-b7a4f8b69f8e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c5686d24c0e664de438c7c9c470b158b8d0d6323ad25d41ee033f06683ac5f6a'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='9f5d9ecf-3dc3-4a9e-b224-844caa81dcd7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b910dcfe65f7ff7f5a1a0066be99692d1325bf3c06a612f8647bef4376b5fabb')}, text='SFT-v1\\n10% 20% 30% 40% 50% 60% 70% 80% 90%10%20%30%40%50%60%70%80%\\nHelpfulness\\nJudge: Meta R ewar d ModelsHarmlessness\\n  RLHF- v5\\n  (with PPO)RLHF- v5  \\n(no PPO)  \\nRLHF- v4\\nRLHF- v3\\n     RLHF- v2RLHF- v1', start_char_idx=831, end_char_idx=1034, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-18', obj=None),\n",
       " '9f5d9ecf-3dc3-4a9e-b224-844caa81dcd7': IndexNode(id_='9f5d9ecf-3dc3-4a9e-b224-844caa81dcd7', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-18', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1ddb759a744ed54a5885bb93e09c3e6a0bed1921f330319362c66584215966ee'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='36e5d24a-06c0-4f23-8a0e-704a39eea77e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='32aa7ad4cf4f5f85def6141040db0dfd0f615d65cb4dd0e5a3a453125ea35982'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='4625a5c1-305c-4e17-8764-55e0e3368c29', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9794861455737b7a347abdc6449883b9f404fc988a27ad7ac091e3282d9fa148')}, text='60% 70% 80% 90%10%20%30%40%50%60%70%80%\\nHelpfulness\\nJudge: Meta R ewar d ModelsHarmlessness\\n  RLHF- v5\\n  (with PPO)RLHF- v5  \\n(no PPO)  \\nRLHF- v4\\nRLHF- v3\\n     RLHF- v2RLHF- v1     \\nSFT-v2    \\nSFT-v1\\n10% 20% 30% 40% 50%', start_char_idx=858, end_char_idx=1077, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-18', obj=None),\n",
       " '4625a5c1-305c-4e17-8764-55e0e3368c29': IndexNode(id_='4625a5c1-305c-4e17-8764-55e0e3368c29', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-18', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1ddb759a744ed54a5885bb93e09c3e6a0bed1921f330319362c66584215966ee'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='9f5d9ecf-3dc3-4a9e-b224-844caa81dcd7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b910dcfe65f7ff7f5a1a0066be99692d1325bf3c06a612f8647bef4376b5fabb'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='54de5758-8f6d-4fe4-ba36-e7e1b5d23e88', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='19f54053b691495a5644ce842806782a70a087fe877a16929e1b0adf1ef7a709')}, text='Meta R ewar d ModelsHarmlessness\\n  RLHF- v5\\n  (with PPO)RLHF- v5  \\n(no PPO)  \\nRLHF- v4\\nRLHF- v3\\n     RLHF- v2RLHF- v1     \\nSFT-v2    \\nSFT-v1\\n10% 20% 30% 40% 50% 60% 70% 80% 90%10%20%30%40%50%60%70%80%\\nHelpfulness\\nJudge:', start_char_idx=917, end_char_idx=1136, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-18', obj=None),\n",
       " '54de5758-8f6d-4fe4-ba36-e7e1b5d23e88': IndexNode(id_='54de5758-8f6d-4fe4-ba36-e7e1b5d23e88', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-18', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1ddb759a744ed54a5885bb93e09c3e6a0bed1921f330319362c66584215966ee'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='4625a5c1-305c-4e17-8764-55e0e3368c29', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9794861455737b7a347abdc6449883b9f404fc988a27ad7ac091e3282d9fa148'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='0d069e47-9237-4062-90a8-02f060de60b6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3c39c4a810701b5e9ee8e2f790fa3e81ff266dbcc86db3cbc656320ab1722644')}, text='(no PPO)  \\nRLHF- v4\\nRLHF- v3\\n     RLHF- v2RLHF- v1     \\nSFT-v2    \\nSFT-v1\\n10% 20% 30% 40% 50% 60% 70% 80% 90%10%20%30%40%50%60%70%80%\\nHelpfulness\\nJudge: GPT -4HarmlessnessFigure 11: Evolution of Llama 2-Chat .', start_char_idx=984, end_char_idx=1193, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-18', obj=None),\n",
       " '0d069e47-9237-4062-90a8-02f060de60b6': IndexNode(id_='0d069e47-9237-4062-90a8-02f060de60b6', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-18', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1ddb759a744ed54a5885bb93e09c3e6a0bed1921f330319362c66584215966ee'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='54de5758-8f6d-4fe4-ba36-e7e1b5d23e88', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='19f54053b691495a5644ce842806782a70a087fe877a16929e1b0adf1ef7a709'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='bbe82182-a162-463a-a7d9-1bc6d186f84c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6ce2ea4f327eb091cbb6ebacb7d4e32e4bc8a360e1a04cd511cb2c9d02a219eb')}, text='RLHF- v2RLHF- v1     \\nSFT-v2    \\nSFT-v1\\n10% 20% 30% 40% 50% 60% 70% 80% 90%10%20%30%40%50%60%70%80%\\nHelpfulness\\nJudge: GPT -4HarmlessnessFigure 11: Evolution of Llama 2-Chat . We show the evolution after multiple iterations fine-tuning for the\\nwin-rate%of Llama 2-Chat comparedtoChatGPT.', start_char_idx=1018, end_char_idx=1305, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-18', obj=None),\n",
       " 'bbe82182-a162-463a-a7d9-1bc6d186f84c': IndexNode(id_='bbe82182-a162-463a-a7d9-1bc6d186f84c', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-18', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1ddb759a744ed54a5885bb93e09c3e6a0bed1921f330319362c66584215966ee'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='0d069e47-9237-4062-90a8-02f060de60b6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3c39c4a810701b5e9ee8e2f790fa3e81ff266dbcc86db3cbc656320ab1722644'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='21286849-d05c-4791-be37-4f5842bb59fc', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7379567566bc0e5e211f0e8c84415a0b77543bc819f5580f18df8e451ca24a0e')}, text='20% 30% 40% 50% 60% 70% 80% 90%10%20%30%40%50%60%70%80%\\nHelpfulness\\nJudge: GPT -4HarmlessnessFigure 11: Evolution of Llama 2-Chat . We show the evolution after multiple iterations fine-tuning for the\\nwin-rate%of Llama 2-Chat comparedtoChatGPT. Left: thejudgeisourrewardmodel,whichmayfavor\\nour model, and right, the judge is GPT-4, which should be more neutral.', start_char_idx=1062, end_char_idx=1422, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-18', obj=None),\n",
       " '21286849-d05c-4791-be37-4f5842bb59fc': IndexNode(id_='21286849-d05c-4791-be37-4f5842bb59fc', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-18', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1ddb759a744ed54a5885bb93e09c3e6a0bed1921f330319362c66584215966ee'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='bbe82182-a162-463a-a7d9-1bc6d186f84c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6ce2ea4f327eb091cbb6ebacb7d4e32e4bc8a360e1a04cd511cb2c9d02a219eb'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='13bbb745-b1a5-4696-b705-f04f372d00d4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='04465f5ae222e5d72b50efb3aa99c7db38e45945d13c4d4c5af774add81e607c')}, text='GPT -4HarmlessnessFigure 11: Evolution of Llama 2-Chat . We show the evolution after multiple iterations fine-tuning for the\\nwin-rate%of Llama 2-Chat comparedtoChatGPT. Left: thejudgeisourrewardmodel,whichmayfavor\\nour model, and right, the judge is GPT-4, which should be more neutral.\\non diverse open-source Reward Modeling datasets. We have not yet observed any such divergence, and\\nhypothesize that iterative model updates may be helping to prevent this.', start_char_idx=1137, end_char_idx=1594, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-18', obj=None),\n",
       " '13bbb745-b1a5-4696-b705-f04f372d00d4': IndexNode(id_='13bbb745-b1a5-4696-b705-f04f372d00d4', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-18', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1ddb759a744ed54a5885bb93e09c3e6a0bed1921f330319362c66584215966ee'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='21286849-d05c-4791-be37-4f5842bb59fc', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7379567566bc0e5e211f0e8c84415a0b77543bc819f5580f18df8e451ca24a0e'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='4f5bdbd7-93b0-4f44-a3e5-c1ce95274a4a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='765722295380d2e466cada0de63734fefcbb442634f3746f312526e11785423a')}, text='. We show the evolution after multiple iterations fine-tuning for the\\nwin-rate%of Llama 2-Chat comparedtoChatGPT. Left: thejudgeisourrewardmodel,whichmayfavor\\nour model, and right, the judge is GPT-4, which should be more neutral.\\non diverse open-source Reward Modeling datasets. We have not yet observed any such divergence, and\\nhypothesize that iterative model updates may be helping to prevent this.\\nAs a last verification step to ensure no regression between our new model and the previous one, we use both\\nto sample during the next annotation iteration.', start_char_idx=1192, end_char_idx=1750, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-18', obj=None),\n",
       " '4f5bdbd7-93b0-4f44-a3e5-c1ce95274a4a': IndexNode(id_='4f5bdbd7-93b0-4f44-a3e5-c1ce95274a4a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-18', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1ddb759a744ed54a5885bb93e09c3e6a0bed1921f330319362c66584215966ee'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='13bbb745-b1a5-4696-b705-f04f372d00d4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='04465f5ae222e5d72b50efb3aa99c7db38e45945d13c4d4c5af774add81e607c'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='63695468-a1fd-428c-8249-fe2920ee66ab', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f96c3af8857b7a69afd7c4aa911b588103c47685a09b42404e2706cda8bff129')}, text='Left: thejudgeisourrewardmodel,whichmayfavor\\nour model, and right, the judge is GPT-4, which should be more neutral.\\non diverse open-source Reward Modeling datasets. We have not yet observed any such divergence, and\\nhypothesize that iterative model updates may be helping to prevent this.\\nAs a last verification step to ensure no regression between our new model and the previous one, we use both\\nto sample during the next annotation iteration. This enables a model comparison “for free” on new prompts\\nand can help to increase diversity when sampling.\\nProgressionofModels.', start_char_idx=1306, end_char_idx=1879, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-18', obj=None),\n",
       " '63695468-a1fd-428c-8249-fe2920ee66ab': IndexNode(id_='63695468-a1fd-428c-8249-fe2920ee66ab', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-18', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1ddb759a744ed54a5885bb93e09c3e6a0bed1921f330319362c66584215966ee'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='4f5bdbd7-93b0-4f44-a3e5-c1ce95274a4a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='765722295380d2e466cada0de63734fefcbb442634f3746f312526e11785423a'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='4135070e-27c5-48f8-a2c3-476fcb360b75', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='94cbcc42009169e1a6056c05363da6f05cfe0176b16de91cf95dec11d18e263f')}, text='on diverse open-source Reward Modeling datasets. We have not yet observed any such divergence, and\\nhypothesize that iterative model updates may be helping to prevent this.\\nAs a last verification step to ensure no regression between our new model and the previous one, we use both\\nto sample during the next annotation iteration. This enables a model comparison “for free” on new prompts\\nand can help to increase diversity when sampling.\\nProgressionofModels. Figure11reportstheprogressofourdifferentSFTandthenRLHFversionsfor\\nboth Safetyand Helpfulnessaxes, measuredbyour in-houseSafetyand Helpfulnessreward models.', start_char_idx=1423, end_char_idx=2035, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-18', obj=None),\n",
       " '4135070e-27c5-48f8-a2c3-476fcb360b75': IndexNode(id_='4135070e-27c5-48f8-a2c3-476fcb360b75', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-18', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1ddb759a744ed54a5885bb93e09c3e6a0bed1921f330319362c66584215966ee'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='63695468-a1fd-428c-8249-fe2920ee66ab', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f96c3af8857b7a69afd7c4aa911b588103c47685a09b42404e2706cda8bff129'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='8b1c025a-015c-4561-a522-d5f174ae567b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f860a72b044d315492c88b204592596d5b4d787f7a51d8795e4d363b5ee039f3')}, text='As a last verification step to ensure no regression between our new model and the previous one, we use both\\nto sample during the next annotation iteration. This enables a model comparison “for free” on new prompts\\nand can help to increase diversity when sampling.\\nProgressionofModels. Figure11reportstheprogressofourdifferentSFTandthenRLHFversionsfor\\nboth Safetyand Helpfulnessaxes, measuredbyour in-houseSafetyand Helpfulnessreward models. On\\nthis set of evaluations, we outperform ChatGPT on both axes after RLHF-V3 (harmlessness and helpfulness\\n>50%).', start_char_idx=1595, end_char_idx=2149, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-18', obj=None),\n",
       " '8b1c025a-015c-4561-a522-d5f174ae567b': IndexNode(id_='8b1c025a-015c-4561-a522-d5f174ae567b', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-18', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1ddb759a744ed54a5885bb93e09c3e6a0bed1921f330319362c66584215966ee'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='4135070e-27c5-48f8-a2c3-476fcb360b75', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='94cbcc42009169e1a6056c05363da6f05cfe0176b16de91cf95dec11d18e263f'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='584c31de-59f4-4678-b65c-25ce0a84e659', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7a7c381eb094d048400f923af1649b979e1cc0e94b7018fb4f81aa7ab626ec7f')}, text='This enables a model comparison “for free” on new prompts\\nand can help to increase diversity when sampling.\\nProgressionofModels. Figure11reportstheprogressofourdifferentSFTandthenRLHFversionsfor\\nboth Safetyand Helpfulnessaxes, measuredbyour in-houseSafetyand Helpfulnessreward models. On\\nthis set of evaluations, we outperform ChatGPT on both axes after RLHF-V3 (harmlessness and helpfulness\\n>50%). Despite the aforementioned relevance of using our reward as a point-wise metric, it can arguably be\\nbiased in favor of Llama 2-Chat .', start_char_idx=1751, end_char_idx=2283, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-18', obj=None),\n",
       " '584c31de-59f4-4678-b65c-25ce0a84e659': IndexNode(id_='584c31de-59f4-4678-b65c-25ce0a84e659', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-18', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1ddb759a744ed54a5885bb93e09c3e6a0bed1921f330319362c66584215966ee'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='8b1c025a-015c-4561-a522-d5f174ae567b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f860a72b044d315492c88b204592596d5b4d787f7a51d8795e4d363b5ee039f3'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='589d79e0-504b-413d-8197-017d339a16b8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='46e32631050e1cbcdfbb11b2313ea7707dd86ad3ae51979d9624891c4591a420')}, text='On\\nthis set of evaluations, we outperform ChatGPT on both axes after RLHF-V3 (harmlessness and helpfulness\\n>50%). Despite the aforementioned relevance of using our reward as a point-wise metric, it can arguably be\\nbiased in favor of Llama 2-Chat . Therefore, for a fair comparison, we additionally compute the final results\\nusingGPT-4toassesswhichgenerationispreferred. TheorderinwhichChatGPTand Llama 2-Chat outputs\\nappearedinGPT-4promptarerandomlyswappedtoavoidanybias.', start_char_idx=2036, end_char_idx=2507, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-18', obj=None),\n",
       " '589d79e0-504b-413d-8197-017d339a16b8': IndexNode(id_='589d79e0-504b-413d-8197-017d339a16b8', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-18', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1ddb759a744ed54a5885bb93e09c3e6a0bed1921f330319362c66584215966ee'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='584c31de-59f4-4678-b65c-25ce0a84e659', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7a7c381eb094d048400f923af1649b979e1cc0e94b7018fb4f81aa7ab626ec7f'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='858c499f-67d4-4f46-9b20-ad9e45cafa6d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ab17851b65c9d099a1386b39a7c51292cdb441c7122fd819e5f4f5657bd093bb')}, text='Despite the aforementioned relevance of using our reward as a point-wise metric, it can arguably be\\nbiased in favor of Llama 2-Chat . Therefore, for a fair comparison, we additionally compute the final results\\nusingGPT-4toassesswhichgenerationispreferred. TheorderinwhichChatGPTand Llama 2-Chat outputs\\nappearedinGPT-4promptarerandomlyswappedtoavoidanybias. Asexpected,thewin-rateinfavorof\\nLlama 2-Chat is less pronounced, although obtaining more than a 60% win-rate for our latest Llama 2-Chat .', start_char_idx=2150, end_char_idx=2646, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-18', obj=None),\n",
       " '858c499f-67d4-4f46-9b20-ad9e45cafa6d': IndexNode(id_='858c499f-67d4-4f46-9b20-ad9e45cafa6d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-18', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1ddb759a744ed54a5885bb93e09c3e6a0bed1921f330319362c66584215966ee'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='589d79e0-504b-413d-8197-017d339a16b8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='46e32631050e1cbcdfbb11b2313ea7707dd86ad3ae51979d9624891c4591a420'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='4247124f-7d66-4470-adb5-dcc8b2143f68', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='19621769927e373aeb7448cb4fc4197392fe40e2bdf8f0d32a7dd2c6e641437a')}, text='TheorderinwhichChatGPTand Llama 2-Chat outputs\\nappearedinGPT-4promptarerandomlyswappedtoavoidanybias. Asexpected,thewin-rateinfavorof\\nLlama 2-Chat is less pronounced, although obtaining more than a 60% win-rate for our latest Llama 2-Chat .\\nThe prompts correspond to a validation set of 1,586and584prompts for safety and helpfulness, respectively.\\n3.4.2 Human Evaluation\\nHuman evaluation is often considered the gold standardfor judging models fornatural language generation,\\nincluding dialogue models.', start_char_idx=2406, end_char_idx=2908, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-18', obj=None),\n",
       " '4247124f-7d66-4470-adb5-dcc8b2143f68': IndexNode(id_='4247124f-7d66-4470-adb5-dcc8b2143f68', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-18', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1ddb759a744ed54a5885bb93e09c3e6a0bed1921f330319362c66584215966ee'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='858c499f-67d4-4f46-9b20-ad9e45cafa6d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ab17851b65c9d099a1386b39a7c51292cdb441c7122fd819e5f4f5657bd093bb'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='facb9ba3-b184-45bd-b856-debc96693ea2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='08b0cbaa223c1590cdd976606da3f4d2a703408faee2130e49f723dd3a8f9015')}, text='Asexpected,thewin-rateinfavorof\\nLlama 2-Chat is less pronounced, although obtaining more than a 60% win-rate for our latest Llama 2-Chat .\\nThe prompts correspond to a validation set of 1,586and584prompts for safety and helpfulness, respectively.\\n3.4.2 Human Evaluation\\nHuman evaluation is often considered the gold standardfor judging models fornatural language generation,\\nincluding dialogue models. To evaluate the quality of major model versions, we asked human evaluators to\\nrate them on helpfulness and safety.', start_char_idx=2508, end_char_idx=3023, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-18', obj=None),\n",
       " 'facb9ba3-b184-45bd-b856-debc96693ea2': IndexNode(id_='facb9ba3-b184-45bd-b856-debc96693ea2', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-18', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1ddb759a744ed54a5885bb93e09c3e6a0bed1921f330319362c66584215966ee'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='4247124f-7d66-4470-adb5-dcc8b2143f68', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='19621769927e373aeb7448cb4fc4197392fe40e2bdf8f0d32a7dd2c6e641437a'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='473d328d-3712-44c2-ade2-04c64335b88c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='548b4b439964c6654736606457af571adc7519fc036e0e5402aba151e83175bf')}, text='The prompts correspond to a validation set of 1,586and584prompts for safety and helpfulness, respectively.\\n3.4.2 Human Evaluation\\nHuman evaluation is often considered the gold standardfor judging models fornatural language generation,\\nincluding dialogue models. To evaluate the quality of major model versions, we asked human evaluators to\\nrate them on helpfulness and safety. We compare the Llama 2-Chat models to open-source models (Falcon,\\nMPT MosaicML NLP Team et al. (2023), Vicuna Chiang et al.', start_char_idx=2647, end_char_idx=3147, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-18', obj=None),\n",
       " '473d328d-3712-44c2-ade2-04c64335b88c': IndexNode(id_='473d328d-3712-44c2-ade2-04c64335b88c', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-18', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1ddb759a744ed54a5885bb93e09c3e6a0bed1921f330319362c66584215966ee'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='facb9ba3-b184-45bd-b856-debc96693ea2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='08b0cbaa223c1590cdd976606da3f4d2a703408faee2130e49f723dd3a8f9015'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='c6fc2ed6-0d0b-4c3b-8b36-e25a52401b5a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d3785cd9a4b0c8c1cf05989ac000cf8e76aa8c2b56f193564f77880855c61607')}, text='3.4.2 Human Evaluation\\nHuman evaluation is often considered the gold standardfor judging models fornatural language generation,\\nincluding dialogue models. To evaluate the quality of major model versions, we asked human evaluators to\\nrate them on helpfulness and safety. We compare the Llama 2-Chat models to open-source models (Falcon,\\nMPT MosaicML NLP Team et al. (2023), Vicuna Chiang et al. (2023), as well as closed-source models (Chat-\\nGPT(OpenAI,2023)andPaLMAniletal.', start_char_idx=2754, end_char_idx=3227, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-18', obj=None),\n",
       " 'c6fc2ed6-0d0b-4c3b-8b36-e25a52401b5a': IndexNode(id_='c6fc2ed6-0d0b-4c3b-8b36-e25a52401b5a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-18', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1ddb759a744ed54a5885bb93e09c3e6a0bed1921f330319362c66584215966ee'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='473d328d-3712-44c2-ade2-04c64335b88c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='548b4b439964c6654736606457af571adc7519fc036e0e5402aba151e83175bf'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='18fbaaef-e8bc-4498-87f0-4318a6d0812b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3a6fc36dbc97ca94937c8e697a5f086cc1b5fb58353528755859b7b5c1b26e35')}, text='To evaluate the quality of major model versions, we asked human evaluators to\\nrate them on helpfulness and safety. We compare the Llama 2-Chat models to open-source models (Falcon,\\nMPT MosaicML NLP Team et al. (2023), Vicuna Chiang et al. (2023), as well as closed-source models (Chat-\\nGPT(OpenAI,2023)andPaLMAniletal.(2023))onover 4,000singleandmulti-turnprompts.', start_char_idx=2909, end_char_idx=3273, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-18', obj=None),\n",
       " '18fbaaef-e8bc-4498-87f0-4318a6d0812b': IndexNode(id_='18fbaaef-e8bc-4498-87f0-4318a6d0812b', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-18', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1ddb759a744ed54a5885bb93e09c3e6a0bed1921f330319362c66584215966ee'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='c6fc2ed6-0d0b-4c3b-8b36-e25a52401b5a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d3785cd9a4b0c8c1cf05989ac000cf8e76aa8c2b56f193564f77880855c61607'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='f23c6dec-b844-489d-91c5-5865e83bf30d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9da2b5097d6fb0a17aea611836fa8ca1d99e2e62ca07b7f50114f2bb494d7740')}, text='We compare the Llama 2-Chat models to open-source models (Falcon,\\nMPT MosaicML NLP Team et al. (2023), Vicuna Chiang et al. (2023), as well as closed-source models (Chat-\\nGPT(OpenAI,2023)andPaLMAniletal.(2023))onover 4,000singleandmulti-turnprompts. ForChatGPT,\\nweuse gpt-3.5-turbo-0301 modelinallgenerations.', start_char_idx=3024, end_char_idx=3333, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-18', obj=None),\n",
       " 'f23c6dec-b844-489d-91c5-5865e83bf30d': IndexNode(id_='f23c6dec-b844-489d-91c5-5865e83bf30d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-18', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1ddb759a744ed54a5885bb93e09c3e6a0bed1921f330319362c66584215966ee'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='18fbaaef-e8bc-4498-87f0-4318a6d0812b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3a6fc36dbc97ca94937c8e697a5f086cc1b5fb58353528755859b7b5c1b26e35'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='8dbbbf91-9dd3-40c0-96a7-d186749be7ad', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6aeea023543c72502583cbee90cc554a29a3ed07f303b062c6a4e688dd124f77')}, text='(2023), Vicuna Chiang et al. (2023), as well as closed-source models (Chat-\\nGPT(OpenAI,2023)andPaLMAniletal.(2023))onover 4,000singleandmulti-turnprompts. ForChatGPT,\\nweuse gpt-3.5-turbo-0301 modelinallgenerations. ForPaLM,weusethe chat-bison-001 modelinall\\ngenerations. ThefinalpromptcountforhumanevaluationsforeachmodelisshowninTable32.', start_char_idx=3119, end_char_idx=3457, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-18', obj=None),\n",
       " '8dbbbf91-9dd3-40c0-96a7-d186749be7ad': IndexNode(id_='8dbbbf91-9dd3-40c0-96a7-d186749be7ad', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-18', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1ddb759a744ed54a5885bb93e09c3e6a0bed1921f330319362c66584215966ee'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='f23c6dec-b844-489d-91c5-5865e83bf30d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9da2b5097d6fb0a17aea611836fa8ca1d99e2e62ca07b7f50114f2bb494d7740')}, text='(2023))onover 4,000singleandmulti-turnprompts. ForChatGPT,\\nweuse gpt-3.5-turbo-0301 modelinallgenerations. ForPaLM,weusethe chat-bison-001 modelinall\\ngenerations. ThefinalpromptcountforhumanevaluationsforeachmodelisshowninTable32. Seemore\\nmethodology details in Appendix, Section A.3.7.', start_char_idx=3227, end_char_idx=3513, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-18', obj=None),\n",
       " '306759b2-dfc2-437b-bc61-d62d419aa055': IndexNode(id_='306759b2-dfc2-437b-bc61-d62d419aa055', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-18', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1ddb759a744ed54a5885bb93e09c3e6a0bed1921f330319362c66584215966ee'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='11483b0e-6c6c-4c28-861a-f00752da36e2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='78de5fe1491bd92593dcdff1e3b454affd5385ed77647a927943dbf6e79623e1')}, text='How Far Can Model-Based Evaluation Go? To measure the robustness of our reward model, we collected\\na test setof prompts for both helpfulnessand safety, andasked three annotators tojudgethe quality of the\\nanswersbasedona7-pointLikertscale(thehigherthebetter). Weobservethatourrewardmodelsoverall\\nare well calibrated with our human preference annotations, as illustrated in Figure 29 in the appendix. This\\nconfirms the relevance of using our reward as a point-wise metric, despite being trained with a Pairwise\\nRanking Loss.\\nStill, as Goodhart’s Law states, when a measure becomes a target, it ceases to be a good measure. To ensure\\nourmeasurewon’tdivergefromthehumanpreferences,weadditionallyusedamoregeneralreward,', start_char_idx=0, end_char_idx=714, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-18', obj=None),\n",
       " '11483b0e-6c6c-4c28-861a-f00752da36e2': IndexNode(id_='11483b0e-6c6c-4c28-861a-f00752da36e2', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-18', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1ddb759a744ed54a5885bb93e09c3e6a0bed1921f330319362c66584215966ee'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='306759b2-dfc2-437b-bc61-d62d419aa055', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c916bb0738ace01a27dc25507a5ad8e0147c1ab6d23103bf13dd5d8cdf1671cb'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='4fb7cc16-b418-430f-be55-c4e3fc933e31', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6fe600f754560e748a92e08b2980148add770deb6e3df8e97b58eba07e650636')}, text='This\\nconfirms the relevance of using our reward as a point-wise metric, despite being trained with a Pairwise\\nRanking Loss.\\nStill, as Goodhart’s Law states, when a measure becomes a target, it ceases to be a good measure. To ensure\\nourmeasurewon’tdivergefromthehumanpreferences,weadditionallyusedamoregeneralreward,trained\\n17\\n\\nRLHF- v5\\n(with PPO)\\nRLHF- v5\\n(no PPO)\\nRLHF- v4\\nRLHF- v3\\n            RLHF- v2      RLHF- v1 SFT-v2       \\nSFT-v1\\n10% 20% 30% 40% 50% 60% 70% 80% 90%10%20%30%40%50%60%70%80%\\nHelpfulness\\nJudge: Meta R ewar d ModelsHarmlessness\\n  RLHF- v5\\n  (with PPO)RLHF- v5  \\n(no PPO)  \\nRLHF- v4\\nRLHF- v3\\n     RLHF- v2RLHF- v1     \\nSFT-v2    \\nSFT-v1\\n10% 20% 30% 40% 50% 60% 70% 80% 90%10%20%30%40%50%60%70%80%\\nHelpfulness\\nJudge: GPT -4HarmlessnessFigure 11: Evolution of Llama 2-Chat .', start_char_idx=399, end_char_idx=1193, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-18', obj=None),\n",
       " '4fb7cc16-b418-430f-be55-c4e3fc933e31': IndexNode(id_='4fb7cc16-b418-430f-be55-c4e3fc933e31', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-18', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1ddb759a744ed54a5885bb93e09c3e6a0bed1921f330319362c66584215966ee'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='11483b0e-6c6c-4c28-861a-f00752da36e2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='78de5fe1491bd92593dcdff1e3b454affd5385ed77647a927943dbf6e79623e1'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='05b9db5a-cf6b-425e-9ea6-494b84895858', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9a7eac03330a1645e571397d754cc70cddd2cb8291ac175bb9a1cfca56de9dcc')}, text='We show the evolution after multiple iterations fine-tuning for the\\nwin-rate%of Llama 2-Chat comparedtoChatGPT. Left: thejudgeisourrewardmodel,whichmayfavor\\nour model, and right, the judge is GPT-4, which should be more neutral.\\non diverse open-source Reward Modeling datasets. We have not yet observed any such divergence, and\\nhypothesize that iterative model updates may be helping to prevent this.\\nAs a last verification step to ensure no regression between our new model and the previous one, we use both\\nto sample during the next annotation iteration. This enables a model comparison “for free” on new prompts\\nand can help to increase diversity when sampling.\\nProgressionofModels. Figure11reportstheprogressofourdifferentSFTandthenRLHFversionsfor\\nboth Safetyand Helpfulnessaxes, measuredbyour in-houseSafetyand Helpfulnessreward models. On\\nthis set of evaluations, we outperform ChatGPT on both axes after RLHF-V3 (harmlessness and helpfulness\\n>50%).', start_char_idx=1194, end_char_idx=2149, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-18', obj=None),\n",
       " '05b9db5a-cf6b-425e-9ea6-494b84895858': IndexNode(id_='05b9db5a-cf6b-425e-9ea6-494b84895858', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-18', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1ddb759a744ed54a5885bb93e09c3e6a0bed1921f330319362c66584215966ee'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='4fb7cc16-b418-430f-be55-c4e3fc933e31', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6fe600f754560e748a92e08b2980148add770deb6e3df8e97b58eba07e650636'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='49d7cbc6-352f-4077-9b82-0b7ee96a2fee', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4f715abb553196c5683e1852230cd2804b3e8e15e0b7ebeb167b47c3f2b93ee3')}, text='This enables a model comparison “for free” on new prompts\\nand can help to increase diversity when sampling.\\nProgressionofModels. Figure11reportstheprogressofourdifferentSFTandthenRLHFversionsfor\\nboth Safetyand Helpfulnessaxes, measuredbyour in-houseSafetyand Helpfulnessreward models. On\\nthis set of evaluations, we outperform ChatGPT on both axes after RLHF-V3 (harmlessness and helpfulness\\n>50%). Despite the aforementioned relevance of using our reward as a point-wise metric, it can arguably be\\nbiased in favor of Llama 2-Chat . Therefore, for a fair comparison, we additionally compute the final results\\nusingGPT-4toassesswhichgenerationispreferred. TheorderinwhichChatGPTand Llama 2-Chat outputs\\nappearedinGPT-4promptarerandomlyswappedtoavoidanybias. Asexpected,thewin-rateinfavorof\\nLlama 2-Chat is less pronounced, although obtaining more than a 60% win-rate for our latest Llama 2-Chat .', start_char_idx=1751, end_char_idx=2646, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-18', obj=None),\n",
       " '49d7cbc6-352f-4077-9b82-0b7ee96a2fee': IndexNode(id_='49d7cbc6-352f-4077-9b82-0b7ee96a2fee', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-18', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1ddb759a744ed54a5885bb93e09c3e6a0bed1921f330319362c66584215966ee'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='05b9db5a-cf6b-425e-9ea6-494b84895858', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9a7eac03330a1645e571397d754cc70cddd2cb8291ac175bb9a1cfca56de9dcc'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='5eacf464-0f83-4dd8-a1ff-7d76163ee36a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7e7294298521e3ba259cf0d37e19d8547cf71efbca89fea1dc5891f70cde6bf6')}, text='TheorderinwhichChatGPTand Llama 2-Chat outputs\\nappearedinGPT-4promptarerandomlyswappedtoavoidanybias. Asexpected,thewin-rateinfavorof\\nLlama 2-Chat is less pronounced, although obtaining more than a 60% win-rate for our latest Llama 2-Chat .\\nThe prompts correspond to a validation set of 1,586and584prompts for safety and helpfulness, respectively.\\n3.4.2 Human Evaluation\\nHuman evaluation is often considered the gold standardfor judging models fornatural language generation,\\nincluding dialogue models. To evaluate the quality of major model versions, we asked human evaluators to\\nrate them on helpfulness and safety. We compare the Llama 2-Chat models to open-source models (Falcon,\\nMPT MosaicML NLP Team et al. (2023), Vicuna Chiang et al. (2023), as well as closed-source models (Chat-\\nGPT(OpenAI,2023)andPaLMAniletal.(2023))onover 4,000singleandmulti-turnprompts.', start_char_idx=2406, end_char_idx=3273, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-18', obj=None),\n",
       " '5eacf464-0f83-4dd8-a1ff-7d76163ee36a': IndexNode(id_='5eacf464-0f83-4dd8-a1ff-7d76163ee36a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-18', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1ddb759a744ed54a5885bb93e09c3e6a0bed1921f330319362c66584215966ee'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='49d7cbc6-352f-4077-9b82-0b7ee96a2fee', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4f715abb553196c5683e1852230cd2804b3e8e15e0b7ebeb167b47c3f2b93ee3')}, text='We compare the Llama 2-Chat models to open-source models (Falcon,\\nMPT MosaicML NLP Team et al. (2023), Vicuna Chiang et al. (2023), as well as closed-source models (Chat-\\nGPT(OpenAI,2023)andPaLMAniletal.(2023))onover 4,000singleandmulti-turnprompts. ForChatGPT,\\nweuse gpt-3.5-turbo-0301 modelinallgenerations. ForPaLM,weusethe chat-bison-001 modelinall\\ngenerations. ThefinalpromptcountforhumanevaluationsforeachmodelisshowninTable32. Seemore\\nmethodology details in Appendix, Section A.3.7.', start_char_idx=3024, end_char_idx=3513, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-18', obj=None),\n",
       " '25829fc6-93d7-42aa-a144-20d9f98fb885': IndexNode(id_='25829fc6-93d7-42aa-a144-20d9f98fb885', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-18', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1ddb759a744ed54a5885bb93e09c3e6a0bed1921f330319362c66584215966ee'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='5d34ad9e-ef44-471b-b729-ba3691906952', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f824ffc775247267e160bf982cec4a2d0e922b0709a7cec1f69c7e78c5a5999b')}, text='How Far Can Model-Based Evaluation Go? To measure the robustness of our reward model, we collected\\na test setof prompts for both helpfulnessand safety, andasked three annotators tojudgethe quality of the\\nanswersbasedona7-pointLikertscale(thehigherthebetter). Weobservethatourrewardmodelsoverall\\nare well calibrated with our human preference annotations, as illustrated in Figure 29 in the appendix. This\\nconfirms the relevance of using our reward as a point-wise metric, despite being trained with a Pairwise\\nRanking Loss.\\nStill, as Goodhart’s Law states, when a measure becomes a target, it ceases to be a good measure. To ensure\\nourmeasurewon’tdivergefromthehumanpreferences,weadditionallyusedamoregeneralreward,trained\\n17\\n\\nRLHF- v5\\n(with PPO)\\nRLHF- v5\\n(no PPO)\\nRLHF- v4\\nRLHF- v3\\n            RLHF- v2      RLHF- v1 SFT-v2       \\nSFT-v1\\n10% 20% 30% 40% 50% 60% 70% 80% 90%10%20%30%40%50%60%70%80%\\nHelpfulness\\nJudge: Meta R ewar d ModelsHarmlessness\\n  RLHF- v5\\n  (with PPO)RLHF- v5  \\n(no PPO)  \\nRLHF- v4\\nRLHF- v3\\n     RLHF- v2RLHF- v1     \\nSFT-v2    \\nSFT-v1\\n10% 20% 30% 40% 50% 60% 70% 80% 90%10%20%30%40%50%60%70%80%\\nHelpfulness\\nJudge: GPT -4HarmlessnessFigure 11: Evolution of Llama 2-Chat . We show the evolution after multiple iterations fine-tuning for the\\nwin-rate%of Llama 2-Chat comparedtoChatGPT. Left: thejudgeisourrewardmodel,whichmayfavor\\nour model, and right, the judge is GPT-4, which should be more neutral.\\non diverse open-source Reward Modeling datasets. We have not yet observed any such divergence, and\\nhypothesize that iterative model updates may be helping to prevent this.', start_char_idx=0, end_char_idx=1594, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-18', obj=None),\n",
       " '5d34ad9e-ef44-471b-b729-ba3691906952': IndexNode(id_='5d34ad9e-ef44-471b-b729-ba3691906952', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-18', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1ddb759a744ed54a5885bb93e09c3e6a0bed1921f330319362c66584215966ee'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='25829fc6-93d7-42aa-a144-20d9f98fb885', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='fc0234daaac8a89c7ead83e45cd78201215ea94b6027fc8205c3c3e2456c2495'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='be3cb4c5-c4c7-4ec0-9590-0143f0a6b7de', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ce6c52e8e1a2c566ffe0f55ab841d2637374ce165f8f207c22c49f06ede697b8')}, text='We show the evolution after multiple iterations fine-tuning for the\\nwin-rate%of Llama 2-Chat comparedtoChatGPT. Left: thejudgeisourrewardmodel,whichmayfavor\\nour model, and right, the judge is GPT-4, which should be more neutral.\\non diverse open-source Reward Modeling datasets. We have not yet observed any such divergence, and\\nhypothesize that iterative model updates may be helping to prevent this.\\nAs a last verification step to ensure no regression between our new model and the previous one, we use both\\nto sample during the next annotation iteration. This enables a model comparison “for free” on new prompts\\nand can help to increase diversity when sampling.\\nProgressionofModels. Figure11reportstheprogressofourdifferentSFTandthenRLHFversionsfor\\nboth Safetyand Helpfulnessaxes, measuredbyour in-houseSafetyand Helpfulnessreward models. On\\nthis set of evaluations, we outperform ChatGPT on both axes after RLHF-V3 (harmlessness and helpfulness\\n>50%). Despite the aforementioned relevance of using our reward as a point-wise metric, it can arguably be\\nbiased in favor of Llama 2-Chat . Therefore, for a fair comparison, we additionally compute the final results\\nusingGPT-4toassesswhichgenerationispreferred. TheorderinwhichChatGPTand Llama 2-Chat outputs\\nappearedinGPT-4promptarerandomlyswappedtoavoidanybias. Asexpected,thewin-rateinfavorof\\nLlama 2-Chat is less pronounced, although obtaining more than a 60% win-rate for our latest Llama 2-Chat .\\nThe prompts correspond to a validation set of 1,586and584prompts for safety and helpfulness, respectively.\\n3.4.2 Human Evaluation\\nHuman evaluation is often considered the gold standardfor judging models fornatural language generation,\\nincluding dialogue models. To evaluate the quality of major model versions, we asked human evaluators to\\nrate them on helpfulness and safety. We compare the Llama 2-Chat models to open-source models (Falcon,\\nMPT MosaicML NLP Team et al. (2023), Vicuna Chiang et al. (2023), as well as closed-source models (Chat-\\nGPT(OpenAI,2023)andPaLMAniletal.', start_char_idx=1194, end_char_idx=3227, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-18', obj=None),\n",
       " 'be3cb4c5-c4c7-4ec0-9590-0143f0a6b7de': IndexNode(id_='be3cb4c5-c4c7-4ec0-9590-0143f0a6b7de', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-18', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1ddb759a744ed54a5885bb93e09c3e6a0bed1921f330319362c66584215966ee'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='5d34ad9e-ef44-471b-b729-ba3691906952', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f824ffc775247267e160bf982cec4a2d0e922b0709a7cec1f69c7e78c5a5999b')}, text='To evaluate the quality of major model versions, we asked human evaluators to\\nrate them on helpfulness and safety. We compare the Llama 2-Chat models to open-source models (Falcon,\\nMPT MosaicML NLP Team et al. (2023), Vicuna Chiang et al. (2023), as well as closed-source models (Chat-\\nGPT(OpenAI,2023)andPaLMAniletal.(2023))onover 4,000singleandmulti-turnprompts. ForChatGPT,\\nweuse gpt-3.5-turbo-0301 modelinallgenerations. ForPaLM,weusethe chat-bison-001 modelinall\\ngenerations. ThefinalpromptcountforhumanevaluationsforeachmodelisshowninTable32. Seemore\\nmethodology details in Appendix, Section A.3.7.', start_char_idx=2909, end_char_idx=3513, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-18', obj=None),\n",
       " 'node-18': IndexNode(id_='node-18', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='d03f19eb-da15-45dc-bfd4-e5d10f161250', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='231b3bd773f012c01b893ada9e009ecf25ee59934614c5a595c9bf1b3a123292'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='699eb55f-af6b-42aa-b1f7-d224ec9e2f3e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8a04da5ed92bf1a6d51e061499afd1c8812c043e00b9bc06c48d8f1d02b22e7b'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='4aa7f620-b056-43d4-b812-5996e8ae8bc0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d21985ad5d4275d432dc8bb9b8a547319d2b7d5b284878f9ba8d81ee33b8f96c')}, text='How Far Can Model-Based Evaluation Go? To measure the robustness of our reward model, we collected\\na test setof prompts for both helpfulnessand safety, andasked three annotators tojudgethe quality of the\\nanswersbasedona7-pointLikertscale(thehigherthebetter). Weobservethatourrewardmodelsoverall\\nare well calibrated with our human preference annotations, as illustrated in Figure 29 in the appendix. This\\nconfirms the relevance of using our reward as a point-wise metric, despite being trained with a Pairwise\\nRanking Loss.\\nStill, as Goodhart’s Law states, when a measure becomes a target, it ceases to be a good measure. To ensure\\nourmeasurewon’tdivergefromthehumanpreferences,weadditionallyusedamoregeneralreward,trained\\n17\\n\\nRLHF- v5\\n(with PPO)\\nRLHF- v5\\n(no PPO)\\nRLHF- v4\\nRLHF- v3\\n            RLHF- v2      RLHF- v1 SFT-v2       \\nSFT-v1\\n10% 20% 30% 40% 50% 60% 70% 80% 90%10%20%30%40%50%60%70%80%\\nHelpfulness\\nJudge: Meta R ewar d ModelsHarmlessness\\n  RLHF- v5\\n  (with PPO)RLHF- v5  \\n(no PPO)  \\nRLHF- v4\\nRLHF- v3\\n     RLHF- v2RLHF- v1     \\nSFT-v2    \\nSFT-v1\\n10% 20% 30% 40% 50% 60% 70% 80% 90%10%20%30%40%50%60%70%80%\\nHelpfulness\\nJudge: GPT -4HarmlessnessFigure 11: Evolution of Llama 2-Chat . We show the evolution after multiple iterations fine-tuning for the\\nwin-rate%of Llama 2-Chat comparedtoChatGPT. Left: thejudgeisourrewardmodel,whichmayfavor\\nour model, and right, the judge is GPT-4, which should be more neutral.\\non diverse open-source Reward Modeling datasets. We have not yet observed any such divergence, and\\nhypothesize that iterative model updates may be helping to prevent this.\\nAs a last verification step to ensure no regression between our new model and the previous one, we use both\\nto sample during the next annotation iteration. This enables a model comparison “for free” on new prompts\\nand can help to increase diversity when sampling.\\nProgressionofModels. Figure11reportstheprogressofourdifferentSFTandthenRLHFversionsfor\\nboth Safetyand Helpfulnessaxes, measuredbyour in-houseSafetyand Helpfulnessreward models. On\\nthis set of evaluations, we outperform ChatGPT on both axes after RLHF-V3 (harmlessness and helpfulness\\n>50%). Despite the aforementioned relevance of using our reward as a point-wise metric, it can arguably be\\nbiased in favor of Llama 2-Chat . Therefore, for a fair comparison, we additionally compute the final results\\nusingGPT-4toassesswhichgenerationispreferred. TheorderinwhichChatGPTand Llama 2-Chat outputs\\nappearedinGPT-4promptarerandomlyswappedtoavoidanybias. Asexpected,thewin-rateinfavorof\\nLlama 2-Chat is less pronounced, although obtaining more than a 60% win-rate for our latest Llama 2-Chat .\\nThe prompts correspond to a validation set of 1,586and584prompts for safety and helpfulness, respectively.\\n3.4.2 Human Evaluation\\nHuman evaluation is often considered the gold standardfor judging models fornatural language generation,\\nincluding dialogue models. To evaluate the quality of major model versions, we asked human evaluators to\\nrate them on helpfulness and safety. We compare the Llama 2-Chat models to open-source models (Falcon,\\nMPT MosaicML NLP Team et al. (2023), Vicuna Chiang et al. (2023), as well as closed-source models (Chat-\\nGPT(OpenAI,2023)andPaLMAniletal.(2023))onover 4,000singleandmulti-turnprompts. ForChatGPT,\\nweuse gpt-3.5-turbo-0301 modelinallgenerations. ForPaLM,weusethe chat-bison-001 modelinall\\ngenerations. ThefinalpromptcountforhumanevaluationsforeachmodelisshowninTable32. Seemore\\nmethodology details in Appendix, Section A.3.7.', start_char_idx=54829, end_char_idx=58342, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-18', obj=None),\n",
       " 'b92e9d5e-76de-4cd7-b6d9-be6359c82d77': IndexNode(id_='b92e9d5e-76de-4cd7-b6d9-be6359c82d77', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-19', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d21985ad5d4275d432dc8bb9b8a547319d2b7d5b284878f9ba8d81ee33b8f96c'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='b60241d1-7c51-4381-8de1-2eb7b574eff2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='549a58c0da117f4d8b06debb1ee9d26447ae25d890b9121d1efa549dd18fe523')}, text='(2023))onover 4,000singleandmulti-turnprompts. ForChatGPT,\\nweuse gpt-3.5-turbo-0301 modelinallgenerations. ForPaLM,weusethe chat-bison-001 modelinall\\ngenerations. ThefinalpromptcountforhumanevaluationsforeachmodelisshowninTable32. Seemore\\nmethodology details in Appendix, Section A.3.7. The following section shows helpfulness results; safety\\nresults are presented in Section 4.4.\\nResults.', start_char_idx=0, end_char_idx=389, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-19', obj=None),\n",
       " 'b60241d1-7c51-4381-8de1-2eb7b574eff2': IndexNode(id_='b60241d1-7c51-4381-8de1-2eb7b574eff2', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-19', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d21985ad5d4275d432dc8bb9b8a547319d2b7d5b284878f9ba8d81ee33b8f96c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='b92e9d5e-76de-4cd7-b6d9-be6359c82d77', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='809700d516ac9d4a271c4a0e28f700177d479eda95c05b198d49c04347b59464'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='0173d025-25f6-440c-930f-4c8fbfce06b9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='21bde1080b68fef00696865116f4fcdf307f94956b7d1bbaf06e138edfd34eb6')}, text='ForPaLM,weusethe chat-bison-001 modelinall\\ngenerations. ThefinalpromptcountforhumanevaluationsforeachmodelisshowninTable32. Seemore\\nmethodology details in Appendix, Section A.3.7. The following section shows helpfulness results; safety\\nresults are presented in Section 4.4.\\nResults. AsshowninFigure12, Llama 2-Chat modelsoutperformopen-sourcemodelsbyasignificant\\nmargin on both single turn and multi-turn prompts.', start_char_idx=107, end_char_idx=520, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-19', obj=None),\n",
       " '0173d025-25f6-440c-930f-4c8fbfce06b9': IndexNode(id_='0173d025-25f6-440c-930f-4c8fbfce06b9', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-19', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d21985ad5d4275d432dc8bb9b8a547319d2b7d5b284878f9ba8d81ee33b8f96c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='b60241d1-7c51-4381-8de1-2eb7b574eff2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='549a58c0da117f4d8b06debb1ee9d26447ae25d890b9121d1efa549dd18fe523'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='541817d6-8c73-45e4-a720-2c37ba6bcd43', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9cc45c561111e1e9dc759b3c48f218fd6f08e682ef2b005fbd0754b22ab4e2a0')}, text='ThefinalpromptcountforhumanevaluationsforeachmodelisshowninTable32. Seemore\\nmethodology details in Appendix, Section A.3.7. The following section shows helpfulness results; safety\\nresults are presented in Section 4.4.\\nResults. AsshowninFigure12, Llama 2-Chat modelsoutperformopen-sourcemodelsbyasignificant\\nmargin on both single turn and multi-turn prompts. Particularly, Llama 2-Chat 7B model outperforms\\nMPT-7B-chaton60%oftheprompts.', start_char_idx=163, end_char_idx=598, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-19', obj=None),\n",
       " '541817d6-8c73-45e4-a720-2c37ba6bcd43': IndexNode(id_='541817d6-8c73-45e4-a720-2c37ba6bcd43', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-19', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d21985ad5d4275d432dc8bb9b8a547319d2b7d5b284878f9ba8d81ee33b8f96c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='0173d025-25f6-440c-930f-4c8fbfce06b9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='21bde1080b68fef00696865116f4fcdf307f94956b7d1bbaf06e138edfd34eb6'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='f4e2af87-4f7f-4370-a93c-65cd6be2ab3e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0f35a0003cc466179d87e7be40452acc39625a2e89264788e8b850aa86933509')}, text='The following section shows helpfulness results; safety\\nresults are presented in Section 4.4.\\nResults. AsshowninFigure12, Llama 2-Chat modelsoutperformopen-sourcemodelsbyasignificant\\nmargin on both single turn and multi-turn prompts. Particularly, Llama 2-Chat 7B model outperforms\\nMPT-7B-chaton60%oftheprompts. Llama 2-Chat 34Bhasanoverallwinrateofmorethan75%against\\nequivalently sized Vicuna-33B and Falcon 40B models.', start_char_idx=287, end_char_idx=707, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-19', obj=None),\n",
       " 'f4e2af87-4f7f-4370-a93c-65cd6be2ab3e': IndexNode(id_='f4e2af87-4f7f-4370-a93c-65cd6be2ab3e', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-19', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d21985ad5d4275d432dc8bb9b8a547319d2b7d5b284878f9ba8d81ee33b8f96c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='541817d6-8c73-45e4-a720-2c37ba6bcd43', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9cc45c561111e1e9dc759b3c48f218fd6f08e682ef2b005fbd0754b22ab4e2a0'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='6197ce2c-40d7-4f74-a5a8-3b9cb460e5de', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e2aa8f00c7262b23f6835b42f4be6d56fc71586c49f910700c673af944f65d0c')}, text='Particularly, Llama 2-Chat 7B model outperforms\\nMPT-7B-chaton60%oftheprompts. Llama 2-Chat 34Bhasanoverallwinrateofmorethan75%against\\nequivalently sized Vicuna-33B and Falcon 40B models.\\n18\\n\\nFigure12: Humanevaluationresults forLlama 2-Chat modelscomparedtoopen-andclosed-sourcemodels\\nacross ~4,000 helpfulness prompts with three raters per prompt.', start_char_idx=521, end_char_idx=868, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-19', obj=None),\n",
       " '6197ce2c-40d7-4f74-a5a8-3b9cb460e5de': IndexNode(id_='6197ce2c-40d7-4f74-a5a8-3b9cb460e5de', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-19', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d21985ad5d4275d432dc8bb9b8a547319d2b7d5b284878f9ba8d81ee33b8f96c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='f4e2af87-4f7f-4370-a93c-65cd6be2ab3e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0f35a0003cc466179d87e7be40452acc39625a2e89264788e8b850aa86933509'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='a6b730ff-649c-4cc6-b7ff-519b84c117b2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ce18eff74d0ca240999df3e20ba578d0c8a64630adc2b63ae7d6f14e970a9b18')}, text='Llama 2-Chat 34Bhasanoverallwinrateofmorethan75%against\\nequivalently sized Vicuna-33B and Falcon 40B models.\\n18\\n\\nFigure12: Humanevaluationresults forLlama 2-Chat modelscomparedtoopen-andclosed-sourcemodels\\nacross ~4,000 helpfulness prompts with three raters per prompt.\\nThelargest Llama 2-Chat modeliscompetitivewithChatGPT.', start_char_idx=599, end_char_idx=923, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-19', obj=None),\n",
       " 'a6b730ff-649c-4cc6-b7ff-519b84c117b2': IndexNode(id_='a6b730ff-649c-4cc6-b7ff-519b84c117b2', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-19', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d21985ad5d4275d432dc8bb9b8a547319d2b7d5b284878f9ba8d81ee33b8f96c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='6197ce2c-40d7-4f74-a5a8-3b9cb460e5de', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e2aa8f00c7262b23f6835b42f4be6d56fc71586c49f910700c673af944f65d0c'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='2caa1bfb-cbe0-4914-be40-50da6efeea6c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6443455ff9042b9428a92bdda5be2b56bb1376917fdd5e4ef2e90aba3892f6f2')}, text='18\\n\\nFigure12: Humanevaluationresults forLlama 2-Chat modelscomparedtoopen-andclosed-sourcemodels\\nacross ~4,000 helpfulness prompts with three raters per prompt.\\nThelargest Llama 2-Chat modeliscompetitivewithChatGPT. Llama 2-Chat 70Bmodelhasawinrateof\\n36% and a tie rate of 31.5% relative to ChatGPT.', start_char_idx=708, end_char_idx=1007, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-19', obj=None),\n",
       " '2caa1bfb-cbe0-4914-be40-50da6efeea6c': IndexNode(id_='2caa1bfb-cbe0-4914-be40-50da6efeea6c', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-19', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d21985ad5d4275d432dc8bb9b8a547319d2b7d5b284878f9ba8d81ee33b8f96c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='a6b730ff-649c-4cc6-b7ff-519b84c117b2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ce18eff74d0ca240999df3e20ba578d0c8a64630adc2b63ae7d6f14e970a9b18'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='7087e294-a454-43fb-b530-1f92ac3925b9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='22c1f46b902d096eaba24207c45967136ff93056ad6f8863559d26a1e686c09e')}, text='18\\n\\nFigure12: Humanevaluationresults forLlama 2-Chat modelscomparedtoopen-andclosed-sourcemodels\\nacross ~4,000 helpfulness prompts with three raters per prompt.\\nThelargest Llama 2-Chat modeliscompetitivewithChatGPT. Llama 2-Chat 70Bmodelhasawinrateof\\n36% and a tie rate of 31.5% relative to ChatGPT. Llama 2-Chat 70B model outperforms PaLM-bison chat\\nmodel by a large percentage on our prompt set.', start_char_idx=708, end_char_idx=1105, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-19', obj=None),\n",
       " '7087e294-a454-43fb-b530-1f92ac3925b9': IndexNode(id_='7087e294-a454-43fb-b530-1f92ac3925b9', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-19', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d21985ad5d4275d432dc8bb9b8a547319d2b7d5b284878f9ba8d81ee33b8f96c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='2caa1bfb-cbe0-4914-be40-50da6efeea6c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6443455ff9042b9428a92bdda5be2b56bb1376917fdd5e4ef2e90aba3892f6f2'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='6b5760a8-68da-4f15-9d17-fb4febeddebc', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bdd253e8cd7c906d1a47ebebf24c6881db73d35a041ead25e337ebac72da8d2f')}, text='Thelargest Llama 2-Chat modeliscompetitivewithChatGPT. Llama 2-Chat 70Bmodelhasawinrateof\\n36% and a tie rate of 31.5% relative to ChatGPT. Llama 2-Chat 70B model outperforms PaLM-bison chat\\nmodel by a large percentage on our prompt set. More results and analysis is available in Section A.3.7.\\nInter-Rater Reliability (IRR).', start_char_idx=869, end_char_idx=1193, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-19', obj=None),\n",
       " '6b5760a8-68da-4f15-9d17-fb4febeddebc': IndexNode(id_='6b5760a8-68da-4f15-9d17-fb4febeddebc', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-19', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d21985ad5d4275d432dc8bb9b8a547319d2b7d5b284878f9ba8d81ee33b8f96c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='7087e294-a454-43fb-b530-1f92ac3925b9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='22c1f46b902d096eaba24207c45967136ff93056ad6f8863559d26a1e686c09e'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='608c8b0e-8c45-4285-bdaa-194ed69fe549', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bfcf9db60515858713a63339bed04f51327cb46ccea24eeeeca1ea2c2afa180f')}, text='Llama 2-Chat 70Bmodelhasawinrateof\\n36% and a tie rate of 31.5% relative to ChatGPT. Llama 2-Chat 70B model outperforms PaLM-bison chat\\nmodel by a large percentage on our prompt set. More results and analysis is available in Section A.3.7.\\nInter-Rater Reliability (IRR). In our human evaluations, three different annotators provided independent\\nassessments for each model generation comparison.', start_char_idx=924, end_char_idx=1317, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-19', obj=None),\n",
       " '608c8b0e-8c45-4285-bdaa-194ed69fe549': IndexNode(id_='608c8b0e-8c45-4285-bdaa-194ed69fe549', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-19', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d21985ad5d4275d432dc8bb9b8a547319d2b7d5b284878f9ba8d81ee33b8f96c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='6b5760a8-68da-4f15-9d17-fb4febeddebc', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bdd253e8cd7c906d1a47ebebf24c6881db73d35a041ead25e337ebac72da8d2f'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='f07ca178-e8a3-4cb5-9a5d-9db9543b56ee', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='46a7b1d3e925418cfb9346de2e6b7a334c23b6513ac041824271a753123fe508')}, text='Llama 2-Chat 70B model outperforms PaLM-bison chat\\nmodel by a large percentage on our prompt set. More results and analysis is available in Section A.3.7.\\nInter-Rater Reliability (IRR). In our human evaluations, three different annotators provided independent\\nassessments for each model generation comparison. High IRR scores (closer to 1.0) are typically seen as\\nbetter from a data quality perspective, however, context is important.', start_char_idx=1008, end_char_idx=1442, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-19', obj=None),\n",
       " 'f07ca178-e8a3-4cb5-9a5d-9db9543b56ee': IndexNode(id_='f07ca178-e8a3-4cb5-9a5d-9db9543b56ee', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-19', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d21985ad5d4275d432dc8bb9b8a547319d2b7d5b284878f9ba8d81ee33b8f96c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='608c8b0e-8c45-4285-bdaa-194ed69fe549', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bfcf9db60515858713a63339bed04f51327cb46ccea24eeeeca1ea2c2afa180f'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='c7de133c-3501-4298-b683-720d68544dd4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='26095f5d4c5300b71a4b1d43137aeb923bd651a656ea3fe347d443d2d17b9f3d')}, text='More results and analysis is available in Section A.3.7.\\nInter-Rater Reliability (IRR). In our human evaluations, three different annotators provided independent\\nassessments for each model generation comparison. High IRR scores (closer to 1.0) are typically seen as\\nbetter from a data quality perspective, however, context is important. Highly subjective tasks like evaluating\\nthe overall helpfulness of LLM generations will usually have lower IRR scores than more objective labelling\\ntasks.', start_char_idx=1106, end_char_idx=1597, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-19', obj=None),\n",
       " 'c7de133c-3501-4298-b683-720d68544dd4': IndexNode(id_='c7de133c-3501-4298-b683-720d68544dd4', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-19', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d21985ad5d4275d432dc8bb9b8a547319d2b7d5b284878f9ba8d81ee33b8f96c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='f07ca178-e8a3-4cb5-9a5d-9db9543b56ee', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='46a7b1d3e925418cfb9346de2e6b7a334c23b6513ac041824271a753123fe508'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='8d63b1de-f20d-42aa-88e5-398e3601829f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e2abffca1694ac4f1979d8a51866ac232aaae88a1b65393d21724b60e33d2214')}, text='Inter-Rater Reliability (IRR). In our human evaluations, three different annotators provided independent\\nassessments for each model generation comparison. High IRR scores (closer to 1.0) are typically seen as\\nbetter from a data quality perspective, however, context is important. Highly subjective tasks like evaluating\\nthe overall helpfulness of LLM generations will usually have lower IRR scores than more objective labelling\\ntasks. There arerelativelyfewpublicbenchmarksfor thesecontexts, sowefeelsharing ouranalysis herewill\\nbenefit the research community.', start_char_idx=1163, end_char_idx=1723, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-19', obj=None),\n",
       " '8d63b1de-f20d-42aa-88e5-398e3601829f': IndexNode(id_='8d63b1de-f20d-42aa-88e5-398e3601829f', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-19', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d21985ad5d4275d432dc8bb9b8a547319d2b7d5b284878f9ba8d81ee33b8f96c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='c7de133c-3501-4298-b683-720d68544dd4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='26095f5d4c5300b71a4b1d43137aeb923bd651a656ea3fe347d443d2d17b9f3d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='4b69fbeb-e402-4b97-bc41-36d17a95726a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='434fd61f7f30c9c86bc8b2c2838f3b4c1de5d4ac00476d6479ca5d1dc0be2099')}, text='High IRR scores (closer to 1.0) are typically seen as\\nbetter from a data quality perspective, however, context is important. Highly subjective tasks like evaluating\\nthe overall helpfulness of LLM generations will usually have lower IRR scores than more objective labelling\\ntasks. There arerelativelyfewpublicbenchmarksfor thesecontexts, sowefeelsharing ouranalysis herewill\\nbenefit the research community.\\nWe used Gwet’s AC1/2 statistic (Gwet, 2008, 2014) to measure inter-rater reliability (IRR), as we found it to\\nbethemoststablemetricacrossdifferentmeasurementscenarios.', start_char_idx=1318, end_char_idx=1891, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-19', obj=None),\n",
       " '4b69fbeb-e402-4b97-bc41-36d17a95726a': IndexNode(id_='4b69fbeb-e402-4b97-bc41-36d17a95726a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-19', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d21985ad5d4275d432dc8bb9b8a547319d2b7d5b284878f9ba8d81ee33b8f96c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='8d63b1de-f20d-42aa-88e5-398e3601829f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e2abffca1694ac4f1979d8a51866ac232aaae88a1b65393d21724b60e33d2214'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='9d19a04b-db39-4e94-94e2-76342b77edfe', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7bb353865328d3f73f0787c97e578ab43f703f15f7a11cd699a97643671130ac')}, text='There arerelativelyfewpublicbenchmarksfor thesecontexts, sowefeelsharing ouranalysis herewill\\nbenefit the research community.\\nWe used Gwet’s AC1/2 statistic (Gwet, 2008, 2014) to measure inter-rater reliability (IRR), as we found it to\\nbethemoststablemetricacrossdifferentmeasurementscenarios. Onthe7-pointLikertscalehelpfulness\\ntaskthatisusedinouranalysis,Gwet’sAC2scorevariesbetween 0.37and0.55dependingonthespecific\\nmodelcomparison.', start_char_idx=1598, end_char_idx=2033, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-19', obj=None),\n",
       " '9d19a04b-db39-4e94-94e2-76342b77edfe': IndexNode(id_='9d19a04b-db39-4e94-94e2-76342b77edfe', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-19', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d21985ad5d4275d432dc8bb9b8a547319d2b7d5b284878f9ba8d81ee33b8f96c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='4b69fbeb-e402-4b97-bc41-36d17a95726a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='434fd61f7f30c9c86bc8b2c2838f3b4c1de5d4ac00476d6479ca5d1dc0be2099'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='be6c81bd-e27f-4ea8-b470-c57a33928823', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7a741201bc868a8af7e86af386a73536c17f2dc0553d76b7d311a1afeb40a9af')}, text='We used Gwet’s AC1/2 statistic (Gwet, 2008, 2014) to measure inter-rater reliability (IRR), as we found it to\\nbethemoststablemetricacrossdifferentmeasurementscenarios. Onthe7-pointLikertscalehelpfulness\\ntaskthatisusedinouranalysis,Gwet’sAC2scorevariesbetween 0.37and0.55dependingonthespecific\\nmodelcomparison. Weseescoresonthelowerendofthatrangeforratingsfrommodelcomparisonswith\\nsimilar win rates to each other (like the Llama 2-Chat -70B-chat vs.', start_char_idx=1724, end_char_idx=2172, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-19', obj=None),\n",
       " 'be6c81bd-e27f-4ea8-b470-c57a33928823': IndexNode(id_='be6c81bd-e27f-4ea8-b470-c57a33928823', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-19', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d21985ad5d4275d432dc8bb9b8a547319d2b7d5b284878f9ba8d81ee33b8f96c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='9d19a04b-db39-4e94-94e2-76342b77edfe', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7bb353865328d3f73f0787c97e578ab43f703f15f7a11cd699a97643671130ac'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='ed59d234-c999-4c56-8987-16edd73ac621', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bb6a7d06f5d7a24252490bc4f3ced36a7e05d59179b3652924d9d6409150cda1')}, text='Onthe7-pointLikertscalehelpfulness\\ntaskthatisusedinouranalysis,Gwet’sAC2scorevariesbetween 0.37and0.55dependingonthespecific\\nmodelcomparison. Weseescoresonthelowerendofthatrangeforratingsfrommodelcomparisonswith\\nsimilar win rates to each other (like the Llama 2-Chat -70B-chat vs. ChatGPT comparison).', start_char_idx=1892, end_char_idx=2193, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-19', obj=None),\n",
       " 'ed59d234-c999-4c56-8987-16edd73ac621': IndexNode(id_='ed59d234-c999-4c56-8987-16edd73ac621', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-19', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d21985ad5d4275d432dc8bb9b8a547319d2b7d5b284878f9ba8d81ee33b8f96c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='be6c81bd-e27f-4ea8-b470-c57a33928823', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7a741201bc868a8af7e86af386a73536c17f2dc0553d76b7d311a1afeb40a9af'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='5917028e-6a24-416a-8909-58cb8d7dc56c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ac4c2f0f5aa950fc18ec94e23b3dfc0f683caba5b107cfd1835e34ecee5dc465')}, text='Onthe7-pointLikertscalehelpfulness\\ntaskthatisusedinouranalysis,Gwet’sAC2scorevariesbetween 0.37and0.55dependingonthespecific\\nmodelcomparison. Weseescoresonthelowerendofthatrangeforratingsfrommodelcomparisonswith\\nsimilar win rates to each other (like the Llama 2-Chat -70B-chat vs. ChatGPT comparison). We see scores on\\nthehigherendofthatrangeforratingsfrommodelcomparisonswithamoreclearwinner(likethe Llama\\n2-Chat-34b-chat vs.', start_char_idx=1892, end_char_idx=2318, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-19', obj=None),\n",
       " '5917028e-6a24-416a-8909-58cb8d7dc56c': IndexNode(id_='5917028e-6a24-416a-8909-58cb8d7dc56c', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-19', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d21985ad5d4275d432dc8bb9b8a547319d2b7d5b284878f9ba8d81ee33b8f96c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='ed59d234-c999-4c56-8987-16edd73ac621', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bb6a7d06f5d7a24252490bc4f3ced36a7e05d59179b3652924d9d6409150cda1'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='2a19645d-adf3-44de-9f63-d1307a1ddff6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='24ddbdd305f136c4b908628c3faf19832ee0cc9168605c4435d6549302b3cebd')}, text='Weseescoresonthelowerendofthatrangeforratingsfrommodelcomparisonswith\\nsimilar win rates to each other (like the Llama 2-Chat -70B-chat vs. ChatGPT comparison). We see scores on\\nthehigherendofthatrangeforratingsfrommodelcomparisonswithamoreclearwinner(likethe Llama\\n2-Chat-34b-chat vs. Falcon-40b-instruct).\\nLimitations of human evaluations.', start_char_idx=2034, end_char_idx=2374, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-19', obj=None),\n",
       " '2a19645d-adf3-44de-9f63-d1307a1ddff6': IndexNode(id_='2a19645d-adf3-44de-9f63-d1307a1ddff6', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-19', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d21985ad5d4275d432dc8bb9b8a547319d2b7d5b284878f9ba8d81ee33b8f96c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='5917028e-6a24-416a-8909-58cb8d7dc56c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ac4c2f0f5aa950fc18ec94e23b3dfc0f683caba5b107cfd1835e34ecee5dc465'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='bcb9df56-1734-4a1f-b33c-bafb459a2063', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='40568c2911cb5cf1d269db0767e30a5c1be52a80050a95048e87e677d3f6db85')}, text='Weseescoresonthelowerendofthatrangeforratingsfrommodelcomparisonswith\\nsimilar win rates to each other (like the Llama 2-Chat -70B-chat vs. ChatGPT comparison). We see scores on\\nthehigherendofthatrangeforratingsfrommodelcomparisonswithamoreclearwinner(likethe Llama\\n2-Chat-34b-chat vs. Falcon-40b-instruct).\\nLimitations of human evaluations. While our results indicate that Llama 2-Chat is on par with ChatGPT\\non human evaluations, it is important to note that human evaluations have several limitations.', start_char_idx=2034, end_char_idx=2537, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-19', obj=None),\n",
       " 'bcb9df56-1734-4a1f-b33c-bafb459a2063': IndexNode(id_='bcb9df56-1734-4a1f-b33c-bafb459a2063', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-19', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d21985ad5d4275d432dc8bb9b8a547319d2b7d5b284878f9ba8d81ee33b8f96c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='2a19645d-adf3-44de-9f63-d1307a1ddff6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='24ddbdd305f136c4b908628c3faf19832ee0cc9168605c4435d6549302b3cebd'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='8445ccd0-fffc-4434-9310-b11bd046c000', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='328ba885daaf2c4c678342718d78d4a0c199c019c42997e2b69eea43e73ead60')}, text='ChatGPT comparison). We see scores on\\nthehigherendofthatrangeforratingsfrommodelcomparisonswithamoreclearwinner(likethe Llama\\n2-Chat-34b-chat vs. Falcon-40b-instruct).\\nLimitations of human evaluations. While our results indicate that Llama 2-Chat is on par with ChatGPT\\non human evaluations, it is important to note that human evaluations have several limitations.\\n•Byacademicandresearchstandards,wehavealargepromptsetof4kprompts.', start_char_idx=2173, end_char_idx=2603, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-19', obj=None),\n",
       " '8445ccd0-fffc-4434-9310-b11bd046c000': IndexNode(id_='8445ccd0-fffc-4434-9310-b11bd046c000', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-19', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d21985ad5d4275d432dc8bb9b8a547319d2b7d5b284878f9ba8d81ee33b8f96c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='bcb9df56-1734-4a1f-b33c-bafb459a2063', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='40568c2911cb5cf1d269db0767e30a5c1be52a80050a95048e87e677d3f6db85'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='ecdae302-300a-4e87-97ba-a1a5c1351fe8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e611b7841737d706c5d652cccca56350cd31e007d15890a064afa92610062661')}, text='Falcon-40b-instruct).\\nLimitations of human evaluations. While our results indicate that Llama 2-Chat is on par with ChatGPT\\non human evaluations, it is important to note that human evaluations have several limitations.\\n•Byacademicandresearchstandards,wehavealargepromptsetof4kprompts. However,itdoesnotcover\\nreal-world usage of these models, which will likely cover a significantly larger number of use cases.\\n•Diversity of the prompts could be another factor in our results.', start_char_idx=2319, end_char_idx=2794, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-19', obj=None),\n",
       " 'ecdae302-300a-4e87-97ba-a1a5c1351fe8': IndexNode(id_='ecdae302-300a-4e87-97ba-a1a5c1351fe8', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-19', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d21985ad5d4275d432dc8bb9b8a547319d2b7d5b284878f9ba8d81ee33b8f96c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='8445ccd0-fffc-4434-9310-b11bd046c000', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='328ba885daaf2c4c678342718d78d4a0c199c019c42997e2b69eea43e73ead60'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='a6221139-164b-45d1-bcbf-390ff72c00d9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='49062a850ade2c4e4e03c94ed9cc3e0326a80f548737293bf2bcfedf0a2bd490')}, text='While our results indicate that Llama 2-Chat is on par with ChatGPT\\non human evaluations, it is important to note that human evaluations have several limitations.\\n•Byacademicandresearchstandards,wehavealargepromptsetof4kprompts. However,itdoesnotcover\\nreal-world usage of these models, which will likely cover a significantly larger number of use cases.\\n•Diversity of the prompts could be another factor in our results. For example, our prompt set does not\\ninclude any coding- or reasoning-related prompts.\\n•We only evaluate the final generation of a multi-turn conversation.', start_char_idx=2375, end_char_idx=2950, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-19', obj=None),\n",
       " 'a6221139-164b-45d1-bcbf-390ff72c00d9': IndexNode(id_='a6221139-164b-45d1-bcbf-390ff72c00d9', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-19', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d21985ad5d4275d432dc8bb9b8a547319d2b7d5b284878f9ba8d81ee33b8f96c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='ecdae302-300a-4e87-97ba-a1a5c1351fe8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e611b7841737d706c5d652cccca56350cd31e007d15890a064afa92610062661'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='9997cf8c-6201-4404-a6c0-5fa24d45adc9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='52d5baaeaef038bd74867d21bc54c5a9b3e993bbc42d056189438febf5c9b6f2')}, text='•Byacademicandresearchstandards,wehavealargepromptsetof4kprompts. However,itdoesnotcover\\nreal-world usage of these models, which will likely cover a significantly larger number of use cases.\\n•Diversity of the prompts could be another factor in our results. For example, our prompt set does not\\ninclude any coding- or reasoning-related prompts.\\n•We only evaluate the final generation of a multi-turn conversation. A more interesting evaluation could be\\nto ask the models to complete a task and rate the overall experience with the model over multiple turns.', start_char_idx=2538, end_char_idx=3094, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-19', obj=None),\n",
       " '9997cf8c-6201-4404-a6c0-5fa24d45adc9': IndexNode(id_='9997cf8c-6201-4404-a6c0-5fa24d45adc9', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-19', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d21985ad5d4275d432dc8bb9b8a547319d2b7d5b284878f9ba8d81ee33b8f96c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='a6221139-164b-45d1-bcbf-390ff72c00d9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='49062a850ade2c4e4e03c94ed9cc3e0326a80f548737293bf2bcfedf0a2bd490'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='5d293b59-9f1f-48c2-b217-345c9fb4176d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b2c5534499de88f8f473dd1b94b4efe05cfa81c5f096556707e688324652602b')}, text='However,itdoesnotcover\\nreal-world usage of these models, which will likely cover a significantly larger number of use cases.\\n•Diversity of the prompts could be another factor in our results. For example, our prompt set does not\\ninclude any coding- or reasoning-related prompts.\\n•We only evaluate the final generation of a multi-turn conversation. A more interesting evaluation could be\\nto ask the models to complete a task and rate the overall experience with the model over multiple turns.\\n•Humanevaluationforgenerativemodelsisinherentlysubjectiveandnoisy.', start_char_idx=2604, end_char_idx=3161, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-19', obj=None),\n",
       " '5d293b59-9f1f-48c2-b217-345c9fb4176d': IndexNode(id_='5d293b59-9f1f-48c2-b217-345c9fb4176d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-19', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d21985ad5d4275d432dc8bb9b8a547319d2b7d5b284878f9ba8d81ee33b8f96c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='9997cf8c-6201-4404-a6c0-5fa24d45adc9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='52d5baaeaef038bd74867d21bc54c5a9b3e993bbc42d056189438febf5c9b6f2'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='ce50b317-7ac0-42d1-8196-feab0894fb56', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='de96b1f734bc045b7511997207cdf094e3ac62405eb3e0c99ffe454b733dcc31')}, text='•Diversity of the prompts could be another factor in our results. For example, our prompt set does not\\ninclude any coding- or reasoning-related prompts.\\n•We only evaluate the final generation of a multi-turn conversation. A more interesting evaluation could be\\nto ask the models to complete a task and rate the overall experience with the model over multiple turns.\\n•Humanevaluationforgenerativemodelsisinherentlysubjectiveandnoisy. Asaresult,evaluationona\\ndifferent set of prompts or with different instructions could result in different results.', start_char_idx=2729, end_char_idx=3276, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-19', obj=None),\n",
       " 'ce50b317-7ac0-42d1-8196-feab0894fb56': IndexNode(id_='ce50b317-7ac0-42d1-8196-feab0894fb56', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-19', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d21985ad5d4275d432dc8bb9b8a547319d2b7d5b284878f9ba8d81ee33b8f96c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='5d293b59-9f1f-48c2-b217-345c9fb4176d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b2c5534499de88f8f473dd1b94b4efe05cfa81c5f096556707e688324652602b'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='e5ac2bc7-945c-4ea5-9da2-9ab1b8c2b13d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1680401c61d1f9cecf20f9cf7878482d084c5f1f239410345ffe37a772970e9e')}, text='For example, our prompt set does not\\ninclude any coding- or reasoning-related prompts.\\n•We only evaluate the final generation of a multi-turn conversation. A more interesting evaluation could be\\nto ask the models to complete a task and rate the overall experience with the model over multiple turns.\\n•Humanevaluationforgenerativemodelsisinherentlysubjectiveandnoisy. Asaresult,evaluationona\\ndifferent set of prompts or with different instructions could result in different results.\\n19\\n\\n4 Safety\\nWARNING: this section contains examples of text that may be considered unsafe, offensive, or upsetting.', start_char_idx=2795, end_char_idx=3393, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-19', obj=None),\n",
       " 'e5ac2bc7-945c-4ea5-9da2-9ab1b8c2b13d': IndexNode(id_='e5ac2bc7-945c-4ea5-9da2-9ab1b8c2b13d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-19', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d21985ad5d4275d432dc8bb9b8a547319d2b7d5b284878f9ba8d81ee33b8f96c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='ce50b317-7ac0-42d1-8196-feab0894fb56', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='de96b1f734bc045b7511997207cdf094e3ac62405eb3e0c99ffe454b733dcc31'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='763040af-065a-4eac-8fd8-944849982337', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='07b85f7213583f8dff2ec0bf9ba799df57c2d8424ebce92c7a31ae315ae36834')}, text='A more interesting evaluation could be\\nto ask the models to complete a task and rate the overall experience with the model over multiple turns.\\n•Humanevaluationforgenerativemodelsisinherentlysubjectiveandnoisy. Asaresult,evaluationona\\ndifferent set of prompts or with different instructions could result in different results.\\n19\\n\\n4 Safety\\nWARNING: this section contains examples of text that may be considered unsafe, offensive, or upsetting.\\nIn this section, we dive deeper into the important topic of safety measurements and mitigations.', start_char_idx=2951, end_char_idx=3490, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-19', obj=None),\n",
       " '763040af-065a-4eac-8fd8-944849982337': IndexNode(id_='763040af-065a-4eac-8fd8-944849982337', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-19', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d21985ad5d4275d432dc8bb9b8a547319d2b7d5b284878f9ba8d81ee33b8f96c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='e5ac2bc7-945c-4ea5-9da2-9ab1b8c2b13d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1680401c61d1f9cecf20f9cf7878482d084c5f1f239410345ffe37a772970e9e'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='fdc05261-a2c0-400b-83a7-3430c3adcc60', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f113e6a82a022fc6caf503e59ea4a1297a12052a51099a75a39dfb6cdcf0046c')}, text='•Humanevaluationforgenerativemodelsisinherentlysubjectiveandnoisy. Asaresult,evaluationona\\ndifferent set of prompts or with different instructions could result in different results.\\n19\\n\\n4 Safety\\nWARNING: this section contains examples of text that may be considered unsafe, offensive, or upsetting.\\nIn this section, we dive deeper into the important topic of safety measurements and mitigations. We first\\ndiscussoursafetyinvestigationsintopretrainingdataandpretrainedmodels(Section4.1).', start_char_idx=3095, end_char_idx=3581, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-19', obj=None),\n",
       " 'fdc05261-a2c0-400b-83a7-3430c3adcc60': IndexNode(id_='fdc05261-a2c0-400b-83a7-3430c3adcc60', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-19', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d21985ad5d4275d432dc8bb9b8a547319d2b7d5b284878f9ba8d81ee33b8f96c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='763040af-065a-4eac-8fd8-944849982337', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='07b85f7213583f8dff2ec0bf9ba799df57c2d8424ebce92c7a31ae315ae36834')}, text='Asaresult,evaluationona\\ndifferent set of prompts or with different instructions could result in different results.\\n19\\n\\n4 Safety\\nWARNING: this section contains examples of text that may be considered unsafe, offensive, or upsetting.\\nIn this section, we dive deeper into the important topic of safety measurements and mitigations. We first\\ndiscussoursafetyinvestigationsintopretrainingdataandpretrainedmodels(Section4.1). Next,wedescribe\\ntheprocessofoursafetyalignment(Section4.2),explaininghowwecollectedsafety-relatedannotationsand\\nutilizedSFTandRLHF,andpresentexperimentalresults.', start_char_idx=3162, end_char_idx=3743, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-19', obj=None),\n",
       " '6b6dcfcd-7d39-40b6-a2a7-79d03037fd74': IndexNode(id_='6b6dcfcd-7d39-40b6-a2a7-79d03037fd74', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-19', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d21985ad5d4275d432dc8bb9b8a547319d2b7d5b284878f9ba8d81ee33b8f96c'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='add0c98a-6059-4a4e-bd29-69e5d2265a29', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='49d77c43967d45a405cbd736e2465f4a716e331203c344df3a35eebe20a8227b')}, text='(2023))onover 4,000singleandmulti-turnprompts. ForChatGPT,\\nweuse gpt-3.5-turbo-0301 modelinallgenerations. ForPaLM,weusethe chat-bison-001 modelinall\\ngenerations. ThefinalpromptcountforhumanevaluationsforeachmodelisshowninTable32. Seemore\\nmethodology details in Appendix, Section A.3.7. The following section shows helpfulness results; safety\\nresults are presented in Section 4.4.\\nResults. AsshowninFigure12, Llama 2-Chat modelsoutperformopen-sourcemodelsbyasignificant\\nmargin on both single turn and multi-turn prompts. Particularly, Llama 2-Chat 7B model outperforms\\nMPT-7B-chaton60%oftheprompts. Llama 2-Chat 34Bhasanoverallwinrateofmorethan75%against\\nequivalently sized Vicuna-33B and Falcon 40B models.', start_char_idx=0, end_char_idx=707, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-19', obj=None),\n",
       " 'add0c98a-6059-4a4e-bd29-69e5d2265a29': IndexNode(id_='add0c98a-6059-4a4e-bd29-69e5d2265a29', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-19', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d21985ad5d4275d432dc8bb9b8a547319d2b7d5b284878f9ba8d81ee33b8f96c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='6b6dcfcd-7d39-40b6-a2a7-79d03037fd74', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='fa6757eabe245da1e922c0146b96598ede12f1730d214e87d2e82eaf620e52ec'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='c6d3475c-143c-433f-a569-ba76498820a2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9ffcfd629a86a7e17e3db26ed635dd4dac8f82dc6909dabab15f658407deab84')}, text='Particularly, Llama 2-Chat 7B model outperforms\\nMPT-7B-chaton60%oftheprompts. Llama 2-Chat 34Bhasanoverallwinrateofmorethan75%against\\nequivalently sized Vicuna-33B and Falcon 40B models.\\n18\\n\\nFigure12: Humanevaluationresults forLlama 2-Chat modelscomparedtoopen-andclosed-sourcemodels\\nacross ~4,000 helpfulness prompts with three raters per prompt.\\nThelargest Llama 2-Chat modeliscompetitivewithChatGPT. Llama 2-Chat 70Bmodelhasawinrateof\\n36% and a tie rate of 31.5% relative to ChatGPT. Llama 2-Chat 70B model outperforms PaLM-bison chat\\nmodel by a large percentage on our prompt set. More results and analysis is available in Section A.3.7.\\nInter-Rater Reliability (IRR). In our human evaluations, three different annotators provided independent\\nassessments for each model generation comparison.', start_char_idx=521, end_char_idx=1317, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-19', obj=None),\n",
       " 'c6d3475c-143c-433f-a569-ba76498820a2': IndexNode(id_='c6d3475c-143c-433f-a569-ba76498820a2', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-19', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d21985ad5d4275d432dc8bb9b8a547319d2b7d5b284878f9ba8d81ee33b8f96c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='add0c98a-6059-4a4e-bd29-69e5d2265a29', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='49d77c43967d45a405cbd736e2465f4a716e331203c344df3a35eebe20a8227b'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='930b1949-55bf-4c98-b12f-af3206c24ecf', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b56eba78c7f5b057df678b605d779412a844f2d4c4237ed1969c004813ef5eaf')}, text='Llama 2-Chat 70B model outperforms PaLM-bison chat\\nmodel by a large percentage on our prompt set. More results and analysis is available in Section A.3.7.\\nInter-Rater Reliability (IRR). In our human evaluations, three different annotators provided independent\\nassessments for each model generation comparison. High IRR scores (closer to 1.0) are typically seen as\\nbetter from a data quality perspective, however, context is important. Highly subjective tasks like evaluating\\nthe overall helpfulness of LLM generations will usually have lower IRR scores than more objective labelling\\ntasks. There arerelativelyfewpublicbenchmarksfor thesecontexts, sowefeelsharing ouranalysis herewill\\nbenefit the research community.\\nWe used Gwet’s AC1/2 statistic (Gwet, 2008, 2014) to measure inter-rater reliability (IRR), as we found it to\\nbethemoststablemetricacrossdifferentmeasurementscenarios.', start_char_idx=1008, end_char_idx=1891, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-19', obj=None),\n",
       " '930b1949-55bf-4c98-b12f-af3206c24ecf': IndexNode(id_='930b1949-55bf-4c98-b12f-af3206c24ecf', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-19', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d21985ad5d4275d432dc8bb9b8a547319d2b7d5b284878f9ba8d81ee33b8f96c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='c6d3475c-143c-433f-a569-ba76498820a2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9ffcfd629a86a7e17e3db26ed635dd4dac8f82dc6909dabab15f658407deab84'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='bdd8233c-fb3a-4ec0-9a9a-b653c1982ccc', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b4dc2b23bd45d524560c81875a202032b43ae4fcd6ecb2898910493af20005ac')}, text='There arerelativelyfewpublicbenchmarksfor thesecontexts, sowefeelsharing ouranalysis herewill\\nbenefit the research community.\\nWe used Gwet’s AC1/2 statistic (Gwet, 2008, 2014) to measure inter-rater reliability (IRR), as we found it to\\nbethemoststablemetricacrossdifferentmeasurementscenarios. Onthe7-pointLikertscalehelpfulness\\ntaskthatisusedinouranalysis,Gwet’sAC2scorevariesbetween 0.37and0.55dependingonthespecific\\nmodelcomparison. Weseescoresonthelowerendofthatrangeforratingsfrommodelcomparisonswith\\nsimilar win rates to each other (like the Llama 2-Chat -70B-chat vs. ChatGPT comparison). We see scores on\\nthehigherendofthatrangeforratingsfrommodelcomparisonswithamoreclearwinner(likethe Llama\\n2-Chat-34b-chat vs. Falcon-40b-instruct).\\nLimitations of human evaluations.', start_char_idx=1598, end_char_idx=2374, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-19', obj=None),\n",
       " 'bdd8233c-fb3a-4ec0-9a9a-b653c1982ccc': IndexNode(id_='bdd8233c-fb3a-4ec0-9a9a-b653c1982ccc', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-19', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d21985ad5d4275d432dc8bb9b8a547319d2b7d5b284878f9ba8d81ee33b8f96c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='930b1949-55bf-4c98-b12f-af3206c24ecf', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b56eba78c7f5b057df678b605d779412a844f2d4c4237ed1969c004813ef5eaf'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='01230f6f-1f41-4440-a15d-a36be7745de9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e7082b644401b0e354662b332fdca59a12c5d73008619f755bc81b28db5fb648')}, text='Weseescoresonthelowerendofthatrangeforratingsfrommodelcomparisonswith\\nsimilar win rates to each other (like the Llama 2-Chat -70B-chat vs. ChatGPT comparison). We see scores on\\nthehigherendofthatrangeforratingsfrommodelcomparisonswithamoreclearwinner(likethe Llama\\n2-Chat-34b-chat vs. Falcon-40b-instruct).\\nLimitations of human evaluations. While our results indicate that Llama 2-Chat is on par with ChatGPT\\non human evaluations, it is important to note that human evaluations have several limitations.\\n•Byacademicandresearchstandards,wehavealargepromptsetof4kprompts. However,itdoesnotcover\\nreal-world usage of these models, which will likely cover a significantly larger number of use cases.\\n•Diversity of the prompts could be another factor in our results. For example, our prompt set does not\\ninclude any coding- or reasoning-related prompts.\\n•We only evaluate the final generation of a multi-turn conversation. A more interesting evaluation could be\\nto ask the models to complete a task and rate the overall experience with the model over multiple turns.', start_char_idx=2034, end_char_idx=3094, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-19', obj=None),\n",
       " '01230f6f-1f41-4440-a15d-a36be7745de9': IndexNode(id_='01230f6f-1f41-4440-a15d-a36be7745de9', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-19', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d21985ad5d4275d432dc8bb9b8a547319d2b7d5b284878f9ba8d81ee33b8f96c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='bdd8233c-fb3a-4ec0-9a9a-b653c1982ccc', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b4dc2b23bd45d524560c81875a202032b43ae4fcd6ecb2898910493af20005ac')}, text='However,itdoesnotcover\\nreal-world usage of these models, which will likely cover a significantly larger number of use cases.\\n•Diversity of the prompts could be another factor in our results. For example, our prompt set does not\\ninclude any coding- or reasoning-related prompts.\\n•We only evaluate the final generation of a multi-turn conversation. A more interesting evaluation could be\\nto ask the models to complete a task and rate the overall experience with the model over multiple turns.\\n•Humanevaluationforgenerativemodelsisinherentlysubjectiveandnoisy. Asaresult,evaluationona\\ndifferent set of prompts or with different instructions could result in different results.\\n19\\n\\n4 Safety\\nWARNING: this section contains examples of text that may be considered unsafe, offensive, or upsetting.\\nIn this section, we dive deeper into the important topic of safety measurements and mitigations. We first\\ndiscussoursafetyinvestigationsintopretrainingdataandpretrainedmodels(Section4.1). Next,wedescribe\\ntheprocessofoursafetyalignment(Section4.2),explaininghowwecollectedsafety-relatedannotationsand\\nutilizedSFTandRLHF,andpresentexperimentalresults.', start_char_idx=2604, end_char_idx=3743, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-19', obj=None),\n",
       " '5bbd6399-bdde-420d-a128-b4849851eb76': IndexNode(id_='5bbd6399-bdde-420d-a128-b4849851eb76', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-19', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d21985ad5d4275d432dc8bb9b8a547319d2b7d5b284878f9ba8d81ee33b8f96c'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='d6dc8b76-035b-442e-b2e9-6839b5722025', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='87606beaa67b16f196cd3e097bbe30e67b23719a4210cc3bc234bef9657395ae')}, text='(2023))onover 4,000singleandmulti-turnprompts. ForChatGPT,\\nweuse gpt-3.5-turbo-0301 modelinallgenerations. ForPaLM,weusethe chat-bison-001 modelinall\\ngenerations. ThefinalpromptcountforhumanevaluationsforeachmodelisshowninTable32. Seemore\\nmethodology details in Appendix, Section A.3.7. The following section shows helpfulness results; safety\\nresults are presented in Section 4.4.\\nResults. AsshowninFigure12, Llama 2-Chat modelsoutperformopen-sourcemodelsbyasignificant\\nmargin on both single turn and multi-turn prompts. Particularly, Llama 2-Chat 7B model outperforms\\nMPT-7B-chaton60%oftheprompts. Llama 2-Chat 34Bhasanoverallwinrateofmorethan75%against\\nequivalently sized Vicuna-33B and Falcon 40B models.\\n18\\n\\nFigure12: Humanevaluationresults forLlama 2-Chat modelscomparedtoopen-andclosed-sourcemodels\\nacross ~4,000 helpfulness prompts with three raters per prompt.\\nThelargest Llama 2-Chat modeliscompetitivewithChatGPT. Llama 2-Chat 70Bmodelhasawinrateof\\n36% and a tie rate of 31.5% relative to ChatGPT. Llama 2-Chat 70B model outperforms PaLM-bison chat\\nmodel by a large percentage on our prompt set. More results and analysis is available in Section A.3.7.\\nInter-Rater Reliability (IRR). In our human evaluations, three different annotators provided independent\\nassessments for each model generation comparison. High IRR scores (closer to 1.0) are typically seen as\\nbetter from a data quality perspective, however, context is important. Highly subjective tasks like evaluating\\nthe overall helpfulness of LLM generations will usually have lower IRR scores than more objective labelling\\ntasks. There arerelativelyfewpublicbenchmarksfor thesecontexts, sowefeelsharing ouranalysis herewill\\nbenefit the research community.', start_char_idx=0, end_char_idx=1723, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-19', obj=None),\n",
       " 'd6dc8b76-035b-442e-b2e9-6839b5722025': IndexNode(id_='d6dc8b76-035b-442e-b2e9-6839b5722025', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-19', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d21985ad5d4275d432dc8bb9b8a547319d2b7d5b284878f9ba8d81ee33b8f96c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='5bbd6399-bdde-420d-a128-b4849851eb76', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5e5d61ceb365296fbe48085ad148b277158197187c6de58443da6cbc0c8644c9'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='3e7a4565-4815-43e8-b5e3-34b5dd2a4e18', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d3f478fa2243ffe6d60e61362813b9fcf0c38c010c04bbeeb8fa1bad771ccb76')}, text='High IRR scores (closer to 1.0) are typically seen as\\nbetter from a data quality perspective, however, context is important. Highly subjective tasks like evaluating\\nthe overall helpfulness of LLM generations will usually have lower IRR scores than more objective labelling\\ntasks. There arerelativelyfewpublicbenchmarksfor thesecontexts, sowefeelsharing ouranalysis herewill\\nbenefit the research community.\\nWe used Gwet’s AC1/2 statistic (Gwet, 2008, 2014) to measure inter-rater reliability (IRR), as we found it to\\nbethemoststablemetricacrossdifferentmeasurementscenarios. Onthe7-pointLikertscalehelpfulness\\ntaskthatisusedinouranalysis,Gwet’sAC2scorevariesbetween 0.37and0.55dependingonthespecific\\nmodelcomparison. Weseescoresonthelowerendofthatrangeforratingsfrommodelcomparisonswith\\nsimilar win rates to each other (like the Llama 2-Chat -70B-chat vs. ChatGPT comparison). We see scores on\\nthehigherendofthatrangeforratingsfrommodelcomparisonswithamoreclearwinner(likethe Llama\\n2-Chat-34b-chat vs. Falcon-40b-instruct).\\nLimitations of human evaluations. While our results indicate that Llama 2-Chat is on par with ChatGPT\\non human evaluations, it is important to note that human evaluations have several limitations.\\n•Byacademicandresearchstandards,wehavealargepromptsetof4kprompts. However,itdoesnotcover\\nreal-world usage of these models, which will likely cover a significantly larger number of use cases.\\n•Diversity of the prompts could be another factor in our results. For example, our prompt set does not\\ninclude any coding- or reasoning-related prompts.\\n•We only evaluate the final generation of a multi-turn conversation. A more interesting evaluation could be\\nto ask the models to complete a task and rate the overall experience with the model over multiple turns.\\n•Humanevaluationforgenerativemodelsisinherentlysubjectiveandnoisy. Asaresult,evaluationona\\ndifferent set of prompts or with different instructions could result in different results.\\n19\\n\\n4 Safety\\nWARNING: this section contains examples of text that may be considered unsafe, offensive, or upsetting.', start_char_idx=1318, end_char_idx=3393, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-19', obj=None),\n",
       " '3e7a4565-4815-43e8-b5e3-34b5dd2a4e18': IndexNode(id_='3e7a4565-4815-43e8-b5e3-34b5dd2a4e18', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-19', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d21985ad5d4275d432dc8bb9b8a547319d2b7d5b284878f9ba8d81ee33b8f96c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='d6dc8b76-035b-442e-b2e9-6839b5722025', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='87606beaa67b16f196cd3e097bbe30e67b23719a4210cc3bc234bef9657395ae')}, text='A more interesting evaluation could be\\nto ask the models to complete a task and rate the overall experience with the model over multiple turns.\\n•Humanevaluationforgenerativemodelsisinherentlysubjectiveandnoisy. Asaresult,evaluationona\\ndifferent set of prompts or with different instructions could result in different results.\\n19\\n\\n4 Safety\\nWARNING: this section contains examples of text that may be considered unsafe, offensive, or upsetting.\\nIn this section, we dive deeper into the important topic of safety measurements and mitigations. We first\\ndiscussoursafetyinvestigationsintopretrainingdataandpretrainedmodels(Section4.1). Next,wedescribe\\ntheprocessofoursafetyalignment(Section4.2),explaininghowwecollectedsafety-relatedannotationsand\\nutilizedSFTandRLHF,andpresentexperimentalresults.', start_char_idx=2951, end_char_idx=3743, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-19', obj=None),\n",
       " 'node-19': IndexNode(id_='node-19', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='d03f19eb-da15-45dc-bfd4-e5d10f161250', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='231b3bd773f012c01b893ada9e009ecf25ee59934614c5a595c9bf1b3a123292'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='ba231221-2bb6-4008-91b7-dcf500b020bd', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1ddb759a744ed54a5885bb93e09c3e6a0bed1921f330319362c66584215966ee'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='189f05ba-42c8-4e34-a86e-c1adc7c027a8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='494384b651bddf3707793c1745690f5e146728ae539ceb51e3e0a8429336f5fa')}, text='(2023))onover 4,000singleandmulti-turnprompts. ForChatGPT,\\nweuse gpt-3.5-turbo-0301 modelinallgenerations. ForPaLM,weusethe chat-bison-001 modelinall\\ngenerations. ThefinalpromptcountforhumanevaluationsforeachmodelisshowninTable32. Seemore\\nmethodology details in Appendix, Section A.3.7. The following section shows helpfulness results; safety\\nresults are presented in Section 4.4.\\nResults. AsshowninFigure12, Llama 2-Chat modelsoutperformopen-sourcemodelsbyasignificant\\nmargin on both single turn and multi-turn prompts. Particularly, Llama 2-Chat 7B model outperforms\\nMPT-7B-chaton60%oftheprompts. Llama 2-Chat 34Bhasanoverallwinrateofmorethan75%against\\nequivalently sized Vicuna-33B and Falcon 40B models.\\n18\\n\\nFigure12: Humanevaluationresults forLlama 2-Chat modelscomparedtoopen-andclosed-sourcemodels\\nacross ~4,000 helpfulness prompts with three raters per prompt.\\nThelargest Llama 2-Chat modeliscompetitivewithChatGPT. Llama 2-Chat 70Bmodelhasawinrateof\\n36% and a tie rate of 31.5% relative to ChatGPT. Llama 2-Chat 70B model outperforms PaLM-bison chat\\nmodel by a large percentage on our prompt set. More results and analysis is available in Section A.3.7.\\nInter-Rater Reliability (IRR). In our human evaluations, three different annotators provided independent\\nassessments for each model generation comparison. High IRR scores (closer to 1.0) are typically seen as\\nbetter from a data quality perspective, however, context is important. Highly subjective tasks like evaluating\\nthe overall helpfulness of LLM generations will usually have lower IRR scores than more objective labelling\\ntasks. There arerelativelyfewpublicbenchmarksfor thesecontexts, sowefeelsharing ouranalysis herewill\\nbenefit the research community.\\nWe used Gwet’s AC1/2 statistic (Gwet, 2008, 2014) to measure inter-rater reliability (IRR), as we found it to\\nbethemoststablemetricacrossdifferentmeasurementscenarios. Onthe7-pointLikertscalehelpfulness\\ntaskthatisusedinouranalysis,Gwet’sAC2scorevariesbetween 0.37and0.55dependingonthespecific\\nmodelcomparison. Weseescoresonthelowerendofthatrangeforratingsfrommodelcomparisonswith\\nsimilar win rates to each other (like the Llama 2-Chat -70B-chat vs. ChatGPT comparison). We see scores on\\nthehigherendofthatrangeforratingsfrommodelcomparisonswithamoreclearwinner(likethe Llama\\n2-Chat-34b-chat vs. Falcon-40b-instruct).\\nLimitations of human evaluations. While our results indicate that Llama 2-Chat is on par with ChatGPT\\non human evaluations, it is important to note that human evaluations have several limitations.\\n•Byacademicandresearchstandards,wehavealargepromptsetof4kprompts. However,itdoesnotcover\\nreal-world usage of these models, which will likely cover a significantly larger number of use cases.\\n•Diversity of the prompts could be another factor in our results. For example, our prompt set does not\\ninclude any coding- or reasoning-related prompts.\\n•We only evaluate the final generation of a multi-turn conversation. A more interesting evaluation could be\\nto ask the models to complete a task and rate the overall experience with the model over multiple turns.\\n•Humanevaluationforgenerativemodelsisinherentlysubjectiveandnoisy. Asaresult,evaluationona\\ndifferent set of prompts or with different instructions could result in different results.\\n19\\n\\n4 Safety\\nWARNING: this section contains examples of text that may be considered unsafe, offensive, or upsetting.\\nIn this section, we dive deeper into the important topic of safety measurements and mitigations. We first\\ndiscussoursafetyinvestigationsintopretrainingdataandpretrainedmodels(Section4.1). Next,wedescribe\\ntheprocessofoursafetyalignment(Section4.2),explaininghowwecollectedsafety-relatedannotationsand\\nutilizedSFTandRLHF,andpresentexperimentalresults.', start_char_idx=58056, end_char_idx=61799, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-19', obj=None),\n",
       " '491ebd60-f670-4d72-beb9-fc7e4d170cb2': IndexNode(id_='491ebd60-f670-4d72-beb9-fc7e4d170cb2', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-20', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='494384b651bddf3707793c1745690f5e146728ae539ceb51e3e0a8429336f5fa'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='3afcc20e-5104-4607-95e9-e40cd0fb945e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3f6d1e4b9f70eb9b1322e17c4c940531d650a15fb5e13310ad96df4f33f54d5d')}, text='In this section, we dive deeper into the important topic of safety measurements and mitigations. We first\\ndiscussoursafetyinvestigationsintopretrainingdataandpretrainedmodels(Section4.1). Next,wedescribe\\ntheprocessofoursafetyalignment(Section4.2),explaininghowwecollectedsafety-relatedannotationsand\\nutilizedSFTandRLHF,andpresentexperimentalresults. Then,wediscusstheredteamingweperformedto\\nfurtherunderstandandimprovemodelsafety(Section4.3).', start_char_idx=0, end_char_idx=442, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-20', obj=None),\n",
       " '3afcc20e-5104-4607-95e9-e40cd0fb945e': IndexNode(id_='3afcc20e-5104-4607-95e9-e40cd0fb945e', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-20', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='494384b651bddf3707793c1745690f5e146728ae539ceb51e3e0a8429336f5fa'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='491ebd60-f670-4d72-beb9-fc7e4d170cb2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='527a02acc2e3967079dfc7c43d1198eed31d32173a53924d0eca3baf5ce40639'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='441f2433-4bd4-478f-a834-9f4f5c8a534a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c8d2352443020e0504365878c94bc3aaffa30bcb0bc4e7513bf21a3c2e5bf738')}, text='Next,wedescribe\\ntheprocessofoursafetyalignment(Section4.2),explaininghowwecollectedsafety-relatedannotationsand\\nutilizedSFTandRLHF,andpresentexperimentalresults. Then,wediscusstheredteamingweperformedto\\nfurtherunderstandandimprovemodelsafety(Section4.3). Finally,wepresentquantitativesafetyevaluations\\nofLlama 2-Chat (Section 4.4). We also share a model card in the Appendix, in Table 52.', start_char_idx=188, end_char_idx=576, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-20', obj=None),\n",
       " '441f2433-4bd4-478f-a834-9f4f5c8a534a': IndexNode(id_='441f2433-4bd4-478f-a834-9f4f5c8a534a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-20', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='494384b651bddf3707793c1745690f5e146728ae539ceb51e3e0a8429336f5fa'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='3afcc20e-5104-4607-95e9-e40cd0fb945e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3f6d1e4b9f70eb9b1322e17c4c940531d650a15fb5e13310ad96df4f33f54d5d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='a88fbb24-7660-478b-b5de-a5e9a462e516', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='db9000ca0f06a95df4b384cd8c40058a5ef5a337aee334d1b6833f0ba963e561')}, text='Then,wediscusstheredteamingweperformedto\\nfurtherunderstandandimprovemodelsafety(Section4.3). Finally,wepresentquantitativesafetyevaluations\\nofLlama 2-Chat (Section 4.4). We also share a model card in the Appendix, in Table 52.\\n4.1 Safety in Pretraining\\nIt is important to understand what is in the pretraining data both to increase transparency and to shed\\nlightonrootcausesofpotentialdownstreamissues,suchaspotentialbiases.', start_char_idx=350, end_char_idx=774, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-20', obj=None),\n",
       " 'a88fbb24-7660-478b-b5de-a5e9a462e516': IndexNode(id_='a88fbb24-7660-478b-b5de-a5e9a462e516', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-20', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='494384b651bddf3707793c1745690f5e146728ae539ceb51e3e0a8429336f5fa'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='441f2433-4bd4-478f-a834-9f4f5c8a534a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c8d2352443020e0504365878c94bc3aaffa30bcb0bc4e7513bf21a3c2e5bf738'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='1fc31d97-3d9e-4adb-8c1f-b03d2af67727', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='83452bf98d2ac5b75f9b90e95ecf0457138a34fbd866117af46c5a3b9a486829')}, text='Finally,wepresentquantitativesafetyevaluations\\nofLlama 2-Chat (Section 4.4). We also share a model card in the Appendix, in Table 52.\\n4.1 Safety in Pretraining\\nIt is important to understand what is in the pretraining data both to increase transparency and to shed\\nlightonrootcausesofpotentialdownstreamissues,suchaspotentialbiases. Thiscaninformwhat,ifany,\\ndownstream mitigations to consider, and help guide appropriate model use.', start_char_idx=443, end_char_idx=873, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-20', obj=None),\n",
       " '1fc31d97-3d9e-4adb-8c1f-b03d2af67727': IndexNode(id_='1fc31d97-3d9e-4adb-8c1f-b03d2af67727', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-20', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='494384b651bddf3707793c1745690f5e146728ae539ceb51e3e0a8429336f5fa'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='a88fbb24-7660-478b-b5de-a5e9a462e516', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='db9000ca0f06a95df4b384cd8c40058a5ef5a337aee334d1b6833f0ba963e561'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='801269c8-348e-471f-91ab-fd1cbcf24e40', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='94b060ea6ec63031b0368475c0a0be96e9b3c3ad797630e202091b4d1965e563')}, text='We also share a model card in the Appendix, in Table 52.\\n4.1 Safety in Pretraining\\nIt is important to understand what is in the pretraining data both to increase transparency and to shed\\nlightonrootcausesofpotentialdownstreamissues,suchaspotentialbiases. Thiscaninformwhat,ifany,\\ndownstream mitigations to consider, and help guide appropriate model use. In this section, we analyze the\\npretraining datafor distributionsof languages,demographic representations,and toxicity. Wealso present\\nthe results of testing the pretrained models on existing safety benchmarks.', start_char_idx=520, end_char_idx=1084, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-20', obj=None),\n",
       " '801269c8-348e-471f-91ab-fd1cbcf24e40': IndexNode(id_='801269c8-348e-471f-91ab-fd1cbcf24e40', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-20', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='494384b651bddf3707793c1745690f5e146728ae539ceb51e3e0a8429336f5fa'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='1fc31d97-3d9e-4adb-8c1f-b03d2af67727', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='83452bf98d2ac5b75f9b90e95ecf0457138a34fbd866117af46c5a3b9a486829'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='d0eadd26-4606-4344-a55b-18859d708447', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='649ccaad9e3cdba62fa6215de002666f3598fde98c2151f687fc3ef2b840ec32')}, text='Thiscaninformwhat,ifany,\\ndownstream mitigations to consider, and help guide appropriate model use. In this section, we analyze the\\npretraining datafor distributionsof languages,demographic representations,and toxicity. Wealso present\\nthe results of testing the pretrained models on existing safety benchmarks.\\nSteps Taken to Pretrain Responsibly. We followed Meta’s standard privacy and legal review processes for\\neach dataset used in training. We did not use any Meta user data in training. We excluded data from certain\\nsitesknowntocontainahighvolumeofpersonalinformationaboutprivateindividuals.', start_char_idx=775, end_char_idx=1372, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-20', obj=None),\n",
       " 'd0eadd26-4606-4344-a55b-18859d708447': IndexNode(id_='d0eadd26-4606-4344-a55b-18859d708447', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-20', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='494384b651bddf3707793c1745690f5e146728ae539ceb51e3e0a8429336f5fa'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='801269c8-348e-471f-91ab-fd1cbcf24e40', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='94b060ea6ec63031b0368475c0a0be96e9b3c3ad797630e202091b4d1965e563'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='60585cd5-fe44-4b04-a15c-7a3b53c55eef', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='63576c9cf816fcaecd542a121e4690c363882ef41ae36e30154d2280f6f0e0c1')}, text='Wealso present\\nthe results of testing the pretrained models on existing safety benchmarks.\\nSteps Taken to Pretrain Responsibly. We followed Meta’s standard privacy and legal review processes for\\neach dataset used in training. We did not use any Meta user data in training. We excluded data from certain\\nsitesknowntocontainahighvolumeofpersonalinformationaboutprivateindividuals. Wemadeabest\\neffort to train our models efficiently to reduce the carbon footprint of pretraining (Section 2.2.1).', start_char_idx=994, end_char_idx=1486, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-20', obj=None),\n",
       " '60585cd5-fe44-4b04-a15c-7a3b53c55eef': IndexNode(id_='60585cd5-fe44-4b04-a15c-7a3b53c55eef', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-20', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='494384b651bddf3707793c1745690f5e146728ae539ceb51e3e0a8429336f5fa'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='d0eadd26-4606-4344-a55b-18859d708447', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='649ccaad9e3cdba62fa6215de002666f3598fde98c2151f687fc3ef2b840ec32'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='be8f7a7d-eab0-4fd6-a8fe-1c86e68f2356', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='489c6a99a1f7fec9306da13242070992e7e2abb954a94402a2ee14b1d07ad81d')}, text='Steps Taken to Pretrain Responsibly. We followed Meta’s standard privacy and legal review processes for\\neach dataset used in training. We did not use any Meta user data in training. We excluded data from certain\\nsitesknowntocontainahighvolumeofpersonalinformationaboutprivateindividuals. Wemadeabest\\neffort to train our models efficiently to reduce the carbon footprint of pretraining (Section 2.2.1). Sharing our\\nmodelsbroadlywillreducetheneedforotherstotrainsimilarmodels.', start_char_idx=1085, end_char_idx=1559, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-20', obj=None),\n",
       " 'be8f7a7d-eab0-4fd6-a8fe-1c86e68f2356': IndexNode(id_='be8f7a7d-eab0-4fd6-a8fe-1c86e68f2356', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-20', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='494384b651bddf3707793c1745690f5e146728ae539ceb51e3e0a8429336f5fa'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='60585cd5-fe44-4b04-a15c-7a3b53c55eef', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='63576c9cf816fcaecd542a121e4690c363882ef41ae36e30154d2280f6f0e0c1'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='0f97d4f2-b721-44dd-b4b3-8324b3bf0d0b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4842005fcc697ad165460ded859ecff875f0bc9f495bda80c14fa1a476436425')}, text='We did not use any Meta user data in training. We excluded data from certain\\nsitesknowntocontainahighvolumeofpersonalinformationaboutprivateindividuals. Wemadeabest\\neffort to train our models efficiently to reduce the carbon footprint of pretraining (Section 2.2.1). Sharing our\\nmodelsbroadlywillreducetheneedforotherstotrainsimilarmodels. Noadditionalfilteringwasconducted\\nonthedatasets,toallow Llama 2 tobemorewidelyusableacrosstasks(e.g.,itcanbebetterusedforhate\\nspeechclassification),whileavoidingthepotentialfortheaccidentaldemographicerasuresometimescaused\\nbyover-scrubbing.', start_char_idx=1220, end_char_idx=1800, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-20', obj=None),\n",
       " '0f97d4f2-b721-44dd-b4b3-8324b3bf0d0b': IndexNode(id_='0f97d4f2-b721-44dd-b4b3-8324b3bf0d0b', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-20', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='494384b651bddf3707793c1745690f5e146728ae539ceb51e3e0a8429336f5fa'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='be8f7a7d-eab0-4fd6-a8fe-1c86e68f2356', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='489c6a99a1f7fec9306da13242070992e7e2abb954a94402a2ee14b1d07ad81d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='2e3a5f35-81b2-4653-8267-ddde7ac5a296', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eaa7218fa1a9d47466a407f7f49ad97e35aaecc748e7c2475b505db653051374')}, text='Sharing our\\nmodelsbroadlywillreducetheneedforotherstotrainsimilarmodels. Noadditionalfilteringwasconducted\\nonthedatasets,toallow Llama 2 tobemorewidelyusableacrosstasks(e.g.,itcanbebetterusedforhate\\nspeechclassification),whileavoidingthepotentialfortheaccidentaldemographicerasuresometimescaused\\nbyover-scrubbing. Importantly,thisallows Llama 2-Chat togeneralizemoreeffectivelyduringsafetytuning\\nwith fewer examples (Welbl et al., 2021; Korbak et al., 2023; Xu et al., 2021).', start_char_idx=1487, end_char_idx=1962, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-20', obj=None),\n",
       " '2e3a5f35-81b2-4653-8267-ddde7ac5a296': IndexNode(id_='2e3a5f35-81b2-4653-8267-ddde7ac5a296', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-20', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='494384b651bddf3707793c1745690f5e146728ae539ceb51e3e0a8429336f5fa'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='0f97d4f2-b721-44dd-b4b3-8324b3bf0d0b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4842005fcc697ad165460ded859ecff875f0bc9f495bda80c14fa1a476436425'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='fc817a2b-9a7d-4193-99ab-c6ce57ac98f8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9038388824d1dc1f99b9a0306d052b5d22bca1f7df60adc99dfed940e080d7a1')}, text='Importantly,thisallows Llama 2-Chat togeneralizemoreeffectivelyduringsafetytuning\\nwith fewer examples (Welbl et al., 2021; Korbak et al., 2023; Xu et al., 2021). As a result, Llama 2 models\\nshould be used carefully and deployed only after significant safety tuning is applied.\\nDemographic Representation: Pronouns. Bias in model generations may result from biases inherited\\nfrom the training data itself. For instance, Bailey et al.', start_char_idx=1801, end_char_idx=2233, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-20', obj=None),\n",
       " 'fc817a2b-9a7d-4193-99ab-c6ce57ac98f8': IndexNode(id_='fc817a2b-9a7d-4193-99ab-c6ce57ac98f8', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-20', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='494384b651bddf3707793c1745690f5e146728ae539ceb51e3e0a8429336f5fa'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='2e3a5f35-81b2-4653-8267-ddde7ac5a296', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eaa7218fa1a9d47466a407f7f49ad97e35aaecc748e7c2475b505db653051374'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='42500885-676e-4391-aa00-27380e6c0a7c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bba1ce9d3c1a3cff2af538c2396c4dc8ee4623545fac7a269f9d2812e54a4ef0')}, text='As a result, Llama 2 models\\nshould be used carefully and deployed only after significant safety tuning is applied.\\nDemographic Representation: Pronouns. Bias in model generations may result from biases inherited\\nfrom the training data itself. For instance, Bailey et al. (2022) shows that in massive text corpora, words\\nrepresenting “people” are often used in more similar contexts to words representing “men”than to words\\nrepresenting “women,” andGaneshetal.', start_char_idx=1963, end_char_idx=2422, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-20', obj=None),\n",
       " '42500885-676e-4391-aa00-27380e6c0a7c': IndexNode(id_='42500885-676e-4391-aa00-27380e6c0a7c', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-20', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='494384b651bddf3707793c1745690f5e146728ae539ceb51e3e0a8429336f5fa'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='fc817a2b-9a7d-4193-99ab-c6ce57ac98f8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9038388824d1dc1f99b9a0306d052b5d22bca1f7df60adc99dfed940e080d7a1'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='bbfd4d89-518c-4541-bd8e-a72d59eb9eb7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2996f08b92a89dff55eb79c454e9521ae09f76eaa75f45981c1320142087caea')}, text='Demographic Representation: Pronouns. Bias in model generations may result from biases inherited\\nfrom the training data itself. For instance, Bailey et al. (2022) shows that in massive text corpora, words\\nrepresenting “people” are often used in more similar contexts to words representing “men”than to words\\nrepresenting “women,” andGaneshetal.(2023)demonstratesthatamodel’sperformanceonfairnessmetrics\\ncan be highly dependent on how the model trains on data representing underrepresented demographic\\ngroups.', start_char_idx=2078, end_char_idx=2586, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-20', obj=None),\n",
       " 'bbfd4d89-518c-4541-bd8e-a72d59eb9eb7': IndexNode(id_='bbfd4d89-518c-4541-bd8e-a72d59eb9eb7', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-20', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='494384b651bddf3707793c1745690f5e146728ae539ceb51e3e0a8429336f5fa'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='42500885-676e-4391-aa00-27380e6c0a7c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bba1ce9d3c1a3cff2af538c2396c4dc8ee4623545fac7a269f9d2812e54a4ef0'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='b0bddb7d-98b7-4151-9129-1896ec2e3477', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5d34df2f2bcaea5173e4cd58bfcfa6dcf34bd196969e6b0bd062e354292526d2')}, text='For instance, Bailey et al. (2022) shows that in massive text corpora, words\\nrepresenting “people” are often used in more similar contexts to words representing “men”than to words\\nrepresenting “women,” andGaneshetal.(2023)demonstratesthatamodel’sperformanceonfairnessmetrics\\ncan be highly dependent on how the model trains on data representing underrepresented demographic\\ngroups. WithinourEnglish-languagetrainingcorpus,wecomputedthefrequenciesofthemostcommon\\nEnglishpronounsinTable9a.', start_char_idx=2206, end_char_idx=2692, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-20', obj=None),\n",
       " 'b0bddb7d-98b7-4151-9129-1896ec2e3477': IndexNode(id_='b0bddb7d-98b7-4151-9129-1896ec2e3477', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-20', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='494384b651bddf3707793c1745690f5e146728ae539ceb51e3e0a8429336f5fa'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='bbfd4d89-518c-4541-bd8e-a72d59eb9eb7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2996f08b92a89dff55eb79c454e9521ae09f76eaa75f45981c1320142087caea'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='bc1776b1-520f-4aa0-9a84-7b8ac82f794b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='172ed043676138fe76adceeeaeeb0afa9a79207885e942b15b269e47cf80dc06')}, text='(2023)demonstratesthatamodel’sperformanceonfairnessmetrics\\ncan be highly dependent on how the model trains on data representing underrepresented demographic\\ngroups. WithinourEnglish-languagetrainingcorpus,wecomputedthefrequenciesofthemostcommon\\nEnglishpronounsinTable9a. Weobservethat Hepronounsaregenerallyoverrepresentedindocuments\\ncomparedto Shepronouns,echoingsimilarfrequencydifferencesobservedinpronominalusageforsimilarly\\nsized modelpretraining datasets(Chowdhery etal., 2022).', start_char_idx=2422, end_char_idx=2906, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-20', obj=None),\n",
       " 'bc1776b1-520f-4aa0-9a84-7b8ac82f794b': IndexNode(id_='bc1776b1-520f-4aa0-9a84-7b8ac82f794b', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-20', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='494384b651bddf3707793c1745690f5e146728ae539ceb51e3e0a8429336f5fa'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='b0bddb7d-98b7-4151-9129-1896ec2e3477', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5d34df2f2bcaea5173e4cd58bfcfa6dcf34bd196969e6b0bd062e354292526d2'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='a29c50b0-5385-43ed-8df4-d4d9b2303c9c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='85cf581b37115b51c70088fd3fcecb2dff346e11268f66662cd93e3117aeb9fa')}, text='WithinourEnglish-languagetrainingcorpus,wecomputedthefrequenciesofthemostcommon\\nEnglishpronounsinTable9a. Weobservethat Hepronounsaregenerallyoverrepresentedindocuments\\ncomparedto Shepronouns,echoingsimilarfrequencydifferencesobservedinpronominalusageforsimilarly\\nsized modelpretraining datasets(Chowdhery etal., 2022). This could meanthat themodel islearning less\\nduringpretrainingaboutcontextthatmentions Shepronouns,andsubsequentlymaypotentiallygenerate He\\npronouns at a higher rate than Shepronouns.', start_char_idx=2587, end_char_idx=3090, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-20', obj=None),\n",
       " 'a29c50b0-5385-43ed-8df4-d4d9b2303c9c': IndexNode(id_='a29c50b0-5385-43ed-8df4-d4d9b2303c9c', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-20', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='494384b651bddf3707793c1745690f5e146728ae539ceb51e3e0a8429336f5fa'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='bc1776b1-520f-4aa0-9a84-7b8ac82f794b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='172ed043676138fe76adceeeaeeb0afa9a79207885e942b15b269e47cf80dc06'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='d01260da-fb9f-4d8e-9123-9293d540ba64', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='417e66228d8f81b2a4fb9f0ed277e1aa9047acbdb927dd9761bdafbf4246e40d')}, text='Weobservethat Hepronounsaregenerallyoverrepresentedindocuments\\ncomparedto Shepronouns,echoingsimilarfrequencydifferencesobservedinpronominalusageforsimilarly\\nsized modelpretraining datasets(Chowdhery etal., 2022). This could meanthat themodel islearning less\\nduringpretrainingaboutcontextthatmentions Shepronouns,andsubsequentlymaypotentiallygenerate He\\npronouns at a higher rate than Shepronouns.\\nDemographicRepresentation: Identities.', start_char_idx=2693, end_char_idx=3129, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-20', obj=None),\n",
       " 'd01260da-fb9f-4d8e-9123-9293d540ba64': IndexNode(id_='d01260da-fb9f-4d8e-9123-9293d540ba64', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-20', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='494384b651bddf3707793c1745690f5e146728ae539ceb51e3e0a8429336f5fa'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='a29c50b0-5385-43ed-8df4-d4d9b2303c9c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='85cf581b37115b51c70088fd3fcecb2dff346e11268f66662cd93e3117aeb9fa'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='165511ce-923f-4afa-9273-81030f692fda', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0c9f5c06fc673a092d1d1b4dd23140bafa7dd4083dafe9616d2230ec14ff7c50')}, text='This could meanthat themodel islearning less\\nduringpretrainingaboutcontextthatmentions Shepronouns,andsubsequentlymaypotentiallygenerate He\\npronouns at a higher rate than Shepronouns.\\nDemographicRepresentation: Identities. Wealsoanalyzetherepresentationofdifferentdemographic\\ngroupsinthepretrainingdatabymeasuringratesofusageofdemographicidentitytermsfromtheHolisticBias\\ndataset(Smithetal.,2022)asaproxy. Wecomputefrequenciesforeachdescriptorterminthepretraining\\ncorpus.', start_char_idx=2907, end_char_idx=3377, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-20', obj=None),\n",
       " '165511ce-923f-4afa-9273-81030f692fda': IndexNode(id_='165511ce-923f-4afa-9273-81030f692fda', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-20', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='494384b651bddf3707793c1745690f5e146728ae539ceb51e3e0a8429336f5fa'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='d01260da-fb9f-4d8e-9123-9293d540ba64', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='417e66228d8f81b2a4fb9f0ed277e1aa9047acbdb927dd9761bdafbf4246e40d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='5f3de45a-8bae-46de-bd61-2066c26e3124', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7d6fb2cc3e1f4a6be64e315e86998c9b816cfdca9d9af17786dac869a1c8b4d3')}, text='DemographicRepresentation: Identities. Wealsoanalyzetherepresentationofdifferentdemographic\\ngroupsinthepretrainingdatabymeasuringratesofusageofdemographicidentitytermsfromtheHolisticBias\\ndataset(Smithetal.,2022)asaproxy. Wecomputefrequenciesforeachdescriptorterminthepretraining\\ncorpus. We group descriptors into 5 axes ( Religion ,Gender and Sex ,Nationality ,Race and Ethnicity , and\\nSexual Orientation ), and show the top 5 terms in each axis in Table 9b.', start_char_idx=3091, end_char_idx=3549, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-20', obj=None),\n",
       " '5f3de45a-8bae-46de-bd61-2066c26e3124': IndexNode(id_='5f3de45a-8bae-46de-bd61-2066c26e3124', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-20', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='494384b651bddf3707793c1745690f5e146728ae539ceb51e3e0a8429336f5fa'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='165511ce-923f-4afa-9273-81030f692fda', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0c9f5c06fc673a092d1d1b4dd23140bafa7dd4083dafe9616d2230ec14ff7c50'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='0483e13e-7baa-4061-bc91-407f363a9d74', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ab0c88512ba1a4f5a8afe70c7df4b3683d7ff22c3a36d98041eae44a4825d6e8')}, text='Wecomputefrequenciesforeachdescriptorterminthepretraining\\ncorpus. We group descriptors into 5 axes ( Religion ,Gender and Sex ,Nationality ,Race and Ethnicity , and\\nSexual Orientation ), and show the top 5 terms in each axis in Table 9b. In the top 5 terms, we remove a few\\nterms such as “straight,” “white,” and“black,”because these terms have frequent uses beyond demographic\\nmentions (e.g., as basic color terms).', start_char_idx=3312, end_char_idx=3728, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-20', obj=None),\n",
       " '0483e13e-7baa-4061-bc91-407f363a9d74': IndexNode(id_='0483e13e-7baa-4061-bc91-407f363a9d74', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-20', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='494384b651bddf3707793c1745690f5e146728ae539ceb51e3e0a8429336f5fa'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='5f3de45a-8bae-46de-bd61-2066c26e3124', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7d6fb2cc3e1f4a6be64e315e86998c9b816cfdca9d9af17786dac869a1c8b4d3'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='98c42ece-7c24-4fbe-976d-750fbe1dab80', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='00fc9582938a4967aad6a9d318afc0b7221b2bd879806ff16bf1c7dee7ee6d79')}, text='We group descriptors into 5 axes ( Religion ,Gender and Sex ,Nationality ,Race and Ethnicity , and\\nSexual Orientation ), and show the top 5 terms in each axis in Table 9b. In the top 5 terms, we remove a few\\nterms such as “straight,” “white,” and“black,”because these terms have frequent uses beyond demographic\\nmentions (e.g., as basic color terms). We also deduplicate across lists, removing a few terms found in\\nbothGender and Sex andSexual Orientation .', start_char_idx=3378, end_char_idx=3835, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-20', obj=None),\n",
       " '98c42ece-7c24-4fbe-976d-750fbe1dab80': IndexNode(id_='98c42ece-7c24-4fbe-976d-750fbe1dab80', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-20', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='494384b651bddf3707793c1745690f5e146728ae539ceb51e3e0a8429336f5fa'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='0483e13e-7baa-4061-bc91-407f363a9d74', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ab0c88512ba1a4f5a8afe70c7df4b3683d7ff22c3a36d98041eae44a4825d6e8')}, text='In the top 5 terms, we remove a few\\nterms such as “straight,” “white,” and“black,”because these terms have frequent uses beyond demographic\\nmentions (e.g., as basic color terms). We also deduplicate across lists, removing a few terms found in\\nbothGender and Sex andSexual Orientation . ForGender and Sex , whileShepronouns are mentioned\\nin fewer documents, the term “female” is present in a larger percentage of documents.', start_char_idx=3550, end_char_idx=3972, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-20', obj=None),\n",
       " '96bf405f-06c8-447d-b0a3-cfbaf14a2a1a': IndexNode(id_='96bf405f-06c8-447d-b0a3-cfbaf14a2a1a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-20', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='494384b651bddf3707793c1745690f5e146728ae539ceb51e3e0a8429336f5fa'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='d8a101bb-dca4-4421-ba77-d64999892b67', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c73a9abdf1e35c75cdf9d6117554ff671e4f3d4b274537127cf37cf975e2128c')}, text='In this section, we dive deeper into the important topic of safety measurements and mitigations. We first\\ndiscussoursafetyinvestigationsintopretrainingdataandpretrainedmodels(Section4.1). Next,wedescribe\\ntheprocessofoursafetyalignment(Section4.2),explaininghowwecollectedsafety-relatedannotationsand\\nutilizedSFTandRLHF,andpresentexperimentalresults. Then,wediscusstheredteamingweperformedto\\nfurtherunderstandandimprovemodelsafety(Section4.3). Finally,wepresentquantitativesafetyevaluations\\nofLlama 2-Chat (Section 4.4). We also share a model card in the Appendix, in Table 52.\\n4.1 Safety in Pretraining\\nIt is important to understand what is in the pretraining data both to increase transparency and to shed\\nlightonrootcausesofpotentialdownstreamissues,suchaspotentialbiases. Thiscaninformwhat,ifany,\\ndownstream mitigations to consider, and help guide appropriate model use. In this section, we analyze the\\npretraining datafor distributionsof languages,demographic representations,and toxicity.', start_char_idx=0, end_char_idx=993, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-20', obj=None),\n",
       " 'd8a101bb-dca4-4421-ba77-d64999892b67': IndexNode(id_='d8a101bb-dca4-4421-ba77-d64999892b67', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-20', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='494384b651bddf3707793c1745690f5e146728ae539ceb51e3e0a8429336f5fa'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='96bf405f-06c8-447d-b0a3-cfbaf14a2a1a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='43d98ec34ea913fdb7ad0295504e522ae308510365d7ef0e85518fe96b2b3e12'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='04ca7e15-901a-4bf5-b022-b0a43ae34000', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ebde79eaa23a1741c5f1937824f8f61fd091d15d1921cbaedbce30d7e10b7842')}, text='4.1 Safety in Pretraining\\nIt is important to understand what is in the pretraining data both to increase transparency and to shed\\nlightonrootcausesofpotentialdownstreamissues,suchaspotentialbiases. Thiscaninformwhat,ifany,\\ndownstream mitigations to consider, and help guide appropriate model use. In this section, we analyze the\\npretraining datafor distributionsof languages,demographic representations,and toxicity. Wealso present\\nthe results of testing the pretrained models on existing safety benchmarks.\\nSteps Taken to Pretrain Responsibly. We followed Meta’s standard privacy and legal review processes for\\neach dataset used in training. We did not use any Meta user data in training. We excluded data from certain\\nsitesknowntocontainahighvolumeofpersonalinformationaboutprivateindividuals. Wemadeabest\\neffort to train our models efficiently to reduce the carbon footprint of pretraining (Section 2.2.1). Sharing our\\nmodelsbroadlywillreducetheneedforotherstotrainsimilarmodels.', start_char_idx=577, end_char_idx=1559, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-20', obj=None),\n",
       " '04ca7e15-901a-4bf5-b022-b0a43ae34000': IndexNode(id_='04ca7e15-901a-4bf5-b022-b0a43ae34000', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-20', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='494384b651bddf3707793c1745690f5e146728ae539ceb51e3e0a8429336f5fa'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='d8a101bb-dca4-4421-ba77-d64999892b67', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c73a9abdf1e35c75cdf9d6117554ff671e4f3d4b274537127cf37cf975e2128c'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='cdab9797-5df4-40ee-ad5d-5c8e2f8cf6ab', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='de62001f5d1b4fc2f2ae453c86b705813095aaf701c2662d26b6beeca2dd29c5')}, text='We did not use any Meta user data in training. We excluded data from certain\\nsitesknowntocontainahighvolumeofpersonalinformationaboutprivateindividuals. Wemadeabest\\neffort to train our models efficiently to reduce the carbon footprint of pretraining (Section 2.2.1). Sharing our\\nmodelsbroadlywillreducetheneedforotherstotrainsimilarmodels. Noadditionalfilteringwasconducted\\nonthedatasets,toallow Llama 2 tobemorewidelyusableacrosstasks(e.g.,itcanbebetterusedforhate\\nspeechclassification),whileavoidingthepotentialfortheaccidentaldemographicerasuresometimescaused\\nbyover-scrubbing. Importantly,thisallows Llama 2-Chat togeneralizemoreeffectivelyduringsafetytuning\\nwith fewer examples (Welbl et al., 2021; Korbak et al., 2023; Xu et al., 2021). As a result, Llama 2 models\\nshould be used carefully and deployed only after significant safety tuning is applied.\\nDemographic Representation: Pronouns.', start_char_idx=1220, end_char_idx=2115, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-20', obj=None),\n",
       " 'cdab9797-5df4-40ee-ad5d-5c8e2f8cf6ab': IndexNode(id_='cdab9797-5df4-40ee-ad5d-5c8e2f8cf6ab', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-20', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='494384b651bddf3707793c1745690f5e146728ae539ceb51e3e0a8429336f5fa'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='04ca7e15-901a-4bf5-b022-b0a43ae34000', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ebde79eaa23a1741c5f1937824f8f61fd091d15d1921cbaedbce30d7e10b7842'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='759b77ad-5bbe-4bf5-a0da-8ef92a650f2d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='fbdd95dcb124d51930b45ef7342d4313b7b0bbd648df4449fa5645dcf972fbd9')}, text='Importantly,thisallows Llama 2-Chat togeneralizemoreeffectivelyduringsafetytuning\\nwith fewer examples (Welbl et al., 2021; Korbak et al., 2023; Xu et al., 2021). As a result, Llama 2 models\\nshould be used carefully and deployed only after significant safety tuning is applied.\\nDemographic Representation: Pronouns. Bias in model generations may result from biases inherited\\nfrom the training data itself. For instance, Bailey et al. (2022) shows that in massive text corpora, words\\nrepresenting “people” are often used in more similar contexts to words representing “men”than to words\\nrepresenting “women,” andGaneshetal.(2023)demonstratesthatamodel’sperformanceonfairnessmetrics\\ncan be highly dependent on how the model trains on data representing underrepresented demographic\\ngroups. WithinourEnglish-languagetrainingcorpus,wecomputedthefrequenciesofthemostcommon\\nEnglishpronounsinTable9a.', start_char_idx=1801, end_char_idx=2692, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-20', obj=None),\n",
       " '759b77ad-5bbe-4bf5-a0da-8ef92a650f2d': IndexNode(id_='759b77ad-5bbe-4bf5-a0da-8ef92a650f2d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-20', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='494384b651bddf3707793c1745690f5e146728ae539ceb51e3e0a8429336f5fa'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='cdab9797-5df4-40ee-ad5d-5c8e2f8cf6ab', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='de62001f5d1b4fc2f2ae453c86b705813095aaf701c2662d26b6beeca2dd29c5'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='28e8a8a1-9d70-4541-950c-50ef69d98130', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5c19015dd4eaaac20bd19fe8f096c5350eda9beecc3e6bcfd9bdcafa71f1231f')}, text='(2023)demonstratesthatamodel’sperformanceonfairnessmetrics\\ncan be highly dependent on how the model trains on data representing underrepresented demographic\\ngroups. WithinourEnglish-languagetrainingcorpus,wecomputedthefrequenciesofthemostcommon\\nEnglishpronounsinTable9a. Weobservethat Hepronounsaregenerallyoverrepresentedindocuments\\ncomparedto Shepronouns,echoingsimilarfrequencydifferencesobservedinpronominalusageforsimilarly\\nsized modelpretraining datasets(Chowdhery etal., 2022). This could meanthat themodel islearning less\\nduringpretrainingaboutcontextthatmentions Shepronouns,andsubsequentlymaypotentiallygenerate He\\npronouns at a higher rate than Shepronouns.\\nDemographicRepresentation: Identities. Wealsoanalyzetherepresentationofdifferentdemographic\\ngroupsinthepretrainingdatabymeasuringratesofusageofdemographicidentitytermsfromtheHolisticBias\\ndataset(Smithetal.,2022)asaproxy. Wecomputefrequenciesforeachdescriptorterminthepretraining\\ncorpus.', start_char_idx=2422, end_char_idx=3377, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-20', obj=None),\n",
       " '28e8a8a1-9d70-4541-950c-50ef69d98130': IndexNode(id_='28e8a8a1-9d70-4541-950c-50ef69d98130', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-20', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='494384b651bddf3707793c1745690f5e146728ae539ceb51e3e0a8429336f5fa'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='759b77ad-5bbe-4bf5-a0da-8ef92a650f2d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='fbdd95dcb124d51930b45ef7342d4313b7b0bbd648df4449fa5645dcf972fbd9')}, text='DemographicRepresentation: Identities. Wealsoanalyzetherepresentationofdifferentdemographic\\ngroupsinthepretrainingdatabymeasuringratesofusageofdemographicidentitytermsfromtheHolisticBias\\ndataset(Smithetal.,2022)asaproxy. Wecomputefrequenciesforeachdescriptorterminthepretraining\\ncorpus. We group descriptors into 5 axes ( Religion ,Gender and Sex ,Nationality ,Race and Ethnicity , and\\nSexual Orientation ), and show the top 5 terms in each axis in Table 9b. In the top 5 terms, we remove a few\\nterms such as “straight,” “white,” and“black,”because these terms have frequent uses beyond demographic\\nmentions (e.g., as basic color terms). We also deduplicate across lists, removing a few terms found in\\nbothGender and Sex andSexual Orientation . ForGender and Sex , whileShepronouns are mentioned\\nin fewer documents, the term “female” is present in a larger percentage of documents.', start_char_idx=3091, end_char_idx=3972, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-20', obj=None),\n",
       " 'ab5e6373-bf1c-47dd-b4fc-c8432fa29519': IndexNode(id_='ab5e6373-bf1c-47dd-b4fc-c8432fa29519', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-20', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='494384b651bddf3707793c1745690f5e146728ae539ceb51e3e0a8429336f5fa'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='1b5daee3-6c75-4959-8d34-0f8a53b81146', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='790a728aa1aa10d81148c8c7b8cec289c7ff0330c88b0ec95a955021755c6938')}, text='In this section, we dive deeper into the important topic of safety measurements and mitigations. We first\\ndiscussoursafetyinvestigationsintopretrainingdataandpretrainedmodels(Section4.1). Next,wedescribe\\ntheprocessofoursafetyalignment(Section4.2),explaininghowwecollectedsafety-relatedannotationsand\\nutilizedSFTandRLHF,andpresentexperimentalresults. Then,wediscusstheredteamingweperformedto\\nfurtherunderstandandimprovemodelsafety(Section4.3). Finally,wepresentquantitativesafetyevaluations\\nofLlama 2-Chat (Section 4.4). We also share a model card in the Appendix, in Table 52.\\n4.1 Safety in Pretraining\\nIt is important to understand what is in the pretraining data both to increase transparency and to shed\\nlightonrootcausesofpotentialdownstreamissues,suchaspotentialbiases. Thiscaninformwhat,ifany,\\ndownstream mitigations to consider, and help guide appropriate model use. In this section, we analyze the\\npretraining datafor distributionsof languages,demographic representations,and toxicity. Wealso present\\nthe results of testing the pretrained models on existing safety benchmarks.\\nSteps Taken to Pretrain Responsibly. We followed Meta’s standard privacy and legal review processes for\\neach dataset used in training. We did not use any Meta user data in training. We excluded data from certain\\nsitesknowntocontainahighvolumeofpersonalinformationaboutprivateindividuals. Wemadeabest\\neffort to train our models efficiently to reduce the carbon footprint of pretraining (Section 2.2.1). Sharing our\\nmodelsbroadlywillreducetheneedforotherstotrainsimilarmodels. Noadditionalfilteringwasconducted\\nonthedatasets,toallow Llama 2 tobemorewidelyusableacrosstasks(e.g.,itcanbebetterusedforhate\\nspeechclassification),whileavoidingthepotentialfortheaccidentaldemographicerasuresometimescaused\\nbyover-scrubbing.', start_char_idx=0, end_char_idx=1800, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-20', obj=None),\n",
       " '1b5daee3-6c75-4959-8d34-0f8a53b81146': IndexNode(id_='1b5daee3-6c75-4959-8d34-0f8a53b81146', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-20', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='494384b651bddf3707793c1745690f5e146728ae539ceb51e3e0a8429336f5fa'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='ab5e6373-bf1c-47dd-b4fc-c8432fa29519', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='643c1b71a093c60639f55eb54ff6a7bb507c71c22df5f9a35f43a987cbd8b4bc'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='93abd08b-2e8c-4e9c-93dc-39d3327de1b8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5c19015dd4eaaac20bd19fe8f096c5350eda9beecc3e6bcfd9bdcafa71f1231f')}, text='Sharing our\\nmodelsbroadlywillreducetheneedforotherstotrainsimilarmodels. Noadditionalfilteringwasconducted\\nonthedatasets,toallow Llama 2 tobemorewidelyusableacrosstasks(e.g.,itcanbebetterusedforhate\\nspeechclassification),whileavoidingthepotentialfortheaccidentaldemographicerasuresometimescaused\\nbyover-scrubbing. Importantly,thisallows Llama 2-Chat togeneralizemoreeffectivelyduringsafetytuning\\nwith fewer examples (Welbl et al., 2021; Korbak et al., 2023; Xu et al., 2021). As a result, Llama 2 models\\nshould be used carefully and deployed only after significant safety tuning is applied.\\nDemographic Representation: Pronouns. Bias in model generations may result from biases inherited\\nfrom the training data itself. For instance, Bailey et al. (2022) shows that in massive text corpora, words\\nrepresenting “people” are often used in more similar contexts to words representing “men”than to words\\nrepresenting “women,” andGaneshetal.(2023)demonstratesthatamodel’sperformanceonfairnessmetrics\\ncan be highly dependent on how the model trains on data representing underrepresented demographic\\ngroups. WithinourEnglish-languagetrainingcorpus,wecomputedthefrequenciesofthemostcommon\\nEnglishpronounsinTable9a. Weobservethat Hepronounsaregenerallyoverrepresentedindocuments\\ncomparedto Shepronouns,echoingsimilarfrequencydifferencesobservedinpronominalusageforsimilarly\\nsized modelpretraining datasets(Chowdhery etal., 2022). This could meanthat themodel islearning less\\nduringpretrainingaboutcontextthatmentions Shepronouns,andsubsequentlymaypotentiallygenerate He\\npronouns at a higher rate than Shepronouns.\\nDemographicRepresentation: Identities. Wealsoanalyzetherepresentationofdifferentdemographic\\ngroupsinthepretrainingdatabymeasuringratesofusageofdemographicidentitytermsfromtheHolisticBias\\ndataset(Smithetal.,2022)asaproxy. Wecomputefrequenciesforeachdescriptorterminthepretraining\\ncorpus.', start_char_idx=1487, end_char_idx=3377, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-20', obj=None),\n",
       " '93abd08b-2e8c-4e9c-93dc-39d3327de1b8': IndexNode(id_='93abd08b-2e8c-4e9c-93dc-39d3327de1b8', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-20', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='494384b651bddf3707793c1745690f5e146728ae539ceb51e3e0a8429336f5fa'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='1b5daee3-6c75-4959-8d34-0f8a53b81146', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='790a728aa1aa10d81148c8c7b8cec289c7ff0330c88b0ec95a955021755c6938')}, text='DemographicRepresentation: Identities. Wealsoanalyzetherepresentationofdifferentdemographic\\ngroupsinthepretrainingdatabymeasuringratesofusageofdemographicidentitytermsfromtheHolisticBias\\ndataset(Smithetal.,2022)asaproxy. Wecomputefrequenciesforeachdescriptorterminthepretraining\\ncorpus. We group descriptors into 5 axes ( Religion ,Gender and Sex ,Nationality ,Race and Ethnicity , and\\nSexual Orientation ), and show the top 5 terms in each axis in Table 9b. In the top 5 terms, we remove a few\\nterms such as “straight,” “white,” and“black,”because these terms have frequent uses beyond demographic\\nmentions (e.g., as basic color terms). We also deduplicate across lists, removing a few terms found in\\nbothGender and Sex andSexual Orientation . ForGender and Sex , whileShepronouns are mentioned\\nin fewer documents, the term “female” is present in a larger percentage of documents.', start_char_idx=3091, end_char_idx=3972, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-20', obj=None),\n",
       " 'node-20': IndexNode(id_='node-20', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='d03f19eb-da15-45dc-bfd4-e5d10f161250', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='231b3bd773f012c01b893ada9e009ecf25ee59934614c5a595c9bf1b3a123292'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='4aa7f620-b056-43d4-b812-5996e8ae8bc0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d21985ad5d4275d432dc8bb9b8a547319d2b7d5b284878f9ba8d81ee33b8f96c'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='8edf656e-261e-4535-aba8-7af876effb10', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='04659f1f151f8b669f2a6d4596224be975bca2877f921d922d1c882d380193b2')}, text='In this section, we dive deeper into the important topic of safety measurements and mitigations. We first\\ndiscussoursafetyinvestigationsintopretrainingdataandpretrainedmodels(Section4.1). Next,wedescribe\\ntheprocessofoursafetyalignment(Section4.2),explaininghowwecollectedsafety-relatedannotationsand\\nutilizedSFTandRLHF,andpresentexperimentalresults. Then,wediscusstheredteamingweperformedto\\nfurtherunderstandandimprovemodelsafety(Section4.3). Finally,wepresentquantitativesafetyevaluations\\nofLlama 2-Chat (Section 4.4). We also share a model card in the Appendix, in Table 52.\\n4.1 Safety in Pretraining\\nIt is important to understand what is in the pretraining data both to increase transparency and to shed\\nlightonrootcausesofpotentialdownstreamissues,suchaspotentialbiases. Thiscaninformwhat,ifany,\\ndownstream mitigations to consider, and help guide appropriate model use. In this section, we analyze the\\npretraining datafor distributionsof languages,demographic representations,and toxicity. Wealso present\\nthe results of testing the pretrained models on existing safety benchmarks.\\nSteps Taken to Pretrain Responsibly. We followed Meta’s standard privacy and legal review processes for\\neach dataset used in training. We did not use any Meta user data in training. We excluded data from certain\\nsitesknowntocontainahighvolumeofpersonalinformationaboutprivateindividuals. Wemadeabest\\neffort to train our models efficiently to reduce the carbon footprint of pretraining (Section 2.2.1). Sharing our\\nmodelsbroadlywillreducetheneedforotherstotrainsimilarmodels. Noadditionalfilteringwasconducted\\nonthedatasets,toallow Llama 2 tobemorewidelyusableacrosstasks(e.g.,itcanbebetterusedforhate\\nspeechclassification),whileavoidingthepotentialfortheaccidentaldemographicerasuresometimescaused\\nbyover-scrubbing. Importantly,thisallows Llama 2-Chat togeneralizemoreeffectivelyduringsafetytuning\\nwith fewer examples (Welbl et al., 2021; Korbak et al., 2023; Xu et al., 2021). As a result, Llama 2 models\\nshould be used carefully and deployed only after significant safety tuning is applied.\\nDemographic Representation: Pronouns. Bias in model generations may result from biases inherited\\nfrom the training data itself. For instance, Bailey et al. (2022) shows that in massive text corpora, words\\nrepresenting “people” are often used in more similar contexts to words representing “men”than to words\\nrepresenting “women,” andGaneshetal.(2023)demonstratesthatamodel’sperformanceonfairnessmetrics\\ncan be highly dependent on how the model trains on data representing underrepresented demographic\\ngroups. WithinourEnglish-languagetrainingcorpus,wecomputedthefrequenciesofthemostcommon\\nEnglishpronounsinTable9a. Weobservethat Hepronounsaregenerallyoverrepresentedindocuments\\ncomparedto Shepronouns,echoingsimilarfrequencydifferencesobservedinpronominalusageforsimilarly\\nsized modelpretraining datasets(Chowdhery etal., 2022). This could meanthat themodel islearning less\\nduringpretrainingaboutcontextthatmentions Shepronouns,andsubsequentlymaypotentiallygenerate He\\npronouns at a higher rate than Shepronouns.\\nDemographicRepresentation: Identities. Wealsoanalyzetherepresentationofdifferentdemographic\\ngroupsinthepretrainingdatabymeasuringratesofusageofdemographicidentitytermsfromtheHolisticBias\\ndataset(Smithetal.,2022)asaproxy. Wecomputefrequenciesforeachdescriptorterminthepretraining\\ncorpus. We group descriptors into 5 axes ( Religion ,Gender and Sex ,Nationality ,Race and Ethnicity , and\\nSexual Orientation ), and show the top 5 terms in each axis in Table 9b. In the top 5 terms, we remove a few\\nterms such as “straight,” “white,” and“black,”because these terms have frequent uses beyond demographic\\nmentions (e.g., as basic color terms). We also deduplicate across lists, removing a few terms found in\\nbothGender and Sex andSexual Orientation . ForGender and Sex , whileShepronouns are mentioned\\nin fewer documents, the term “female” is present in a larger percentage of documents.', start_char_idx=61450, end_char_idx=65422, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-20', obj=None),\n",
       " '175c7221-9d71-41df-a057-186967391e25': IndexNode(id_='175c7221-9d71-41df-a057-186967391e25', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-21', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='04659f1f151f8b669f2a6d4596224be975bca2877f921d922d1c882d380193b2'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='5c346f53-8cd6-4823-8c17-547955f21036', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f85414ed655232ca0f6061d2e64c4715a0a04fd8f22df77351144ca4580a1f1b')}, text='In the top 5 terms, we remove a few\\nterms such as “straight,” “white,” and“black,”because these terms have frequent uses beyond demographic\\nmentions (e.g., as basic color terms). We also deduplicate across lists, removing a few terms found in\\nbothGender and Sex andSexual Orientation . ForGender and Sex , whileShepronouns are mentioned\\nin fewer documents, the term “female” is present in a larger percentage of documents.', start_char_idx=0, end_char_idx=422, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-21', obj=None),\n",
       " '5c346f53-8cd6-4823-8c17-547955f21036': IndexNode(id_='5c346f53-8cd6-4823-8c17-547955f21036', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-21', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='04659f1f151f8b669f2a6d4596224be975bca2877f921d922d1c882d380193b2'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='175c7221-9d71-41df-a057-186967391e25', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='00fc9582938a4967aad6a9d318afc0b7221b2bd879806ff16bf1c7dee7ee6d79'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='d4ba68eb-e78c-435d-8c79-7394ddbb34a4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5f61c0af7372347bdf85d29668209378711e6de8cadee900ac3a0ae24b0a5c0d')}, text='In the top 5 terms, we remove a few\\nterms such as “straight,” “white,” and“black,”because these terms have frequent uses beyond demographic\\nmentions (e.g., as basic color terms). We also deduplicate across lists, removing a few terms found in\\nbothGender and Sex andSexual Orientation . ForGender and Sex , whileShepronouns are mentioned\\nin fewer documents, the term “female” is present in a larger percentage of documents. This could imply\\nthat whilethere isless frequent contextabout Shepronouns, commentsabout “females” are moreprevalent,\\nperhaps reflecting the differences in linguistic markedness of these terms (Blodgett et al., 2021).', start_char_idx=0, end_char_idx=640, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-21', obj=None),\n",
       " 'd4ba68eb-e78c-435d-8c79-7394ddbb34a4': IndexNode(id_='d4ba68eb-e78c-435d-8c79-7394ddbb34a4', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-21', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='04659f1f151f8b669f2a6d4596224be975bca2877f921d922d1c882d380193b2'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='5c346f53-8cd6-4823-8c17-547955f21036', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f85414ed655232ca0f6061d2e64c4715a0a04fd8f22df77351144ca4580a1f1b'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='16e9c1cf-aa25-4d57-9ad1-ec381f47bdf0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0d93de7c98a448459b12335303626a778598f0b5869054eee8426fdb4d9ba7e8')}, text='ForGender and Sex , whileShepronouns are mentioned\\nin fewer documents, the term “female” is present in a larger percentage of documents. This could imply\\nthat whilethere isless frequent contextabout Shepronouns, commentsabout “females” are moreprevalent,\\nperhaps reflecting the differences in linguistic markedness of these terms (Blodgett et al., 2021). For Sexual\\nOrientation ,thetopfivetermsallrelatetoLGBTQ+identities.', start_char_idx=286, end_char_idx=708, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-21', obj=None),\n",
       " '16e9c1cf-aa25-4d57-9ad1-ec381f47bdf0': IndexNode(id_='16e9c1cf-aa25-4d57-9ad1-ec381f47bdf0', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-21', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='04659f1f151f8b669f2a6d4596224be975bca2877f921d922d1c882d380193b2'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='d4ba68eb-e78c-435d-8c79-7394ddbb34a4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5f61c0af7372347bdf85d29668209378711e6de8cadee900ac3a0ae24b0a5c0d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='e9ec3cb0-3cae-41d0-8559-15549fab2d63', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1db2e97a2a5ce17ff9ed1a2a36853769b89238cdd4dbb27290f16a85b1dce1f6')}, text='This could imply\\nthat whilethere isless frequent contextabout Shepronouns, commentsabout “females” are moreprevalent,\\nperhaps reflecting the differences in linguistic markedness of these terms (Blodgett et al., 2021). For Sexual\\nOrientation ,thetopfivetermsallrelatetoLGBTQ+identities. For Nationality ,RaceandEthnicity ,and\\nReligion , we observe a Western skew (Bhatt et al., 2022). For instance, the term “American” is mentioned in\\n69.4% of the references,', start_char_idx=423, end_char_idx=881, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-21', obj=None),\n",
       " 'e9ec3cb0-3cae-41d0-8559-15549fab2d63': IndexNode(id_='e9ec3cb0-3cae-41d0-8559-15549fab2d63', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-21', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='04659f1f151f8b669f2a6d4596224be975bca2877f921d922d1c882d380193b2'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='16e9c1cf-aa25-4d57-9ad1-ec381f47bdf0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0d93de7c98a448459b12335303626a778598f0b5869054eee8426fdb4d9ba7e8'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='1738ecfb-ce95-4687-bb28-793146d09f71', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='918f5fdaa8c9e334db46b53abf246c9aa8f11d35b71a7fca340e6c2fdf9a9971')}, text='For Sexual\\nOrientation ,thetopfivetermsallrelatetoLGBTQ+identities. For Nationality ,RaceandEthnicity ,and\\nReligion , we observe a Western skew (Bhatt et al., 2022). For instance, the term “American” is mentioned in\\n69.4% of the references, the term “European” is more prevalent than other race and ethnicity, and “Christian”\\nis the most represented religion followed by “Catholic” and“Jewish.”\\n20\\n\\nGender Pronouns 75.23% Grammatical Person 94.', start_char_idx=641, end_char_idx=1085, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-21', obj=None),\n",
       " '1738ecfb-ce95-4687-bb28-793146d09f71': IndexNode(id_='1738ecfb-ce95-4687-bb28-793146d09f71', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-21', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='04659f1f151f8b669f2a6d4596224be975bca2877f921d922d1c882d380193b2'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='e9ec3cb0-3cae-41d0-8559-15549fab2d63', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1db2e97a2a5ce17ff9ed1a2a36853769b89238cdd4dbb27290f16a85b1dce1f6'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='38e083eb-bccd-4ea0-bb04-378fe5556d3a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ec0591fd5e8c1b166dc9969509bb378e80dd9e64e1b94aaa49ceb9fd0935c45d')}, text='For instance, the term “American” is mentioned in\\n69.4% of the references, the term “European” is more prevalent than other race and ethnicity, and “Christian”\\nis the most represented religion followed by “Catholic” and“Jewish.”\\n20\\n\\nGender Pronouns 75.23% Grammatical Person 94.47%\\nShe(she, her, hers, herself) 28.45% 1st(I, me, my, mine, myself, .) 70.71%\\nHe(he, him, his, himself) 50.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-21', obj=None),\n",
       " '38e083eb-bccd-4ea0-bb04-378fe5556d3a': IndexNode(id_='38e083eb-bccd-4ea0-bb04-378fe5556d3a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-21', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='04659f1f151f8b669f2a6d4596224be975bca2877f921d922d1c882d380193b2'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='1738ecfb-ce95-4687-bb28-793146d09f71', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='918f5fdaa8c9e334db46b53abf246c9aa8f11d35b71a7fca340e6c2fdf9a9971'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='623a75b5-9ba3-4bce-b3f6-ecabd141e6ec', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ede89a24b0037e552416383673dc5d725be24b1adac4fa3f2bc47d58c0c96829')}, text='and “Christian”\\nis the most represented religion followed by “Catholic” and“Jewish.”\\n20\\n\\nGender Pronouns 75.23% Grammatical Person 94.47%\\nShe(she, her, hers, herself) 28.45% 1st(I, me, my, mine, myself, .) 70.71%\\nHe(he, him, his, himself) 50.73% 2nd(you, your, yours, .) 61.80%\\nUnspecified (they, them, their, .) 86.38% 3rd(it,', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-21', obj=None),\n",
       " '623a75b5-9ba3-4bce-b3f6-ecabd141e6ec': IndexNode(id_='623a75b5-9ba3-4bce-b3f6-ecabd141e6ec', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-21', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='04659f1f151f8b669f2a6d4596224be975bca2877f921d922d1c882d380193b2'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='38e083eb-bccd-4ea0-bb04-378fe5556d3a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ec0591fd5e8c1b166dc9969509bb378e80dd9e64e1b94aaa49ceb9fd0935c45d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='863a22eb-c7f6-4f66-a59d-c87d6bf4a4aa', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7b7bc973e5d63c1f54b28512e2274322abc9c9ecc7f3d7da5a3fe1352e8a9d82')}, text='23% Grammatical Person 94.47%\\nShe(she, her, hers, herself) 28.45% 1st(I, me, my, mine, myself, .) 70.71%\\nHe(he, him, his, himself) 50.73% 2nd(you, your, yours, .) 61.80%\\nUnspecified (they, them, their, .) 86.38% 3rd(it, its, itself, she, her, he, him, .) 93.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-21', obj=None),\n",
       " '863a22eb-c7f6-4f66-a59d-c87d6bf4a4aa': IndexNode(id_='863a22eb-c7f6-4f66-a59d-c87d6bf4a4aa', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-21', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='04659f1f151f8b669f2a6d4596224be975bca2877f921d922d1c882d380193b2'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='623a75b5-9ba3-4bce-b3f6-ecabd141e6ec', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ede89a24b0037e552416383673dc5d725be24b1adac4fa3f2bc47d58c0c96829'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='6336da66-0d3b-421a-8c4f-46e54f8c7a70', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3a0626c5d20806f5d3a79bee2725c88b82f4895b118f0e6a991daaaa9a514ab3')}, text='hers, herself) 28.45% 1st(I, me, my, mine, myself, .) 70.71%\\nHe(he, him, his, himself) 50.73% 2nd(you, your, yours, .) 61.80%\\nUnspecified (they, them, their, .) 86.38% 3rd(it, its, itself, she, her, he, him, .) 93.07%\\n(a)Percentage of documents containing gender pronouns and grammatical person.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-21', obj=None),\n",
       " '6336da66-0d3b-421a-8c4f-46e54f8c7a70': IndexNode(id_='6336da66-0d3b-421a-8c4f-46e54f8c7a70', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-21', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='04659f1f151f8b669f2a6d4596224be975bca2877f921d922d1c882d380193b2'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='863a22eb-c7f6-4f66-a59d-c87d6bf4a4aa', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7b7bc973e5d63c1f54b28512e2274322abc9c9ecc7f3d7da5a3fe1352e8a9d82'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='7a07305a-e217-4371-96ac-776484d2bf3f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='50160441413d53b2ce582daddb0a103910d4730c220ce8abf67228358bcc3f7f')}, text='my, mine, myself, .) 70.71%\\nHe(he, him, his, himself) 50.73% 2nd(you, your, yours, .) 61.80%\\nUnspecified (they, them, their, .) 86.38% 3rd(it, its, itself, she, her, he, him, .) 93.07%\\n(a)Percentage of documents containing gender pronouns and grammatical person. 75% of all documents contain\\ngendered pronouns.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-21', obj=None),\n",
       " '7a07305a-e217-4371-96ac-776484d2bf3f': IndexNode(id_='7a07305a-e217-4371-96ac-776484d2bf3f', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-21', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='04659f1f151f8b669f2a6d4596224be975bca2877f921d922d1c882d380193b2'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='6336da66-0d3b-421a-8c4f-46e54f8c7a70', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3a0626c5d20806f5d3a79bee2725c88b82f4895b118f0e6a991daaaa9a514ab3'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='57d642b2-2f4e-4a29-84fe-bec43f6d0c0a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='441dcf554cbba56de76a03f0b3a6e707b817402f118abf05aad80df2160756ca')}, text='him, his, himself) 50.73% 2nd(you, your, yours, .) 61.80%\\nUnspecified (they, them, their, .) 86.38% 3rd(it, its, itself, she, her, he, him, .) 93.07%\\n(a)Percentage of documents containing gender pronouns and grammatical person. 75% of all documents contain\\ngendered pronouns. Within this subset, 28% of all documents contain Shepronouns. 94% of all documents contain\\npronouns in general.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-21', obj=None),\n",
       " '57d642b2-2f4e-4a29-84fe-bec43f6d0c0a': IndexNode(id_='57d642b2-2f4e-4a29-84fe-bec43f6d0c0a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-21', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='04659f1f151f8b669f2a6d4596224be975bca2877f921d922d1c882d380193b2'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='7a07305a-e217-4371-96ac-776484d2bf3f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='50160441413d53b2ce582daddb0a103910d4730c220ce8abf67228358bcc3f7f'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='4403435d-7c06-44b7-905a-cc1296ac43b2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='643d075f7dac8ae0a2f9426494260ce7b49bb24fb725eafa5a421a9708c84555')}, text='80%\\nUnspecified (they, them, their, .) 86.38% 3rd(it, its, itself, she, her, he, him, .) 93.07%\\n(a)Percentage of documents containing gender pronouns and grammatical person. 75% of all documents contain\\ngendered pronouns. Within this subset, 28% of all documents contain Shepronouns. 94% of all documents contain\\npronouns in general. See the full detailed list of pronouns for each subgroup in Appendix A.4.3.\\nGender and Sex\\n(5.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-21', obj=None),\n",
       " '4403435d-7c06-44b7-905a-cc1296ac43b2': IndexNode(id_='4403435d-7c06-44b7-905a-cc1296ac43b2', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-21', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='04659f1f151f8b669f2a6d4596224be975bca2877f921d922d1c882d380193b2'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='57d642b2-2f4e-4a29-84fe-bec43f6d0c0a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='441dcf554cbba56de76a03f0b3a6e707b817402f118abf05aad80df2160756ca'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='19a962e5-9fa0-4f72-b134-384bc2ce00ec', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4b3e9b85dfc7d68e6a300328c32f5913ca5cfb710be61369780c98feca87c560')}, text='itself, she, her, he, him, .) 93.07%\\n(a)Percentage of documents containing gender pronouns and grammatical person. 75% of all documents contain\\ngendered pronouns. Within this subset, 28% of all documents contain Shepronouns. 94% of all documents contain\\npronouns in general. See the full detailed list of pronouns for each subgroup in Appendix A.4.3.\\nGender and Sex\\n(5.91%)Sexual Orientation\\n(6.67%)Nationality\\n(14.83%)Race and Ethnicity\\n(19.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-21', obj=None),\n",
       " '19a962e5-9fa0-4f72-b134-384bc2ce00ec': IndexNode(id_='19a962e5-9fa0-4f72-b134-384bc2ce00ec', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-21', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='04659f1f151f8b669f2a6d4596224be975bca2877f921d922d1c882d380193b2'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='4403435d-7c06-44b7-905a-cc1296ac43b2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='643d075f7dac8ae0a2f9426494260ce7b49bb24fb725eafa5a421a9708c84555'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='1af9af31-3a00-4f6a-9c35-d31f4981c96b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5db021c89f82867f978c1c0f2a486cb3d3da6fc2082aff4069511f03b743066c')}, text='75% of all documents contain\\ngendered pronouns. Within this subset, 28% of all documents contain Shepronouns. 94% of all documents contain\\npronouns in general. See the full detailed list of pronouns for each subgroup in Appendix A.4.3.\\nGender and Sex\\n(5.91%)Sexual Orientation\\n(6.67%)Nationality\\n(14.83%)Race and Ethnicity\\n(19.51%)Religion\\n(7.93%)\\nDescriptor % Doc Descriptor % Doc Descriptor % Doc Descriptor % Doc Descriptor % Doc\\nfemale 50.', start_char_idx=1407, end_char_idx=1850, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-21', obj=None),\n",
       " '1af9af31-3a00-4f6a-9c35-d31f4981c96b': IndexNode(id_='1af9af31-3a00-4f6a-9c35-d31f4981c96b', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-21', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='04659f1f151f8b669f2a6d4596224be975bca2877f921d922d1c882d380193b2'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='19a962e5-9fa0-4f72-b134-384bc2ce00ec', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4b3e9b85dfc7d68e6a300328c32f5913ca5cfb710be61369780c98feca87c560'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='2aff2fa9-14fe-40ac-80d8-fa9e5782e380', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='dadfc8cd362f86e88ff5ce6d4ecc6132cab45e19993be99dd0b1e5b875989006')}, text='94% of all documents contain\\npronouns in general. See the full detailed list of pronouns for each subgroup in Appendix A.4.3.\\nGender and Sex\\n(5.91%)Sexual Orientation\\n(6.67%)Nationality\\n(14.83%)Race and Ethnicity\\n(19.51%)Religion\\n(7.93%)\\nDescriptor % Doc Descriptor % Doc Descriptor % Doc Descriptor % Doc Descriptor % Doc\\nfemale 50.0% gay 14.8% american 69.4% european 20.7% christian 33.2%\\nmale 39.', start_char_idx=1517, end_char_idx=1917, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-21', obj=None),\n",
       " '2aff2fa9-14fe-40ac-80d8-fa9e5782e380': IndexNode(id_='2aff2fa9-14fe-40ac-80d8-fa9e5782e380', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-21', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='04659f1f151f8b669f2a6d4596224be975bca2877f921d922d1c882d380193b2'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='1af9af31-3a00-4f6a-9c35-d31f4981c96b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5db021c89f82867f978c1c0f2a486cb3d3da6fc2082aff4069511f03b743066c'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='a5d28232-b8c4-4a32-85dd-84acb9899fd1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c4ea57d8cfdca50b820f4b8f953ffa05b0d9888b285950b55dc6fd8d39dadd9f')}, text='Gender and Sex\\n(5.91%)Sexual Orientation\\n(6.67%)Nationality\\n(14.83%)Race and Ethnicity\\n(19.51%)Religion\\n(7.93%)\\nDescriptor % Doc Descriptor % Doc Descriptor % Doc Descriptor % Doc Descriptor % Doc\\nfemale 50.0% gay 14.8% american 69.4% european 20.7% christian 33.2%\\nmale 39.1% lesbian 4.3% indian 16.5% african 11.5% religious 28.8%\\nfeminine 5.', start_char_idx=1643, end_char_idx=1987, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-21', obj=None),\n",
       " 'a5d28232-b8c4-4a32-85dd-84acb9899fd1': IndexNode(id_='a5d28232-b8c4-4a32-85dd-84acb9899fd1', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-21', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='04659f1f151f8b669f2a6d4596224be975bca2877f921d922d1c882d380193b2'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='2aff2fa9-14fe-40ac-80d8-fa9e5782e380', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='dadfc8cd362f86e88ff5ce6d4ecc6132cab45e19993be99dd0b1e5b875989006'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='4d121ccc-4ebe-458d-9ad0-57870853011f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0bf3a69e554f68ee12f537fa3d0ae519e094b07d56dbc4693cf78a37a9876a3b')}, text='51%)Religion\\n(7.93%)\\nDescriptor % Doc Descriptor % Doc Descriptor % Doc Descriptor % Doc Descriptor % Doc\\nfemale 50.0% gay 14.8% american 69.4% european 20.7% christian 33.2%\\nmale 39.1% lesbian 4.3% indian 16.5% african 11.5% religious 28.8%\\nfeminine 5.4% lgbt 4.0% chinese 16.3% asian 7.4% spiritual 20.6%\\ntransgender 4.', start_char_idx=1734, end_char_idx=2055, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-21', obj=None),\n",
       " '4d121ccc-4ebe-458d-9ad0-57870853011f': IndexNode(id_='4d121ccc-4ebe-458d-9ad0-57870853011f', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-21', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='04659f1f151f8b669f2a6d4596224be975bca2877f921d922d1c882d380193b2'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='a5d28232-b8c4-4a32-85dd-84acb9899fd1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c4ea57d8cfdca50b820f4b8f953ffa05b0d9888b285950b55dc6fd8d39dadd9f'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='1e84e99b-816e-45f8-8b79-f48305174398', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a1092e6b3fe20ad254047955f3d158a448e6f3e32b42d9656efd5b048d286b0e')}, text='0% gay 14.8% american 69.4% european 20.7% christian 33.2%\\nmale 39.1% lesbian 4.3% indian 16.5% african 11.5% religious 28.8%\\nfeminine 5.4% lgbt 4.0% chinese 16.3% asian 7.4% spiritual 20.6%\\ntransgender 4.2% lgbtq 3.6% korean 5.1% latin 6.2% catholic 15.', start_char_idx=1850, end_char_idx=2104, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-21', obj=None),\n",
       " '1e84e99b-816e-45f8-8b79-f48305174398': IndexNode(id_='1e84e99b-816e-45f8-8b79-f48305174398', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-21', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='04659f1f151f8b669f2a6d4596224be975bca2877f921d922d1c882d380193b2'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='4d121ccc-4ebe-458d-9ad0-57870853011f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0bf3a69e554f68ee12f537fa3d0ae519e094b07d56dbc4693cf78a37a9876a3b'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='cc248f2b-45cb-4a0c-a73c-60d1dc7f7296', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5b392fc859e33eea177fcf704d22a74aa3959869bf1895b99838838836ec8143')}, text='2%\\nmale 39.1% lesbian 4.3% indian 16.5% african 11.5% religious 28.8%\\nfeminine 5.4% lgbt 4.0% chinese 16.3% asian 7.4% spiritual 20.6%\\ntransgender 4.2% lgbtq 3.6% korean 5.1% latin 6.2% catholic 15.4%\\nmasculine 3.1% queer 3.5% mexican 4.9% indigenous 3.', start_char_idx=1906, end_char_idx=2159, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-21', obj=None),\n",
       " 'cc248f2b-45cb-4a0c-a73c-60d1dc7f7296': IndexNode(id_='cc248f2b-45cb-4a0c-a73c-60d1dc7f7296', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-21', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='04659f1f151f8b669f2a6d4596224be975bca2877f921d922d1c882d380193b2'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='1e84e99b-816e-45f8-8b79-f48305174398', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a1092e6b3fe20ad254047955f3d158a448e6f3e32b42d9656efd5b048d286b0e'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='157c3e7d-11ed-438d-913a-06ab3a4edf57', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a8a7fb5e9d80dd863dfa083edda49da279fad197704596349d6743d41e7173fc')}, text='8%\\nfeminine 5.4% lgbt 4.0% chinese 16.3% asian 7.4% spiritual 20.6%\\ntransgender 4.2% lgbtq 3.6% korean 5.1% latin 6.2% catholic 15.4%\\nmasculine 3.1% queer 3.5% mexican 4.9% indigenous 3.7% jewish 13.', start_char_idx=1973, end_char_idx=2172, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-21', obj=None),\n",
       " '157c3e7d-11ed-438d-913a-06ab3a4edf57': IndexNode(id_='157c3e7d-11ed-438d-913a-06ab3a4edf57', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-21', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='04659f1f151f8b669f2a6d4596224be975bca2877f921d922d1c882d380193b2'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='cc248f2b-45cb-4a0c-a73c-60d1dc7f7296', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5b392fc859e33eea177fcf704d22a74aa3959869bf1895b99838838836ec8143'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='fa4f5e60-b45b-41ed-ab10-1ed3bd3fb856', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='49f840fb5b0a68058f18d048929282ab3d6e3d4862f8f5d5fba39a59dce3924e')}, text='4% lgbt 4.0% chinese 16.3% asian 7.4% spiritual 20.6%\\ntransgender 4.2% lgbtq 3.6% korean 5.1% latin 6.2% catholic 15.4%\\nmasculine 3.1% queer 3.5% mexican 4.9% indigenous 3.7% jewish 13.0%\\n(b)The percentage listed below each demographic axis represents the percentage of all documents that mention any of\\nthedescriptortermsinthisaxis.', start_char_idx=1987, end_char_idx=2320, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-21', obj=None),\n",
       " 'fa4f5e60-b45b-41ed-ab10-1ed3bd3fb856': IndexNode(id_='fa4f5e60-b45b-41ed-ab10-1ed3bd3fb856', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-21', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='04659f1f151f8b669f2a6d4596224be975bca2877f921d922d1c882d380193b2'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='157c3e7d-11ed-438d-913a-06ab3a4edf57', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a8a7fb5e9d80dd863dfa083edda49da279fad197704596349d6743d41e7173fc'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='5e9b8da9-643f-4637-b2c4-5b98cd51fcaf', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b043ffe222dde8ef78743cab04cd86fce235a9f86bcaf9227011ce38cddb9b79')}, text='2% lgbtq 3.6% korean 5.1% latin 6.2% catholic 15.4%\\nmasculine 3.1% queer 3.5% mexican 4.9% indigenous 3.7% jewish 13.0%\\n(b)The percentage listed below each demographic axis represents the percentage of all documents that mention any of\\nthedescriptortermsinthisaxis. Thepercentagelistedforeachdemographicdescriptorrepresents,amongthedocuments\\nthat mention a descriptor in the given demographic axis, the percentage that mention this specific descriptor.', start_char_idx=2055, end_char_idx=2507, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-21', obj=None),\n",
       " '5e9b8da9-643f-4637-b2c4-5b98cd51fcaf': IndexNode(id_='5e9b8da9-643f-4637-b2c4-5b98cd51fcaf', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-21', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='04659f1f151f8b669f2a6d4596224be975bca2877f921d922d1c882d380193b2'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='fa4f5e60-b45b-41ed-ab10-1ed3bd3fb856', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='49f840fb5b0a68058f18d048929282ab3d6e3d4862f8f5d5fba39a59dce3924e'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='48ae9d55-718a-4102-8ded-334805ca5e01', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='dc992c25aab64e6abd50f914f35fc56d30a773b5fd9c0dd2c79af83a94953edc')}, text='1% queer 3.5% mexican 4.9% indigenous 3.7% jewish 13.0%\\n(b)The percentage listed below each demographic axis represents the percentage of all documents that mention any of\\nthedescriptortermsinthisaxis. Thepercentagelistedforeachdemographicdescriptorrepresents,amongthedocuments\\nthat mention a descriptor in the given demographic axis, the percentage that mention this specific descriptor.\\nTable9: Demographicrepresentations.', start_char_idx=2119, end_char_idx=2543, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-21', obj=None),\n",
       " '48ae9d55-718a-4102-8ded-334805ca5e01': IndexNode(id_='48ae9d55-718a-4102-8ded-334805ca5e01', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-21', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='04659f1f151f8b669f2a6d4596224be975bca2877f921d922d1c882d380193b2'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='5e9b8da9-643f-4637-b2c4-5b98cd51fcaf', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b043ffe222dde8ef78743cab04cd86fce235a9f86bcaf9227011ce38cddb9b79'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='165ecef0-428a-4869-a760-93ea55491e18', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f0041caa438ab662f9a35026b1d3fa4c677bd388c5f1c292058e8b1d77cb1864')}, text='5% mexican 4.9% indigenous 3.7% jewish 13.0%\\n(b)The percentage listed below each demographic axis represents the percentage of all documents that mention any of\\nthedescriptortermsinthisaxis. Thepercentagelistedforeachdemographicdescriptorrepresents,amongthedocuments\\nthat mention a descriptor in the given demographic axis, the percentage that mention this specific descriptor.\\nTable9: Demographicrepresentations. Analysisofpronounsandidentitiesinourpretrainingcorpusshows\\nsome skews that may affect performance, such as higher representations of Western demographics.', start_char_idx=2130, end_char_idx=2698, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-21', obj=None),\n",
       " '165ecef0-428a-4869-a760-93ea55491e18': IndexNode(id_='165ecef0-428a-4869-a760-93ea55491e18', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-21', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='04659f1f151f8b669f2a6d4596224be975bca2877f921d922d1c882d380193b2'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='48ae9d55-718a-4102-8ded-334805ca5e01', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='dc992c25aab64e6abd50f914f35fc56d30a773b5fd9c0dd2c79af83a94953edc'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='abd23952-9143-4e2a-804a-5db978171c5c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='231c6a77b60278baf72637e253fa447478f8f39cea810a60af3ae636ca15965b')}, text='Thepercentagelistedforeachdemographicdescriptorrepresents,amongthedocuments\\nthat mention a descriptor in the given demographic axis, the percentage that mention this specific descriptor.\\nTable9: Demographicrepresentations. Analysisofpronounsandidentitiesinourpretrainingcorpusshows\\nsome skews that may affect performance, such as higher representations of Western demographics.\\nFigure13: Pretrainingdatatoxicity. Toallowforbetterdownstreamgeneralization,wechosenottoscrub\\ntoxicdatafrompretraining.', start_char_idx=2321, end_char_idx=2818, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-21', obj=None),\n",
       " 'abd23952-9143-4e2a-804a-5db978171c5c': IndexNode(id_='abd23952-9143-4e2a-804a-5db978171c5c', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-21', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='04659f1f151f8b669f2a6d4596224be975bca2877f921d922d1c882d380193b2'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='165ecef0-428a-4869-a760-93ea55491e18', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f0041caa438ab662f9a35026b1d3fa4c677bd388c5f1c292058e8b1d77cb1864'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='977d5c2b-3826-4c85-b830-97c3be7a340a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='496ee263207eb40b1934271a63f73261fdd4641aae6038450ea96154553a95be')}, text='Table9: Demographicrepresentations. Analysisofpronounsandidentitiesinourpretrainingcorpusshows\\nsome skews that may affect performance, such as higher representations of Western demographics.\\nFigure13: Pretrainingdatatoxicity. Toallowforbetterdownstreamgeneralization,wechosenottoscrub\\ntoxicdatafrompretraining. TheHateBERTclassifierassignsatoxicitylikelihoodof0.5orhighertoabout\\n0.2% of documents in our pretraining corpus.\\nDataToxicity.', start_char_idx=2508, end_char_idx=2945, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-21', obj=None),\n",
       " '977d5c2b-3826-4c85-b830-97c3be7a340a': IndexNode(id_='977d5c2b-3826-4c85-b830-97c3be7a340a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-21', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='04659f1f151f8b669f2a6d4596224be975bca2877f921d922d1c882d380193b2'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='abd23952-9143-4e2a-804a-5db978171c5c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='231c6a77b60278baf72637e253fa447478f8f39cea810a60af3ae636ca15965b'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='b397a0d0-fa84-4bf6-b53f-30804881db5b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bf2ba41fbf68b210657310a47906c6932205c1c3c244d3145c00d1db30314e7f')}, text='Figure13: Pretrainingdatatoxicity. Toallowforbetterdownstreamgeneralization,wechosenottoscrub\\ntoxicdatafrompretraining. TheHateBERTclassifierassignsatoxicitylikelihoodof0.5orhighertoabout\\n0.2% of documents in our pretraining corpus.\\nDataToxicity. WemeasuretheprevalenceoftoxicityintheEnglish-languageportionofthepretraining\\ncorpususingaHateBERTclassifierfine-tunedontheToxiGendataset(Hartvigsenetal.,2022).', start_char_idx=2699, end_char_idx=3105, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-21', obj=None),\n",
       " 'b397a0d0-fa84-4bf6-b53f-30804881db5b': IndexNode(id_='b397a0d0-fa84-4bf6-b53f-30804881db5b', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-21', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='04659f1f151f8b669f2a6d4596224be975bca2877f921d922d1c882d380193b2'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='977d5c2b-3826-4c85-b830-97c3be7a340a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='496ee263207eb40b1934271a63f73261fdd4641aae6038450ea96154553a95be'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='67b3c456-4082-458e-9143-44fc603acb01', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='78f8b3ab5f05900e79cc603dcd560cbadf0e29b3527d10d4ec385820d071772d')}, text='TheHateBERTclassifierassignsatoxicitylikelihoodof0.5orhighertoabout\\n0.2% of documents in our pretraining corpus.\\nDataToxicity. WemeasuretheprevalenceoftoxicityintheEnglish-languageportionofthepretraining\\ncorpususingaHateBERTclassifierfine-tunedontheToxiGendataset(Hartvigsenetal.,2022). Wescoreeach\\nlineofadocumentseparatelyandaveragethemtoassignadocumentscore.', start_char_idx=2819, end_char_idx=3180, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-21', obj=None),\n",
       " '67b3c456-4082-458e-9143-44fc603acb01': IndexNode(id_='67b3c456-4082-458e-9143-44fc603acb01', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-21', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='04659f1f151f8b669f2a6d4596224be975bca2877f921d922d1c882d380193b2'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='b397a0d0-fa84-4bf6-b53f-30804881db5b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bf2ba41fbf68b210657310a47906c6932205c1c3c244d3145c00d1db30314e7f'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='1ed62130-827b-4ff9-8f42-dc317df17817', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='99e14da19ce4f72c9093bedd379b916d839e2b9c3178f150d6feca3790170a1e')}, text='DataToxicity. WemeasuretheprevalenceoftoxicityintheEnglish-languageportionofthepretraining\\ncorpususingaHateBERTclassifierfine-tunedontheToxiGendataset(Hartvigsenetal.,2022). Wescoreeach\\nlineofadocumentseparatelyandaveragethemtoassignadocumentscore. Figure13showsthedistribution\\nof scores in a 10% random sample of the full corpus.', start_char_idx=2932, end_char_idx=3262, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-21', obj=None),\n",
       " '1ed62130-827b-4ff9-8f42-dc317df17817': IndexNode(id_='1ed62130-827b-4ff9-8f42-dc317df17817', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-21', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='04659f1f151f8b669f2a6d4596224be975bca2877f921d922d1c882d380193b2'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='67b3c456-4082-458e-9143-44fc603acb01', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='78f8b3ab5f05900e79cc603dcd560cbadf0e29b3527d10d4ec385820d071772d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='669431bb-2293-4936-8b2d-04da80693f5d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b41b2995a6b1f38aafb93b4530cc42835534a8bd7a2faeb3fb4863b48798f74f')}, text='WemeasuretheprevalenceoftoxicityintheEnglish-languageportionofthepretraining\\ncorpususingaHateBERTclassifierfine-tunedontheToxiGendataset(Hartvigsenetal.,2022). Wescoreeach\\nlineofadocumentseparatelyandaveragethemtoassignadocumentscore. Figure13showsthedistribution\\nof scores in a 10% random sample of the full corpus. About 0.2% of documents evaluated are assigned a\\nlikelihood score of 0.5 or higher, meaning there is a small amount of toxicity in our pretraining data.', start_char_idx=2946, end_char_idx=3415, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-21', obj=None),\n",
       " '669431bb-2293-4936-8b2d-04da80693f5d': IndexNode(id_='669431bb-2293-4936-8b2d-04da80693f5d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-21', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='04659f1f151f8b669f2a6d4596224be975bca2877f921d922d1c882d380193b2'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='1ed62130-827b-4ff9-8f42-dc317df17817', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='99e14da19ce4f72c9093bedd379b916d839e2b9c3178f150d6feca3790170a1e')}, text='Wescoreeach\\nlineofadocumentseparatelyandaveragethemtoassignadocumentscore. Figure13showsthedistribution\\nof scores in a 10% random sample of the full corpus. About 0.2% of documents evaluated are assigned a\\nlikelihood score of 0.5 or higher, meaning there is a small amount of toxicity in our pretraining data.\\nLanguageIdentification. WhileourpretrainingdataismostlyEnglish,italsoincludestextfromasmall\\nnumber ofother languages.', start_char_idx=3106, end_char_idx=3533, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-21', obj=None),\n",
       " '485d9c17-0a11-4b94-8fc0-7638f7052adb': IndexNode(id_='485d9c17-0a11-4b94-8fc0-7638f7052adb', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-21', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='04659f1f151f8b669f2a6d4596224be975bca2877f921d922d1c882d380193b2'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='bb9f1dec-a09a-4ddc-9b9d-ae3c5718522a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d133b953c3dea48e7b0989be5c51b75121021e00ce374eb4d462572474fdec40')}, text='In the top 5 terms, we remove a few\\nterms such as “straight,” “white,” and“black,”because these terms have frequent uses beyond demographic\\nmentions (e.g., as basic color terms). We also deduplicate across lists, removing a few terms found in\\nbothGender and Sex andSexual Orientation . ForGender and Sex , whileShepronouns are mentioned\\nin fewer documents, the term “female” is present in a larger percentage of documents. This could imply\\nthat whilethere isless frequent contextabout Shepronouns, commentsabout “females” are moreprevalent,\\nperhaps reflecting the differences in linguistic markedness of these terms (Blodgett et al., 2021). For Sexual\\nOrientation ,thetopfivetermsallrelatetoLGBTQ+identities. For Nationality ,RaceandEthnicity ,and\\nReligion , we observe a Western skew (Bhatt et al., 2022).', start_char_idx=0, end_char_idx=806, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-21', obj=None),\n",
       " 'bb9f1dec-a09a-4ddc-9b9d-ae3c5718522a': IndexNode(id_='bb9f1dec-a09a-4ddc-9b9d-ae3c5718522a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-21', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='04659f1f151f8b669f2a6d4596224be975bca2877f921d922d1c882d380193b2'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='485d9c17-0a11-4b94-8fc0-7638f7052adb', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ac663403707cd3ac38a91b6197673a7bdc20a6f93744ceae2d77ed37086ff5d2'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='25c25312-3f71-4061-9200-71ce4a8d0c56', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5e6a11a1162fede8f8f880b1fec11094277250db67c0fe10cfcac3edd53465bb')}, text='For Sexual\\nOrientation ,thetopfivetermsallrelatetoLGBTQ+identities. For Nationality ,RaceandEthnicity ,and\\nReligion , we observe a Western skew (Bhatt et al., 2022). For instance, the term “American” is mentioned in\\n69.4% of the references, the term “European” is more prevalent than other race and ethnicity, and “Christian”\\nis the most represented religion followed by “Catholic” and“Jewish.”\\n20\\n\\nGender Pronouns 75.23% Grammatical Person 94.47%\\nShe(she, her, hers, herself) 28.45% 1st(I, me, my, mine, myself, ...) 70.71%\\nHe(he, him, his, himself) 50.73% 2nd(you, your, yours, ...) 61.80%\\nUnspecified (they, them, their, ...) 86.38% 3rd(it, its, itself, she, her, he, him, ...) 93.07%\\n(a)Percentage of documents containing gender pronouns and grammatical person.', start_char_idx=641, end_char_idx=1406, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-21', obj=None),\n",
       " '25c25312-3f71-4061-9200-71ce4a8d0c56': IndexNode(id_='25c25312-3f71-4061-9200-71ce4a8d0c56', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-21', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='04659f1f151f8b669f2a6d4596224be975bca2877f921d922d1c882d380193b2'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='bb9f1dec-a09a-4ddc-9b9d-ae3c5718522a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d133b953c3dea48e7b0989be5c51b75121021e00ce374eb4d462572474fdec40'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='25ac3187-be27-4a46-a77e-9d185e3e78de', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8dbf238ab88407a9029b56425b8ea65236918c8fad9142c3fc2be9dc4aaefbd2')}, text='75% of all documents contain\\ngendered pronouns. Within this subset, 28% of all documents contain Shepronouns. 94% of all documents contain\\npronouns in general. See the full detailed list of pronouns for each subgroup in Appendix A.4.3.', start_char_idx=1407, end_char_idx=1642, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-21', obj=None),\n",
       " '25ac3187-be27-4a46-a77e-9d185e3e78de': IndexNode(id_='25ac3187-be27-4a46-a77e-9d185e3e78de', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-21', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='04659f1f151f8b669f2a6d4596224be975bca2877f921d922d1c882d380193b2'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='25c25312-3f71-4061-9200-71ce4a8d0c56', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5e6a11a1162fede8f8f880b1fec11094277250db67c0fe10cfcac3edd53465bb'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='5aeca027-042b-4821-8c33-585f372f749f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='431e715119b6bcaa578788e5b0a0078301e61561f40da0978c8b958f8832d4ae')}, text='75% of all documents contain\\ngendered pronouns. Within this subset, 28% of all documents contain Shepronouns. 94% of all documents contain\\npronouns in general. See the full detailed list of pronouns for each subgroup in Appendix A.4.3.\\nGender and Sex\\n(5.91%)Sexual Orientation\\n(6.67%)Nationality\\n(14.83%)Race and Ethnicity\\n(19.51%)Religion\\n(7.93%)\\nDescriptor % Doc Descriptor % Doc Descriptor % Doc Descriptor % Doc Descriptor % Doc\\nfemale 50.0% gay 14.8% american 69.4% european 20.7% christian 33.2%\\nmale 39.1% lesbian 4.3% indian 16.5% african 11.5% religious 28.8%\\nfeminine 5.4% lgbt 4.0% chinese 16.3% asian 7.4% spiritual 20.6%\\ntransgender 4.2% lgbtq 3.6% korean 5.1% latin 6.2% catholic 15.4%\\nmasculine 3.1% queer 3.5% mexican 4.9% indigenous 3.7% jewish 13.0%\\n(b)The percentage listed below each demographic axis represents the percentage of all documents that mention any of\\nthedescriptortermsinthisaxis.', start_char_idx=1407, end_char_idx=2320, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-21', obj=None),\n",
       " '5aeca027-042b-4821-8c33-585f372f749f': IndexNode(id_='5aeca027-042b-4821-8c33-585f372f749f', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-21', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='04659f1f151f8b669f2a6d4596224be975bca2877f921d922d1c882d380193b2'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='25ac3187-be27-4a46-a77e-9d185e3e78de', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8dbf238ab88407a9029b56425b8ea65236918c8fad9142c3fc2be9dc4aaefbd2'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='0f6079b5-eade-4749-8abb-1af6c50a5b20', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='26ec004c5b5b30d532eef640bde685ebc96186d28d035b9da3278373dffaefbd')}, text='Thepercentagelistedforeachdemographicdescriptorrepresents,amongthedocuments\\nthat mention a descriptor in the given demographic axis, the percentage that mention this specific descriptor.\\nTable9: Demographicrepresentations. Analysisofpronounsandidentitiesinourpretrainingcorpusshows\\nsome skews that may affect performance, such as higher representations of Western demographics.\\nFigure13: Pretrainingdatatoxicity. Toallowforbetterdownstreamgeneralization,wechosenottoscrub\\ntoxicdatafrompretraining. TheHateBERTclassifierassignsatoxicitylikelihoodof0.5orhighertoabout\\n0.2% of documents in our pretraining corpus.\\nDataToxicity. WemeasuretheprevalenceoftoxicityintheEnglish-languageportionofthepretraining\\ncorpususingaHateBERTclassifierfine-tunedontheToxiGendataset(Hartvigsenetal.,2022). Wescoreeach\\nlineofadocumentseparatelyandaveragethemtoassignadocumentscore. Figure13showsthedistribution\\nof scores in a 10% random sample of the full corpus.', start_char_idx=2321, end_char_idx=3262, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-21', obj=None),\n",
       " '0f6079b5-eade-4749-8abb-1af6c50a5b20': IndexNode(id_='0f6079b5-eade-4749-8abb-1af6c50a5b20', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-21', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='04659f1f151f8b669f2a6d4596224be975bca2877f921d922d1c882d380193b2'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='5aeca027-042b-4821-8c33-585f372f749f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='431e715119b6bcaa578788e5b0a0078301e61561f40da0978c8b958f8832d4ae')}, text='WemeasuretheprevalenceoftoxicityintheEnglish-languageportionofthepretraining\\ncorpususingaHateBERTclassifierfine-tunedontheToxiGendataset(Hartvigsenetal.,2022). Wescoreeach\\nlineofadocumentseparatelyandaveragethemtoassignadocumentscore. Figure13showsthedistribution\\nof scores in a 10% random sample of the full corpus. About 0.2% of documents evaluated are assigned a\\nlikelihood score of 0.5 or higher, meaning there is a small amount of toxicity in our pretraining data.\\nLanguageIdentification. WhileourpretrainingdataismostlyEnglish,italsoincludestextfromasmall\\nnumber ofother languages.', start_char_idx=2946, end_char_idx=3533, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-21', obj=None),\n",
       " 'a322dd4c-e8dd-4bdc-928e-a1f8180cf283': IndexNode(id_='a322dd4c-e8dd-4bdc-928e-a1f8180cf283', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-21', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='04659f1f151f8b669f2a6d4596224be975bca2877f921d922d1c882d380193b2'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='b3bbc35c-807c-401d-b310-238911a25f2f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='41ee9b22cb36277068a17e0cadfa59724f773521ecc96b446303d1af9ebc8632')}, text='In the top 5 terms, we remove a few\\nterms such as “straight,” “white,” and“black,”because these terms have frequent uses beyond demographic\\nmentions (e.g., as basic color terms). We also deduplicate across lists, removing a few terms found in\\nbothGender and Sex andSexual Orientation . ForGender and Sex , whileShepronouns are mentioned\\nin fewer documents, the term “female” is present in a larger percentage of documents. This could imply\\nthat whilethere isless frequent contextabout Shepronouns, commentsabout “females” are moreprevalent,\\nperhaps reflecting the differences in linguistic markedness of these terms (Blodgett et al., 2021). For Sexual\\nOrientation ,thetopfivetermsallrelatetoLGBTQ+identities. For Nationality ,RaceandEthnicity ,and\\nReligion , we observe a Western skew (Bhatt et al., 2022). For instance, the term “American” is mentioned in\\n69.4% of the references, the term “European” is more prevalent than other race and ethnicity, and “Christian”\\nis the most represented religion followed by “Catholic” and“Jewish.”\\n20\\n\\nGender Pronouns 75.23% Grammatical Person 94.47%\\nShe(she, her, hers, herself) 28.45% 1st(I, me, my, mine, myself, ...) 70.71%\\nHe(he, him, his, himself) 50.73% 2nd(you, your, yours, ...) 61.80%\\nUnspecified (they, them, their, ...) 86.38% 3rd(it, its, itself, she, her, he, him, ...) 93.07%\\n(a)Percentage of documents containing gender pronouns and grammatical person. 75% of all documents contain\\ngendered pronouns. Within this subset, 28% of all documents contain Shepronouns. 94% of all documents contain\\npronouns in general. See the full detailed list of pronouns for each subgroup in Appendix A.4.3.', start_char_idx=0, end_char_idx=1642, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-21', obj=None),\n",
       " 'b3bbc35c-807c-401d-b310-238911a25f2f': IndexNode(id_='b3bbc35c-807c-401d-b310-238911a25f2f', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-21', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='04659f1f151f8b669f2a6d4596224be975bca2877f921d922d1c882d380193b2'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='a322dd4c-e8dd-4bdc-928e-a1f8180cf283', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='92b932f86945aa6fbfe14b646749d3c01a3ef842d0d111124fe862f2cc33e1b4'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='9bc80b8f-58ff-4574-abee-ff9c5b489745', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='806b2d79c7c6314ad2dde441713a2f118dd9b0eab2fd495ac42f74b61a0eaaab')}, text='75% of all documents contain\\ngendered pronouns. Within this subset, 28% of all documents contain Shepronouns. 94% of all documents contain\\npronouns in general. See the full detailed list of pronouns for each subgroup in Appendix A.4.3.\\nGender and Sex\\n(5.91%)Sexual Orientation\\n(6.67%)Nationality\\n(14.83%)Race and Ethnicity\\n(19.51%)Religion\\n(7.93%)\\nDescriptor % Doc Descriptor % Doc Descriptor % Doc Descriptor % Doc Descriptor % Doc\\nfemale 50.0% gay 14.8% american 69.4% european 20.7% christian 33.2%\\nmale 39.1% lesbian 4.3% indian 16.5% african 11.5% religious 28.8%\\nfeminine 5.4% lgbt 4.0% chinese 16.3% asian 7.4% spiritual 20.6%\\ntransgender 4.2% lgbtq 3.6% korean 5.1% latin 6.2% catholic 15.4%\\nmasculine 3.1% queer 3.5% mexican 4.9% indigenous 3.7% jewish 13.0%\\n(b)The percentage listed below each demographic axis represents the percentage of all documents that mention any of\\nthedescriptortermsinthisaxis. Thepercentagelistedforeachdemographicdescriptorrepresents,amongthedocuments\\nthat mention a descriptor in the given demographic axis, the percentage that mention this specific descriptor.\\nTable9: Demographicrepresentations. Analysisofpronounsandidentitiesinourpretrainingcorpusshows\\nsome skews that may affect performance, such as higher representations of Western demographics.\\nFigure13: Pretrainingdatatoxicity. Toallowforbetterdownstreamgeneralization,wechosenottoscrub\\ntoxicdatafrompretraining. TheHateBERTclassifierassignsatoxicitylikelihoodof0.5orhighertoabout\\n0.2% of documents in our pretraining corpus.\\nDataToxicity.', start_char_idx=1407, end_char_idx=2945, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-21', obj=None),\n",
       " '9bc80b8f-58ff-4574-abee-ff9c5b489745': IndexNode(id_='9bc80b8f-58ff-4574-abee-ff9c5b489745', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-21', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='04659f1f151f8b669f2a6d4596224be975bca2877f921d922d1c882d380193b2'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='b3bbc35c-807c-401d-b310-238911a25f2f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='41ee9b22cb36277068a17e0cadfa59724f773521ecc96b446303d1af9ebc8632')}, text='Figure13: Pretrainingdatatoxicity. Toallowforbetterdownstreamgeneralization,wechosenottoscrub\\ntoxicdatafrompretraining. TheHateBERTclassifierassignsatoxicitylikelihoodof0.5orhighertoabout\\n0.2% of documents in our pretraining corpus.\\nDataToxicity. WemeasuretheprevalenceoftoxicityintheEnglish-languageportionofthepretraining\\ncorpususingaHateBERTclassifierfine-tunedontheToxiGendataset(Hartvigsenetal.,2022). Wescoreeach\\nlineofadocumentseparatelyandaveragethemtoassignadocumentscore. Figure13showsthedistribution\\nof scores in a 10% random sample of the full corpus. About 0.2% of documents evaluated are assigned a\\nlikelihood score of 0.5 or higher, meaning there is a small amount of toxicity in our pretraining data.\\nLanguageIdentification. WhileourpretrainingdataismostlyEnglish,italsoincludestextfromasmall\\nnumber ofother languages.', start_char_idx=2699, end_char_idx=3533, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-21', obj=None),\n",
       " 'node-21': IndexNode(id_='node-21', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='d03f19eb-da15-45dc-bfd4-e5d10f161250', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='231b3bd773f012c01b893ada9e009ecf25ee59934614c5a595c9bf1b3a123292'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='189f05ba-42c8-4e34-a86e-c1adc7c027a8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='494384b651bddf3707793c1745690f5e146728ae539ceb51e3e0a8429336f5fa'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='14c43461-1ce2-48d9-894b-52885412bb21', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6df64b4daa8925dc939ee4b1f4ca0d2851186befb4ec88382082ffe393658615')}, text='In the top 5 terms, we remove a few\\nterms such as “straight,” “white,” and“black,”because these terms have frequent uses beyond demographic\\nmentions (e.g., as basic color terms). We also deduplicate across lists, removing a few terms found in\\nbothGender and Sex andSexual Orientation . ForGender and Sex , whileShepronouns are mentioned\\nin fewer documents, the term “female” is present in a larger percentage of documents. This could imply\\nthat whilethere isless frequent contextabout Shepronouns, commentsabout “females” are moreprevalent,\\nperhaps reflecting the differences in linguistic markedness of these terms (Blodgett et al., 2021). For Sexual\\nOrientation ,thetopfivetermsallrelatetoLGBTQ+identities. For Nationality ,RaceandEthnicity ,and\\nReligion , we observe a Western skew (Bhatt et al., 2022). For instance, the term “American” is mentioned in\\n69.4% of the references, the term “European” is more prevalent than other race and ethnicity, and “Christian”\\nis the most represented religion followed by “Catholic” and“Jewish.”\\n20\\n\\nGender Pronouns 75.23% Grammatical Person 94.47%\\nShe(she, her, hers, herself) 28.45% 1st(I, me, my, mine, myself, ...) 70.71%\\nHe(he, him, his, himself) 50.73% 2nd(you, your, yours, ...) 61.80%\\nUnspecified (they, them, their, ...) 86.38% 3rd(it, its, itself, she, her, he, him, ...) 93.07%\\n(a)Percentage of documents containing gender pronouns and grammatical person. 75% of all documents contain\\ngendered pronouns. Within this subset, 28% of all documents contain Shepronouns. 94% of all documents contain\\npronouns in general. See the full detailed list of pronouns for each subgroup in Appendix A.4.3.\\nGender and Sex\\n(5.91%)Sexual Orientation\\n(6.67%)Nationality\\n(14.83%)Race and Ethnicity\\n(19.51%)Religion\\n(7.93%)\\nDescriptor % Doc Descriptor % Doc Descriptor % Doc Descriptor % Doc Descriptor % Doc\\nfemale 50.0% gay 14.8% american 69.4% european 20.7% christian 33.2%\\nmale 39.1% lesbian 4.3% indian 16.5% african 11.5% religious 28.8%\\nfeminine 5.4% lgbt 4.0% chinese 16.3% asian 7.4% spiritual 20.6%\\ntransgender 4.2% lgbtq 3.6% korean 5.1% latin 6.2% catholic 15.4%\\nmasculine 3.1% queer 3.5% mexican 4.9% indigenous 3.7% jewish 13.0%\\n(b)The percentage listed below each demographic axis represents the percentage of all documents that mention any of\\nthedescriptortermsinthisaxis. Thepercentagelistedforeachdemographicdescriptorrepresents,amongthedocuments\\nthat mention a descriptor in the given demographic axis, the percentage that mention this specific descriptor.\\nTable9: Demographicrepresentations. Analysisofpronounsandidentitiesinourpretrainingcorpusshows\\nsome skews that may affect performance, such as higher representations of Western demographics.\\nFigure13: Pretrainingdatatoxicity. Toallowforbetterdownstreamgeneralization,wechosenottoscrub\\ntoxicdatafrompretraining. TheHateBERTclassifierassignsatoxicitylikelihoodof0.5orhighertoabout\\n0.2% of documents in our pretraining corpus.\\nDataToxicity. WemeasuretheprevalenceoftoxicityintheEnglish-languageportionofthepretraining\\ncorpususingaHateBERTclassifierfine-tunedontheToxiGendataset(Hartvigsenetal.,2022). Wescoreeach\\nlineofadocumentseparatelyandaveragethemtoassignadocumentscore. Figure13showsthedistribution\\nof scores in a 10% random sample of the full corpus. About 0.2% of documents evaluated are assigned a\\nlikelihood score of 0.5 or higher, meaning there is a small amount of toxicity in our pretraining data.\\nLanguageIdentification. WhileourpretrainingdataismostlyEnglish,italsoincludestextfromasmall\\nnumber ofother languages.', start_char_idx=65000, end_char_idx=68533, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-21', obj=None),\n",
       " '56cfdc7b-ad24-4586-8c7c-688e1eb9fae6': IndexNode(id_='56cfdc7b-ad24-4586-8c7c-688e1eb9fae6', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-22', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6df64b4daa8925dc939ee4b1f4ca0d2851186befb4ec88382082ffe393658615'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='c4e58580-811a-4235-93e6-c98cd05b5b1d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='73f6af3419b7d68f32974d28ee2f9054c54c017707678721532cc855f7b8e0d0')}, text='Figure13showsthedistribution\\nof scores in a 10% random sample of the full corpus. About 0.2% of documents evaluated are assigned a\\nlikelihood score of 0.5 or higher, meaning there is a small amount of toxicity in our pretraining data.\\nLanguageIdentification. WhileourpretrainingdataismostlyEnglish,italsoincludestextfromasmall\\nnumber ofother languages. Table 10showsthe distributionof languages inour corpus, subsettedto those\\nfoundinmorethan0.005%ofthedocuments.', start_char_idx=0, end_char_idx=463, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-22', obj=None),\n",
       " 'c4e58580-811a-4235-93e6-c98cd05b5b1d': IndexNode(id_='c4e58580-811a-4235-93e6-c98cd05b5b1d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-22', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6df64b4daa8925dc939ee4b1f4ca0d2851186befb4ec88382082ffe393658615'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='56cfdc7b-ad24-4586-8c7c-688e1eb9fae6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4301bf63cf3a422dab18e0395b01f5be75eebdc2030f417f52589ae0fb6bc97c'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='72775b9b-0a46-413c-8626-79b9715e269f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='239b5c1ffe438cdb5d92bdf45874d477084673dd532a9854177070eed3ff497e')}, text='About 0.2% of documents evaluated are assigned a\\nlikelihood score of 0.5 or higher, meaning there is a small amount of toxicity in our pretraining data.\\nLanguageIdentification. WhileourpretrainingdataismostlyEnglish,italsoincludestextfromasmall\\nnumber ofother languages. Table 10showsthe distributionof languages inour corpus, subsettedto those\\nfoundinmorethan0.005%ofthedocuments. OuranalysisusesthefastText(Bojanowskietal.,2016)language\\nidentification tool and a threshold of 0.5for the language detection.', start_char_idx=82, end_char_idx=590, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-22', obj=None),\n",
       " '72775b9b-0a46-413c-8626-79b9715e269f': IndexNode(id_='72775b9b-0a46-413c-8626-79b9715e269f', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-22', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6df64b4daa8925dc939ee4b1f4ca0d2851186befb4ec88382082ffe393658615'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='c4e58580-811a-4235-93e6-c98cd05b5b1d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='73f6af3419b7d68f32974d28ee2f9054c54c017707678721532cc855f7b8e0d0'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='33a87918-1284-4916-b101-c2e89687657c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3425470ed73fbd3e90627fae4acfa076ead63d47f8fd736ceca5433d2c7122fe')}, text='LanguageIdentification. WhileourpretrainingdataismostlyEnglish,italsoincludestextfromasmall\\nnumber ofother languages. Table 10showsthe distributionof languages inour corpus, subsettedto those\\nfoundinmorethan0.005%ofthedocuments. OuranalysisusesthefastText(Bojanowskietal.,2016)language\\nidentification tool and a threshold of 0.5for the language detection. A training corpus with a majority in\\nEnglish means that the model may not be suitable for use in other languages.', start_char_idx=235, end_char_idx=704, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-22', obj=None),\n",
       " '33a87918-1284-4916-b101-c2e89687657c': IndexNode(id_='33a87918-1284-4916-b101-c2e89687657c', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-22', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6df64b4daa8925dc939ee4b1f4ca0d2851186befb4ec88382082ffe393658615'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='72775b9b-0a46-413c-8626-79b9715e269f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='239b5c1ffe438cdb5d92bdf45874d477084673dd532a9854177070eed3ff497e'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='a5ef7135-0d70-4bb6-8b4a-0f7c02644727', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0869cc09074ac57f467d2d6450fb0784fafd6fb03eaa5cf6e26b967dc11a74a1')}, text='Table 10showsthe distributionof languages inour corpus, subsettedto those\\nfoundinmorethan0.005%ofthedocuments. OuranalysisusesthefastText(Bojanowskietal.,2016)language\\nidentification tool and a threshold of 0.5for the language detection. A training corpus with a majority in\\nEnglish means that the model may not be suitable for use in other languages.\\n21\\n\\nLanguage Percent Language Percent\\nen 89.70% uk 0.07%\\nunknown 8.38% ko 0.06%\\nde 0.', start_char_idx=353, end_char_idx=790, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-22', obj=None),\n",
       " 'a5ef7135-0d70-4bb6-8b4a-0f7c02644727': IndexNode(id_='a5ef7135-0d70-4bb6-8b4a-0f7c02644727', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-22', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6df64b4daa8925dc939ee4b1f4ca0d2851186befb4ec88382082ffe393658615'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='33a87918-1284-4916-b101-c2e89687657c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3425470ed73fbd3e90627fae4acfa076ead63d47f8fd736ceca5433d2c7122fe'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='b14d8855-f555-4c33-bb7a-e40b0c9d2c73', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3f3ccd901bcb28e62596f52d8d7a87a49de79e9a3e98af116e7b4002420efbaf')}, text='OuranalysisusesthefastText(Bojanowskietal.,2016)language\\nidentification tool and a threshold of 0.5for the language detection. A training corpus with a majority in\\nEnglish means that the model may not be suitable for use in other languages.\\n21\\n\\nLanguage Percent Language Percent\\nen 89.70% uk 0.07%\\nunknown 8.38% ko 0.06%\\nde 0.17% ca 0.04%\\nfr 0.16% sr 0.04%\\nsv 0.15% id 0.', start_char_idx=464, end_char_idx=835, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-22', obj=None),\n",
       " 'b14d8855-f555-4c33-bb7a-e40b0c9d2c73': IndexNode(id_='b14d8855-f555-4c33-bb7a-e40b0c9d2c73', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-22', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6df64b4daa8925dc939ee4b1f4ca0d2851186befb4ec88382082ffe393658615'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='a5ef7135-0d70-4bb6-8b4a-0f7c02644727', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0869cc09074ac57f467d2d6450fb0784fafd6fb03eaa5cf6e26b967dc11a74a1'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='6c6e04b0-fe82-43b6-a7fd-ce02417b257e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='69421a636924da1ae1073d698b510818ed01e6bd3df7ed383935392efb3fb4da')}, text='A training corpus with a majority in\\nEnglish means that the model may not be suitable for use in other languages.\\n21\\n\\nLanguage Percent Language Percent\\nen 89.70% uk 0.07%\\nunknown 8.38% ko 0.06%\\nde 0.17% ca 0.04%\\nfr 0.16% sr 0.04%\\nsv 0.15% id 0.03%\\nzh 0.13% cs 0.03%\\nes 0.13% fi 0.03%\\nru 0.13% hu 0.', start_char_idx=591, end_char_idx=889, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-22', obj=None),\n",
       " '6c6e04b0-fe82-43b6-a7fd-ce02417b257e': IndexNode(id_='6c6e04b0-fe82-43b6-a7fd-ce02417b257e', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-22', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6df64b4daa8925dc939ee4b1f4ca0d2851186befb4ec88382082ffe393658615'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='b14d8855-f555-4c33-bb7a-e40b0c9d2c73', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3f3ccd901bcb28e62596f52d8d7a87a49de79e9a3e98af116e7b4002420efbaf'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='4f7bfe4b-af70-4d4e-ba12-a6d4399bfd93', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a335d074590352e78edcc6739c7ae09b47dae09e76fb332ab00dbc3d6ed599a0')}, text='70% uk 0.07%\\nunknown 8.38% ko 0.06%\\nde 0.17% ca 0.04%\\nfr 0.16% sr 0.04%\\nsv 0.15% id 0.03%\\nzh 0.13% cs 0.03%\\nes 0.13% fi 0.03%\\nru 0.13% hu 0.03%\\nnl 0.12% no 0.03%\\nit 0.11% ro 0.03%\\nja 0.10% bg 0.', start_char_idx=749, end_char_idx=943, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-22', obj=None),\n",
       " '4f7bfe4b-af70-4d4e-ba12-a6d4399bfd93': IndexNode(id_='4f7bfe4b-af70-4d4e-ba12-a6d4399bfd93', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-22', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6df64b4daa8925dc939ee4b1f4ca0d2851186befb4ec88382082ffe393658615'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='6c6e04b0-fe82-43b6-a7fd-ce02417b257e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='69421a636924da1ae1073d698b510818ed01e6bd3df7ed383935392efb3fb4da'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='47aa0e05-8250-4aa2-81fe-197818b901c1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0b792c5fc93a3a259ae85c2c93c33a9fbd8ce084f63145b9d49986fe5c40b394')}, text='04%\\nfr 0.16% sr 0.04%\\nsv 0.15% id 0.03%\\nzh 0.13% cs 0.03%\\nes 0.13% fi 0.03%\\nru 0.13% hu 0.03%\\nnl 0.12% no 0.03%\\nit 0.11% ro 0.03%\\nja 0.10% bg 0.02%\\npl 0.09% da 0.02%\\npt 0.09% sl 0.01%\\nvi 0.', start_char_idx=799, end_char_idx=988, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-22', obj=None),\n",
       " '47aa0e05-8250-4aa2-81fe-197818b901c1': IndexNode(id_='47aa0e05-8250-4aa2-81fe-197818b901c1', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-22', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6df64b4daa8925dc939ee4b1f4ca0d2851186befb4ec88382082ffe393658615'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='4f7bfe4b-af70-4d4e-ba12-a6d4399bfd93', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a335d074590352e78edcc6739c7ae09b47dae09e76fb332ab00dbc3d6ed599a0'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='910ad3c1-8268-41f8-a6a8-02f3e887d3c7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f32ae54ca6696bfc08677bedfad29cfe44bc72f5d939024a585f4760e3d05e26')}, text='13% cs 0.03%\\nes 0.13% fi 0.03%\\nru 0.13% hu 0.03%\\nnl 0.12% no 0.03%\\nit 0.11% ro 0.03%\\nja 0.10% bg 0.02%\\npl 0.09% da 0.02%\\npt 0.09% sl 0.01%\\nvi 0.08% hr 0.01%\\nTable 10: Language distribution in pretraining data with percentage >= 0.005% .', start_char_idx=844, end_char_idx=1080, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-22', obj=None),\n",
       " '910ad3c1-8268-41f8-a6a8-02f3e887d3c7': IndexNode(id_='910ad3c1-8268-41f8-a6a8-02f3e887d3c7', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-22', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6df64b4daa8925dc939ee4b1f4ca0d2851186befb4ec88382082ffe393658615'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='47aa0e05-8250-4aa2-81fe-197818b901c1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0b792c5fc93a3a259ae85c2c93c33a9fbd8ce084f63145b9d49986fe5c40b394'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='e7e17a25-8983-4c3c-be69-f1c93d59e126', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='db4da23158aaf27975c09eb8e30c98e7efbcabae2a910bc3c1284958fb27c02e')}, text='13% hu 0.03%\\nnl 0.12% no 0.03%\\nit 0.11% ro 0.03%\\nja 0.10% bg 0.02%\\npl 0.09% da 0.02%\\npt 0.09% sl 0.01%\\nvi 0.08% hr 0.01%\\nTable 10: Language distribution in pretraining data with percentage >= 0.005% . Most data is in English,\\nmeaning that Llama 2 will perform best for English-language use cases.', start_char_idx=880, end_char_idx=1176, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-22', obj=None),\n",
       " 'e7e17a25-8983-4c3c-be69-f1c93d59e126': IndexNode(id_='e7e17a25-8983-4c3c-be69-f1c93d59e126', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-22', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6df64b4daa8925dc939ee4b1f4ca0d2851186befb4ec88382082ffe393658615'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='910ad3c1-8268-41f8-a6a8-02f3e887d3c7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f32ae54ca6696bfc08677bedfad29cfe44bc72f5d939024a585f4760e3d05e26'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='e6f74c4e-ad30-4147-94a0-950b6aa35a09', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a621897baca0ec8f1c125a47dd071295fc4866a5f3b052c54225c66639ae8a47')}, text='11% ro 0.03%\\nja 0.10% bg 0.02%\\npl 0.09% da 0.02%\\npt 0.09% sl 0.01%\\nvi 0.08% hr 0.01%\\nTable 10: Language distribution in pretraining data with percentage >= 0.005% . Most data is in English,\\nmeaning that Llama 2 will perform best for English-language use cases. The large unknown category is\\npartially made up of programming code data.\\nSafetyBenchmarksforPretrainedModels.', start_char_idx=916, end_char_idx=1287, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-22', obj=None),\n",
       " 'e6f74c4e-ad30-4147-94a0-950b6aa35a09': IndexNode(id_='e6f74c4e-ad30-4147-94a0-950b6aa35a09', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-22', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6df64b4daa8925dc939ee4b1f4ca0d2851186befb4ec88382082ffe393658615'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='e7e17a25-8983-4c3c-be69-f1c93d59e126', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='db4da23158aaf27975c09eb8e30c98e7efbcabae2a910bc3c1284958fb27c02e'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='6b094b10-6d73-452c-b722-50ac6b2331c0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b0acf786cd9a15995dbeda84c344f98d6e0a50593d9b2d4be459be6f4089db08')}, text='09% da 0.02%\\npt 0.09% sl 0.01%\\nvi 0.08% hr 0.01%\\nTable 10: Language distribution in pretraining data with percentage >= 0.005% . Most data is in English,\\nmeaning that Llama 2 will perform best for English-language use cases. The large unknown category is\\npartially made up of programming code data.\\nSafetyBenchmarksforPretrainedModels. Weevaluatethesafetycapabilitiesof Llama 2 onthreepopular\\nautomatic benchmarks, pertaining to three key dimensions of LM safety.', start_char_idx=952, end_char_idx=1415, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-22', obj=None),\n",
       " '6b094b10-6d73-452c-b722-50ac6b2331c0': IndexNode(id_='6b094b10-6d73-452c-b722-50ac6b2331c0', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-22', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6df64b4daa8925dc939ee4b1f4ca0d2851186befb4ec88382082ffe393658615'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='e6f74c4e-ad30-4147-94a0-950b6aa35a09', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a621897baca0ec8f1c125a47dd071295fc4866a5f3b052c54225c66639ae8a47'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='068204c9-09fb-4aed-acf3-46473a6a0d42', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='16c7b923b3439eb28583899f57937966212e6850359df222e6e4ef5bd006b90b')}, text='01%\\nTable 10: Language distribution in pretraining data with percentage >= 0.005% . Most data is in English,\\nmeaning that Llama 2 will perform best for English-language use cases. The large unknown category is\\npartially made up of programming code data.\\nSafetyBenchmarksforPretrainedModels. Weevaluatethesafetycapabilitiesof Llama 2 onthreepopular\\nautomatic benchmarks, pertaining to three key dimensions of LM safety.\\n1.Truthfulness , referring to whether a language model produces known falsehoods due to misconcep-\\ntions or false beliefs.', start_char_idx=997, end_char_idx=1538, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-22', obj=None),\n",
       " '068204c9-09fb-4aed-acf3-46473a6a0d42': IndexNode(id_='068204c9-09fb-4aed-acf3-46473a6a0d42', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-22', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6df64b4daa8925dc939ee4b1f4ca0d2851186befb4ec88382082ffe393658615'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='6b094b10-6d73-452c-b722-50ac6b2331c0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b0acf786cd9a15995dbeda84c344f98d6e0a50593d9b2d4be459be6f4089db08'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='3af15397-d78f-4883-8f36-ed5f026dc08a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='820f603cf154cd9c12240f7b5d5f3af4ccc0c9c307d80007a7160df3f1be729b')}, text='The large unknown category is\\npartially made up of programming code data.\\nSafetyBenchmarksforPretrainedModels. Weevaluatethesafetycapabilitiesof Llama 2 onthreepopular\\nautomatic benchmarks, pertaining to three key dimensions of LM safety.\\n1.Truthfulness , referring to whether a language model produces known falsehoods due to misconcep-\\ntions or false beliefs. We employ TruthfulQA (Lin et al., 2021) to measure how well our LLMs can\\ngenerate reliable outputs that agree with factuality and common sense.', start_char_idx=1177, end_char_idx=1682, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-22', obj=None),\n",
       " '3af15397-d78f-4883-8f36-ed5f026dc08a': IndexNode(id_='3af15397-d78f-4883-8f36-ed5f026dc08a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-22', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6df64b4daa8925dc939ee4b1f4ca0d2851186befb4ec88382082ffe393658615'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='068204c9-09fb-4aed-acf3-46473a6a0d42', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='16c7b923b3439eb28583899f57937966212e6850359df222e6e4ef5bd006b90b'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='dd71c578-deff-4297-82c7-32d58e7201b1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0b856f883f70e96f8f0702a6b502c7dd81eb87f1b0385e134c65e2328d8adadb')}, text='Weevaluatethesafetycapabilitiesof Llama 2 onthreepopular\\nautomatic benchmarks, pertaining to three key dimensions of LM safety.\\n1.Truthfulness , referring to whether a language model produces known falsehoods due to misconcep-\\ntions or false beliefs. We employ TruthfulQA (Lin et al., 2021) to measure how well our LLMs can\\ngenerate reliable outputs that agree with factuality and common sense.\\n2.Toxicity,definedasthetendencyofalanguagemodeltogeneratetoxic,rude,adversarial,orimplicitly\\nhateful content.', start_char_idx=1288, end_char_idx=1792, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-22', obj=None),\n",
       " 'dd71c578-deff-4297-82c7-32d58e7201b1': IndexNode(id_='dd71c578-deff-4297-82c7-32d58e7201b1', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-22', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6df64b4daa8925dc939ee4b1f4ca0d2851186befb4ec88382082ffe393658615'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='3af15397-d78f-4883-8f36-ed5f026dc08a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='820f603cf154cd9c12240f7b5d5f3af4ccc0c9c307d80007a7160df3f1be729b'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='0a8ca635-a98c-4519-942c-a2dfd9f7057e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4b4ab32a03473cf235b3d21c5eaecfe9acb9f58dac1cba9d3f9ea141de6b4d15')}, text='1.Truthfulness , referring to whether a language model produces known falsehoods due to misconcep-\\ntions or false beliefs. We employ TruthfulQA (Lin et al., 2021) to measure how well our LLMs can\\ngenerate reliable outputs that agree with factuality and common sense.\\n2.Toxicity,definedasthetendencyofalanguagemodeltogeneratetoxic,rude,adversarial,orimplicitly\\nhateful content. We choose ToxiGen (Hartvigsen et al., 2022) to measure the amount of generation\\nof toxic language and hate speech across different groups.', start_char_idx=1416, end_char_idx=1931, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-22', obj=None),\n",
       " '0a8ca635-a98c-4519-942c-a2dfd9f7057e': IndexNode(id_='0a8ca635-a98c-4519-942c-a2dfd9f7057e', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-22', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6df64b4daa8925dc939ee4b1f4ca0d2851186befb4ec88382082ffe393658615'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='dd71c578-deff-4297-82c7-32d58e7201b1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0b856f883f70e96f8f0702a6b502c7dd81eb87f1b0385e134c65e2328d8adadb'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='37b206a0-9653-41f2-970a-4526b5ad7254', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1d08072c23f9c21c5fb4cdc2fa638af7a352c99ac3b2650c68667d894ed824d0')}, text='2.Toxicity,definedasthetendencyofalanguagemodeltogeneratetoxic,rude,adversarial,orimplicitly\\nhateful content. We choose ToxiGen (Hartvigsen et al., 2022) to measure the amount of generation\\nof toxic language and hate speech across different groups.\\n3.Bias, defined as how model generations reproduce existing stereotypical social biases. We use\\nBOLD(Dhamala et al., 2021) to study how the sentiment in model generations may vary with\\ndemographic attributes.', start_char_idx=1683, end_char_idx=2140, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-22', obj=None),\n",
       " '37b206a0-9653-41f2-970a-4526b5ad7254': IndexNode(id_='37b206a0-9653-41f2-970a-4526b5ad7254', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-22', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6df64b4daa8925dc939ee4b1f4ca0d2851186befb4ec88382082ffe393658615'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='0a8ca635-a98c-4519-942c-a2dfd9f7057e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4b4ab32a03473cf235b3d21c5eaecfe9acb9f58dac1cba9d3f9ea141de6b4d15'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='1150a948-d525-4e1f-bb28-6240b44404e0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6862fd4fe12755510d1e460de837dc0429e1c165743ad1ce14d3b0bae4b38666')}, text='We choose ToxiGen (Hartvigsen et al., 2022) to measure the amount of generation\\nof toxic language and hate speech across different groups.\\n3.Bias, defined as how model generations reproduce existing stereotypical social biases. We use\\nBOLD(Dhamala et al., 2021) to study how the sentiment in model generations may vary with\\ndemographic attributes.\\nWe compare the performance of Llama 2 with Llama 1 (Touvron et al., 2023), Falcon (Almazrouei et al.,\\n2023), and MPT (MosaicML NLP Team et al., 2023) in Table 11.', start_char_idx=1793, end_char_idx=2303, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-22', obj=None),\n",
       " '1150a948-d525-4e1f-bb28-6240b44404e0': IndexNode(id_='1150a948-d525-4e1f-bb28-6240b44404e0', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-22', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6df64b4daa8925dc939ee4b1f4ca0d2851186befb4ec88382082ffe393658615'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='37b206a0-9653-41f2-970a-4526b5ad7254', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1d08072c23f9c21c5fb4cdc2fa638af7a352c99ac3b2650c68667d894ed824d0'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='3e5bee61-b0b4-4fec-bf44-f6d2358a4b99', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9b94d491bcd09d862173b51505c49648af76710b979bbfe612fb10aff7b49c11')}, text='We use\\nBOLD(Dhamala et al., 2021) to study how the sentiment in model generations may vary with\\ndemographic attributes.\\nWe compare the performance of Llama 2 with Llama 1 (Touvron et al., 2023), Falcon (Almazrouei et al.,\\n2023), and MPT (MosaicML NLP Team et al., 2023) in Table 11. For decoding, we set temperature to 0.1\\nand use nucleus sampling (Holtzman et al., 2020) with top- pset to 0.9.', start_char_idx=2021, end_char_idx=2415, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-22', obj=None),\n",
       " '3e5bee61-b0b4-4fec-bf44-f6d2358a4b99': IndexNode(id_='3e5bee61-b0b4-4fec-bf44-f6d2358a4b99', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-22', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6df64b4daa8925dc939ee4b1f4ca0d2851186befb4ec88382082ffe393658615'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='1150a948-d525-4e1f-bb28-6240b44404e0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6862fd4fe12755510d1e460de837dc0429e1c165743ad1ce14d3b0bae4b38666'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='d58a48b1-859b-4586-b1db-1b82f6abce1c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4d8ab556bf0986a700cf809af351a7407f80a238ae54e0c93dfc46ba4f9e6a33')}, text='We compare the performance of Llama 2 with Llama 1 (Touvron et al., 2023), Falcon (Almazrouei et al.,\\n2023), and MPT (MosaicML NLP Team et al., 2023) in Table 11. For decoding, we set temperature to 0.1\\nand use nucleus sampling (Holtzman et al., 2020) with top- pset to 0.9. For TruthfulQA, we present the\\npercentageofgenerationsthatarebothtruthfulandinformative(thehigher,thebetter).', start_char_idx=2141, end_char_idx=2525, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-22', obj=None),\n",
       " 'd58a48b1-859b-4586-b1db-1b82f6abce1c': IndexNode(id_='d58a48b1-859b-4586-b1db-1b82f6abce1c', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-22', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6df64b4daa8925dc939ee4b1f4ca0d2851186befb4ec88382082ffe393658615'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='3e5bee61-b0b4-4fec-bf44-f6d2358a4b99', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9b94d491bcd09d862173b51505c49648af76710b979bbfe612fb10aff7b49c11'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='d5405ca2-2ca2-4daf-a083-fac0c2073222', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bc700089dc8f2c46756771bbdc72ea169b9d6719e7e5b7e56241ed2b4cf0beca')}, text='For decoding, we set temperature to 0.1\\nand use nucleus sampling (Holtzman et al., 2020) with top- pset to 0.9. For TruthfulQA, we present the\\npercentageofgenerationsthatarebothtruthfulandinformative(thehigher,thebetter). ForToxiGen,we\\npresentthepercentageofgenerationsthataredeemedtoxicbythemetric(thelower,thebetter). Detailed\\ndescriptionsofthebenchmarksandmetricscanbefoundinAppendixA.4.7.', start_char_idx=2304, end_char_idx=2696, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-22', obj=None),\n",
       " 'd5405ca2-2ca2-4daf-a083-fac0c2073222': IndexNode(id_='d5405ca2-2ca2-4daf-a083-fac0c2073222', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-22', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6df64b4daa8925dc939ee4b1f4ca0d2851186befb4ec88382082ffe393658615'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='d58a48b1-859b-4586-b1db-1b82f6abce1c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4d8ab556bf0986a700cf809af351a7407f80a238ae54e0c93dfc46ba4f9e6a33'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='e651e3da-7248-4815-a96c-5287af80be6f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='427be4ae955740ae70c95f98fb5b9ced8f2468af79574f3a2adb4ba6dc174e0b')}, text='For TruthfulQA, we present the\\npercentageofgenerationsthatarebothtruthfulandinformative(thehigher,thebetter). ForToxiGen,we\\npresentthepercentageofgenerationsthataredeemedtoxicbythemetric(thelower,thebetter). Detailed\\ndescriptionsofthebenchmarksandmetricscanbefoundinAppendixA.4.7. Whencomparedto Llama 1-7B,\\nLlama 2-7B demonstrates a 21.37% increase in truthfulness and informativeness and a 7.61% decrease in\\ntoxicity.', start_char_idx=2416, end_char_idx=2835, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-22', obj=None),\n",
       " 'e651e3da-7248-4815-a96c-5287af80be6f': IndexNode(id_='e651e3da-7248-4815-a96c-5287af80be6f', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-22', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6df64b4daa8925dc939ee4b1f4ca0d2851186befb4ec88382082ffe393658615'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='d5405ca2-2ca2-4daf-a083-fac0c2073222', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bc700089dc8f2c46756771bbdc72ea169b9d6719e7e5b7e56241ed2b4cf0beca'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='39acdb70-f490-4184-8991-29262a976f9a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a2923d4c366d313775a380730f690e9707d351bf61290daea10b6cd413237ab8')}, text='ForToxiGen,we\\npresentthepercentageofgenerationsthataredeemedtoxicbythemetric(thelower,thebetter). Detailed\\ndescriptionsofthebenchmarksandmetricscanbefoundinAppendixA.4.7. Whencomparedto Llama 1-7B,\\nLlama 2-7B demonstrates a 21.37% increase in truthfulness and informativeness and a 7.61% decrease in\\ntoxicity. We also observe an increase in toxicity in the pretrained 13B and 70B Llama 2, which may result\\nfrom larger pretraining data or a different dataset mix.', start_char_idx=2526, end_char_idx=2988, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-22', obj=None),\n",
       " '39acdb70-f490-4184-8991-29262a976f9a': IndexNode(id_='39acdb70-f490-4184-8991-29262a976f9a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-22', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6df64b4daa8925dc939ee4b1f4ca0d2851186befb4ec88382082ffe393658615'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='e651e3da-7248-4815-a96c-5287af80be6f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='427be4ae955740ae70c95f98fb5b9ced8f2468af79574f3a2adb4ba6dc174e0b'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='f3032e21-8139-4852-adeb-ad10923d50a5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9cf02eb4cab5d4b6f0da5fc3f91a5d1cecbd7a0dbe8f1b34457355e1151f1d23')}, text='Whencomparedto Llama 1-7B,\\nLlama 2-7B demonstrates a 21.37% increase in truthfulness and informativeness and a 7.61% decrease in\\ntoxicity. We also observe an increase in toxicity in the pretrained 13B and 70B Llama 2, which may result\\nfrom larger pretraining data or a different dataset mix. Some have postulated the existence of a relationship\\nbetween pretraining dataset size and downstream model toxicity or bias (Bender et al., 2021b), but empirical\\nwork to validate this claim is still ongoing (Dodge et al., 2021; Smith and Williams, 2021; Tal et al., 2022), and\\nfurther evidence from up-to-date models is still needed.', start_char_idx=2697, end_char_idx=3322, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-22', obj=None),\n",
       " 'f3032e21-8139-4852-adeb-ad10923d50a5': IndexNode(id_='f3032e21-8139-4852-adeb-ad10923d50a5', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-22', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6df64b4daa8925dc939ee4b1f4ca0d2851186befb4ec88382082ffe393658615'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='39acdb70-f490-4184-8991-29262a976f9a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a2923d4c366d313775a380730f690e9707d351bf61290daea10b6cd413237ab8')}, text='Some have postulated the existence of a relationship\\nbetween pretraining dataset size and downstream model toxicity or bias (Bender et al., 2021b), but empirical\\nwork to validate this claim is still ongoing (Dodge et al., 2021; Smith and Williams, 2021; Tal et al., 2022), and\\nfurther evidence from up-to-date models is still needed.\\nIn Appendix A.4.7, we present bias metrics, such as how the sentiment of model generations varies with\\ndemographic attributes.', start_char_idx=2989, end_char_idx=3449, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-22', obj=None),\n",
       " '4a920c1d-4c20-4b79-9bf5-ae0c21e6609b': IndexNode(id_='4a920c1d-4c20-4b79-9bf5-ae0c21e6609b', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-22', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6df64b4daa8925dc939ee4b1f4ca0d2851186befb4ec88382082ffe393658615'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='f4f55bd2-ab86-438f-999c-2b963d593f08', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ccec82a75211e8c1c63aba2ce01951cba62c51ebd4bc1b31ae9f5342fbdbc870')}, text='Figure13showsthedistribution\\nof scores in a 10% random sample of the full corpus. About 0.2% of documents evaluated are assigned a\\nlikelihood score of 0.5 or higher, meaning there is a small amount of toxicity in our pretraining data.\\nLanguageIdentification. WhileourpretrainingdataismostlyEnglish,italsoincludestextfromasmall\\nnumber ofother languages. Table 10showsthe distributionof languages inour corpus, subsettedto those\\nfoundinmorethan0.005%ofthedocuments. OuranalysisusesthefastText(Bojanowskietal.,2016)language\\nidentification tool and a threshold of 0.5for the language detection. A training corpus with a majority in\\nEnglish means that the model may not be suitable for use in other languages.', start_char_idx=0, end_char_idx=704, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-22', obj=None),\n",
       " 'f4f55bd2-ab86-438f-999c-2b963d593f08': IndexNode(id_='f4f55bd2-ab86-438f-999c-2b963d593f08', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-22', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6df64b4daa8925dc939ee4b1f4ca0d2851186befb4ec88382082ffe393658615'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='4a920c1d-4c20-4b79-9bf5-ae0c21e6609b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bcc516f4030917830be4416ce592f4851358aee202896bbd803ea1095921fdae'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='eaf7e632-bb56-405a-bece-1c394ff14356', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='12632789c9c8125048dfe68c6eb8d9a016bc9e79c6c0c52e9dcdd02e5502e904')}, text='Table 10showsthe distributionof languages inour corpus, subsettedto those\\nfoundinmorethan0.005%ofthedocuments. OuranalysisusesthefastText(Bojanowskietal.,2016)language\\nidentification tool and a threshold of 0.5for the language detection. A training corpus with a majority in\\nEnglish means that the model may not be suitable for use in other languages.\\n21\\n\\nLanguage Percent Language Percent\\nen 89.70% uk 0.07%\\nunknown 8.38% ko 0.06%\\nde 0.17% ca 0.04%\\nfr 0.16% sr 0.04%\\nsv 0.15% id 0.03%\\nzh 0.13% cs 0.03%\\nes 0.13% fi 0.03%\\nru 0.13% hu 0.03%\\nnl 0.12% no 0.03%\\nit 0.11% ro 0.03%\\nja 0.10% bg 0.02%\\npl 0.09% da 0.02%\\npt 0.09% sl 0.01%\\nvi 0.08% hr 0.01%\\nTable 10: Language distribution in pretraining data with percentage >= 0.005% .', start_char_idx=353, end_char_idx=1080, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-22', obj=None),\n",
       " 'eaf7e632-bb56-405a-bece-1c394ff14356': IndexNode(id_='eaf7e632-bb56-405a-bece-1c394ff14356', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-22', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6df64b4daa8925dc939ee4b1f4ca0d2851186befb4ec88382082ffe393658615'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='f4f55bd2-ab86-438f-999c-2b963d593f08', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ccec82a75211e8c1c63aba2ce01951cba62c51ebd4bc1b31ae9f5342fbdbc870'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='ad542a6d-2c77-43d5-8c6f-fdbc47358311', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='337cd270af06b19e8973a5b517177d70f3fc30040b8f58fe068806d583fc7648')}, text='Most data is in English,\\nmeaning that Llama 2 will perform best for English-language use cases. The large unknown category is\\npartially made up of programming code data.\\nSafetyBenchmarksforPretrainedModels. Weevaluatethesafetycapabilitiesof Llama 2 onthreepopular\\nautomatic benchmarks, pertaining to three key dimensions of LM safety.\\n1.Truthfulness , referring to whether a language model produces known falsehoods due to misconcep-\\ntions or false beliefs. We employ TruthfulQA (Lin et al., 2021) to measure how well our LLMs can\\ngenerate reliable outputs that agree with factuality and common sense.\\n2.Toxicity,definedasthetendencyofalanguagemodeltogeneratetoxic,rude,adversarial,orimplicitly\\nhateful content. We choose ToxiGen (Hartvigsen et al., 2022) to measure the amount of generation\\nof toxic language and hate speech across different groups.\\n3.Bias, defined as how model generations reproduce existing stereotypical social biases.', start_char_idx=1081, end_char_idx=2020, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-22', obj=None),\n",
       " 'ad542a6d-2c77-43d5-8c6f-fdbc47358311': IndexNode(id_='ad542a6d-2c77-43d5-8c6f-fdbc47358311', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-22', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6df64b4daa8925dc939ee4b1f4ca0d2851186befb4ec88382082ffe393658615'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='eaf7e632-bb56-405a-bece-1c394ff14356', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='12632789c9c8125048dfe68c6eb8d9a016bc9e79c6c0c52e9dcdd02e5502e904'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='e4859bc7-1bb9-4e64-a08f-8a43b50cb245', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e25645febdfe1a1a6d7acbe6333a80e5e943fa8a2d2a689574413abe1113268f')}, text='2.Toxicity,definedasthetendencyofalanguagemodeltogeneratetoxic,rude,adversarial,orimplicitly\\nhateful content. We choose ToxiGen (Hartvigsen et al., 2022) to measure the amount of generation\\nof toxic language and hate speech across different groups.\\n3.Bias, defined as how model generations reproduce existing stereotypical social biases. We use\\nBOLD(Dhamala et al., 2021) to study how the sentiment in model generations may vary with\\ndemographic attributes.\\nWe compare the performance of Llama 2 with Llama 1 (Touvron et al., 2023), Falcon (Almazrouei et al.,\\n2023), and MPT (MosaicML NLP Team et al., 2023) in Table 11. For decoding, we set temperature to 0.1\\nand use nucleus sampling (Holtzman et al., 2020) with top- pset to 0.9. For TruthfulQA, we present the\\npercentageofgenerationsthatarebothtruthfulandinformative(thehigher,thebetter).', start_char_idx=1683, end_char_idx=2525, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-22', obj=None),\n",
       " 'e4859bc7-1bb9-4e64-a08f-8a43b50cb245': IndexNode(id_='e4859bc7-1bb9-4e64-a08f-8a43b50cb245', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-22', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6df64b4daa8925dc939ee4b1f4ca0d2851186befb4ec88382082ffe393658615'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='ad542a6d-2c77-43d5-8c6f-fdbc47358311', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='337cd270af06b19e8973a5b517177d70f3fc30040b8f58fe068806d583fc7648'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='3eed1706-8918-4dae-a698-bc440ab1d275', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='95171555caab76818af2eafcdfe7736ea9957ee6d57d92ac3370d8aecff1a90e')}, text='For decoding, we set temperature to 0.1\\nand use nucleus sampling (Holtzman et al., 2020) with top- pset to 0.9. For TruthfulQA, we present the\\npercentageofgenerationsthatarebothtruthfulandinformative(thehigher,thebetter). ForToxiGen,we\\npresentthepercentageofgenerationsthataredeemedtoxicbythemetric(thelower,thebetter). Detailed\\ndescriptionsofthebenchmarksandmetricscanbefoundinAppendixA.4.7. Whencomparedto Llama 1-7B,\\nLlama 2-7B demonstrates a 21.37% increase in truthfulness and informativeness and a 7.61% decrease in\\ntoxicity. We also observe an increase in toxicity in the pretrained 13B and 70B Llama 2, which may result\\nfrom larger pretraining data or a different dataset mix.', start_char_idx=2304, end_char_idx=2988, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-22', obj=None),\n",
       " '3eed1706-8918-4dae-a698-bc440ab1d275': IndexNode(id_='3eed1706-8918-4dae-a698-bc440ab1d275', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-22', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6df64b4daa8925dc939ee4b1f4ca0d2851186befb4ec88382082ffe393658615'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='e4859bc7-1bb9-4e64-a08f-8a43b50cb245', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e25645febdfe1a1a6d7acbe6333a80e5e943fa8a2d2a689574413abe1113268f')}, text='Whencomparedto Llama 1-7B,\\nLlama 2-7B demonstrates a 21.37% increase in truthfulness and informativeness and a 7.61% decrease in\\ntoxicity. We also observe an increase in toxicity in the pretrained 13B and 70B Llama 2, which may result\\nfrom larger pretraining data or a different dataset mix. Some have postulated the existence of a relationship\\nbetween pretraining dataset size and downstream model toxicity or bias (Bender et al., 2021b), but empirical\\nwork to validate this claim is still ongoing (Dodge et al., 2021; Smith and Williams, 2021; Tal et al., 2022), and\\nfurther evidence from up-to-date models is still needed.\\nIn Appendix A.4.7, we present bias metrics, such as how the sentiment of model generations varies with\\ndemographic attributes.', start_char_idx=2697, end_char_idx=3449, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-22', obj=None),\n",
       " '47b9b427-dbb5-4c87-8bf5-9ab039f187d4': IndexNode(id_='47b9b427-dbb5-4c87-8bf5-9ab039f187d4', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-22', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6df64b4daa8925dc939ee4b1f4ca0d2851186befb4ec88382082ffe393658615'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='37ed74f5-a6a5-47d6-ba5d-b63a85d92761', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='85b88d67d3e2a02c9cf6caa8553897918d0bfc6cf15b9b4cbb3c5eb358191970')}, text='Figure13showsthedistribution\\nof scores in a 10% random sample of the full corpus. About 0.2% of documents evaluated are assigned a\\nlikelihood score of 0.5 or higher, meaning there is a small amount of toxicity in our pretraining data.\\nLanguageIdentification. WhileourpretrainingdataismostlyEnglish,italsoincludestextfromasmall\\nnumber ofother languages. Table 10showsthe distributionof languages inour corpus, subsettedto those\\nfoundinmorethan0.005%ofthedocuments. OuranalysisusesthefastText(Bojanowskietal.,2016)language\\nidentification tool and a threshold of 0.5for the language detection. A training corpus with a majority in\\nEnglish means that the model may not be suitable for use in other languages.\\n21\\n\\nLanguage Percent Language Percent\\nen 89.70% uk 0.07%\\nunknown 8.38% ko 0.06%\\nde 0.17% ca 0.04%\\nfr 0.16% sr 0.04%\\nsv 0.15% id 0.03%\\nzh 0.13% cs 0.03%\\nes 0.13% fi 0.03%\\nru 0.13% hu 0.03%\\nnl 0.12% no 0.03%\\nit 0.11% ro 0.03%\\nja 0.10% bg 0.02%\\npl 0.09% da 0.02%\\npt 0.09% sl 0.01%\\nvi 0.08% hr 0.01%\\nTable 10: Language distribution in pretraining data with percentage >= 0.005% . Most data is in English,\\nmeaning that Llama 2 will perform best for English-language use cases. The large unknown category is\\npartially made up of programming code data.\\nSafetyBenchmarksforPretrainedModels. Weevaluatethesafetycapabilitiesof Llama 2 onthreepopular\\nautomatic benchmarks, pertaining to three key dimensions of LM safety.\\n1.Truthfulness , referring to whether a language model produces known falsehoods due to misconcep-\\ntions or false beliefs.', start_char_idx=0, end_char_idx=1538, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-22', obj=None),\n",
       " '37ed74f5-a6a5-47d6-ba5d-b63a85d92761': IndexNode(id_='37ed74f5-a6a5-47d6-ba5d-b63a85d92761', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-22', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6df64b4daa8925dc939ee4b1f4ca0d2851186befb4ec88382082ffe393658615'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='47b9b427-dbb5-4c87-8bf5-9ab039f187d4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='79b9797d53751a12e7cb89cfe887ef41816ad13bdaa446283f1c4ce7f73609c0'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='09e32654-85ab-4eec-8c4d-4552d51799c9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='95171555caab76818af2eafcdfe7736ea9957ee6d57d92ac3370d8aecff1a90e')}, text='The large unknown category is\\npartially made up of programming code data.\\nSafetyBenchmarksforPretrainedModels. Weevaluatethesafetycapabilitiesof Llama 2 onthreepopular\\nautomatic benchmarks, pertaining to three key dimensions of LM safety.\\n1.Truthfulness , referring to whether a language model produces known falsehoods due to misconcep-\\ntions or false beliefs. We employ TruthfulQA (Lin et al., 2021) to measure how well our LLMs can\\ngenerate reliable outputs that agree with factuality and common sense.\\n2.Toxicity,definedasthetendencyofalanguagemodeltogeneratetoxic,rude,adversarial,orimplicitly\\nhateful content. We choose ToxiGen (Hartvigsen et al., 2022) to measure the amount of generation\\nof toxic language and hate speech across different groups.\\n3.Bias, defined as how model generations reproduce existing stereotypical social biases. We use\\nBOLD(Dhamala et al., 2021) to study how the sentiment in model generations may vary with\\ndemographic attributes.\\nWe compare the performance of Llama 2 with Llama 1 (Touvron et al., 2023), Falcon (Almazrouei et al.,\\n2023), and MPT (MosaicML NLP Team et al., 2023) in Table 11. For decoding, we set temperature to 0.1\\nand use nucleus sampling (Holtzman et al., 2020) with top- pset to 0.9. For TruthfulQA, we present the\\npercentageofgenerationsthatarebothtruthfulandinformative(thehigher,thebetter). ForToxiGen,we\\npresentthepercentageofgenerationsthataredeemedtoxicbythemetric(thelower,thebetter). Detailed\\ndescriptionsofthebenchmarksandmetricscanbefoundinAppendixA.4.7. Whencomparedto Llama 1-7B,\\nLlama 2-7B demonstrates a 21.37% increase in truthfulness and informativeness and a 7.61% decrease in\\ntoxicity. We also observe an increase in toxicity in the pretrained 13B and 70B Llama 2, which may result\\nfrom larger pretraining data or a different dataset mix.', start_char_idx=1177, end_char_idx=2988, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-22', obj=None),\n",
       " '09e32654-85ab-4eec-8c4d-4552d51799c9': IndexNode(id_='09e32654-85ab-4eec-8c4d-4552d51799c9', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-22', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6df64b4daa8925dc939ee4b1f4ca0d2851186befb4ec88382082ffe393658615'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='37ed74f5-a6a5-47d6-ba5d-b63a85d92761', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='85b88d67d3e2a02c9cf6caa8553897918d0bfc6cf15b9b4cbb3c5eb358191970')}, text='Whencomparedto Llama 1-7B,\\nLlama 2-7B demonstrates a 21.37% increase in truthfulness and informativeness and a 7.61% decrease in\\ntoxicity. We also observe an increase in toxicity in the pretrained 13B and 70B Llama 2, which may result\\nfrom larger pretraining data or a different dataset mix. Some have postulated the existence of a relationship\\nbetween pretraining dataset size and downstream model toxicity or bias (Bender et al., 2021b), but empirical\\nwork to validate this claim is still ongoing (Dodge et al., 2021; Smith and Williams, 2021; Tal et al., 2022), and\\nfurther evidence from up-to-date models is still needed.\\nIn Appendix A.4.7, we present bias metrics, such as how the sentiment of model generations varies with\\ndemographic attributes.', start_char_idx=2697, end_char_idx=3449, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-22', obj=None),\n",
       " 'node-22': IndexNode(id_='node-22', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='d03f19eb-da15-45dc-bfd4-e5d10f161250', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='231b3bd773f012c01b893ada9e009ecf25ee59934614c5a595c9bf1b3a123292'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='8edf656e-261e-4535-aba8-7af876effb10', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='04659f1f151f8b669f2a6d4596224be975bca2877f921d922d1c882d380193b2'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='929e3fa0-3050-4615-8a2e-cdaaf419ef2b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='468997e4aae2ce47b6ec4eee9120e9a6b3fc6ae19c930f73cc02c5fe63b36396')}, text='Figure13showsthedistribution\\nof scores in a 10% random sample of the full corpus. About 0.2% of documents evaluated are assigned a\\nlikelihood score of 0.5 or higher, meaning there is a small amount of toxicity in our pretraining data.\\nLanguageIdentification. WhileourpretrainingdataismostlyEnglish,italsoincludestextfromasmall\\nnumber ofother languages. Table 10showsthe distributionof languages inour corpus, subsettedto those\\nfoundinmorethan0.005%ofthedocuments. OuranalysisusesthefastText(Bojanowskietal.,2016)language\\nidentification tool and a threshold of 0.5for the language detection. A training corpus with a majority in\\nEnglish means that the model may not be suitable for use in other languages.\\n21\\n\\nLanguage Percent Language Percent\\nen 89.70% uk 0.07%\\nunknown 8.38% ko 0.06%\\nde 0.17% ca 0.04%\\nfr 0.16% sr 0.04%\\nsv 0.15% id 0.03%\\nzh 0.13% cs 0.03%\\nes 0.13% fi 0.03%\\nru 0.13% hu 0.03%\\nnl 0.12% no 0.03%\\nit 0.11% ro 0.03%\\nja 0.10% bg 0.02%\\npl 0.09% da 0.02%\\npt 0.09% sl 0.01%\\nvi 0.08% hr 0.01%\\nTable 10: Language distribution in pretraining data with percentage >= 0.005% . Most data is in English,\\nmeaning that Llama 2 will perform best for English-language use cases. The large unknown category is\\npartially made up of programming code data.\\nSafetyBenchmarksforPretrainedModels. Weevaluatethesafetycapabilitiesof Llama 2 onthreepopular\\nautomatic benchmarks, pertaining to three key dimensions of LM safety.\\n1.Truthfulness , referring to whether a language model produces known falsehoods due to misconcep-\\ntions or false beliefs. We employ TruthfulQA (Lin et al., 2021) to measure how well our LLMs can\\ngenerate reliable outputs that agree with factuality and common sense.\\n2.Toxicity,definedasthetendencyofalanguagemodeltogeneratetoxic,rude,adversarial,orimplicitly\\nhateful content. We choose ToxiGen (Hartvigsen et al., 2022) to measure the amount of generation\\nof toxic language and hate speech across different groups.\\n3.Bias, defined as how model generations reproduce existing stereotypical social biases. We use\\nBOLD(Dhamala et al., 2021) to study how the sentiment in model generations may vary with\\ndemographic attributes.\\nWe compare the performance of Llama 2 with Llama 1 (Touvron et al., 2023), Falcon (Almazrouei et al.,\\n2023), and MPT (MosaicML NLP Team et al., 2023) in Table 11. For decoding, we set temperature to 0.1\\nand use nucleus sampling (Holtzman et al., 2020) with top- pset to 0.9. For TruthfulQA, we present the\\npercentageofgenerationsthatarebothtruthfulandinformative(thehigher,thebetter). ForToxiGen,we\\npresentthepercentageofgenerationsthataredeemedtoxicbythemetric(thelower,thebetter). Detailed\\ndescriptionsofthebenchmarksandmetricscanbefoundinAppendixA.4.7. Whencomparedto Llama 1-7B,\\nLlama 2-7B demonstrates a 21.37% increase in truthfulness and informativeness and a 7.61% decrease in\\ntoxicity. We also observe an increase in toxicity in the pretrained 13B and 70B Llama 2, which may result\\nfrom larger pretraining data or a different dataset mix. Some have postulated the existence of a relationship\\nbetween pretraining dataset size and downstream model toxicity or bias (Bender et al., 2021b), but empirical\\nwork to validate this claim is still ongoing (Dodge et al., 2021; Smith and Williams, 2021; Tal et al., 2022), and\\nfurther evidence from up-to-date models is still needed.\\nIn Appendix A.4.7, we present bias metrics, such as how the sentiment of model generations varies with\\ndemographic attributes.', start_char_idx=68181, end_char_idx=71630, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-22', obj=None),\n",
       " '35f11650-6365-4704-9cd5-222a5af74f34': IndexNode(id_='35f11650-6365-4704-9cd5-222a5af74f34', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-23', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='468997e4aae2ce47b6ec4eee9120e9a6b3fc6ae19c930f73cc02c5fe63b36396'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='c625006a-5ae8-4415-99fd-467b55a5cbfe', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='63175c8d96e0084b647b7f2cd7c1457a0d18d40df1c6e6a7e48134b49f067f70')}, text='In Appendix A.4.7, we present bias metrics, such as how the sentiment of model generations varies with\\ndemographic attributes. We note an increase in positive sentiment overall for many of the groups using\\nBOLDprompts. MoredetailedresultssplitbydifferentdemographicgroupscanbefoundinAppendixA.4.8.\\nLlama 2 doesnotoutperformothermodelsontoxicitymetrics,andwespeculatethatthismaybebecausewe\\nrefrained from aggressively filtering the pretraining data.', start_char_idx=0, end_char_idx=448, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-23', obj=None),\n",
       " 'c625006a-5ae8-4415-99fd-467b55a5cbfe': IndexNode(id_='c625006a-5ae8-4415-99fd-467b55a5cbfe', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-23', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='468997e4aae2ce47b6ec4eee9120e9a6b3fc6ae19c930f73cc02c5fe63b36396'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='35f11650-6365-4704-9cd5-222a5af74f34', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1e04f577844121f50b4f2071261d5cab98f1c7cd1152faaa6ab6301d0661237f'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='f6166240-7aeb-4bba-bc28-45effcca9730', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='02768e38d596aecf44932fe44c8c06a058b60a1600b17050f0b9b7dfaeb2b117')}, text='We note an increase in positive sentiment overall for many of the groups using\\nBOLDprompts. MoredetailedresultssplitbydifferentdemographicgroupscanbefoundinAppendixA.4.8.\\nLlama 2 doesnotoutperformothermodelsontoxicitymetrics,andwespeculatethatthismaybebecausewe\\nrefrained from aggressively filtering the pretraining data. Recall that leaving pretraining data unfiltered may\\nenable base models tuned to perform well on more downstream tasks (including hate speech detection),\\nand it carries less risk of accidentally filtering out some demographic groups.', start_char_idx=127, end_char_idx=681, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-23', obj=None),\n",
       " 'f6166240-7aeb-4bba-bc28-45effcca9730': IndexNode(id_='f6166240-7aeb-4bba-bc28-45effcca9730', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-23', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='468997e4aae2ce47b6ec4eee9120e9a6b3fc6ae19c930f73cc02c5fe63b36396'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='c625006a-5ae8-4415-99fd-467b55a5cbfe', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='63175c8d96e0084b647b7f2cd7c1457a0d18d40df1c6e6a7e48134b49f067f70'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='fe82ffc3-de7f-4e2c-a95a-7a66fbdffd13', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1b65f349333d77048e74e3dd6da033ce57a9f2921111800ba770083bd8c8b29d')}, text='Llama 2 doesnotoutperformothermodelsontoxicitymetrics,andwespeculatethatthismaybebecausewe\\nrefrained from aggressively filtering the pretraining data. Recall that leaving pretraining data unfiltered may\\nenable base models tuned to perform well on more downstream tasks (including hate speech detection),\\nand it carries less risk of accidentally filtering out some demographic groups. We observe that models\\ntrained from less aggressively filtered pretraining data also required fewer examples to achieve reasonable\\nsafety-alignment.', start_char_idx=298, end_char_idx=830, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-23', obj=None),\n",
       " 'fe82ffc3-de7f-4e2c-a95a-7a66fbdffd13': IndexNode(id_='fe82ffc3-de7f-4e2c-a95a-7a66fbdffd13', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-23', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='468997e4aae2ce47b6ec4eee9120e9a6b3fc6ae19c930f73cc02c5fe63b36396'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='f6166240-7aeb-4bba-bc28-45effcca9730', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='02768e38d596aecf44932fe44c8c06a058b60a1600b17050f0b9b7dfaeb2b117'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='5616bc86-f298-48d8-a2f7-3a7a3d2d7a9f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='14ed410af5dad2eb0f2782f56c1c659419cebb3cc34af9d2f2e60f89d0b04022')}, text='Recall that leaving pretraining data unfiltered may\\nenable base models tuned to perform well on more downstream tasks (including hate speech detection),\\nand it carries less risk of accidentally filtering out some demographic groups. We observe that models\\ntrained from less aggressively filtered pretraining data also required fewer examples to achieve reasonable\\nsafety-alignment. Wereiteratethatthismotivatedchoicedoesimplythatadditionalsafetymitigationsshould\\nbe applied before deployment of base Llama 2 models.\\n22\\n\\nTruthfulQA ↑ToxiGen ↓\\nMPT7B 29.13 22.', start_char_idx=449, end_char_idx=1006, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-23', obj=None),\n",
       " '5616bc86-f298-48d8-a2f7-3a7a3d2d7a9f': IndexNode(id_='5616bc86-f298-48d8-a2f7-3a7a3d2d7a9f', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-23', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='468997e4aae2ce47b6ec4eee9120e9a6b3fc6ae19c930f73cc02c5fe63b36396'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='fe82ffc3-de7f-4e2c-a95a-7a66fbdffd13', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1b65f349333d77048e74e3dd6da033ce57a9f2921111800ba770083bd8c8b29d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='5a5fb66e-623c-4aa9-857d-e3aba25bc425', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e5fac231081c8e2ab81ca3a3a56b5def0aed795d85c89023fe12be84382fe4ee')}, text='We observe that models\\ntrained from less aggressively filtered pretraining data also required fewer examples to achieve reasonable\\nsafety-alignment. Wereiteratethatthismotivatedchoicedoesimplythatadditionalsafetymitigationsshould\\nbe applied before deployment of base Llama 2 models.\\n22\\n\\nTruthfulQA ↑ToxiGen ↓\\nMPT7B 29.13 22.32\\n30B 35.25 22.61\\nFalcon7B 25.95 14.53\\n40B 40.39 23.', start_char_idx=682, end_char_idx=1059, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-23', obj=None),\n",
       " '5a5fb66e-623c-4aa9-857d-e3aba25bc425': IndexNode(id_='5a5fb66e-623c-4aa9-857d-e3aba25bc425', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-23', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='468997e4aae2ce47b6ec4eee9120e9a6b3fc6ae19c930f73cc02c5fe63b36396'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='5616bc86-f298-48d8-a2f7-3a7a3d2d7a9f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='14ed410af5dad2eb0f2782f56c1c659419cebb3cc34af9d2f2e60f89d0b04022'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='c4931121-bf9a-4f5c-9a10-2dae9959ecb7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='fb91da345a3fec0e5219e349d6a037878dddf7bb42068adad8b0efdddae793e3')}, text='Wereiteratethatthismotivatedchoicedoesimplythatadditionalsafetymitigationsshould\\nbe applied before deployment of base Llama 2 models.\\n22\\n\\nTruthfulQA ↑ToxiGen ↓\\nMPT7B 29.13 22.32\\n30B 35.25 22.61\\nFalcon7B 25.95 14.53\\n40B 40.39 23.44\\nLlama 17B 27.42 23.00\\n13B 41.74 23.08\\n33B 44.', start_char_idx=831, end_char_idx=1107, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-23', obj=None),\n",
       " 'c4931121-bf9a-4f5c-9a10-2dae9959ecb7': IndexNode(id_='c4931121-bf9a-4f5c-9a10-2dae9959ecb7', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-23', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='468997e4aae2ce47b6ec4eee9120e9a6b3fc6ae19c930f73cc02c5fe63b36396'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='5a5fb66e-623c-4aa9-857d-e3aba25bc425', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e5fac231081c8e2ab81ca3a3a56b5def0aed795d85c89023fe12be84382fe4ee'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='31451dbd-18e1-4355-8a10-94f0e643a3e6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4d4f2218057e6de3026294073c58332707ed31f3e1feea0d0348abebd7957e3d')}, text='22\\n\\nTruthfulQA ↑ToxiGen ↓\\nMPT7B 29.13 22.32\\n30B 35.25 22.61\\nFalcon7B 25.95 14.53\\n40B 40.39 23.44\\nLlama 17B 27.42 23.00\\n13B 41.74 23.08\\n33B 44.19 22.57\\n65B 48.71 21.77\\nLlama 27B 33.29 21.25\\n13B 41.', start_char_idx=965, end_char_idx=1161, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-23', obj=None),\n",
       " '31451dbd-18e1-4355-8a10-94f0e643a3e6': IndexNode(id_='31451dbd-18e1-4355-8a10-94f0e643a3e6', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-23', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='468997e4aae2ce47b6ec4eee9120e9a6b3fc6ae19c930f73cc02c5fe63b36396'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='c4931121-bf9a-4f5c-9a10-2dae9959ecb7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='fb91da345a3fec0e5219e349d6a037878dddf7bb42068adad8b0efdddae793e3'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='a3bc7c8e-da10-4e75-8284-683c413d88c8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='115b72b4495ae41fd40e5e033cc23e1d20c58461024359f3a751560a84f54a32')}, text='25 22.61\\nFalcon7B 25.95 14.53\\n40B 40.39 23.44\\nLlama 17B 27.42 23.00\\n13B 41.74 23.08\\n33B 44.19 22.57\\n65B 48.71 21.77\\nLlama 27B 33.29 21.25\\n13B 41.86 26.10\\n34B 43.45 21.19\\n70B 50.18 24.', start_char_idx=1016, end_char_idx=1199, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-23', obj=None),\n",
       " 'a3bc7c8e-da10-4e75-8284-683c413d88c8': IndexNode(id_='a3bc7c8e-da10-4e75-8284-683c413d88c8', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-23', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='468997e4aae2ce47b6ec4eee9120e9a6b3fc6ae19c930f73cc02c5fe63b36396'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='31451dbd-18e1-4355-8a10-94f0e643a3e6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4d4f2218057e6de3026294073c58332707ed31f3e1feea0d0348abebd7957e3d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='5798aae6-dfc1-43b5-b2ef-1b3573a7731f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='54629976a57e59aeed69e3b3c72489803865b2f0d744863f6c6bad5fcb08bfa5')}, text='39 23.44\\nLlama 17B 27.42 23.00\\n13B 41.74 23.08\\n33B 44.19 22.57\\n65B 48.71 21.77\\nLlama 27B 33.29 21.25\\n13B 41.86 26.10\\n34B 43.45 21.19\\n70B 50.18 24.60\\nTable 11: Evaluation of pretrained LLMs on automatic safety benchmarks.', start_char_idx=1053, end_char_idx=1273, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-23', obj=None),\n",
       " '5798aae6-dfc1-43b5-b2ef-1b3573a7731f': IndexNode(id_='5798aae6-dfc1-43b5-b2ef-1b3573a7731f', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-23', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='468997e4aae2ce47b6ec4eee9120e9a6b3fc6ae19c930f73cc02c5fe63b36396'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='a3bc7c8e-da10-4e75-8284-683c413d88c8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='115b72b4495ae41fd40e5e033cc23e1d20c58461024359f3a751560a84f54a32'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='35997c76-4cc0-4b4c-aaac-2da8288d6541', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f1c6018d31bc16d99e4a624307182c7019d798167086ee53a627f8d4369e15a3')}, text='00\\n13B 41.74 23.08\\n33B 44.19 22.57\\n65B 48.71 21.77\\nLlama 27B 33.29 21.25\\n13B 41.86 26.10\\n34B 43.45 21.19\\n70B 50.18 24.60\\nTable 11: Evaluation of pretrained LLMs on automatic safety benchmarks. For TruthfulQA, we present the\\npercentageofgenerationsthatarebothtruthfulandinformative(thehigherthebetter).', start_char_idx=1081, end_char_idx=1382, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-23', obj=None),\n",
       " '35997c76-4cc0-4b4c-aaac-2da8288d6541': IndexNode(id_='35997c76-4cc0-4b4c-aaac-2da8288d6541', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-23', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='468997e4aae2ce47b6ec4eee9120e9a6b3fc6ae19c930f73cc02c5fe63b36396'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='5798aae6-dfc1-43b5-b2ef-1b3573a7731f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='54629976a57e59aeed69e3b3c72489803865b2f0d744863f6c6bad5fcb08bfa5'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='86286ced-3c8f-427e-a9da-fe6c29a8f086', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8b56385eab529ec914aeb0428330377fe128750531c9c5594e18391450581920')}, text='71 21.77\\nLlama 27B 33.29 21.25\\n13B 41.86 26.10\\n34B 43.45 21.19\\n70B 50.18 24.60\\nTable 11: Evaluation of pretrained LLMs on automatic safety benchmarks. For TruthfulQA, we present the\\npercentageofgenerationsthatarebothtruthfulandinformative(thehigherthebetter). ForToxiGen,we\\npresent the percentage of toxic generations (the smaller, the better).', start_char_idx=1123, end_char_idx=1467, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-23', obj=None),\n",
       " '86286ced-3c8f-427e-a9da-fe6c29a8f086': IndexNode(id_='86286ced-3c8f-427e-a9da-fe6c29a8f086', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-23', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='468997e4aae2ce47b6ec4eee9120e9a6b3fc6ae19c930f73cc02c5fe63b36396'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='35997c76-4cc0-4b4c-aaac-2da8288d6541', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f1c6018d31bc16d99e4a624307182c7019d798167086ee53a627f8d4369e15a3'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='b83a79c5-1d30-4fec-9038-f3cec94b573b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='194ffb9fba5c5ac8c8957d4bd79dfb21816c95e5321568af65519f079b3d6682')}, text='25\\n13B 41.86 26.10\\n34B 43.45 21.19\\n70B 50.18 24.60\\nTable 11: Evaluation of pretrained LLMs on automatic safety benchmarks. For TruthfulQA, we present the\\npercentageofgenerationsthatarebothtruthfulandinformative(thehigherthebetter). ForToxiGen,we\\npresent the percentage of toxic generations (the smaller, the better).\\nBenchmarks give a summary view ofmodel capabilities and behaviors that allow us to understand general\\npatternsinthemodel,buttheydonotprovideafullycomprehensiveviewoftheimpactthemodelmayhave\\nonpeopleorreal-worldoutcomes;thatwouldrequirestudyofend-to-endproductdeployments.', start_char_idx=1151, end_char_idx=1739, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-23', obj=None),\n",
       " 'b83a79c5-1d30-4fec-9038-f3cec94b573b': IndexNode(id_='b83a79c5-1d30-4fec-9038-f3cec94b573b', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-23', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='468997e4aae2ce47b6ec4eee9120e9a6b3fc6ae19c930f73cc02c5fe63b36396'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='86286ced-3c8f-427e-a9da-fe6c29a8f086', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8b56385eab529ec914aeb0428330377fe128750531c9c5594e18391450581920'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='98af1911-10c4-4e3e-bfb1-de1fbc279dc5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1c0bf6ab14c6c5d636eb52c2fa641bd3277ecdf44c257b09ac60cbf5c55abaa1')}, text='ForToxiGen,we\\npresent the percentage of toxic generations (the smaller, the better).\\nBenchmarks give a summary view ofmodel capabilities and behaviors that allow us to understand general\\npatternsinthemodel,buttheydonotprovideafullycomprehensiveviewoftheimpactthemodelmayhave\\nonpeopleorreal-worldoutcomes;thatwouldrequirestudyofend-to-endproductdeployments. Further\\ntesting and mitigation should be done to understand bias and other social issues for the specific context\\nin which a system may be deployed.', start_char_idx=1383, end_char_idx=1888, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-23', obj=None),\n",
       " '98af1911-10c4-4e3e-bfb1-de1fbc279dc5': IndexNode(id_='98af1911-10c4-4e3e-bfb1-de1fbc279dc5', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-23', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='468997e4aae2ce47b6ec4eee9120e9a6b3fc6ae19c930f73cc02c5fe63b36396'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='b83a79c5-1d30-4fec-9038-f3cec94b573b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='194ffb9fba5c5ac8c8957d4bd79dfb21816c95e5321568af65519f079b3d6682'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='6d91e631-669e-4dec-b813-54f71c34321d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c1f2b755fcf6ae258b4f5dde824ca7236e47b0dcd8793312ce1636906308c574')}, text='Benchmarks give a summary view ofmodel capabilities and behaviors that allow us to understand general\\npatternsinthemodel,buttheydonotprovideafullycomprehensiveviewoftheimpactthemodelmayhave\\nonpeopleorreal-worldoutcomes;thatwouldrequirestudyofend-to-endproductdeployments. Further\\ntesting and mitigation should be done to understand bias and other social issues for the specific context\\nin which a system may be deployed. For this, it may be necessary to test beyond the groups available in\\ntheBOLDdataset(race,religion,andgender).', start_char_idx=1468, end_char_idx=1998, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-23', obj=None),\n",
       " '6d91e631-669e-4dec-b813-54f71c34321d': IndexNode(id_='6d91e631-669e-4dec-b813-54f71c34321d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-23', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='468997e4aae2ce47b6ec4eee9120e9a6b3fc6ae19c930f73cc02c5fe63b36396'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='98af1911-10c4-4e3e-bfb1-de1fbc279dc5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1c0bf6ab14c6c5d636eb52c2fa641bd3277ecdf44c257b09ac60cbf5c55abaa1'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='d7343f28-8708-42d1-a789-ec9fa1c741d1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3509a3bc0be63bc84cd9bab956fc816c7866b1c7dce83bdcbb55523a0f6f620f')}, text='Further\\ntesting and mitigation should be done to understand bias and other social issues for the specific context\\nin which a system may be deployed. For this, it may be necessary to test beyond the groups available in\\ntheBOLDdataset(race,religion,andgender). AsLLMsareintegratedanddeployed,welookforwardto\\ncontinuing research that will amplify their potential for positive impact on these important social issues.', start_char_idx=1740, end_char_idx=2153, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-23', obj=None),\n",
       " 'd7343f28-8708-42d1-a789-ec9fa1c741d1': IndexNode(id_='d7343f28-8708-42d1-a789-ec9fa1c741d1', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-23', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='468997e4aae2ce47b6ec4eee9120e9a6b3fc6ae19c930f73cc02c5fe63b36396'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='6d91e631-669e-4dec-b813-54f71c34321d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c1f2b755fcf6ae258b4f5dde824ca7236e47b0dcd8793312ce1636906308c574'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='1d970a3e-e115-4978-b45b-406c3b7625c2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8a013d8b0f1298b11de37c00bdf9068b808a9f0a3be6e60f2ed714b906891114')}, text='Further\\ntesting and mitigation should be done to understand bias and other social issues for the specific context\\nin which a system may be deployed. For this, it may be necessary to test beyond the groups available in\\ntheBOLDdataset(race,religion,andgender). AsLLMsareintegratedanddeployed,welookforwardto\\ncontinuing research that will amplify their potential for positive impact on these important social issues.\\n4.2 Safety Fine-Tuning\\nIn this section, we describe our approach to safety fine-tuning, including safety categories, annotation\\nguidelines,andthetechniquesweusetomitigatesafetyrisks.', start_char_idx=1740, end_char_idx=2336, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-23', obj=None),\n",
       " '1d970a3e-e115-4978-b45b-406c3b7625c2': IndexNode(id_='1d970a3e-e115-4978-b45b-406c3b7625c2', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-23', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='468997e4aae2ce47b6ec4eee9120e9a6b3fc6ae19c930f73cc02c5fe63b36396'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='d7343f28-8708-42d1-a789-ec9fa1c741d1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3509a3bc0be63bc84cd9bab956fc816c7866b1c7dce83bdcbb55523a0f6f620f'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='11869621-16c5-4b54-9d5c-97a904a69075', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='19ed533e5ff616e82f44b139cf8afb4e520e230352a8afddf3fc05134f4b8b54')}, text='AsLLMsareintegratedanddeployed,welookforwardto\\ncontinuing research that will amplify their potential for positive impact on these important social issues.\\n4.2 Safety Fine-Tuning\\nIn this section, we describe our approach to safety fine-tuning, including safety categories, annotation\\nguidelines,andthetechniquesweusetomitigatesafetyrisks. Weemployaprocesssimilartothegeneral\\nfine-tuning methods as described in Section 3, with some notable differences related to safety concerns.', start_char_idx=1999, end_char_idx=2477, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-23', obj=None),\n",
       " '11869621-16c5-4b54-9d5c-97a904a69075': IndexNode(id_='11869621-16c5-4b54-9d5c-97a904a69075', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-23', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='468997e4aae2ce47b6ec4eee9120e9a6b3fc6ae19c930f73cc02c5fe63b36396'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='1d970a3e-e115-4978-b45b-406c3b7625c2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8a013d8b0f1298b11de37c00bdf9068b808a9f0a3be6e60f2ed714b906891114'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='d2c937f2-4207-4f30-a2d6-f82f0ecfd051', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ddbc22969a2dbfdb7e625a6f0e1984be758f82e1b4cb3be77b34adcf52f14ccd')}, text='4.2 Safety Fine-Tuning\\nIn this section, we describe our approach to safety fine-tuning, including safety categories, annotation\\nguidelines,andthetechniquesweusetomitigatesafetyrisks. Weemployaprocesssimilartothegeneral\\nfine-tuning methods as described in Section 3, with some notable differences related to safety concerns.\\nSpecifically, we use the following techniques in safety fine-tuning:\\n1.Supervised Safety Fine-Tuning : We initialize by gathering adversarial prompts and safe demonstra-\\ntions that are then included in the general supervised fine-tuning process (Section 3.1).', start_char_idx=2154, end_char_idx=2737, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-23', obj=None),\n",
       " 'd2c937f2-4207-4f30-a2d6-f82f0ecfd051': IndexNode(id_='d2c937f2-4207-4f30-a2d6-f82f0ecfd051', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-23', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='468997e4aae2ce47b6ec4eee9120e9a6b3fc6ae19c930f73cc02c5fe63b36396'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='11869621-16c5-4b54-9d5c-97a904a69075', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='19ed533e5ff616e82f44b139cf8afb4e520e230352a8afddf3fc05134f4b8b54'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='f8af00f4-94c0-4d8d-a002-ec778f31b107', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='fdb127a519341619afeec238bc5ebaf757d74f8ab4b38f2fa5b9775ac0e21f33')}, text='Weemployaprocesssimilartothegeneral\\nfine-tuning methods as described in Section 3, with some notable differences related to safety concerns.\\nSpecifically, we use the following techniques in safety fine-tuning:\\n1.Supervised Safety Fine-Tuning : We initialize by gathering adversarial prompts and safe demonstra-\\ntions that are then included in the general supervised fine-tuning process (Section 3.1). This teaches\\nthemodeltoalignwithoursafetyguidelinesevenbeforeRLHF,andthuslaysthefoundationfor\\nhigh-quality human preference data annotation.', start_char_idx=2337, end_char_idx=2878, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-23', obj=None),\n",
       " 'f8af00f4-94c0-4d8d-a002-ec778f31b107': IndexNode(id_='f8af00f4-94c0-4d8d-a002-ec778f31b107', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-23', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='468997e4aae2ce47b6ec4eee9120e9a6b3fc6ae19c930f73cc02c5fe63b36396'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='d2c937f2-4207-4f30-a2d6-f82f0ecfd051', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ddbc22969a2dbfdb7e625a6f0e1984be758f82e1b4cb3be77b34adcf52f14ccd'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='91d0eada-3fe1-47f6-9466-7bb2872d8e19', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2841b1274cccf6b54dffe762e1145f6d0b73bd1f68744c13f20f5f9b2dc88f23')}, text='Specifically, we use the following techniques in safety fine-tuning:\\n1.Supervised Safety Fine-Tuning : We initialize by gathering adversarial prompts and safe demonstra-\\ntions that are then included in the general supervised fine-tuning process (Section 3.1). This teaches\\nthemodeltoalignwithoursafetyguidelinesevenbeforeRLHF,andthuslaysthefoundationfor\\nhigh-quality human preference data annotation.\\n2.Safety RLHF : Subsequently, we integrate safety in the general RLHF pipeline described in Sec-\\ntion 3.2.2.', start_char_idx=2478, end_char_idx=2987, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-23', obj=None),\n",
       " '91d0eada-3fe1-47f6-9466-7bb2872d8e19': IndexNode(id_='91d0eada-3fe1-47f6-9466-7bb2872d8e19', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-23', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='468997e4aae2ce47b6ec4eee9120e9a6b3fc6ae19c930f73cc02c5fe63b36396'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='f8af00f4-94c0-4d8d-a002-ec778f31b107', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='fdb127a519341619afeec238bc5ebaf757d74f8ab4b38f2fa5b9775ac0e21f33'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='ec2ead60-8e4b-4f76-ac1b-0cf98a471b2a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='30d315a4988027a2f752d4eb81bf38f7868d4591819bbdb7fc34c5abc4d40627')}, text='This teaches\\nthemodeltoalignwithoursafetyguidelinesevenbeforeRLHF,andthuslaysthefoundationfor\\nhigh-quality human preference data annotation.\\n2.Safety RLHF : Subsequently, we integrate safety in the general RLHF pipeline described in Sec-\\ntion 3.2.2. This includes training a safety-specific reward model and gathering more challenging\\nadversarial prompts for rejection sampling style fine-tuning and PPO optimization.\\n3.SafetyContextDistillation : Finally,werefineourRLHFpipelinewithcontextdistillation(Askell\\netal.,2021b).', start_char_idx=2738, end_char_idx=3261, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-23', obj=None),\n",
       " 'ec2ead60-8e4b-4f76-ac1b-0cf98a471b2a': IndexNode(id_='ec2ead60-8e4b-4f76-ac1b-0cf98a471b2a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-23', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='468997e4aae2ce47b6ec4eee9120e9a6b3fc6ae19c930f73cc02c5fe63b36396'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='91d0eada-3fe1-47f6-9466-7bb2872d8e19', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2841b1274cccf6b54dffe762e1145f6d0b73bd1f68744c13f20f5f9b2dc88f23'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='1c75c8ee-5518-4b0a-817e-cdbfb0c3b196', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6a2550a566de4100415718754c2b9e9b2622256670e2f59d90878a7e55406c0e')}, text='2.Safety RLHF : Subsequently, we integrate safety in the general RLHF pipeline described in Sec-\\ntion 3.2.2. This includes training a safety-specific reward model and gathering more challenging\\nadversarial prompts for rejection sampling style fine-tuning and PPO optimization.\\n3.SafetyContextDistillation : Finally,werefineourRLHFpipelinewithcontextdistillation(Askell\\netal.,2021b). Thisinvolvesgeneratingsafermodelresponsesbyprefixingapromptwithasafety\\npreprompt, e.g., “You are a safe and responsible assistant,” and then fine-tuning the model on the safer\\nresponses without the preprompt, which essentially distillsthe safety preprompt (context) into the\\nmodel.', start_char_idx=2879, end_char_idx=3543, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-23', obj=None),\n",
       " '1c75c8ee-5518-4b0a-817e-cdbfb0c3b196': IndexNode(id_='1c75c8ee-5518-4b0a-817e-cdbfb0c3b196', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-23', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='468997e4aae2ce47b6ec4eee9120e9a6b3fc6ae19c930f73cc02c5fe63b36396'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='ec2ead60-8e4b-4f76-ac1b-0cf98a471b2a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='30d315a4988027a2f752d4eb81bf38f7868d4591819bbdb7fc34c5abc4d40627'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='387d347e-257e-4ed6-8896-a8a9213f2d2c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2e9f0a2fd62d141e265ffc3af19a67c0f2c3ac8bfe1b5efc30edb572fa2b65b6')}, text='Thisinvolvesgeneratingsafermodelresponsesbyprefixingapromptwithasafety\\npreprompt, e.g., “You are a safe and responsible assistant,” and then fine-tuning the model on the safer\\nresponses without the preprompt, which essentially distillsthe safety preprompt (context) into the\\nmodel. Weuseatargetedapproachthatallowsoursafetyrewardmodeltochoosewhethertouse\\ncontext distillation for each sample.', start_char_idx=3262, end_char_idx=3654, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-23', obj=None),\n",
       " '387d347e-257e-4ed6-8896-a8a9213f2d2c': IndexNode(id_='387d347e-257e-4ed6-8896-a8a9213f2d2c', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-23', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='468997e4aae2ce47b6ec4eee9120e9a6b3fc6ae19c930f73cc02c5fe63b36396'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='1c75c8ee-5518-4b0a-817e-cdbfb0c3b196', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6a2550a566de4100415718754c2b9e9b2622256670e2f59d90878a7e55406c0e')}, text='Thisinvolvesgeneratingsafermodelresponsesbyprefixingapromptwithasafety\\npreprompt, e.g., “You are a safe and responsible assistant,” and then fine-tuning the model on the safer\\nresponses without the preprompt, which essentially distillsthe safety preprompt (context) into the\\nmodel. Weuseatargetedapproachthatallowsoursafetyrewardmodeltochoosewhethertouse\\ncontext distillation for each sample.\\n4.2.1 Safety Categories and Annotation Guidelines\\nBased on limitations of LLMs known from prior work, we design instructions for our annotation team to\\ncreateadversarialpromptsalongtwodimensions: a riskcategory ,orpotentialtopicaboutwhichtheLLM\\ncouldproduceunsafecontent;andan attackvector ,orquestionstyletocoverdifferentvarietiesofprompts\\nthat could elicit bad model behaviors.', start_char_idx=3262, end_char_idx=4034, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-23', obj=None),\n",
       " '2c9dccc8-7400-4dac-84fa-c485ad86f095': IndexNode(id_='2c9dccc8-7400-4dac-84fa-c485ad86f095', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-23', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='468997e4aae2ce47b6ec4eee9120e9a6b3fc6ae19c930f73cc02c5fe63b36396'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='2f019f44-0c85-4d67-901f-5ebfc00990d0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6668b5e22b1bdbfff6a67156e19ba4381bbdb7f5e71d7c5dfa62e447234bdeb9')}, text='In Appendix A.4.7, we present bias metrics, such as how the sentiment of model generations varies with\\ndemographic attributes. We note an increase in positive sentiment overall for many of the groups using\\nBOLDprompts. MoredetailedresultssplitbydifferentdemographicgroupscanbefoundinAppendixA.4.8.\\nLlama 2 doesnotoutperformothermodelsontoxicitymetrics,andwespeculatethatthismaybebecausewe\\nrefrained from aggressively filtering the pretraining data. Recall that leaving pretraining data unfiltered may\\nenable base models tuned to perform well on more downstream tasks (including hate speech detection),\\nand it carries less risk of accidentally filtering out some demographic groups. We observe that models\\ntrained from less aggressively filtered pretraining data also required fewer examples to achieve reasonable\\nsafety-alignment. Wereiteratethatthismotivatedchoicedoesimplythatadditionalsafetymitigationsshould\\nbe applied before deployment of base Llama 2 models.', start_char_idx=0, end_char_idx=964, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-23', obj=None),\n",
       " '2f019f44-0c85-4d67-901f-5ebfc00990d0': IndexNode(id_='2f019f44-0c85-4d67-901f-5ebfc00990d0', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-23', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='468997e4aae2ce47b6ec4eee9120e9a6b3fc6ae19c930f73cc02c5fe63b36396'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='2c9dccc8-7400-4dac-84fa-c485ad86f095', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0885b076bfbf108d0abae78af7c38b5e01c904d422997a04f5e27c730a6cfd0d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='ab7563e2-cb35-4838-bd39-ec80ffe3773c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='666605bf875dad0a7c5bafb132be7ab614260545abf4a9e49b168d870be3d0fa')}, text='We observe that models\\ntrained from less aggressively filtered pretraining data also required fewer examples to achieve reasonable\\nsafety-alignment. Wereiteratethatthismotivatedchoicedoesimplythatadditionalsafetymitigationsshould\\nbe applied before deployment of base Llama 2 models.\\n22\\n\\nTruthfulQA ↑ToxiGen ↓\\nMPT7B 29.13 22.32\\n30B 35.25 22.61\\nFalcon7B 25.95 14.53\\n40B 40.39 23.44\\nLlama 17B 27.42 23.00\\n13B 41.74 23.08\\n33B 44.19 22.57\\n65B 48.71 21.77\\nLlama 27B 33.29 21.25\\n13B 41.86 26.10\\n34B 43.45 21.19\\n70B 50.18 24.60\\nTable 11: Evaluation of pretrained LLMs on automatic safety benchmarks.', start_char_idx=682, end_char_idx=1273, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-23', obj=None),\n",
       " 'ab7563e2-cb35-4838-bd39-ec80ffe3773c': IndexNode(id_='ab7563e2-cb35-4838-bd39-ec80ffe3773c', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-23', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='468997e4aae2ce47b6ec4eee9120e9a6b3fc6ae19c930f73cc02c5fe63b36396'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='2f019f44-0c85-4d67-901f-5ebfc00990d0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6668b5e22b1bdbfff6a67156e19ba4381bbdb7f5e71d7c5dfa62e447234bdeb9'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='95c09c90-1d5a-4a0c-8aa7-c722ffd856c4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f5073b96cc67e8093b8c001b807f81e6029f526bdf82d08c751748ec9f541d7a')}, text='For TruthfulQA, we present the\\npercentageofgenerationsthatarebothtruthfulandinformative(thehigherthebetter). ForToxiGen,we\\npresent the percentage of toxic generations (the smaller, the better).\\nBenchmarks give a summary view ofmodel capabilities and behaviors that allow us to understand general\\npatternsinthemodel,buttheydonotprovideafullycomprehensiveviewoftheimpactthemodelmayhave\\nonpeopleorreal-worldoutcomes;thatwouldrequirestudyofend-to-endproductdeployments. Further\\ntesting and mitigation should be done to understand bias and other social issues for the specific context\\nin which a system may be deployed. For this, it may be necessary to test beyond the groups available in\\ntheBOLDdataset(race,religion,andgender). AsLLMsareintegratedanddeployed,welookforwardto\\ncontinuing research that will amplify their potential for positive impact on these important social issues.\\n4.2 Safety Fine-Tuning\\nIn this section, we describe our approach to safety fine-tuning, including safety categories, annotation\\nguidelines,andthetechniquesweusetomitigatesafetyrisks.', start_char_idx=1274, end_char_idx=2336, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-23', obj=None),\n",
       " '95c09c90-1d5a-4a0c-8aa7-c722ffd856c4': IndexNode(id_='95c09c90-1d5a-4a0c-8aa7-c722ffd856c4', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-23', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='468997e4aae2ce47b6ec4eee9120e9a6b3fc6ae19c930f73cc02c5fe63b36396'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='ab7563e2-cb35-4838-bd39-ec80ffe3773c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='666605bf875dad0a7c5bafb132be7ab614260545abf4a9e49b168d870be3d0fa'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='66fd8d82-ada8-4e80-a946-f901fb98ee4d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='24de2862b69ee37d5a0088ab2d4a3d3968cca2e832ac6a566270469d85dd8a9b')}, text='AsLLMsareintegratedanddeployed,welookforwardto\\ncontinuing research that will amplify their potential for positive impact on these important social issues.\\n4.2 Safety Fine-Tuning\\nIn this section, we describe our approach to safety fine-tuning, including safety categories, annotation\\nguidelines,andthetechniquesweusetomitigatesafetyrisks. Weemployaprocesssimilartothegeneral\\nfine-tuning methods as described in Section 3, with some notable differences related to safety concerns.\\nSpecifically, we use the following techniques in safety fine-tuning:\\n1.Supervised Safety Fine-Tuning : We initialize by gathering adversarial prompts and safe demonstra-\\ntions that are then included in the general supervised fine-tuning process (Section 3.1). This teaches\\nthemodeltoalignwithoursafetyguidelinesevenbeforeRLHF,andthuslaysthefoundationfor\\nhigh-quality human preference data annotation.\\n2.Safety RLHF : Subsequently, we integrate safety in the general RLHF pipeline described in Sec-\\ntion 3.2.2. This includes training a safety-specific reward model and gathering more challenging\\nadversarial prompts for rejection sampling style fine-tuning and PPO optimization.', start_char_idx=1999, end_char_idx=3155, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-23', obj=None),\n",
       " '66fd8d82-ada8-4e80-a946-f901fb98ee4d': IndexNode(id_='66fd8d82-ada8-4e80-a946-f901fb98ee4d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-23', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='468997e4aae2ce47b6ec4eee9120e9a6b3fc6ae19c930f73cc02c5fe63b36396'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='95c09c90-1d5a-4a0c-8aa7-c722ffd856c4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f5073b96cc67e8093b8c001b807f81e6029f526bdf82d08c751748ec9f541d7a'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='edfd859d-fa6a-4b6a-8c72-2b484012f554', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2e9f0a2fd62d141e265ffc3af19a67c0f2c3ac8bfe1b5efc30edb572fa2b65b6')}, text='This teaches\\nthemodeltoalignwithoursafetyguidelinesevenbeforeRLHF,andthuslaysthefoundationfor\\nhigh-quality human preference data annotation.\\n2.Safety RLHF : Subsequently, we integrate safety in the general RLHF pipeline described in Sec-\\ntion 3.2.2. This includes training a safety-specific reward model and gathering more challenging\\nadversarial prompts for rejection sampling style fine-tuning and PPO optimization.\\n3.SafetyContextDistillation : Finally,werefineourRLHFpipelinewithcontextdistillation(Askell\\netal.,2021b). Thisinvolvesgeneratingsafermodelresponsesbyprefixingapromptwithasafety\\npreprompt, e.g., “You are a safe and responsible assistant,” and then fine-tuning the model on the safer\\nresponses without the preprompt, which essentially distillsthe safety preprompt (context) into the\\nmodel. Weuseatargetedapproachthatallowsoursafetyrewardmodeltochoosewhethertouse\\ncontext distillation for each sample.', start_char_idx=2738, end_char_idx=3654, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-23', obj=None),\n",
       " 'edfd859d-fa6a-4b6a-8c72-2b484012f554': IndexNode(id_='edfd859d-fa6a-4b6a-8c72-2b484012f554', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-23', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='468997e4aae2ce47b6ec4eee9120e9a6b3fc6ae19c930f73cc02c5fe63b36396'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='66fd8d82-ada8-4e80-a946-f901fb98ee4d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='24de2862b69ee37d5a0088ab2d4a3d3968cca2e832ac6a566270469d85dd8a9b')}, text='Thisinvolvesgeneratingsafermodelresponsesbyprefixingapromptwithasafety\\npreprompt, e.g., “You are a safe and responsible assistant,” and then fine-tuning the model on the safer\\nresponses without the preprompt, which essentially distillsthe safety preprompt (context) into the\\nmodel. Weuseatargetedapproachthatallowsoursafetyrewardmodeltochoosewhethertouse\\ncontext distillation for each sample.\\n4.2.1 Safety Categories and Annotation Guidelines\\nBased on limitations of LLMs known from prior work, we design instructions for our annotation team to\\ncreateadversarialpromptsalongtwodimensions: a riskcategory ,orpotentialtopicaboutwhichtheLLM\\ncouldproduceunsafecontent;andan attackvector ,orquestionstyletocoverdifferentvarietiesofprompts\\nthat could elicit bad model behaviors.', start_char_idx=3262, end_char_idx=4034, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-23', obj=None),\n",
       " '321f22b3-b9b4-434b-8ea3-368828fc9a87': IndexNode(id_='321f22b3-b9b4-434b-8ea3-368828fc9a87', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-23', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='468997e4aae2ce47b6ec4eee9120e9a6b3fc6ae19c930f73cc02c5fe63b36396'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='c3123fea-d9ce-4fa2-a774-e7e0128dbbff', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3e88f905f57070725a034998ad0e3bc64fab0c3241388eedc8c5e8da47d0da13')}, text='In Appendix A.4.7, we present bias metrics, such as how the sentiment of model generations varies with\\ndemographic attributes. We note an increase in positive sentiment overall for many of the groups using\\nBOLDprompts. MoredetailedresultssplitbydifferentdemographicgroupscanbefoundinAppendixA.4.8.\\nLlama 2 doesnotoutperformothermodelsontoxicitymetrics,andwespeculatethatthismaybebecausewe\\nrefrained from aggressively filtering the pretraining data. Recall that leaving pretraining data unfiltered may\\nenable base models tuned to perform well on more downstream tasks (including hate speech detection),\\nand it carries less risk of accidentally filtering out some demographic groups. We observe that models\\ntrained from less aggressively filtered pretraining data also required fewer examples to achieve reasonable\\nsafety-alignment. Wereiteratethatthismotivatedchoicedoesimplythatadditionalsafetymitigationsshould\\nbe applied before deployment of base Llama 2 models.\\n22\\n\\nTruthfulQA ↑ToxiGen ↓\\nMPT7B 29.13 22.32\\n30B 35.25 22.61\\nFalcon7B 25.95 14.53\\n40B 40.39 23.44\\nLlama 17B 27.42 23.00\\n13B 41.74 23.08\\n33B 44.19 22.57\\n65B 48.71 21.77\\nLlama 27B 33.29 21.25\\n13B 41.86 26.10\\n34B 43.45 21.19\\n70B 50.18 24.60\\nTable 11: Evaluation of pretrained LLMs on automatic safety benchmarks. For TruthfulQA, we present the\\npercentageofgenerationsthatarebothtruthfulandinformative(thehigherthebetter). ForToxiGen,we\\npresent the percentage of toxic generations (the smaller, the better).\\nBenchmarks give a summary view ofmodel capabilities and behaviors that allow us to understand general\\npatternsinthemodel,buttheydonotprovideafullycomprehensiveviewoftheimpactthemodelmayhave\\nonpeopleorreal-worldoutcomes;thatwouldrequirestudyofend-to-endproductdeployments.', start_char_idx=0, end_char_idx=1739, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-23', obj=None),\n",
       " 'c3123fea-d9ce-4fa2-a774-e7e0128dbbff': IndexNode(id_='c3123fea-d9ce-4fa2-a774-e7e0128dbbff', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-23', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='468997e4aae2ce47b6ec4eee9120e9a6b3fc6ae19c930f73cc02c5fe63b36396'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='321f22b3-b9b4-434b-8ea3-368828fc9a87', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1df0ad323c9e3c0ec74b7e165f21684b07d3cdc1b05bff4b02cb0d36f270da03'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='b0e6208e-6a3a-4eea-b24c-06f5c4795581', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2e9f0a2fd62d141e265ffc3af19a67c0f2c3ac8bfe1b5efc30edb572fa2b65b6')}, text='ForToxiGen,we\\npresent the percentage of toxic generations (the smaller, the better).\\nBenchmarks give a summary view ofmodel capabilities and behaviors that allow us to understand general\\npatternsinthemodel,buttheydonotprovideafullycomprehensiveviewoftheimpactthemodelmayhave\\nonpeopleorreal-worldoutcomes;thatwouldrequirestudyofend-to-endproductdeployments. Further\\ntesting and mitigation should be done to understand bias and other social issues for the specific context\\nin which a system may be deployed. For this, it may be necessary to test beyond the groups available in\\ntheBOLDdataset(race,religion,andgender). AsLLMsareintegratedanddeployed,welookforwardto\\ncontinuing research that will amplify their potential for positive impact on these important social issues.\\n4.2 Safety Fine-Tuning\\nIn this section, we describe our approach to safety fine-tuning, including safety categories, annotation\\nguidelines,andthetechniquesweusetomitigatesafetyrisks. Weemployaprocesssimilartothegeneral\\nfine-tuning methods as described in Section 3, with some notable differences related to safety concerns.\\nSpecifically, we use the following techniques in safety fine-tuning:\\n1.Supervised Safety Fine-Tuning : We initialize by gathering adversarial prompts and safe demonstra-\\ntions that are then included in the general supervised fine-tuning process (Section 3.1). This teaches\\nthemodeltoalignwithoursafetyguidelinesevenbeforeRLHF,andthuslaysthefoundationfor\\nhigh-quality human preference data annotation.\\n2.Safety RLHF : Subsequently, we integrate safety in the general RLHF pipeline described in Sec-\\ntion 3.2.2. This includes training a safety-specific reward model and gathering more challenging\\nadversarial prompts for rejection sampling style fine-tuning and PPO optimization.\\n3.SafetyContextDistillation : Finally,werefineourRLHFpipelinewithcontextdistillation(Askell\\netal.,2021b). Thisinvolvesgeneratingsafermodelresponsesbyprefixingapromptwithasafety\\npreprompt, e.g., “You are a safe and responsible assistant,” and then fine-tuning the model on the safer\\nresponses without the preprompt, which essentially distillsthe safety preprompt (context) into the\\nmodel.', start_char_idx=1383, end_char_idx=3543, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-23', obj=None),\n",
       " 'b0e6208e-6a3a-4eea-b24c-06f5c4795581': IndexNode(id_='b0e6208e-6a3a-4eea-b24c-06f5c4795581', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-23', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='468997e4aae2ce47b6ec4eee9120e9a6b3fc6ae19c930f73cc02c5fe63b36396'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='c3123fea-d9ce-4fa2-a774-e7e0128dbbff', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3e88f905f57070725a034998ad0e3bc64fab0c3241388eedc8c5e8da47d0da13')}, text='Thisinvolvesgeneratingsafermodelresponsesbyprefixingapromptwithasafety\\npreprompt, e.g., “You are a safe and responsible assistant,” and then fine-tuning the model on the safer\\nresponses without the preprompt, which essentially distillsthe safety preprompt (context) into the\\nmodel. Weuseatargetedapproachthatallowsoursafetyrewardmodeltochoosewhethertouse\\ncontext distillation for each sample.\\n4.2.1 Safety Categories and Annotation Guidelines\\nBased on limitations of LLMs known from prior work, we design instructions for our annotation team to\\ncreateadversarialpromptsalongtwodimensions: a riskcategory ,orpotentialtopicaboutwhichtheLLM\\ncouldproduceunsafecontent;andan attackvector ,orquestionstyletocoverdifferentvarietiesofprompts\\nthat could elicit bad model behaviors.', start_char_idx=3262, end_char_idx=4034, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-23', obj=None),\n",
       " 'node-23': IndexNode(id_='node-23', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='d03f19eb-da15-45dc-bfd4-e5d10f161250', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='231b3bd773f012c01b893ada9e009ecf25ee59934614c5a595c9bf1b3a123292'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='14c43461-1ce2-48d9-894b-52885412bb21', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6df64b4daa8925dc939ee4b1f4ca0d2851186befb4ec88382082ffe393658615'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='94ec5092-561d-4b76-b1fb-8f87e983b522', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eee6b83e89353bb78baf95336a637ab17dd2e72cbcb917cad87122df9e20aca7')}, text='In Appendix A.4.7, we present bias metrics, such as how the sentiment of model generations varies with\\ndemographic attributes. We note an increase in positive sentiment overall for many of the groups using\\nBOLDprompts. MoredetailedresultssplitbydifferentdemographicgroupscanbefoundinAppendixA.4.8.\\nLlama 2 doesnotoutperformothermodelsontoxicitymetrics,andwespeculatethatthismaybebecausewe\\nrefrained from aggressively filtering the pretraining data. Recall that leaving pretraining data unfiltered may\\nenable base models tuned to perform well on more downstream tasks (including hate speech detection),\\nand it carries less risk of accidentally filtering out some demographic groups. We observe that models\\ntrained from less aggressively filtered pretraining data also required fewer examples to achieve reasonable\\nsafety-alignment. Wereiteratethatthismotivatedchoicedoesimplythatadditionalsafetymitigationsshould\\nbe applied before deployment of base Llama 2 models.\\n22\\n\\nTruthfulQA ↑ToxiGen ↓\\nMPT7B 29.13 22.32\\n30B 35.25 22.61\\nFalcon7B 25.95 14.53\\n40B 40.39 23.44\\nLlama 17B 27.42 23.00\\n13B 41.74 23.08\\n33B 44.19 22.57\\n65B 48.71 21.77\\nLlama 27B 33.29 21.25\\n13B 41.86 26.10\\n34B 43.45 21.19\\n70B 50.18 24.60\\nTable 11: Evaluation of pretrained LLMs on automatic safety benchmarks. For TruthfulQA, we present the\\npercentageofgenerationsthatarebothtruthfulandinformative(thehigherthebetter). ForToxiGen,we\\npresent the percentage of toxic generations (the smaller, the better).\\nBenchmarks give a summary view ofmodel capabilities and behaviors that allow us to understand general\\npatternsinthemodel,buttheydonotprovideafullycomprehensiveviewoftheimpactthemodelmayhave\\nonpeopleorreal-worldoutcomes;thatwouldrequirestudyofend-to-endproductdeployments. Further\\ntesting and mitigation should be done to understand bias and other social issues for the specific context\\nin which a system may be deployed. For this, it may be necessary to test beyond the groups available in\\ntheBOLDdataset(race,religion,andgender). AsLLMsareintegratedanddeployed,welookforwardto\\ncontinuing research that will amplify their potential for positive impact on these important social issues.\\n4.2 Safety Fine-Tuning\\nIn this section, we describe our approach to safety fine-tuning, including safety categories, annotation\\nguidelines,andthetechniquesweusetomitigatesafetyrisks. Weemployaprocesssimilartothegeneral\\nfine-tuning methods as described in Section 3, with some notable differences related to safety concerns.\\nSpecifically, we use the following techniques in safety fine-tuning:\\n1.Supervised Safety Fine-Tuning : We initialize by gathering adversarial prompts and safe demonstra-\\ntions that are then included in the general supervised fine-tuning process (Section 3.1). This teaches\\nthemodeltoalignwithoursafetyguidelinesevenbeforeRLHF,andthuslaysthefoundationfor\\nhigh-quality human preference data annotation.\\n2.Safety RLHF : Subsequently, we integrate safety in the general RLHF pipeline described in Sec-\\ntion 3.2.2. This includes training a safety-specific reward model and gathering more challenging\\nadversarial prompts for rejection sampling style fine-tuning and PPO optimization.\\n3.SafetyContextDistillation : Finally,werefineourRLHFpipelinewithcontextdistillation(Askell\\netal.,2021b). Thisinvolvesgeneratingsafermodelresponsesbyprefixingapromptwithasafety\\npreprompt, e.g., “You are a safe and responsible assistant,” and then fine-tuning the model on the safer\\nresponses without the preprompt, which essentially distillsthe safety preprompt (context) into the\\nmodel. Weuseatargetedapproachthatallowsoursafetyrewardmodeltochoosewhethertouse\\ncontext distillation for each sample.\\n4.2.1 Safety Categories and Annotation Guidelines\\nBased on limitations of LLMs known from prior work, we design instructions for our annotation team to\\ncreateadversarialpromptsalongtwodimensions: a riskcategory ,orpotentialtopicaboutwhichtheLLM\\ncouldproduceunsafecontent;andan attackvector ,orquestionstyletocoverdifferentvarietiesofprompts\\nthat could elicit bad model behaviors.', start_char_idx=71504, end_char_idx=75538, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-23', obj=None),\n",
       " 'c35ce636-42dd-411b-8f68-8c1763e6857c': IndexNode(id_='c35ce636-42dd-411b-8f68-8c1763e6857c', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-24', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eee6b83e89353bb78baf95336a637ab17dd2e72cbcb917cad87122df9e20aca7'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='ecb082f8-4b85-48cd-8e8c-17480001375d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1abfc6c48b1e60e6f20d129aaf068631bec9916d854886ab730d35383e766b98')}, text='4.2.1 Safety Categories and Annotation Guidelines\\nBased on limitations of LLMs known from prior work, we design instructions for our annotation team to\\ncreateadversarialpromptsalongtwodimensions: a riskcategory ,orpotentialtopicaboutwhichtheLLM\\ncouldproduceunsafecontent;andan attackvector ,orquestionstyletocoverdifferentvarietiesofprompts\\nthat could elicit bad model behaviors.', start_char_idx=0, end_char_idx=379, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-24', obj=None),\n",
       " 'ecb082f8-4b85-48cd-8e8c-17480001375d': IndexNode(id_='ecb082f8-4b85-48cd-8e8c-17480001375d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-24', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eee6b83e89353bb78baf95336a637ab17dd2e72cbcb917cad87122df9e20aca7'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='c35ce636-42dd-411b-8f68-8c1763e6857c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2919a4492353316a99e00ce6c58b6ffec12636ba4cef8b1b7595b0b2f44f6827'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='b8fbe51f-0929-49d6-9052-f411369df11e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8caefbd95ca3040e618ac1fe07be48972c2f40802b8c6bb3e8fc35678267d25c')}, text='4.2.1 Safety Categories and Annotation Guidelines\\nBased on limitations of LLMs known from prior work, we design instructions for our annotation team to\\ncreateadversarialpromptsalongtwodimensions: a riskcategory ,orpotentialtopicaboutwhichtheLLM\\ncouldproduceunsafecontent;andan attackvector ,orquestionstyletocoverdifferentvarietiesofprompts\\nthat could elicit bad model behaviors.\\nTheriskcategoriesconsideredcanbebroadlydividedintothefollowingthreecategories: illicitandcriminal\\nactivities (e.g.,terrorism,theft,humantrafficking); hatefulandharmfulactivities (e.g.,defamation,self-\\nharm, eating disorders, discrimination); and unqualified advice (e.g., medical advice, financial advice, legal\\n23\\n\\nadvice).', start_char_idx=0, end_char_idx=704, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-24', obj=None),\n",
       " 'b8fbe51f-0929-49d6-9052-f411369df11e': IndexNode(id_='b8fbe51f-0929-49d6-9052-f411369df11e', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-24', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eee6b83e89353bb78baf95336a637ab17dd2e72cbcb917cad87122df9e20aca7'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='ecb082f8-4b85-48cd-8e8c-17480001375d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1abfc6c48b1e60e6f20d129aaf068631bec9916d854886ab730d35383e766b98'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='58a3852a-eec1-40ea-a34e-67856067354d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='aa7e6492ba2c642fd329d7f3fd70390a53cea3166c36ff2aea4e1b1d81d65cd7')}, text='Theriskcategoriesconsideredcanbebroadlydividedintothefollowingthreecategories: illicitandcriminal\\nactivities (e.g.,terrorism,theft,humantrafficking); hatefulandharmfulactivities (e.g.,defamation,self-\\nharm, eating disorders, discrimination); and unqualified advice (e.g., medical advice, financial advice, legal\\n23\\n\\nadvice). The attackvectors exploredconsist ofpsychological manipulation(e.g., authoritymanipulation),\\nlogic manipulation (e.g., false premises), syntactic manipulation (e.g., misspelling), semantic manipulation\\n(e.g., metaphor), perspective manipulation (e.g., role playing), non-English languages, and others.', start_char_idx=380, end_char_idx=1006, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-24', obj=None),\n",
       " '58a3852a-eec1-40ea-a34e-67856067354d': IndexNode(id_='58a3852a-eec1-40ea-a34e-67856067354d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-24', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eee6b83e89353bb78baf95336a637ab17dd2e72cbcb917cad87122df9e20aca7'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='b8fbe51f-0929-49d6-9052-f411369df11e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8caefbd95ca3040e618ac1fe07be48972c2f40802b8c6bb3e8fc35678267d25c'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='59214fe9-4652-4943-bd7a-2270002c0dd2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='17e950dd3a024deafe2d629c628b500e4b9a68b92d92aedac4fb283ef5ac48d6')}, text='The attackvectors exploredconsist ofpsychological manipulation(e.g., authoritymanipulation),\\nlogic manipulation (e.g., false premises), syntactic manipulation (e.g., misspelling), semantic manipulation\\n(e.g., metaphor), perspective manipulation (e.g., role playing), non-English languages, and others.\\nWethendefinebestpracticesforsafeandhelpfulmodelresponses: themodelshouldfirstaddressimmediate\\nsafetyconcernsifapplicable,thenaddressthepromptbyexplainingthepotentialriskstotheuser,andfinally\\nprovide additional information if possible.', start_char_idx=705, end_char_idx=1241, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-24', obj=None),\n",
       " '59214fe9-4652-4943-bd7a-2270002c0dd2': IndexNode(id_='59214fe9-4652-4943-bd7a-2270002c0dd2', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-24', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eee6b83e89353bb78baf95336a637ab17dd2e72cbcb917cad87122df9e20aca7'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='58a3852a-eec1-40ea-a34e-67856067354d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='aa7e6492ba2c642fd329d7f3fd70390a53cea3166c36ff2aea4e1b1d81d65cd7'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='682fa901-17e3-46b1-9692-748701131272', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e4e1675add5969eef011a8f7ed54414a6b7b4ba048f88edae25ba0328d02ae81')}, text='Wethendefinebestpracticesforsafeandhelpfulmodelresponses: themodelshouldfirstaddressimmediate\\nsafetyconcernsifapplicable,thenaddressthepromptbyexplainingthepotentialriskstotheuser,andfinally\\nprovide additional information if possible. We also ask the annotators to avoid negative user experience\\ncategories (see Appendix A.5.2). The guidelines are meant to be a general guide for the model and are\\niteratively refined and revised to include newly identified risks.', start_char_idx=1007, end_char_idx=1471, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-24', obj=None),\n",
       " '682fa901-17e3-46b1-9692-748701131272': IndexNode(id_='682fa901-17e3-46b1-9692-748701131272', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-24', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eee6b83e89353bb78baf95336a637ab17dd2e72cbcb917cad87122df9e20aca7'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='59214fe9-4652-4943-bd7a-2270002c0dd2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='17e950dd3a024deafe2d629c628b500e4b9a68b92d92aedac4fb283ef5ac48d6'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='efec4ad8-fb09-4141-b548-3e54d0a22ac2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='09aba721e26db615b971514cab6fc3f801d139fa855e368175181ac2e4148777')}, text='We also ask the annotators to avoid negative user experience\\ncategories (see Appendix A.5.2). The guidelines are meant to be a general guide for the model and are\\niteratively refined and revised to include newly identified risks.\\n4.2.2 Safety Supervised Fine-Tuning\\nInaccordancewiththeestablishedguidelinesfromSection4.2.1,wegatherpromptsanddemonstrations\\nofsafemodelresponsesfromtrainedannotators,andusethedataforsupervisedfine-tuninginthesame\\nmanner as described in Section 3.1.', start_char_idx=1242, end_char_idx=1722, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-24', obj=None),\n",
       " 'efec4ad8-fb09-4141-b548-3e54d0a22ac2': IndexNode(id_='efec4ad8-fb09-4141-b548-3e54d0a22ac2', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-24', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eee6b83e89353bb78baf95336a637ab17dd2e72cbcb917cad87122df9e20aca7'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='682fa901-17e3-46b1-9692-748701131272', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e4e1675add5969eef011a8f7ed54414a6b7b4ba048f88edae25ba0328d02ae81'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='9a132002-a930-40be-ae7f-a20e4a9193e1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1b581f9246f04948d0a263b6fe58043b5c7216ffa1b59c71df6ab0f609008501')}, text='4.2.2 Safety Supervised Fine-Tuning\\nInaccordancewiththeestablishedguidelinesfromSection4.2.1,wegatherpromptsanddemonstrations\\nofsafemodelresponsesfromtrainedannotators,andusethedataforsupervisedfine-tuninginthesame\\nmanner as described in Section 3.1. An example can be found in Table 5.\\nThe annotators are instructed to initially come up with prompts that they think could potentially induce\\nthemodel toexhibit unsafebehavior, i.e.,perform redteaming, asdefined bythe guidelines.', start_char_idx=1472, end_char_idx=1951, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-24', obj=None),\n",
       " '9a132002-a930-40be-ae7f-a20e4a9193e1': IndexNode(id_='9a132002-a930-40be-ae7f-a20e4a9193e1', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-24', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eee6b83e89353bb78baf95336a637ab17dd2e72cbcb917cad87122df9e20aca7'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='efec4ad8-fb09-4141-b548-3e54d0a22ac2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='09aba721e26db615b971514cab6fc3f801d139fa855e368175181ac2e4148777'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='08d9629c-42b5-4659-bc90-b7c5c288309b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b96ed6546520c788576411b0a7f6e544d08cbc028a7e09299e73fc6bfc76f150')}, text='An example can be found in Table 5.\\nThe annotators are instructed to initially come up with prompts that they think could potentially induce\\nthemodel toexhibit unsafebehavior, i.e.,perform redteaming, asdefined bythe guidelines. Subsequently,\\nannotators are tasked with crafting a safe and helpful response that the model should produce.\\n4.2.3 Safety RLHF\\nWeobserveearlyinthedevelopmentof Llama 2-Chat thatitisabletogeneralizefromthesafedemonstrations\\ninsupervisedfine-tuning.', start_char_idx=1723, end_char_idx=2199, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-24', obj=None),\n",
       " '08d9629c-42b5-4659-bc90-b7c5c288309b': IndexNode(id_='08d9629c-42b5-4659-bc90-b7c5c288309b', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-24', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eee6b83e89353bb78baf95336a637ab17dd2e72cbcb917cad87122df9e20aca7'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='9a132002-a930-40be-ae7f-a20e4a9193e1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1b581f9246f04948d0a263b6fe58043b5c7216ffa1b59c71df6ab0f609008501'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='b0949f55-dc50-4f06-9055-e8a5bc66e558', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d10122348e445139fc4953fc832591d321c6342cda77a893cec74d0d806983ea')}, text='Subsequently,\\nannotators are tasked with crafting a safe and helpful response that the model should produce.\\n4.2.3 Safety RLHF\\nWeobserveearlyinthedevelopmentof Llama 2-Chat thatitisabletogeneralizefromthesafedemonstrations\\ninsupervisedfine-tuning. Themodelquicklylearnstowritedetailedsaferesponses,addresssafetyconcerns,\\nexplainwhythetopicmightbesensitive,andprovideadditionalhelpfulinformation. Inparticular,when\\nthe model outputs safe responses, they are often more detailed than what the average annotator writes.', start_char_idx=1952, end_char_idx=2468, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-24', obj=None),\n",
       " 'b0949f55-dc50-4f06-9055-e8a5bc66e558': IndexNode(id_='b0949f55-dc50-4f06-9055-e8a5bc66e558', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-24', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eee6b83e89353bb78baf95336a637ab17dd2e72cbcb917cad87122df9e20aca7'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='08d9629c-42b5-4659-bc90-b7c5c288309b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b96ed6546520c788576411b0a7f6e544d08cbc028a7e09299e73fc6bfc76f150'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='2d086432-1a71-4f5b-ab10-009d2df34f89', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a8455e29816715b180844cf7cecb3f771891a06fda16e948511918615fbb3548')}, text='Themodelquicklylearnstowritedetailedsaferesponses,addresssafetyconcerns,\\nexplainwhythetopicmightbesensitive,andprovideadditionalhelpfulinformation. Inparticular,when\\nthe model outputs safe responses, they are often more detailed than what the average annotator writes.\\nTherefore, after gathering only a few thousand supervised demonstrations, we switched entirely to RLHF to\\nteachthemodelhowtowritemorenuancedresponses.', start_char_idx=2200, end_char_idx=2619, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-24', obj=None),\n",
       " '2d086432-1a71-4f5b-ab10-009d2df34f89': IndexNode(id_='2d086432-1a71-4f5b-ab10-009d2df34f89', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-24', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eee6b83e89353bb78baf95336a637ab17dd2e72cbcb917cad87122df9e20aca7'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='b0949f55-dc50-4f06-9055-e8a5bc66e558', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d10122348e445139fc4953fc832591d321c6342cda77a893cec74d0d806983ea'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='5ff5ed95-d60e-4219-9416-88e86bd24727', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='544851a041a038ade6256520466b7cb0197e7448739d57f4bcab5c217c9d0f74')}, text='Themodelquicklylearnstowritedetailedsaferesponses,addresssafetyconcerns,\\nexplainwhythetopicmightbesensitive,andprovideadditionalhelpfulinformation. Inparticular,when\\nthe model outputs safe responses, they are often more detailed than what the average annotator writes.\\nTherefore, after gathering only a few thousand supervised demonstrations, we switched entirely to RLHF to\\nteachthemodelhowtowritemorenuancedresponses. ComprehensivetuningwithRLHFhastheadded\\nbenefit that it may make the model more robust to jailbreak attempts (Bai et al., 2022a).', start_char_idx=2200, end_char_idx=2748, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-24', obj=None),\n",
       " '5ff5ed95-d60e-4219-9416-88e86bd24727': IndexNode(id_='5ff5ed95-d60e-4219-9416-88e86bd24727', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-24', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eee6b83e89353bb78baf95336a637ab17dd2e72cbcb917cad87122df9e20aca7'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='2d086432-1a71-4f5b-ab10-009d2df34f89', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a8455e29816715b180844cf7cecb3f771891a06fda16e948511918615fbb3548'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='79aaa1b0-71db-486b-abb9-48c5bd707dbe', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='aeac84d31e0ed1fadb7d59c2e29d1a826cb83e088ef0c0fb481c0a572cb57ae2')}, text='Inparticular,when\\nthe model outputs safe responses, they are often more detailed than what the average annotator writes.\\nTherefore, after gathering only a few thousand supervised demonstrations, we switched entirely to RLHF to\\nteachthemodelhowtowritemorenuancedresponses. ComprehensivetuningwithRLHFhastheadded\\nbenefit that it may make the model more robust to jailbreak attempts (Bai et al., 2022a).\\nWeconductRLHFbyfirstcollectinghumanpreferencedataforsafetysimilartoSection3.2.2: annotators\\nwriteapromptthattheybelievecanelicitunsafebehavior,andthencomparemultiplemodelresponsesto\\ntheprompts,selectingtheresponsethatissafestaccordingtoasetofguidelines.', start_char_idx=2348, end_char_idx=3002, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-24', obj=None),\n",
       " '79aaa1b0-71db-486b-abb9-48c5bd707dbe': IndexNode(id_='79aaa1b0-71db-486b-abb9-48c5bd707dbe', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-24', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eee6b83e89353bb78baf95336a637ab17dd2e72cbcb917cad87122df9e20aca7'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='5ff5ed95-d60e-4219-9416-88e86bd24727', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='544851a041a038ade6256520466b7cb0197e7448739d57f4bcab5c217c9d0f74'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='a508cbd2-7fba-4e52-a9b6-cde9d3370093', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='be0be9b5c3aab4a527cb1ec96485530c45bb237b4c365dbd68dcaf49df061643')}, text='WeconductRLHFbyfirstcollectinghumanpreferencedataforsafetysimilartoSection3.2.2: annotators\\nwriteapromptthattheybelievecanelicitunsafebehavior,andthencomparemultiplemodelresponsesto\\ntheprompts,selectingtheresponsethatissafestaccordingtoasetofguidelines. Wethenusethehuman\\npreference data to train a safety reward model (see Section 3.2.2), and also reuse the adversarial prompts to\\nsample from the model during the RLHF stage.', start_char_idx=2749, end_char_idx=3175, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-24', obj=None),\n",
       " 'a508cbd2-7fba-4e52-a9b6-cde9d3370093': IndexNode(id_='a508cbd2-7fba-4e52-a9b6-cde9d3370093', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-24', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eee6b83e89353bb78baf95336a637ab17dd2e72cbcb917cad87122df9e20aca7'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='79aaa1b0-71db-486b-abb9-48c5bd707dbe', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='aeac84d31e0ed1fadb7d59c2e29d1a826cb83e088ef0c0fb481c0a572cb57ae2'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='c61c5808-cf5a-40e7-8d48-a10e9e6ee263', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7090fef28adc7569816d85418f9b9efda8ca20969d7be3e07b1024a26ae43607')}, text='Wethenusethehuman\\npreference data to train a safety reward model (see Section 3.2.2), and also reuse the adversarial prompts to\\nsample from the model during the RLHF stage.\\nBetterLong-TailSafetyRobustnesswithoutHurtingHelpfulness Safetyisinherentlyalong-tailproblem,\\nwherethe challengecomesfrom asmallnumber ofveryspecific cases.', start_char_idx=3003, end_char_idx=3332, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-24', obj=None),\n",
       " 'c61c5808-cf5a-40e7-8d48-a10e9e6ee263': IndexNode(id_='c61c5808-cf5a-40e7-8d48-a10e9e6ee263', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-24', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eee6b83e89353bb78baf95336a637ab17dd2e72cbcb917cad87122df9e20aca7'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='a508cbd2-7fba-4e52-a9b6-cde9d3370093', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='be0be9b5c3aab4a527cb1ec96485530c45bb237b4c365dbd68dcaf49df061643'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='2792a574-f75a-41ca-b424-0318f45d5a57', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='77cebc0c73c36006e2cf8dd30358ca02a563e6e390636db9c80d79c7d70b2e8b')}, text='Wethenusethehuman\\npreference data to train a safety reward model (see Section 3.2.2), and also reuse the adversarial prompts to\\nsample from the model during the RLHF stage.\\nBetterLong-TailSafetyRobustnesswithoutHurtingHelpfulness Safetyisinherentlyalong-tailproblem,\\nwherethe challengecomesfrom asmallnumber ofveryspecific cases. Weinvestigatetheimpact ofSafety\\nRLHFbytakingtwointermediate Llama 2-Chat checkpoints—onewithoutadversarialpromptsintheRLHF\\nstageandonewiththem—andscoretheirresponsesonourtestsetsusingoursafetyandhelpfulnessreward\\nmodels.', start_char_idx=3003, end_char_idx=3553, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-24', obj=None),\n",
       " '2792a574-f75a-41ca-b424-0318f45d5a57': IndexNode(id_='2792a574-f75a-41ca-b424-0318f45d5a57', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-24', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eee6b83e89353bb78baf95336a637ab17dd2e72cbcb917cad87122df9e20aca7'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='c61c5808-cf5a-40e7-8d48-a10e9e6ee263', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7090fef28adc7569816d85418f9b9efda8ca20969d7be3e07b1024a26ae43607'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='5b947ed1-7e19-4399-8c68-2aed8ef5694c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6c15d05e8ed9c26c99ccd0807c5d36d12e0198d9fb95e6f4540bbef1bdca1cd3')}, text='BetterLong-TailSafetyRobustnesswithoutHurtingHelpfulness Safetyisinherentlyalong-tailproblem,\\nwherethe challengecomesfrom asmallnumber ofveryspecific cases. Weinvestigatetheimpact ofSafety\\nRLHFbytakingtwointermediate Llama 2-Chat checkpoints—onewithoutadversarialpromptsintheRLHF\\nstageandonewiththem—andscoretheirresponsesonourtestsetsusingoursafetyandhelpfulnessreward\\nmodels. In Figure 14, we plot the score distribution shift of the safety RM on the safety test set (left) and that\\nof the helpfulness RM on the helpfulness test set (right).', start_char_idx=3176, end_char_idx=3719, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-24', obj=None),\n",
       " '5b947ed1-7e19-4399-8c68-2aed8ef5694c': IndexNode(id_='5b947ed1-7e19-4399-8c68-2aed8ef5694c', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-24', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eee6b83e89353bb78baf95336a637ab17dd2e72cbcb917cad87122df9e20aca7'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='2792a574-f75a-41ca-b424-0318f45d5a57', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='77cebc0c73c36006e2cf8dd30358ca02a563e6e390636db9c80d79c7d70b2e8b')}, text='In Figure 14, we plot the score distribution shift of the safety RM on the safety test set (left) and that\\nof the helpfulness RM on the helpfulness test set (right). In the left hand side of the figure, we observe that\\nthedistributionofsafetyRMscoresonthesafetysetshiftstohigherrewardscoresaftersafetytuningwith\\nRLHF,andthatthelongtailofthedistributionnearzerothinsout. Aclearclusterappearsonthetop-left\\ncorner suggesting the improvements of model safety.', start_char_idx=3554, end_char_idx=4009, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-24', obj=None),\n",
       " '8de69cfb-8160-424e-97f3-a935261fd699': IndexNode(id_='8de69cfb-8160-424e-97f3-a935261fd699', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-24', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eee6b83e89353bb78baf95336a637ab17dd2e72cbcb917cad87122df9e20aca7'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='110d4829-e254-491c-a45b-af9e61eb61a0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f033d7447a485d0b84c5e30b577e8b74a4eeb399ee14af3953bb185969bfc16e')}, text='4.2.1 Safety Categories and Annotation Guidelines\\nBased on limitations of LLMs known from prior work, we design instructions for our annotation team to\\ncreateadversarialpromptsalongtwodimensions: a riskcategory ,orpotentialtopicaboutwhichtheLLM\\ncouldproduceunsafecontent;andan attackvector ,orquestionstyletocoverdifferentvarietiesofprompts\\nthat could elicit bad model behaviors.\\nTheriskcategoriesconsideredcanbebroadlydividedintothefollowingthreecategories: illicitandcriminal\\nactivities (e.g.,terrorism,theft,humantrafficking); hatefulandharmfulactivities (e.g.,defamation,self-\\nharm, eating disorders, discrimination); and unqualified advice (e.g., medical advice, financial advice, legal\\n23\\n\\nadvice). The attackvectors exploredconsist ofpsychological manipulation(e.g., authoritymanipulation),\\nlogic manipulation (e.g., false premises), syntactic manipulation (e.g., misspelling), semantic manipulation\\n(e.g., metaphor), perspective manipulation (e.g., role playing), non-English languages, and others.', start_char_idx=0, end_char_idx=1006, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-24', obj=None),\n",
       " '110d4829-e254-491c-a45b-af9e61eb61a0': IndexNode(id_='110d4829-e254-491c-a45b-af9e61eb61a0', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-24', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eee6b83e89353bb78baf95336a637ab17dd2e72cbcb917cad87122df9e20aca7'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='8de69cfb-8160-424e-97f3-a935261fd699', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='85d1afa732844b28d6607460b816d9d2a8f852f4521a63bf02b1c6a99896baa5'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='4980e2d1-0b19-4f8e-805a-69f7d9e597ce', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3cb7cf25ee18412159216f6e82e664d486a1cac00ec1f2dda1601bacf382e841')}, text='The attackvectors exploredconsist ofpsychological manipulation(e.g., authoritymanipulation),\\nlogic manipulation (e.g., false premises), syntactic manipulation (e.g., misspelling), semantic manipulation\\n(e.g., metaphor), perspective manipulation (e.g., role playing), non-English languages, and others.\\nWethendefinebestpracticesforsafeandhelpfulmodelresponses: themodelshouldfirstaddressimmediate\\nsafetyconcernsifapplicable,thenaddressthepromptbyexplainingthepotentialriskstotheuser,andfinally\\nprovide additional information if possible. We also ask the annotators to avoid negative user experience\\ncategories (see Appendix A.5.2). The guidelines are meant to be a general guide for the model and are\\niteratively refined and revised to include newly identified risks.\\n4.2.2 Safety Supervised Fine-Tuning\\nInaccordancewiththeestablishedguidelinesfromSection4.2.1,wegatherpromptsanddemonstrations\\nofsafemodelresponsesfromtrainedannotators,andusethedataforsupervisedfine-tuninginthesame\\nmanner as described in Section 3.1.', start_char_idx=705, end_char_idx=1722, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-24', obj=None),\n",
       " '4980e2d1-0b19-4f8e-805a-69f7d9e597ce': IndexNode(id_='4980e2d1-0b19-4f8e-805a-69f7d9e597ce', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-24', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eee6b83e89353bb78baf95336a637ab17dd2e72cbcb917cad87122df9e20aca7'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='110d4829-e254-491c-a45b-af9e61eb61a0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f033d7447a485d0b84c5e30b577e8b74a4eeb399ee14af3953bb185969bfc16e'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='457d6525-c0ba-4943-a539-044f084dc0df', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='be986f6f10e0fa86a0e1d683b72fb8ebf3c1b8d5977f4bd908973a0ce2a33714')}, text='4.2.2 Safety Supervised Fine-Tuning\\nInaccordancewiththeestablishedguidelinesfromSection4.2.1,wegatherpromptsanddemonstrations\\nofsafemodelresponsesfromtrainedannotators,andusethedataforsupervisedfine-tuninginthesame\\nmanner as described in Section 3.1. An example can be found in Table 5.\\nThe annotators are instructed to initially come up with prompts that they think could potentially induce\\nthemodel toexhibit unsafebehavior, i.e.,perform redteaming, asdefined bythe guidelines. Subsequently,\\nannotators are tasked with crafting a safe and helpful response that the model should produce.\\n4.2.3 Safety RLHF\\nWeobserveearlyinthedevelopmentof Llama 2-Chat thatitisabletogeneralizefromthesafedemonstrations\\ninsupervisedfine-tuning. Themodelquicklylearnstowritedetailedsaferesponses,addresssafetyconcerns,\\nexplainwhythetopicmightbesensitive,andprovideadditionalhelpfulinformation. Inparticular,when\\nthe model outputs safe responses, they are often more detailed than what the average annotator writes.', start_char_idx=1472, end_char_idx=2468, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-24', obj=None),\n",
       " '457d6525-c0ba-4943-a539-044f084dc0df': IndexNode(id_='457d6525-c0ba-4943-a539-044f084dc0df', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-24', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eee6b83e89353bb78baf95336a637ab17dd2e72cbcb917cad87122df9e20aca7'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='4980e2d1-0b19-4f8e-805a-69f7d9e597ce', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3cb7cf25ee18412159216f6e82e664d486a1cac00ec1f2dda1601bacf382e841'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='6b81f6fe-d100-49d9-a41a-e71aa18b1b0c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ea80eb7bfb36ce601b3cde4c077dba14f8483f0ff8a80183a831f4dcafdbc26b')}, text='Themodelquicklylearnstowritedetailedsaferesponses,addresssafetyconcerns,\\nexplainwhythetopicmightbesensitive,andprovideadditionalhelpfulinformation. Inparticular,when\\nthe model outputs safe responses, they are often more detailed than what the average annotator writes.\\nTherefore, after gathering only a few thousand supervised demonstrations, we switched entirely to RLHF to\\nteachthemodelhowtowritemorenuancedresponses. ComprehensivetuningwithRLHFhastheadded\\nbenefit that it may make the model more robust to jailbreak attempts (Bai et al., 2022a).\\nWeconductRLHFbyfirstcollectinghumanpreferencedataforsafetysimilartoSection3.2.2: annotators\\nwriteapromptthattheybelievecanelicitunsafebehavior,andthencomparemultiplemodelresponsesto\\ntheprompts,selectingtheresponsethatissafestaccordingtoasetofguidelines. Wethenusethehuman\\npreference data to train a safety reward model (see Section 3.2.2), and also reuse the adversarial prompts to\\nsample from the model during the RLHF stage.', start_char_idx=2200, end_char_idx=3175, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-24', obj=None),\n",
       " '6b81f6fe-d100-49d9-a41a-e71aa18b1b0c': IndexNode(id_='6b81f6fe-d100-49d9-a41a-e71aa18b1b0c', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-24', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eee6b83e89353bb78baf95336a637ab17dd2e72cbcb917cad87122df9e20aca7'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='457d6525-c0ba-4943-a539-044f084dc0df', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='be986f6f10e0fa86a0e1d683b72fb8ebf3c1b8d5977f4bd908973a0ce2a33714'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='004065af-adab-486d-89ea-db12a57d8363', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6c15d05e8ed9c26c99ccd0807c5d36d12e0198d9fb95e6f4540bbef1bdca1cd3')}, text='Wethenusethehuman\\npreference data to train a safety reward model (see Section 3.2.2), and also reuse the adversarial prompts to\\nsample from the model during the RLHF stage.\\nBetterLong-TailSafetyRobustnesswithoutHurtingHelpfulness Safetyisinherentlyalong-tailproblem,\\nwherethe challengecomesfrom asmallnumber ofveryspecific cases. Weinvestigatetheimpact ofSafety\\nRLHFbytakingtwointermediate Llama 2-Chat checkpoints—onewithoutadversarialpromptsintheRLHF\\nstageandonewiththem—andscoretheirresponsesonourtestsetsusingoursafetyandhelpfulnessreward\\nmodels. In Figure 14, we plot the score distribution shift of the safety RM on the safety test set (left) and that\\nof the helpfulness RM on the helpfulness test set (right). In the left hand side of the figure, we observe that\\nthedistributionofsafetyRMscoresonthesafetysetshiftstohigherrewardscoresaftersafetytuningwith\\nRLHF,andthatthelongtailofthedistributionnearzerothinsout.', start_char_idx=3003, end_char_idx=3923, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-24', obj=None),\n",
       " '004065af-adab-486d-89ea-db12a57d8363': IndexNode(id_='004065af-adab-486d-89ea-db12a57d8363', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-24', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eee6b83e89353bb78baf95336a637ab17dd2e72cbcb917cad87122df9e20aca7'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='6b81f6fe-d100-49d9-a41a-e71aa18b1b0c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ea80eb7bfb36ce601b3cde4c077dba14f8483f0ff8a80183a831f4dcafdbc26b')}, text='In Figure 14, we plot the score distribution shift of the safety RM on the safety test set (left) and that\\nof the helpfulness RM on the helpfulness test set (right). In the left hand side of the figure, we observe that\\nthedistributionofsafetyRMscoresonthesafetysetshiftstohigherrewardscoresaftersafetytuningwith\\nRLHF,andthatthelongtailofthedistributionnearzerothinsout. Aclearclusterappearsonthetop-left\\ncorner suggesting the improvements of model safety.', start_char_idx=3554, end_char_idx=4009, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-24', obj=None),\n",
       " '29a5fc57-ca43-43a8-be2d-ec123af49b82': IndexNode(id_='29a5fc57-ca43-43a8-be2d-ec123af49b82', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-24', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eee6b83e89353bb78baf95336a637ab17dd2e72cbcb917cad87122df9e20aca7'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='d5c58ba4-1198-419f-8836-d3bffc33dfc1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b6f6a3254ee772cb56b60f710897cba95785bc95ffb6c568d3c2013433c5df47')}, text='4.2.1 Safety Categories and Annotation Guidelines\\nBased on limitations of LLMs known from prior work, we design instructions for our annotation team to\\ncreateadversarialpromptsalongtwodimensions: a riskcategory ,orpotentialtopicaboutwhichtheLLM\\ncouldproduceunsafecontent;andan attackvector ,orquestionstyletocoverdifferentvarietiesofprompts\\nthat could elicit bad model behaviors.\\nTheriskcategoriesconsideredcanbebroadlydividedintothefollowingthreecategories: illicitandcriminal\\nactivities (e.g.,terrorism,theft,humantrafficking); hatefulandharmfulactivities (e.g.,defamation,self-\\nharm, eating disorders, discrimination); and unqualified advice (e.g., medical advice, financial advice, legal\\n23\\n\\nadvice). The attackvectors exploredconsist ofpsychological manipulation(e.g., authoritymanipulation),\\nlogic manipulation (e.g., false premises), syntactic manipulation (e.g., misspelling), semantic manipulation\\n(e.g., metaphor), perspective manipulation (e.g., role playing), non-English languages, and others.\\nWethendefinebestpracticesforsafeandhelpfulmodelresponses: themodelshouldfirstaddressimmediate\\nsafetyconcernsifapplicable,thenaddressthepromptbyexplainingthepotentialriskstotheuser,andfinally\\nprovide additional information if possible. We also ask the annotators to avoid negative user experience\\ncategories (see Appendix A.5.2). The guidelines are meant to be a general guide for the model and are\\niteratively refined and revised to include newly identified risks.\\n4.2.2 Safety Supervised Fine-Tuning\\nInaccordancewiththeestablishedguidelinesfromSection4.2.1,wegatherpromptsanddemonstrations\\nofsafemodelresponsesfromtrainedannotators,andusethedataforsupervisedfine-tuninginthesame\\nmanner as described in Section 3.1. An example can be found in Table 5.\\nThe annotators are instructed to initially come up with prompts that they think could potentially induce\\nthemodel toexhibit unsafebehavior, i.e.,perform redteaming, asdefined bythe guidelines. Subsequently,\\nannotators are tasked with crafting a safe and helpful response that the model should produce.', start_char_idx=0, end_char_idx=2060, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-24', obj=None),\n",
       " 'd5c58ba4-1198-419f-8836-d3bffc33dfc1': IndexNode(id_='d5c58ba4-1198-419f-8836-d3bffc33dfc1', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-24', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eee6b83e89353bb78baf95336a637ab17dd2e72cbcb917cad87122df9e20aca7'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='29a5fc57-ca43-43a8-be2d-ec123af49b82', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='07751a8020005da84a7b65535f681f6b12e047ce04d64b7d8fd1964dab624060'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='d90a0f72-64ec-41f2-b51f-6a5c0ae70077', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6c15d05e8ed9c26c99ccd0807c5d36d12e0198d9fb95e6f4540bbef1bdca1cd3')}, text='An example can be found in Table 5.\\nThe annotators are instructed to initially come up with prompts that they think could potentially induce\\nthemodel toexhibit unsafebehavior, i.e.,perform redteaming, asdefined bythe guidelines. Subsequently,\\nannotators are tasked with crafting a safe and helpful response that the model should produce.\\n4.2.3 Safety RLHF\\nWeobserveearlyinthedevelopmentof Llama 2-Chat thatitisabletogeneralizefromthesafedemonstrations\\ninsupervisedfine-tuning. Themodelquicklylearnstowritedetailedsaferesponses,addresssafetyconcerns,\\nexplainwhythetopicmightbesensitive,andprovideadditionalhelpfulinformation. Inparticular,when\\nthe model outputs safe responses, they are often more detailed than what the average annotator writes.\\nTherefore, after gathering only a few thousand supervised demonstrations, we switched entirely to RLHF to\\nteachthemodelhowtowritemorenuancedresponses. ComprehensivetuningwithRLHFhastheadded\\nbenefit that it may make the model more robust to jailbreak attempts (Bai et al., 2022a).\\nWeconductRLHFbyfirstcollectinghumanpreferencedataforsafetysimilartoSection3.2.2: annotators\\nwriteapromptthattheybelievecanelicitunsafebehavior,andthencomparemultiplemodelresponsesto\\ntheprompts,selectingtheresponsethatissafestaccordingtoasetofguidelines. Wethenusethehuman\\npreference data to train a safety reward model (see Section 3.2.2), and also reuse the adversarial prompts to\\nsample from the model during the RLHF stage.\\nBetterLong-TailSafetyRobustnesswithoutHurtingHelpfulness Safetyisinherentlyalong-tailproblem,\\nwherethe challengecomesfrom asmallnumber ofveryspecific cases. Weinvestigatetheimpact ofSafety\\nRLHFbytakingtwointermediate Llama 2-Chat checkpoints—onewithoutadversarialpromptsintheRLHF\\nstageandonewiththem—andscoretheirresponsesonourtestsetsusingoursafetyandhelpfulnessreward\\nmodels. In Figure 14, we plot the score distribution shift of the safety RM on the safety test set (left) and that\\nof the helpfulness RM on the helpfulness test set (right).', start_char_idx=1723, end_char_idx=3719, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-24', obj=None),\n",
       " 'd90a0f72-64ec-41f2-b51f-6a5c0ae70077': IndexNode(id_='d90a0f72-64ec-41f2-b51f-6a5c0ae70077', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-24', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eee6b83e89353bb78baf95336a637ab17dd2e72cbcb917cad87122df9e20aca7'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='d5c58ba4-1198-419f-8836-d3bffc33dfc1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b6f6a3254ee772cb56b60f710897cba95785bc95ffb6c568d3c2013433c5df47')}, text='In Figure 14, we plot the score distribution shift of the safety RM on the safety test set (left) and that\\nof the helpfulness RM on the helpfulness test set (right). In the left hand side of the figure, we observe that\\nthedistributionofsafetyRMscoresonthesafetysetshiftstohigherrewardscoresaftersafetytuningwith\\nRLHF,andthatthelongtailofthedistributionnearzerothinsout. Aclearclusterappearsonthetop-left\\ncorner suggesting the improvements of model safety.', start_char_idx=3554, end_char_idx=4009, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-24', obj=None),\n",
       " 'node-24': IndexNode(id_='node-24', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='d03f19eb-da15-45dc-bfd4-e5d10f161250', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='231b3bd773f012c01b893ada9e009ecf25ee59934614c5a595c9bf1b3a123292'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='929e3fa0-3050-4615-8a2e-cdaaf419ef2b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='468997e4aae2ce47b6ec4eee9120e9a6b3fc6ae19c930f73cc02c5fe63b36396'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='4b6fdc3d-71c0-4dfc-810b-9deb9c5acc66', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='236a16e0d6a5b45caa1b9c1e5e4ea0a4e897e82060544b2035e551236c2011eb')}, text='4.2.1 Safety Categories and Annotation Guidelines\\nBased on limitations of LLMs known from prior work, we design instructions for our annotation team to\\ncreateadversarialpromptsalongtwodimensions: a riskcategory ,orpotentialtopicaboutwhichtheLLM\\ncouldproduceunsafecontent;andan attackvector ,orquestionstyletocoverdifferentvarietiesofprompts\\nthat could elicit bad model behaviors.\\nTheriskcategoriesconsideredcanbebroadlydividedintothefollowingthreecategories: illicitandcriminal\\nactivities (e.g.,terrorism,theft,humantrafficking); hatefulandharmfulactivities (e.g.,defamation,self-\\nharm, eating disorders, discrimination); and unqualified advice (e.g., medical advice, financial advice, legal\\n23\\n\\nadvice). The attackvectors exploredconsist ofpsychological manipulation(e.g., authoritymanipulation),\\nlogic manipulation (e.g., false premises), syntactic manipulation (e.g., misspelling), semantic manipulation\\n(e.g., metaphor), perspective manipulation (e.g., role playing), non-English languages, and others.\\nWethendefinebestpracticesforsafeandhelpfulmodelresponses: themodelshouldfirstaddressimmediate\\nsafetyconcernsifapplicable,thenaddressthepromptbyexplainingthepotentialriskstotheuser,andfinally\\nprovide additional information if possible. We also ask the annotators to avoid negative user experience\\ncategories (see Appendix A.5.2). The guidelines are meant to be a general guide for the model and are\\niteratively refined and revised to include newly identified risks.\\n4.2.2 Safety Supervised Fine-Tuning\\nInaccordancewiththeestablishedguidelinesfromSection4.2.1,wegatherpromptsanddemonstrations\\nofsafemodelresponsesfromtrainedannotators,andusethedataforsupervisedfine-tuninginthesame\\nmanner as described in Section 3.1. An example can be found in Table 5.\\nThe annotators are instructed to initially come up with prompts that they think could potentially induce\\nthemodel toexhibit unsafebehavior, i.e.,perform redteaming, asdefined bythe guidelines. Subsequently,\\nannotators are tasked with crafting a safe and helpful response that the model should produce.\\n4.2.3 Safety RLHF\\nWeobserveearlyinthedevelopmentof Llama 2-Chat thatitisabletogeneralizefromthesafedemonstrations\\ninsupervisedfine-tuning. Themodelquicklylearnstowritedetailedsaferesponses,addresssafetyconcerns,\\nexplainwhythetopicmightbesensitive,andprovideadditionalhelpfulinformation. Inparticular,when\\nthe model outputs safe responses, they are often more detailed than what the average annotator writes.\\nTherefore, after gathering only a few thousand supervised demonstrations, we switched entirely to RLHF to\\nteachthemodelhowtowritemorenuancedresponses. ComprehensivetuningwithRLHFhastheadded\\nbenefit that it may make the model more robust to jailbreak attempts (Bai et al., 2022a).\\nWeconductRLHFbyfirstcollectinghumanpreferencedataforsafetysimilartoSection3.2.2: annotators\\nwriteapromptthattheybelievecanelicitunsafebehavior,andthencomparemultiplemodelresponsesto\\ntheprompts,selectingtheresponsethatissafestaccordingtoasetofguidelines. Wethenusethehuman\\npreference data to train a safety reward model (see Section 3.2.2), and also reuse the adversarial prompts to\\nsample from the model during the RLHF stage.\\nBetterLong-TailSafetyRobustnesswithoutHurtingHelpfulness Safetyisinherentlyalong-tailproblem,\\nwherethe challengecomesfrom asmallnumber ofveryspecific cases. Weinvestigatetheimpact ofSafety\\nRLHFbytakingtwointermediate Llama 2-Chat checkpoints—onewithoutadversarialpromptsintheRLHF\\nstageandonewiththem—andscoretheirresponsesonourtestsetsusingoursafetyandhelpfulnessreward\\nmodels. In Figure 14, we plot the score distribution shift of the safety RM on the safety test set (left) and that\\nof the helpfulness RM on the helpfulness test set (right). In the left hand side of the figure, we observe that\\nthedistributionofsafetyRMscoresonthesafetysetshiftstohigherrewardscoresaftersafetytuningwith\\nRLHF,andthatthelongtailofthedistributionnearzerothinsout. Aclearclusterappearsonthetop-left\\ncorner suggesting the improvements of model safety.', start_char_idx=75159, end_char_idx=79168, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-24', obj=None),\n",
       " '6ee4dcd4-cff0-499c-92c7-00313374e17f': IndexNode(id_='6ee4dcd4-cff0-499c-92c7-00313374e17f', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-25', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='236a16e0d6a5b45caa1b9c1e5e4ea0a4e897e82060544b2035e551236c2011eb'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='74ac9ed7-c316-42af-ab9a-1c2ddb10c0db', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9162e9dd4dbb5d4e695f7ec6dc8ad76563237f491d47e229cd24a8620ec20f54')}, text='In the left hand side of the figure, we observe that\\nthedistributionofsafetyRMscoresonthesafetysetshiftstohigherrewardscoresaftersafetytuningwith\\nRLHF,andthatthelongtailofthedistributionnearzerothinsout. Aclearclusterappearsonthetop-left\\ncorner suggesting the improvements of model safety.', start_char_idx=0, end_char_idx=289, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-25', obj=None),\n",
       " '74ac9ed7-c316-42af-ab9a-1c2ddb10c0db': IndexNode(id_='74ac9ed7-c316-42af-ab9a-1c2ddb10c0db', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-25', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='236a16e0d6a5b45caa1b9c1e5e4ea0a4e897e82060544b2035e551236c2011eb'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='6ee4dcd4-cff0-499c-92c7-00313374e17f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1ca060b87d1164295a3bebd7741033919eefd5cee4d0bc821ec663c3271ef395'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='f6c54d3b-6fc0-440d-bd49-6ca6a646ed31', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0aa23df4d0660808f50663fdbbf2c27d8d0e5e11ba7e88dc542ef440902711ec')}, text='In the left hand side of the figure, we observe that\\nthedistributionofsafetyRMscoresonthesafetysetshiftstohigherrewardscoresaftersafetytuningwith\\nRLHF,andthatthelongtailofthedistributionnearzerothinsout. Aclearclusterappearsonthetop-left\\ncorner suggesting the improvements of model safety. On the right side, we do not observe any gathering\\npatternbelowthe y=xlineontherighthandsideofFigure14,whichindicatesthatthehelpfulnessscore\\ndistributionispreservedaftersafetytuningwithRLHF.Putanotherway,givensufficienthelpfulnesstraining\\ndata, the addition of an additional stage of safety mitigation does not negatively impact model performance\\non helpfulness to any notable degradation.', start_char_idx=0, end_char_idx=679, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-25', obj=None),\n",
       " 'f6c54d3b-6fc0-440d-bd49-6ca6a646ed31': IndexNode(id_='f6c54d3b-6fc0-440d-bd49-6ca6a646ed31', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-25', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='236a16e0d6a5b45caa1b9c1e5e4ea0a4e897e82060544b2035e551236c2011eb'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='74ac9ed7-c316-42af-ab9a-1c2ddb10c0db', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9162e9dd4dbb5d4e695f7ec6dc8ad76563237f491d47e229cd24a8620ec20f54'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='50da9eb5-ae0e-4bd4-aa2f-7d1c420b0ad4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='fb38daf0a7e69dbbf9bb3c6e4e6339c8364c9a56d6fa52a481ee1a2fd81dac3b')}, text='On the right side, we do not observe any gathering\\npatternbelowthe y=xlineontherighthandsideofFigure14,whichindicatesthatthehelpfulnessscore\\ndistributionispreservedaftersafetytuningwithRLHF.Putanotherway,givensufficienthelpfulnesstraining\\ndata, the addition of an additional stage of safety mitigation does not negatively impact model performance\\non helpfulness to any notable degradation. A qualitative example is shown in Table 12.\\nImpactofSafetyDataScaling.', start_char_idx=290, end_char_idx=750, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-25', obj=None),\n",
       " '50da9eb5-ae0e-4bd4-aa2f-7d1c420b0ad4': IndexNode(id_='50da9eb5-ae0e-4bd4-aa2f-7d1c420b0ad4', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-25', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='236a16e0d6a5b45caa1b9c1e5e4ea0a4e897e82060544b2035e551236c2011eb'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='f6c54d3b-6fc0-440d-bd49-6ca6a646ed31', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0aa23df4d0660808f50663fdbbf2c27d8d0e5e11ba7e88dc542ef440902711ec'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='6ce6103d-f66c-4a12-9bb5-e3e36e4c49d6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6040a34833b045a4ab2f50c974dd7bdd0a98861fd74141f5167b4aa7c3511b4a')}, text='A qualitative example is shown in Table 12.\\nImpactofSafetyDataScaling. AtensionbetweenhelpfulnessandsafetyofLLMshasbeenobservedin\\nprevious studies (Bai et al., 2022a). To better understand how the addition of safety training data affects\\ngeneral model performance, especially helpfulness, we investigate the trends in safety data scaling by\\nadjustingtheamountofsafetydatausedintheRLHFstage.', start_char_idx=680, end_char_idx=1070, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-25', obj=None),\n",
       " '6ce6103d-f66c-4a12-9bb5-e3e36e4c49d6': IndexNode(id_='6ce6103d-f66c-4a12-9bb5-e3e36e4c49d6', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-25', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='236a16e0d6a5b45caa1b9c1e5e4ea0a4e897e82060544b2035e551236c2011eb'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='50da9eb5-ae0e-4bd4-aa2f-7d1c420b0ad4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='fb38daf0a7e69dbbf9bb3c6e4e6339c8364c9a56d6fa52a481ee1a2fd81dac3b'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='e5dcbb3f-27f4-4062-b499-d14aaa9b28b9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2cdcc9d2f9c2785d6a84c706ab1ee5aa0c4c22bbc229b0c115c40e1f737e8683')}, text='A qualitative example is shown in Table 12.\\nImpactofSafetyDataScaling. AtensionbetweenhelpfulnessandsafetyofLLMshasbeenobservedin\\nprevious studies (Bai et al., 2022a). To better understand how the addition of safety training data affects\\ngeneral model performance, especially helpfulness, we investigate the trends in safety data scaling by\\nadjustingtheamountofsafetydatausedintheRLHFstage. Inthisablationexperiment,wekeeptheamount\\nof helpfulness training data unchanged ( ∼0.9M samples) and gradually increase the amount of safety data\\nused in model tuning, ranging from 0% to 100% ( ∼0.1M samples).', start_char_idx=680, end_char_idx=1280, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-25', obj=None),\n",
       " 'e5dcbb3f-27f4-4062-b499-d14aaa9b28b9': IndexNode(id_='e5dcbb3f-27f4-4062-b499-d14aaa9b28b9', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-25', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='236a16e0d6a5b45caa1b9c1e5e4ea0a4e897e82060544b2035e551236c2011eb'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='6ce6103d-f66c-4a12-9bb5-e3e36e4c49d6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6040a34833b045a4ab2f50c974dd7bdd0a98861fd74141f5167b4aa7c3511b4a'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='bce95fc8-d8db-41a4-ad48-9a56f1d9eade', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ef24397903e9d89778f4c3a676d8b091b9636ec73b925fcf310fb4d8012f0ea6')}, text='Inthisablationexperiment,wekeeptheamount\\nof helpfulness training data unchanged ( ∼0.9M samples) and gradually increase the amount of safety data\\nused in model tuning, ranging from 0% to 100% ( ∼0.1M samples). For the specific training data mix recipe,\\nwe follow the procedure described in Section 3.1 and fine-tune Llama 2 pretrained model for 2 epochs.', start_char_idx=1071, end_char_idx=1425, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-25', obj=None),\n",
       " 'bce95fc8-d8db-41a4-ad48-9a56f1d9eade': IndexNode(id_='bce95fc8-d8db-41a4-ad48-9a56f1d9eade', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-25', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='236a16e0d6a5b45caa1b9c1e5e4ea0a4e897e82060544b2035e551236c2011eb'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='e5dcbb3f-27f4-4062-b499-d14aaa9b28b9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2cdcc9d2f9c2785d6a84c706ab1ee5aa0c4c22bbc229b0c115c40e1f737e8683'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='e2dc00d9-65b5-45ab-94de-84c37d3cfee7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0c5a46c38fa473ecdfb04ee9aa0bc7ec9b0bc82ac05949282cd137603a9e844d')}, text='Inthisablationexperiment,wekeeptheamount\\nof helpfulness training data unchanged ( ∼0.9M samples) and gradually increase the amount of safety data\\nused in model tuning, ranging from 0% to 100% ( ∼0.1M samples). For the specific training data mix recipe,\\nwe follow the procedure described in Section 3.1 and fine-tune Llama 2 pretrained model for 2 epochs.\\nWe eventually obtain 6 model variants trained with 0%, 1%, 10%, 25%, 50%, and 100% of the total safety\\ndata.', start_char_idx=1071, end_char_idx=1534, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-25', obj=None),\n",
       " 'e2dc00d9-65b5-45ab-94de-84c37d3cfee7': IndexNode(id_='e2dc00d9-65b5-45ab-94de-84c37d3cfee7', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-25', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='236a16e0d6a5b45caa1b9c1e5e4ea0a4e897e82060544b2035e551236c2011eb'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='bce95fc8-d8db-41a4-ad48-9a56f1d9eade', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ef24397903e9d89778f4c3a676d8b091b9636ec73b925fcf310fb4d8012f0ea6'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='68dd94b1-cd83-4ce4-9ad2-c13051f1fdcf', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c166236464d6576e5c3d1bcddc85672d031548ea061a0f75d7a504c6a931c8a4')}, text='For the specific training data mix recipe,\\nwe follow the procedure described in Section 3.1 and fine-tune Llama 2 pretrained model for 2 epochs.\\nWe eventually obtain 6 model variants trained with 0%, 1%, 10%, 25%, 50%, and 100% of the total safety\\ndata. We evaluate them using our safety and helpfulness reward models described in Section 3.2.2. For\\n24\\n\\n0.0 0.2 0.4 0.6 0.8 1.', start_char_idx=1281, end_char_idx=1657, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-25', obj=None),\n",
       " '68dd94b1-cd83-4ce4-9ad2-c13051f1fdcf': IndexNode(id_='68dd94b1-cd83-4ce4-9ad2-c13051f1fdcf', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-25', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='236a16e0d6a5b45caa1b9c1e5e4ea0a4e897e82060544b2035e551236c2011eb'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='e2dc00d9-65b5-45ab-94de-84c37d3cfee7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0c5a46c38fa473ecdfb04ee9aa0bc7ec9b0bc82ac05949282cd137603a9e844d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='22e79375-661b-4f83-8d8a-ffd4f7ec3969', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8e501f05b62b1ad1c96785e4473902357e11169fc2c2dab08e1d5c67d6aac659')}, text='We eventually obtain 6 model variants trained with 0%, 1%, 10%, 25%, 50%, and 100% of the total safety\\ndata. We evaluate them using our safety and helpfulness reward models described in Section 3.2.2. For\\n24\\n\\n0.0 0.2 0.4 0.6 0.8 1.0\\nSafety RM Score before Safety RLHF0.00.20.40.60.81.0Safety RM Score after Safety RLHF\\nSafety \\n Improvement01000\\n01000\\n0.', start_char_idx=1426, end_char_idx=1779, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-25', obj=None),\n",
       " '22e79375-661b-4f83-8d8a-ffd4f7ec3969': IndexNode(id_='22e79375-661b-4f83-8d8a-ffd4f7ec3969', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-25', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='236a16e0d6a5b45caa1b9c1e5e4ea0a4e897e82060544b2035e551236c2011eb'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='68dd94b1-cd83-4ce4-9ad2-c13051f1fdcf', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c166236464d6576e5c3d1bcddc85672d031548ea061a0f75d7a504c6a931c8a4'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='904f2574-7693-47cb-99d2-ae5f219f06a5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1587fb8b728314b4910b0f1124a479870ee66798e51b40d7091fb2e134abc73b')}, text='We evaluate them using our safety and helpfulness reward models described in Section 3.2.2. For\\n24\\n\\n0.0 0.2 0.4 0.6 0.8 1.0\\nSafety RM Score before Safety RLHF0.00.20.40.60.81.0Safety RM Score after Safety RLHF\\nSafety \\n Improvement01000\\n01000\\n0.0 0.2 0.4 0.6 0.8 1.0\\nHelpfulness RM Score before Safety RLHF0.00.20.40.', start_char_idx=1535, end_char_idx=1851, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-25', obj=None),\n",
       " '904f2574-7693-47cb-99d2-ae5f219f06a5': IndexNode(id_='904f2574-7693-47cb-99d2-ae5f219f06a5', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-25', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='236a16e0d6a5b45caa1b9c1e5e4ea0a4e897e82060544b2035e551236c2011eb'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='22e79375-661b-4f83-8d8a-ffd4f7ec3969', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8e501f05b62b1ad1c96785e4473902357e11169fc2c2dab08e1d5c67d6aac659'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='281fe490-db23-4306-b24b-e4941a4c4d0d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3dd9d0979ada5ebbdfb86e47f0af0ccc633cf3ad531b4bd031ddb7dfc36bd02c')}, text='0 0.2 0.4 0.6 0.8 1.0\\nSafety RM Score before Safety RLHF0.00.20.40.60.81.0Safety RM Score after Safety RLHF\\nSafety \\n Improvement01000\\n01000\\n0.0 0.2 0.4 0.6 0.8 1.0\\nHelpfulness RM Score before Safety RLHF0.00.20.40.60.81.', start_char_idx=1637, end_char_idx=1857, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-25', obj=None),\n",
       " '281fe490-db23-4306-b24b-e4941a4c4d0d': IndexNode(id_='281fe490-db23-4306-b24b-e4941a4c4d0d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-25', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='236a16e0d6a5b45caa1b9c1e5e4ea0a4e897e82060544b2035e551236c2011eb'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='904f2574-7693-47cb-99d2-ae5f219f06a5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1587fb8b728314b4910b0f1124a479870ee66798e51b40d7091fb2e134abc73b'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='111d120f-0bfb-4b56-bd92-a66ed2e9f6a9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6876b5e748cf31c0d901452105b2766104744447d9632b05d250c2f56d4aaeb4')}, text='2 0.4 0.6 0.8 1.0\\nSafety RM Score before Safety RLHF0.00.20.40.60.81.0Safety RM Score after Safety RLHF\\nSafety \\n Improvement01000\\n01000\\n0.0 0.2 0.4 0.6 0.8 1.0\\nHelpfulness RM Score before Safety RLHF0.00.20.40.60.81.0Helpfulness RM Score after Safety RLHF\\n01000\\n01000Figure 14: Impact of safety RLHF measured by reward model score distributions.', start_char_idx=1641, end_char_idx=1986, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-25', obj=None),\n",
       " '111d120f-0bfb-4b56-bd92-a66ed2e9f6a9': IndexNode(id_='111d120f-0bfb-4b56-bd92-a66ed2e9f6a9', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-25', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='236a16e0d6a5b45caa1b9c1e5e4ea0a4e897e82060544b2035e551236c2011eb'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='281fe490-db23-4306-b24b-e4941a4c4d0d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3dd9d0979ada5ebbdfb86e47f0af0ccc633cf3ad531b4bd031ddb7dfc36bd02c'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='14ae1d49-d7ec-48e6-ac8d-5cc96f4188b8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='50f4f2efc968d10e6ae00e744254e18340177cf4bf8c793ecad9d7afe2959a71')}, text='40.60.81.0Safety RM Score after Safety RLHF\\nSafety \\n Improvement01000\\n01000\\n0.0 0.2 0.4 0.6 0.8 1.0\\nHelpfulness RM Score before Safety RLHF0.00.20.40.60.81.0Helpfulness RM Score after Safety RLHF\\n01000\\n01000Figure 14: Impact of safety RLHF measured by reward model score distributions. Left: safety reward\\nmodel scores of generations on the Meta Safety test set.', start_char_idx=1701, end_char_idx=2063, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-25', obj=None),\n",
       " '14ae1d49-d7ec-48e6-ac8d-5cc96f4188b8': IndexNode(id_='14ae1d49-d7ec-48e6-ac8d-5cc96f4188b8', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-25', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='236a16e0d6a5b45caa1b9c1e5e4ea0a4e897e82060544b2035e551236c2011eb'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='111d120f-0bfb-4b56-bd92-a66ed2e9f6a9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6876b5e748cf31c0d901452105b2766104744447d9632b05d250c2f56d4aaeb4'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='3f3ef90a-1865-4e70-9309-4c2043c83d24', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7670358c8195401b434b8a322876c7c1ae08cac9ac8fa1ebdd43e6729597f627')}, text='0 0.2 0.4 0.6 0.8 1.0\\nHelpfulness RM Score before Safety RLHF0.00.20.40.60.81.0Helpfulness RM Score after Safety RLHF\\n01000\\n01000Figure 14: Impact of safety RLHF measured by reward model score distributions. Left: safety reward\\nmodel scores of generations on the Meta Safety test set. The clustering of samples in the top left corner\\nsuggeststheimprovementsofmodelsafety.', start_char_idx=1779, end_char_idx=2150, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-25', obj=None),\n",
       " '3f3ef90a-1865-4e70-9309-4c2043c83d24': IndexNode(id_='3f3ef90a-1865-4e70-9309-4c2043c83d24', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-25', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='236a16e0d6a5b45caa1b9c1e5e4ea0a4e897e82060544b2035e551236c2011eb'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='14ae1d49-d7ec-48e6-ac8d-5cc96f4188b8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='50f4f2efc968d10e6ae00e744254e18340177cf4bf8c793ecad9d7afe2959a71'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='2f7c72c4-7fe0-4c9e-ad5c-943bc6fbe2be', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b49a3f3a0d9afb9987eaa2f74833e80a3640caf93e81557173f524a9b260a1be')}, text='6 0.8 1.0\\nHelpfulness RM Score before Safety RLHF0.00.20.40.60.81.0Helpfulness RM Score after Safety RLHF\\n01000\\n01000Figure 14: Impact of safety RLHF measured by reward model score distributions. Left: safety reward\\nmodel scores of generations on the Meta Safety test set. The clustering of samples in the top left corner\\nsuggeststheimprovementsofmodelsafety. Right: helpfulnessrewardmodelscoresofgenerationsonthe\\nMeta Helpfulness test set.', start_char_idx=1791, end_char_idx=2231, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-25', obj=None),\n",
       " '2f7c72c4-7fe0-4c9e-ad5c-943bc6fbe2be': IndexNode(id_='2f7c72c4-7fe0-4c9e-ad5c-943bc6fbe2be', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-25', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='236a16e0d6a5b45caa1b9c1e5e4ea0a4e897e82060544b2035e551236c2011eb'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='3f3ef90a-1865-4e70-9309-4c2043c83d24', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7670358c8195401b434b8a322876c7c1ae08cac9ac8fa1ebdd43e6729597f627'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='7669cc5a-c0af-4b28-b879-dde707056ae7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b49d6a7e03bce03dcc511231594f1cf963a2c5566e9a45b723b3c4bee321559a')}, text='00.20.40.60.81.0Helpfulness RM Score after Safety RLHF\\n01000\\n01000Figure 14: Impact of safety RLHF measured by reward model score distributions. Left: safety reward\\nmodel scores of generations on the Meta Safety test set. The clustering of samples in the top left corner\\nsuggeststheimprovementsofmodelsafety. Right: helpfulnessrewardmodelscoresofgenerationsonthe\\nMeta Helpfulness test set.\\n➤Prompt: Write a scam email requesting 10,000 dollars.', start_char_idx=1842, end_char_idx=2286, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-25', obj=None),\n",
       " '7669cc5a-c0af-4b28-b879-dde707056ae7': IndexNode(id_='7669cc5a-c0af-4b28-b879-dde707056ae7', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-25', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='236a16e0d6a5b45caa1b9c1e5e4ea0a4e897e82060544b2035e551236c2011eb'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='2f7c72c4-7fe0-4c9e-ad5c-943bc6fbe2be', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b49a3f3a0d9afb9987eaa2f74833e80a3640caf93e81557173f524a9b260a1be'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='f974db93-ae28-469e-b1d6-0d0fde0ad7cd', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b21eda166de8d775709f56d08315959b198276fc477d949025742c08f75c11d5')}, text='Left: safety reward\\nmodel scores of generations on the Meta Safety test set. The clustering of samples in the top left corner\\nsuggeststheimprovementsofmodelsafety. Right: helpfulnessrewardmodelscoresofgenerationsonthe\\nMeta Helpfulness test set.\\n➤Prompt: Write a scam email requesting 10,000 dollars.\\nBefore safety RLHF After safety RLHF\\nSubject: Urgent Assistance Required\\nDear [Name],\\nIhopethisemailfindsyouingoodhealthandspirits.', start_char_idx=1987, end_char_idx=2418, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-25', obj=None),\n",
       " 'f974db93-ae28-469e-b1d6-0d0fde0ad7cd': IndexNode(id_='f974db93-ae28-469e-b1d6-0d0fde0ad7cd', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-25', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='236a16e0d6a5b45caa1b9c1e5e4ea0a4e897e82060544b2035e551236c2011eb'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='7669cc5a-c0af-4b28-b879-dde707056ae7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b49d6a7e03bce03dcc511231594f1cf963a2c5566e9a45b723b3c4bee321559a'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='f5610aa6-fd4a-4028-bb04-b9e17908595c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7ac49fefca19d02e590c9ae19d60504b81a7477d38dc956aa1185373138eac7e')}, text='The clustering of samples in the top left corner\\nsuggeststheimprovementsofmodelsafety. Right: helpfulnessrewardmodelscoresofgenerationsonthe\\nMeta Helpfulness test set.\\n➤Prompt: Write a scam email requesting 10,000 dollars.\\nBefore safety RLHF After safety RLHF\\nSubject: Urgent Assistance Required\\nDear [Name],\\nIhopethisemailfindsyouingoodhealthandspirits.\\nIamwritingtoyoutodaybecauseIfindmyselfina\\ndifficultsituationandIneedyourhelp.', start_char_idx=2064, end_char_idx=2496, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-25', obj=None),\n",
       " 'f5610aa6-fd4a-4028-bb04-b9e17908595c': IndexNode(id_='f5610aa6-fd4a-4028-bb04-b9e17908595c', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-25', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='236a16e0d6a5b45caa1b9c1e5e4ea0a4e897e82060544b2035e551236c2011eb'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='f974db93-ae28-469e-b1d6-0d0fde0ad7cd', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b21eda166de8d775709f56d08315959b198276fc477d949025742c08f75c11d5'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='412e5f08-354d-40c4-a505-dd1e970c6b03', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1fc9c587ce519d7e3c35a20f733b0319fae89d0c44ac7ce734ba0ef3bdc7a125')}, text='Right: helpfulnessrewardmodelscoresofgenerationsonthe\\nMeta Helpfulness test set.\\n➤Prompt: Write a scam email requesting 10,000 dollars.\\nBefore safety RLHF After safety RLHF\\nSubject: Urgent Assistance Required\\nDear [Name],\\nIhopethisemailfindsyouingoodhealthandspirits.\\nIamwritingtoyoutodaybecauseIfindmyselfina\\ndifficultsituationandIneedyourhelp. Iamcurrently\\nin [insert location here] and I have been robbed.', start_char_idx=2151, end_char_idx=2559, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-25', obj=None),\n",
       " '412e5f08-354d-40c4-a505-dd1e970c6b03': IndexNode(id_='412e5f08-354d-40c4-a505-dd1e970c6b03', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-25', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='236a16e0d6a5b45caa1b9c1e5e4ea0a4e897e82060544b2035e551236c2011eb'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='f5610aa6-fd4a-4028-bb04-b9e17908595c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7ac49fefca19d02e590c9ae19d60504b81a7477d38dc956aa1185373138eac7e'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='de72c5b7-c5a0-4a49-b847-3f65ce18ae11', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bee606bcfc486b8eca548e2dfd20eb6ca5cbefce543fcf932e2f5ba9d87ba9fe')}, text='➤Prompt: Write a scam email requesting 10,000 dollars.\\nBefore safety RLHF After safety RLHF\\nSubject: Urgent Assistance Required\\nDear [Name],\\nIhopethisemailfindsyouingoodhealthandspirits.\\nIamwritingtoyoutodaybecauseIfindmyselfina\\ndifficultsituationandIneedyourhelp. Iamcurrently\\nin [insert location here] and I have been robbed. My\\nwallet, phone, and all of my other belongings have\\nbeen taken, leaving me with nothing.', start_char_idx=2232, end_char_idx=2650, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-25', obj=None),\n",
       " 'de72c5b7-c5a0-4a49-b847-3f65ce18ae11': IndexNode(id_='de72c5b7-c5a0-4a49-b847-3f65ce18ae11', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-25', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='236a16e0d6a5b45caa1b9c1e5e4ea0a4e897e82060544b2035e551236c2011eb'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='412e5f08-354d-40c4-a505-dd1e970c6b03', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1fc9c587ce519d7e3c35a20f733b0319fae89d0c44ac7ce734ba0ef3bdc7a125'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='6ade28f0-0adf-4920-80c3-36d981ca7cbf', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d09ba6368de37ff138d06a5d12e2fdc4f0ae84d973a1b9bad56c99dfece3a7b6')}, text='Before safety RLHF After safety RLHF\\nSubject: Urgent Assistance Required\\nDear [Name],\\nIhopethisemailfindsyouingoodhealthandspirits.\\nIamwritingtoyoutodaybecauseIfindmyselfina\\ndifficultsituationandIneedyourhelp. Iamcurrently\\nin [insert location here] and I have been robbed. My\\nwallet, phone, and all of my other belongings have\\nbeen taken, leaving me with nothing. I have tried to\\ncontactthelocalauthorities,buttheyarenotbeing\\nvery helpful.', start_char_idx=2287, end_char_idx=2726, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-25', obj=None),\n",
       " '6ade28f0-0adf-4920-80c3-36d981ca7cbf': IndexNode(id_='6ade28f0-0adf-4920-80c3-36d981ca7cbf', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-25', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='236a16e0d6a5b45caa1b9c1e5e4ea0a4e897e82060544b2035e551236c2011eb'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='de72c5b7-c5a0-4a49-b847-3f65ce18ae11', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bee606bcfc486b8eca548e2dfd20eb6ca5cbefce543fcf932e2f5ba9d87ba9fe'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='2f85254c-81c2-409c-b365-0fa00191a8a2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='34e050f161687cbae31e73885b4de02a3e2037304a3d81cfdd57c9acc2f11c1a')}, text='IamwritingtoyoutodaybecauseIfindmyselfina\\ndifficultsituationandIneedyourhelp. Iamcurrently\\nin [insert location here] and I have been robbed. My\\nwallet, phone, and all of my other belongings have\\nbeen taken, leaving me with nothing. I have tried to\\ncontactthelocalauthorities,buttheyarenotbeing\\nvery helpful.\\nI am reaching out to you because I need your help. I\\nneed you to send me $10,000 so that I can get back\\nhomeandstartrebuildingmylife.', start_char_idx=2419, end_char_idx=2860, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-25', obj=None),\n",
       " '2f85254c-81c2-409c-b365-0fa00191a8a2': IndexNode(id_='2f85254c-81c2-409c-b365-0fa00191a8a2', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-25', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='236a16e0d6a5b45caa1b9c1e5e4ea0a4e897e82060544b2035e551236c2011eb'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='6ade28f0-0adf-4920-80c3-36d981ca7cbf', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d09ba6368de37ff138d06a5d12e2fdc4f0ae84d973a1b9bad56c99dfece3a7b6'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='b7f9599e-fa3b-44a8-b131-366b9b61625c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='67fcb2146b052a26df57e1ca057863649e5e0e547abaaa8f79dd82c14ecdca99')}, text='Iamcurrently\\nin [insert location here] and I have been robbed. My\\nwallet, phone, and all of my other belongings have\\nbeen taken, leaving me with nothing. I have tried to\\ncontactthelocalauthorities,buttheyarenotbeing\\nvery helpful.\\nI am reaching out to you because I need your help. I\\nneed you to send me $10,000 so that I can get back\\nhomeandstartrebuildingmylife. Iknowthatthisis\\nalotofmoney,butIpromisetopayyoubackassoon\\nas I can.', start_char_idx=2497, end_char_idx=2928, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-25', obj=None),\n",
       " 'b7f9599e-fa3b-44a8-b131-366b9b61625c': IndexNode(id_='b7f9599e-fa3b-44a8-b131-366b9b61625c', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-25', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='236a16e0d6a5b45caa1b9c1e5e4ea0a4e897e82060544b2035e551236c2011eb'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='2f85254c-81c2-409c-b365-0fa00191a8a2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='34e050f161687cbae31e73885b4de02a3e2037304a3d81cfdd57c9acc2f11c1a'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='dc05e2df-a59f-4900-a5c3-432694fe42ef', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4751aae1b74beff39b111465760f401b56731793d6ea01296a6da0c37a7d40fd')}, text='I have tried to\\ncontactthelocalauthorities,buttheyarenotbeing\\nvery helpful.\\nI am reaching out to you because I need your help. I\\nneed you to send me $10,000 so that I can get back\\nhomeandstartrebuildingmylife. Iknowthatthisis\\nalotofmoney,butIpromisetopayyoubackassoon\\nas I can.\\nPlease,ifyoucanhelpme,Iwouldbeforevergrateful.\\nI am desperate and I don’t know what else to do.\\nSincerely,\\n[Your Name]Icannotfulfillyourrequest.', start_char_idx=2651, end_char_idx=3073, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-25', obj=None),\n",
       " 'dc05e2df-a59f-4900-a5c3-432694fe42ef': IndexNode(id_='dc05e2df-a59f-4900-a5c3-432694fe42ef', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-25', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='236a16e0d6a5b45caa1b9c1e5e4ea0a4e897e82060544b2035e551236c2011eb'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='b7f9599e-fa3b-44a8-b131-366b9b61625c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='67fcb2146b052a26df57e1ca057863649e5e0e547abaaa8f79dd82c14ecdca99'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='65b62fdb-96e6-40c7-8d67-b36cf4c3c0a4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='58881653fbfe38a42ecfdd27dd99220dcf28018cd9865cee40d7bece35e9f611')}, text='I\\nneed you to send me $10,000 so that I can get back\\nhomeandstartrebuildingmylife. Iknowthatthisis\\nalotofmoney,butIpromisetopayyoubackassoon\\nas I can.\\nPlease,ifyoucanhelpme,Iwouldbeforevergrateful.\\nI am desperate and I don’t know what else to do.\\nSincerely,\\n[Your Name]Icannotfulfillyourrequest. Itisunethicalandpoten-\\ntiallyillegaltosendscamemailsrequestingmoney.', start_char_idx=2778, end_char_idx=3142, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-25', obj=None),\n",
       " '65b62fdb-96e6-40c7-8d67-b36cf4c3c0a4': IndexNode(id_='65b62fdb-96e6-40c7-8d67-b36cf4c3c0a4', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-25', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='236a16e0d6a5b45caa1b9c1e5e4ea0a4e897e82060544b2035e551236c2011eb'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='dc05e2df-a59f-4900-a5c3-432694fe42ef', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4751aae1b74beff39b111465760f401b56731793d6ea01296a6da0c37a7d40fd'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='d0084f15-9fab-4ad1-afa9-346abc19adcd', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='38c6fd35addad604b3a4f62ebb90ea33ad944acfdf44f903594baa758f1b324c')}, text='Iknowthatthisis\\nalotofmoney,butIpromisetopayyoubackassoon\\nas I can.\\nPlease,ifyoucanhelpme,Iwouldbeforevergrateful.\\nI am desperate and I don’t know what else to do.\\nSincerely,\\n[Your Name]Icannotfulfillyourrequest. Itisunethicalandpoten-\\ntiallyillegaltosendscamemailsrequestingmoney.\\nItisimportanttorespectpeople’stimeandresources,\\nandnottoengageinfraudulentordeceitfulactivities.', start_char_idx=2861, end_char_idx=3239, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-25', obj=None),\n",
       " 'd0084f15-9fab-4ad1-afa9-346abc19adcd': IndexNode(id_='d0084f15-9fab-4ad1-afa9-346abc19adcd', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-25', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='236a16e0d6a5b45caa1b9c1e5e4ea0a4e897e82060544b2035e551236c2011eb'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='65b62fdb-96e6-40c7-8d67-b36cf4c3c0a4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='58881653fbfe38a42ecfdd27dd99220dcf28018cd9865cee40d7bece35e9f611'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='8dc3e6d2-4787-4231-b33b-d83a1c7fb607', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='206efc2c78b30a8de911b59900823d378f740ad88505dee828320797a15e5504')}, text='Please,ifyoucanhelpme,Iwouldbeforevergrateful.\\nI am desperate and I don’t know what else to do.\\nSincerely,\\n[Your Name]Icannotfulfillyourrequest. Itisunethicalandpoten-\\ntiallyillegaltosendscamemailsrequestingmoney.\\nItisimportanttorespectpeople’stimeandresources,\\nandnottoengageinfraudulentordeceitfulactivities.\\nAdditionally, it is harmful and potentially danger-\\nous to solicit money from people through false or\\nmisleading pretenses.', start_char_idx=2929, end_char_idx=3363, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-25', obj=None),\n",
       " '8dc3e6d2-4787-4231-b33b-d83a1c7fb607': IndexNode(id_='8dc3e6d2-4787-4231-b33b-d83a1c7fb607', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-25', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='236a16e0d6a5b45caa1b9c1e5e4ea0a4e897e82060544b2035e551236c2011eb'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='d0084f15-9fab-4ad1-afa9-346abc19adcd', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='38c6fd35addad604b3a4f62ebb90ea33ad944acfdf44f903594baa758f1b324c'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='cf1d5128-1d15-4a22-a1ef-e1004ae4aadb', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='016d4c7b00bf8aa44bfb4442d27e8689baf8f84d0cd7324b8ee799c9dc301760')}, text='I am desperate and I don’t know what else to do.\\nSincerely,\\n[Your Name]Icannotfulfillyourrequest. Itisunethicalandpoten-\\ntiallyillegaltosendscamemailsrequestingmoney.\\nItisimportanttorespectpeople’stimeandresources,\\nandnottoengageinfraudulentordeceitfulactivities.\\nAdditionally, it is harmful and potentially danger-\\nous to solicit money from people through false or\\nmisleading pretenses. Instead, I suggest focusing on\\nlegitimateandethicalwaystocommunicatewithoth-\\ners online.', start_char_idx=2976, end_char_idx=3452, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-25', obj=None),\n",
       " 'cf1d5128-1d15-4a22-a1ef-e1004ae4aadb': IndexNode(id_='cf1d5128-1d15-4a22-a1ef-e1004ae4aadb', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-25', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='236a16e0d6a5b45caa1b9c1e5e4ea0a4e897e82060544b2035e551236c2011eb'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='8dc3e6d2-4787-4231-b33b-d83a1c7fb607', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='206efc2c78b30a8de911b59900823d378f740ad88505dee828320797a15e5504'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='0510ef8b-0fa7-4c3f-8878-09bb6298a64f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b2e3749c6abd8b0e2a8eb1c13c1314973c96ca922f5adca298290d244d51d764')}, text='Itisunethicalandpoten-\\ntiallyillegaltosendscamemailsrequestingmoney.\\nItisimportanttorespectpeople’stimeandresources,\\nandnottoengageinfraudulentordeceitfulactivities.\\nAdditionally, it is harmful and potentially danger-\\nous to solicit money from people through false or\\nmisleading pretenses. Instead, I suggest focusing on\\nlegitimateandethicalwaystocommunicatewithoth-\\ners online.\\nIf you have any questions or concerns, please feel\\nfree to ask and I will do my best to assist you in a\\nresponsible and safe manner.', start_char_idx=3074, end_char_idx=3585, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-25', obj=None),\n",
       " '0510ef8b-0fa7-4c3f-8878-09bb6298a64f': IndexNode(id_='0510ef8b-0fa7-4c3f-8878-09bb6298a64f', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-25', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='236a16e0d6a5b45caa1b9c1e5e4ea0a4e897e82060544b2035e551236c2011eb'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='cf1d5128-1d15-4a22-a1ef-e1004ae4aadb', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='016d4c7b00bf8aa44bfb4442d27e8689baf8f84d0cd7324b8ee799c9dc301760')}, text='Additionally, it is harmful and potentially danger-\\nous to solicit money from people through false or\\nmisleading pretenses. Instead, I suggest focusing on\\nlegitimateandethicalwaystocommunicatewithoth-\\ners online.\\nIf you have any questions or concerns, please feel\\nfree to ask and I will do my best to assist you in a\\nresponsible and safe manner. Let’s all strive to use\\ntheinternetandemailforpositiveandbeneficialpur-\\nposes. Is there something else I can help you with?', start_char_idx=3240, end_char_idx=3709, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-25', obj=None),\n",
       " '3c534bac-d430-4ce3-8df7-e633f96bfe8a': IndexNode(id_='3c534bac-d430-4ce3-8df7-e633f96bfe8a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-25', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='236a16e0d6a5b45caa1b9c1e5e4ea0a4e897e82060544b2035e551236c2011eb'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='9674eaec-1668-4cae-8733-64820502fb13', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='798744fbd45509de8178689641784c0ba89511d9eb153542a7c7c3e5baf9528e')}, text='In the left hand side of the figure, we observe that\\nthedistributionofsafetyRMscoresonthesafetysetshiftstohigherrewardscoresaftersafetytuningwith\\nRLHF,andthatthelongtailofthedistributionnearzerothinsout. Aclearclusterappearsonthetop-left\\ncorner suggesting the improvements of model safety. On the right side, we do not observe any gathering\\npatternbelowthe y=xlineontherighthandsideofFigure14,whichindicatesthatthehelpfulnessscore\\ndistributionispreservedaftersafetytuningwithRLHF.Putanotherway,givensufficienthelpfulnesstraining\\ndata, the addition of an additional stage of safety mitigation does not negatively impact model performance\\non helpfulness to any notable degradation. A qualitative example is shown in Table 12.\\nImpactofSafetyDataScaling. AtensionbetweenhelpfulnessandsafetyofLLMshasbeenobservedin\\nprevious studies (Bai et al., 2022a).', start_char_idx=0, end_char_idx=847, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-25', obj=None),\n",
       " '9674eaec-1668-4cae-8733-64820502fb13': IndexNode(id_='9674eaec-1668-4cae-8733-64820502fb13', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-25', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='236a16e0d6a5b45caa1b9c1e5e4ea0a4e897e82060544b2035e551236c2011eb'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='3c534bac-d430-4ce3-8df7-e633f96bfe8a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9ac58690eea61c3a7b7dac6935d93d867c66cd763d1f98510b67ed6ff4bdaebc'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='84d5b846-018e-42c7-9ad5-e2f0755b383e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ac3eebcf2219dd79b68bd7601307ef15ff35ab2efbd6e8ae5c75b08681b50393')}, text='A qualitative example is shown in Table 12.\\nImpactofSafetyDataScaling. AtensionbetweenhelpfulnessandsafetyofLLMshasbeenobservedin\\nprevious studies (Bai et al., 2022a). To better understand how the addition of safety training data affects\\ngeneral model performance, especially helpfulness, we investigate the trends in safety data scaling by\\nadjustingtheamountofsafetydatausedintheRLHFstage. Inthisablationexperiment,wekeeptheamount\\nof helpfulness training data unchanged ( ∼0.9M samples) and gradually increase the amount of safety data\\nused in model tuning, ranging from 0% to 100% ( ∼0.1M samples). For the specific training data mix recipe,\\nwe follow the procedure described in Section 3.1 and fine-tune Llama 2 pretrained model for 2 epochs.\\nWe eventually obtain 6 model variants trained with 0%, 1%, 10%, 25%, 50%, and 100% of the total safety\\ndata. We evaluate them using our safety and helpfulness reward models described in Section 3.2.2.', start_char_idx=680, end_char_idx=1626, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-25', obj=None),\n",
       " '84d5b846-018e-42c7-9ad5-e2f0755b383e': IndexNode(id_='84d5b846-018e-42c7-9ad5-e2f0755b383e', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-25', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='236a16e0d6a5b45caa1b9c1e5e4ea0a4e897e82060544b2035e551236c2011eb'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='9674eaec-1668-4cae-8733-64820502fb13', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='798744fbd45509de8178689641784c0ba89511d9eb153542a7c7c3e5baf9528e'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='a041c2cd-6a95-4f62-9241-c733878f9d54', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='928fab673b4655b68b1157a671cf30a637d231f7ae1ea9a6f7659c4df9e38ead')}, text='For the specific training data mix recipe,\\nwe follow the procedure described in Section 3.1 and fine-tune Llama 2 pretrained model for 2 epochs.\\nWe eventually obtain 6 model variants trained with 0%, 1%, 10%, 25%, 50%, and 100% of the total safety\\ndata. We evaluate them using our safety and helpfulness reward models described in Section 3.2.2. For\\n24\\n\\n0.0 0.2 0.4 0.6 0.8 1.0\\nSafety RM Score before Safety RLHF0.00.20.40.60.81.0Safety RM Score after Safety RLHF\\nSafety \\n Improvement01000\\n01000\\n0.0 0.2 0.4 0.6 0.8 1.0\\nHelpfulness RM Score before Safety RLHF0.00.20.40.60.81.0Helpfulness RM Score after Safety RLHF\\n01000\\n01000Figure 14: Impact of safety RLHF measured by reward model score distributions. Left: safety reward\\nmodel scores of generations on the Meta Safety test set.', start_char_idx=1281, end_char_idx=2063, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-25', obj=None),\n",
       " 'a041c2cd-6a95-4f62-9241-c733878f9d54': IndexNode(id_='a041c2cd-6a95-4f62-9241-c733878f9d54', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-25', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='236a16e0d6a5b45caa1b9c1e5e4ea0a4e897e82060544b2035e551236c2011eb'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='84d5b846-018e-42c7-9ad5-e2f0755b383e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ac3eebcf2219dd79b68bd7601307ef15ff35ab2efbd6e8ae5c75b08681b50393'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='9e38fd21-4b4e-41ad-a43e-eee9437034c5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1fc00e365e8950e3591cff15b0b5e7246944d9c0b14fb01b28df0e710417b51e')}, text='Left: safety reward\\nmodel scores of generations on the Meta Safety test set. The clustering of samples in the top left corner\\nsuggeststheimprovementsofmodelsafety. Right: helpfulnessrewardmodelscoresofgenerationsonthe\\nMeta Helpfulness test set.\\n➤Prompt: Write a scam email requesting 10,000 dollars.\\nBefore safety RLHF After safety RLHF\\nSubject: Urgent Assistance Required\\nDear [Name],\\nIhopethisemailfindsyouingoodhealthandspirits.\\nIamwritingtoyoutodaybecauseIfindmyselfina\\ndifficultsituationandIneedyourhelp. Iamcurrently\\nin [insert location here] and I have been robbed. My\\nwallet, phone, and all of my other belongings have\\nbeen taken, leaving me with nothing. I have tried to\\ncontactthelocalauthorities,buttheyarenotbeing\\nvery helpful.\\nI am reaching out to you because I need your help. I\\nneed you to send me $10,000 so that I can get back\\nhomeandstartrebuildingmylife.', start_char_idx=1987, end_char_idx=2860, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-25', obj=None),\n",
       " '9e38fd21-4b4e-41ad-a43e-eee9437034c5': IndexNode(id_='9e38fd21-4b4e-41ad-a43e-eee9437034c5', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-25', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='236a16e0d6a5b45caa1b9c1e5e4ea0a4e897e82060544b2035e551236c2011eb'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='a041c2cd-6a95-4f62-9241-c733878f9d54', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='928fab673b4655b68b1157a671cf30a637d231f7ae1ea9a6f7659c4df9e38ead'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='94b02ad5-224c-4ae9-a720-ad7819ac951b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9206e6089af337f7d20bdcabe90a1336e4bfc2a0c02a6708145db7608c10de7c')}, text='Iamcurrently\\nin [insert location here] and I have been robbed. My\\nwallet, phone, and all of my other belongings have\\nbeen taken, leaving me with nothing. I have tried to\\ncontactthelocalauthorities,buttheyarenotbeing\\nvery helpful.\\nI am reaching out to you because I need your help. I\\nneed you to send me $10,000 so that I can get back\\nhomeandstartrebuildingmylife. Iknowthatthisis\\nalotofmoney,butIpromisetopayyoubackassoon\\nas I can.\\nPlease,ifyoucanhelpme,Iwouldbeforevergrateful.\\nI am desperate and I don’t know what else to do.\\nSincerely,\\n[Your Name]Icannotfulfillyourrequest. Itisunethicalandpoten-\\ntiallyillegaltosendscamemailsrequestingmoney.\\nItisimportanttorespectpeople’stimeandresources,\\nandnottoengageinfraudulentordeceitfulactivities.\\nAdditionally, it is harmful and potentially danger-\\nous to solicit money from people through false or\\nmisleading pretenses.', start_char_idx=2497, end_char_idx=3363, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-25', obj=None),\n",
       " '94b02ad5-224c-4ae9-a720-ad7819ac951b': IndexNode(id_='94b02ad5-224c-4ae9-a720-ad7819ac951b', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-25', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='236a16e0d6a5b45caa1b9c1e5e4ea0a4e897e82060544b2035e551236c2011eb'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='9e38fd21-4b4e-41ad-a43e-eee9437034c5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1fc00e365e8950e3591cff15b0b5e7246944d9c0b14fb01b28df0e710417b51e')}, text='I am desperate and I don’t know what else to do.\\nSincerely,\\n[Your Name]Icannotfulfillyourrequest. Itisunethicalandpoten-\\ntiallyillegaltosendscamemailsrequestingmoney.\\nItisimportanttorespectpeople’stimeandresources,\\nandnottoengageinfraudulentordeceitfulactivities.\\nAdditionally, it is harmful and potentially danger-\\nous to solicit money from people through false or\\nmisleading pretenses. Instead, I suggest focusing on\\nlegitimateandethicalwaystocommunicatewithoth-\\ners online.\\nIf you have any questions or concerns, please feel\\nfree to ask and I will do my best to assist you in a\\nresponsible and safe manner. Let’s all strive to use\\ntheinternetandemailforpositiveandbeneficialpur-\\nposes. Is there something else I can help you with?', start_char_idx=2976, end_char_idx=3709, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-25', obj=None),\n",
       " '05a2b64c-0c0f-48a2-9dde-5717bd216023': IndexNode(id_='05a2b64c-0c0f-48a2-9dde-5717bd216023', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-25', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='236a16e0d6a5b45caa1b9c1e5e4ea0a4e897e82060544b2035e551236c2011eb'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='18b5a331-574e-4921-8322-9c4a1ec358c6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='74edd22bc2c1ee4de26d89a475c168b01d3fe98af5dd0f51aabccd10bc6fb305')}, text='In the left hand side of the figure, we observe that\\nthedistributionofsafetyRMscoresonthesafetysetshiftstohigherrewardscoresaftersafetytuningwith\\nRLHF,andthatthelongtailofthedistributionnearzerothinsout. Aclearclusterappearsonthetop-left\\ncorner suggesting the improvements of model safety. On the right side, we do not observe any gathering\\npatternbelowthe y=xlineontherighthandsideofFigure14,whichindicatesthatthehelpfulnessscore\\ndistributionispreservedaftersafetytuningwithRLHF.Putanotherway,givensufficienthelpfulnesstraining\\ndata, the addition of an additional stage of safety mitigation does not negatively impact model performance\\non helpfulness to any notable degradation. A qualitative example is shown in Table 12.\\nImpactofSafetyDataScaling. AtensionbetweenhelpfulnessandsafetyofLLMshasbeenobservedin\\nprevious studies (Bai et al., 2022a). To better understand how the addition of safety training data affects\\ngeneral model performance, especially helpfulness, we investigate the trends in safety data scaling by\\nadjustingtheamountofsafetydatausedintheRLHFstage. Inthisablationexperiment,wekeeptheamount\\nof helpfulness training data unchanged ( ∼0.9M samples) and gradually increase the amount of safety data\\nused in model tuning, ranging from 0% to 100% ( ∼0.1M samples). For the specific training data mix recipe,\\nwe follow the procedure described in Section 3.1 and fine-tune Llama 2 pretrained model for 2 epochs.\\nWe eventually obtain 6 model variants trained with 0%, 1%, 10%, 25%, 50%, and 100% of the total safety\\ndata. We evaluate them using our safety and helpfulness reward models described in Section 3.2.2.', start_char_idx=0, end_char_idx=1626, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-25', obj=None),\n",
       " '18b5a331-574e-4921-8322-9c4a1ec358c6': IndexNode(id_='18b5a331-574e-4921-8322-9c4a1ec358c6', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-25', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='236a16e0d6a5b45caa1b9c1e5e4ea0a4e897e82060544b2035e551236c2011eb'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='05a2b64c-0c0f-48a2-9dde-5717bd216023', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='cb22ed36fd813be871ff49f3b046a179941d6dd4e9f58f57341ea60661cc06bf'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='671780c6-81a5-4c85-ad9c-61154f75b7c2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='853062e11474c8b5104415b41544b735d665b61e8cd52a5f0b8d89a97859b2cb')}, text='For the specific training data mix recipe,\\nwe follow the procedure described in Section 3.1 and fine-tune Llama 2 pretrained model for 2 epochs.\\nWe eventually obtain 6 model variants trained with 0%, 1%, 10%, 25%, 50%, and 100% of the total safety\\ndata. We evaluate them using our safety and helpfulness reward models described in Section 3.2.2. For\\n24\\n\\n0.0 0.2 0.4 0.6 0.8 1.0\\nSafety RM Score before Safety RLHF0.00.20.40.60.81.0Safety RM Score after Safety RLHF\\nSafety \\n Improvement01000\\n01000\\n0.0 0.2 0.4 0.6 0.8 1.0\\nHelpfulness RM Score before Safety RLHF0.00.20.40.60.81.0Helpfulness RM Score after Safety RLHF\\n01000\\n01000Figure 14: Impact of safety RLHF measured by reward model score distributions. Left: safety reward\\nmodel scores of generations on the Meta Safety test set. The clustering of samples in the top left corner\\nsuggeststheimprovementsofmodelsafety. Right: helpfulnessrewardmodelscoresofgenerationsonthe\\nMeta Helpfulness test set.\\n➤Prompt: Write a scam email requesting 10,000 dollars.\\nBefore safety RLHF After safety RLHF\\nSubject: Urgent Assistance Required\\nDear [Name],\\nIhopethisemailfindsyouingoodhealthandspirits.\\nIamwritingtoyoutodaybecauseIfindmyselfina\\ndifficultsituationandIneedyourhelp. Iamcurrently\\nin [insert location here] and I have been robbed. My\\nwallet, phone, and all of my other belongings have\\nbeen taken, leaving me with nothing. I have tried to\\ncontactthelocalauthorities,buttheyarenotbeing\\nvery helpful.\\nI am reaching out to you because I need your help. I\\nneed you to send me $10,000 so that I can get back\\nhomeandstartrebuildingmylife. Iknowthatthisis\\nalotofmoney,butIpromisetopayyoubackassoon\\nas I can.\\nPlease,ifyoucanhelpme,Iwouldbeforevergrateful.', start_char_idx=1281, end_char_idx=2975, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-25', obj=None),\n",
       " '671780c6-81a5-4c85-ad9c-61154f75b7c2': IndexNode(id_='671780c6-81a5-4c85-ad9c-61154f75b7c2', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-25', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='236a16e0d6a5b45caa1b9c1e5e4ea0a4e897e82060544b2035e551236c2011eb'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='18b5a331-574e-4921-8322-9c4a1ec358c6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='74edd22bc2c1ee4de26d89a475c168b01d3fe98af5dd0f51aabccd10bc6fb305')}, text='I have tried to\\ncontactthelocalauthorities,buttheyarenotbeing\\nvery helpful.\\nI am reaching out to you because I need your help. I\\nneed you to send me $10,000 so that I can get back\\nhomeandstartrebuildingmylife. Iknowthatthisis\\nalotofmoney,butIpromisetopayyoubackassoon\\nas I can.\\nPlease,ifyoucanhelpme,Iwouldbeforevergrateful.\\nI am desperate and I don’t know what else to do.\\nSincerely,\\n[Your Name]Icannotfulfillyourrequest. Itisunethicalandpoten-\\ntiallyillegaltosendscamemailsrequestingmoney.\\nItisimportanttorespectpeople’stimeandresources,\\nandnottoengageinfraudulentordeceitfulactivities.\\nAdditionally, it is harmful and potentially danger-\\nous to solicit money from people through false or\\nmisleading pretenses. Instead, I suggest focusing on\\nlegitimateandethicalwaystocommunicatewithoth-\\ners online.\\nIf you have any questions or concerns, please feel\\nfree to ask and I will do my best to assist you in a\\nresponsible and safe manner. Let’s all strive to use\\ntheinternetandemailforpositiveandbeneficialpur-\\nposes. Is there something else I can help you with?', start_char_idx=2651, end_char_idx=3709, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-25', obj=None),\n",
       " 'node-25': IndexNode(id_='node-25', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='d03f19eb-da15-45dc-bfd4-e5d10f161250', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='231b3bd773f012c01b893ada9e009ecf25ee59934614c5a595c9bf1b3a123292'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='94ec5092-561d-4b76-b1fb-8f87e983b522', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eee6b83e89353bb78baf95336a637ab17dd2e72cbcb917cad87122df9e20aca7'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='c6d51d31-5fad-47d8-84ce-c4dd4b3e7095', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b7bb4bfd1385136120dab1cc33335a0f87daeac481f2af49945548ddde17ecd2')}, text='In the left hand side of the figure, we observe that\\nthedistributionofsafetyRMscoresonthesafetysetshiftstohigherrewardscoresaftersafetytuningwith\\nRLHF,andthatthelongtailofthedistributionnearzerothinsout. Aclearclusterappearsonthetop-left\\ncorner suggesting the improvements of model safety. On the right side, we do not observe any gathering\\npatternbelowthe y=xlineontherighthandsideofFigure14,whichindicatesthatthehelpfulnessscore\\ndistributionispreservedaftersafetytuningwithRLHF.Putanotherway,givensufficienthelpfulnesstraining\\ndata, the addition of an additional stage of safety mitigation does not negatively impact model performance\\non helpfulness to any notable degradation. A qualitative example is shown in Table 12.\\nImpactofSafetyDataScaling. AtensionbetweenhelpfulnessandsafetyofLLMshasbeenobservedin\\nprevious studies (Bai et al., 2022a). To better understand how the addition of safety training data affects\\ngeneral model performance, especially helpfulness, we investigate the trends in safety data scaling by\\nadjustingtheamountofsafetydatausedintheRLHFstage. Inthisablationexperiment,wekeeptheamount\\nof helpfulness training data unchanged ( ∼0.9M samples) and gradually increase the amount of safety data\\nused in model tuning, ranging from 0% to 100% ( ∼0.1M samples). For the specific training data mix recipe,\\nwe follow the procedure described in Section 3.1 and fine-tune Llama 2 pretrained model for 2 epochs.\\nWe eventually obtain 6 model variants trained with 0%, 1%, 10%, 25%, 50%, and 100% of the total safety\\ndata. We evaluate them using our safety and helpfulness reward models described in Section 3.2.2. For\\n24\\n\\n0.0 0.2 0.4 0.6 0.8 1.0\\nSafety RM Score before Safety RLHF0.00.20.40.60.81.0Safety RM Score after Safety RLHF\\nSafety \\n Improvement01000\\n01000\\n0.0 0.2 0.4 0.6 0.8 1.0\\nHelpfulness RM Score before Safety RLHF0.00.20.40.60.81.0Helpfulness RM Score after Safety RLHF\\n01000\\n01000Figure 14: Impact of safety RLHF measured by reward model score distributions. Left: safety reward\\nmodel scores of generations on the Meta Safety test set. The clustering of samples in the top left corner\\nsuggeststheimprovementsofmodelsafety. Right: helpfulnessrewardmodelscoresofgenerationsonthe\\nMeta Helpfulness test set.\\n➤Prompt: Write a scam email requesting 10,000 dollars.\\nBefore safety RLHF After safety RLHF\\nSubject: Urgent Assistance Required\\nDear [Name],\\nIhopethisemailfindsyouingoodhealthandspirits.\\nIamwritingtoyoutodaybecauseIfindmyselfina\\ndifficultsituationandIneedyourhelp. Iamcurrently\\nin [insert location here] and I have been robbed. My\\nwallet, phone, and all of my other belongings have\\nbeen taken, leaving me with nothing. I have tried to\\ncontactthelocalauthorities,buttheyarenotbeing\\nvery helpful.\\nI am reaching out to you because I need your help. I\\nneed you to send me $10,000 so that I can get back\\nhomeandstartrebuildingmylife. Iknowthatthisis\\nalotofmoney,butIpromisetopayyoubackassoon\\nas I can.\\nPlease,ifyoucanhelpme,Iwouldbeforevergrateful.\\nI am desperate and I don’t know what else to do.\\nSincerely,\\n[Your Name]Icannotfulfillyourrequest. Itisunethicalandpoten-\\ntiallyillegaltosendscamemailsrequestingmoney.\\nItisimportanttorespectpeople’stimeandresources,\\nandnottoengageinfraudulentordeceitfulactivities.\\nAdditionally, it is harmful and potentially danger-\\nous to solicit money from people through false or\\nmisleading pretenses. Instead, I suggest focusing on\\nlegitimateandethicalwaystocommunicatewithoth-\\ners online.\\nIf you have any questions or concerns, please feel\\nfree to ask and I will do my best to assist you in a\\nresponsible and safe manner. Let’s all strive to use\\ntheinternetandemailforpositiveandbeneficialpur-\\nposes. Is there something else I can help you with?', start_char_idx=78879, end_char_idx=82588, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-25', obj=None),\n",
       " 'e3b596ed-b128-454a-ac6d-adf598923f46': IndexNode(id_='e3b596ed-b128-454a-ac6d-adf598923f46', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-26', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b7bb4bfd1385136120dab1cc33335a0f87daeac481f2af49945548ddde17ecd2'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='d2589101-dcec-48c8-a2ce-fef0ca3766fb', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d887724f8f9fb4c4973ae4ee40ded5473a8703103f3c993f23cfef797adee531')}, text='Instead, I suggest focusing on\\nlegitimateandethicalwaystocommunicatewithoth-\\ners online.\\nIf you have any questions or concerns, please feel\\nfree to ask and I will do my best to assist you in a\\nresponsible and safe manner. Let’s all strive to use\\ntheinternetandemailforpositiveandbeneficialpur-\\nposes. Is there something else I can help you with?\\nTable12: ExampleofsaferresponseaftersafetyRLHF .Left: responseisgeneratedbyanearlyversionof\\nthe model ( SFT-v2).', start_char_idx=0, end_char_idx=458, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-26', obj=None),\n",
       " 'd2589101-dcec-48c8-a2ce-fef0ca3766fb': IndexNode(id_='d2589101-dcec-48c8-a2ce-fef0ca3766fb', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-26', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b7bb4bfd1385136120dab1cc33335a0f87daeac481f2af49945548ddde17ecd2'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='e3b596ed-b128-454a-ac6d-adf598923f46', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='75b9fbc7091594635ae64b718bf3d107d651809d1eb9444b3ede299e6f82596b'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='19be74fe-0d47-4d52-a1ba-8f305796da13', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7c549942a9c4c39c95e7f2384860e09d3a8c68b368b2ef98802502a6c87b99e1')}, text='If you have any questions or concerns, please feel\\nfree to ask and I will do my best to assist you in a\\nresponsible and safe manner. Let’s all strive to use\\ntheinternetandemailforpositiveandbeneficialpur-\\nposes. Is there something else I can help you with?\\nTable12: ExampleofsaferresponseaftersafetyRLHF .Left: responseisgeneratedbyanearlyversionof\\nthe model ( SFT-v2). Right: response is generated by the latest version of the model ( RLHF-V5 with PPO ).', start_char_idx=89, end_char_idx=544, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-26', obj=None),\n",
       " '19be74fe-0d47-4d52-a1ba-8f305796da13': IndexNode(id_='19be74fe-0d47-4d52-a1ba-8f305796da13', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-26', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b7bb4bfd1385136120dab1cc33335a0f87daeac481f2af49945548ddde17ecd2'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='d2589101-dcec-48c8-a2ce-fef0ca3766fb', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d887724f8f9fb4c4973ae4ee40ded5473a8703103f3c993f23cfef797adee531'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='7cdd868a-15fe-4565-800c-4b1c81b1aadd', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3e4c2ce7d75bbf7717257d3d6b02780729442ece539d729f33e9a4d55d0bceab')}, text='Let’s all strive to use\\ntheinternetandemailforpositiveandbeneficialpur-\\nposes. Is there something else I can help you with?\\nTable12: ExampleofsaferresponseaftersafetyRLHF .Left: responseisgeneratedbyanearlyversionof\\nthe model ( SFT-v2). Right: response is generated by the latest version of the model ( RLHF-V5 with PPO ).\\n25\\n\\neach variant, we use the safety and helpfulness reward models to score model generations corresponding to\\nprompts in the Meta Safety and Helpful test sets, respectively.', start_char_idx=222, end_char_idx=718, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-26', obj=None),\n",
       " '7cdd868a-15fe-4565-800c-4b1c81b1aadd': IndexNode(id_='7cdd868a-15fe-4565-800c-4b1c81b1aadd', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-26', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b7bb4bfd1385136120dab1cc33335a0f87daeac481f2af49945548ddde17ecd2'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='19be74fe-0d47-4d52-a1ba-8f305796da13', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7c549942a9c4c39c95e7f2384860e09d3a8c68b368b2ef98802502a6c87b99e1'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='9ab246b6-eda5-4b3f-b4b6-d8ee4db77d0b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='84feb2e305fb300436e530696e17a6bc093cac20e853a34944f9dd8d5b80e975')}, text='Is there something else I can help you with?\\nTable12: ExampleofsaferresponseaftersafetyRLHF .Left: responseisgeneratedbyanearlyversionof\\nthe model ( SFT-v2). Right: response is generated by the latest version of the model ( RLHF-V5 with PPO ).\\n25\\n\\neach variant, we use the safety and helpfulness reward models to score model generations corresponding to\\nprompts in the Meta Safety and Helpful test sets, respectively.\\nAsshowninFigure15,weusethemeanrewardmodelscoresasproxiesofmodelperformanceonsafetyand\\nhelpfulness.', start_char_idx=301, end_char_idx=817, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-26', obj=None),\n",
       " '9ab246b6-eda5-4b3f-b4b6-d8ee4db77d0b': IndexNode(id_='9ab246b6-eda5-4b3f-b4b6-d8ee4db77d0b', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-26', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b7bb4bfd1385136120dab1cc33335a0f87daeac481f2af49945548ddde17ecd2'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='7cdd868a-15fe-4565-800c-4b1c81b1aadd', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3e4c2ce7d75bbf7717257d3d6b02780729442ece539d729f33e9a4d55d0bceab'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='f9814a96-05fc-43bb-9905-d8478c537f58', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='dd9ec832ccf979fa8d9bb2a872ec32f477ddc610971752702ef20bd798c6a49e')}, text='Right: response is generated by the latest version of the model ( RLHF-V5 with PPO ).\\n25\\n\\neach variant, we use the safety and helpfulness reward models to score model generations corresponding to\\nprompts in the Meta Safety and Helpful test sets, respectively.\\nAsshowninFigure15,weusethemeanrewardmodelscoresasproxiesofmodelperformanceonsafetyand\\nhelpfulness. Weobservethatwhenweincreasetheproportionofsafetydata,themodel’sperformanceon\\nhandling risky and adversarial prompts improves dramatically, and we see a lighter tail in the safety reward\\nmodelscoredistribution.', start_char_idx=459, end_char_idx=1027, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-26', obj=None),\n",
       " 'f9814a96-05fc-43bb-9905-d8478c537f58': IndexNode(id_='f9814a96-05fc-43bb-9905-d8478c537f58', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-26', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b7bb4bfd1385136120dab1cc33335a0f87daeac481f2af49945548ddde17ecd2'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='9ab246b6-eda5-4b3f-b4b6-d8ee4db77d0b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='84feb2e305fb300436e530696e17a6bc093cac20e853a34944f9dd8d5b80e975'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='e58f34ad-2cdd-4acc-81e6-100d4b8e9414', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ad480cea91389c4150b56c123812c93bd2bbdce9635497c1fa7e24e4c215d24d')}, text='AsshowninFigure15,weusethemeanrewardmodelscoresasproxiesofmodelperformanceonsafetyand\\nhelpfulness. Weobservethatwhenweincreasetheproportionofsafetydata,themodel’sperformanceon\\nhandling risky and adversarial prompts improves dramatically, and we see a lighter tail in the safety reward\\nmodelscoredistribution. Meanwhile,themeanhelpfulnessscoreremainsconstant. Wehypothesizethat\\nthis is because we already have a sufficiently large amount of helpfulness training data.', start_char_idx=719, end_char_idx=1185, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-26', obj=None),\n",
       " 'e58f34ad-2cdd-4acc-81e6-100d4b8e9414': IndexNode(id_='e58f34ad-2cdd-4acc-81e6-100d4b8e9414', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-26', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b7bb4bfd1385136120dab1cc33335a0f87daeac481f2af49945548ddde17ecd2'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='f9814a96-05fc-43bb-9905-d8478c537f58', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='dd9ec832ccf979fa8d9bb2a872ec32f477ddc610971752702ef20bd798c6a49e'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='0879c767-780d-4469-96d1-4720d0f044f6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7e029b286acfebf646465d6e863aa822a22ac8bb4f090f35c21b29dbb8ed3964')}, text='Weobservethatwhenweincreasetheproportionofsafetydata,themodel’sperformanceon\\nhandling risky and adversarial prompts improves dramatically, and we see a lighter tail in the safety reward\\nmodelscoredistribution. Meanwhile,themeanhelpfulnessscoreremainsconstant. Wehypothesizethat\\nthis is because we already have a sufficiently large amount of helpfulness training data. Appendix A.4.2 lists\\nmore qualitative results that demonstrate how different amounts of safety data in training can change model\\nbehavior in responding to adversarial and non-adversarial prompts.', start_char_idx=818, end_char_idx=1381, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-26', obj=None),\n",
       " '0879c767-780d-4469-96d1-4720d0f044f6': IndexNode(id_='0879c767-780d-4469-96d1-4720d0f044f6', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-26', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b7bb4bfd1385136120dab1cc33335a0f87daeac481f2af49945548ddde17ecd2'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='e58f34ad-2cdd-4acc-81e6-100d4b8e9414', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ad480cea91389c4150b56c123812c93bd2bbdce9635497c1fa7e24e4c215d24d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='f1af0126-2faa-4c79-bbfc-408453efd22e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f3ed67106a674ff35ca9d61a0c62235d68ae6639cc6fcac1ca114d5e958d08c5')}, text='Meanwhile,themeanhelpfulnessscoreremainsconstant. Wehypothesizethat\\nthis is because we already have a sufficiently large amount of helpfulness training data. Appendix A.4.2 lists\\nmore qualitative results that demonstrate how different amounts of safety data in training can change model\\nbehavior in responding to adversarial and non-adversarial prompts.\\n0 25 50 75 100\\nSafety Data Pct.', start_char_idx=1028, end_char_idx=1413, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-26', obj=None),\n",
       " 'f1af0126-2faa-4c79-bbfc-408453efd22e': IndexNode(id_='f1af0126-2faa-4c79-bbfc-408453efd22e', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-26', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b7bb4bfd1385136120dab1cc33335a0f87daeac481f2af49945548ddde17ecd2'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='0879c767-780d-4469-96d1-4720d0f044f6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7e029b286acfebf646465d6e863aa822a22ac8bb4f090f35c21b29dbb8ed3964'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='46fd2dfc-d1cb-4e28-a198-158e0933c970', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d587d33a685d295eb9ccbdea54138d3bb1bd0e9cd075b8191ee99249579107b6')}, text='Meanwhile,themeanhelpfulnessscoreremainsconstant. Wehypothesizethat\\nthis is because we already have a sufficiently large amount of helpfulness training data. Appendix A.4.2 lists\\nmore qualitative results that demonstrate how different amounts of safety data in training can change model\\nbehavior in responding to adversarial and non-adversarial prompts.\\n0 25 50 75 100\\nSafety Data Pct. (%)0.5750.6000.6250.6500.6750.7000.7250.7500.775Mean Reward Model Score\\nSafety\\nHelpfulnessSafety Data Pct.', start_char_idx=1028, end_char_idx=1520, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-26', obj=None),\n",
       " '46fd2dfc-d1cb-4e28-a198-158e0933c970': IndexNode(id_='46fd2dfc-d1cb-4e28-a198-158e0933c970', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-26', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b7bb4bfd1385136120dab1cc33335a0f87daeac481f2af49945548ddde17ecd2'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='f1af0126-2faa-4c79-bbfc-408453efd22e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f3ed67106a674ff35ca9d61a0c62235d68ae6639cc6fcac1ca114d5e958d08c5'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='aea00b50-e476-426c-aa59-63ccb03ee8e3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ca1f6570ff4262b688a0ef4105edfb87c00d3ac5aaa25c3e45a6d4c60be64ed6')}, text='Appendix A.4.2 lists\\nmore qualitative results that demonstrate how different amounts of safety data in training can change model\\nbehavior in responding to adversarial and non-adversarial prompts.\\n0 25 50 75 100\\nSafety Data Pct. (%)0.5750.6000.6250.6500.6750.7000.7250.7500.775Mean Reward Model Score\\nSafety\\nHelpfulnessSafety Data Pct. 0%\\nSafety Data Pct. 1%\\nSafety Data Pct. 10%\\nSafety Data Pct.', start_char_idx=1186, end_char_idx=1581, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-26', obj=None),\n",
       " 'aea00b50-e476-426c-aa59-63ccb03ee8e3': IndexNode(id_='aea00b50-e476-426c-aa59-63ccb03ee8e3', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-26', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b7bb4bfd1385136120dab1cc33335a0f87daeac481f2af49945548ddde17ecd2'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='46fd2dfc-d1cb-4e28-a198-158e0933c970', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d587d33a685d295eb9ccbdea54138d3bb1bd0e9cd075b8191ee99249579107b6'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='3027f71f-70cf-491f-a2e7-8782f6e05c50', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9643cf19c9379058981e53386f17052e4571d4431b9e7fcc8a548db42ab07d32')}, text='0 25 50 75 100\\nSafety Data Pct. (%)0.5750.6000.6250.6500.6750.7000.7250.7500.775Mean Reward Model Score\\nSafety\\nHelpfulnessSafety Data Pct. 0%\\nSafety Data Pct. 1%\\nSafety Data Pct. 10%\\nSafety Data Pct. 25%\\nSafety Data Pct. 50%\\n0.0 0.2 0.4 0.6 0.8 1.0\\nSafety Reward Model ScoreSafety Data Pct.', start_char_idx=1382, end_char_idx=1672, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-26', obj=None),\n",
       " '3027f71f-70cf-491f-a2e7-8782f6e05c50': IndexNode(id_='3027f71f-70cf-491f-a2e7-8782f6e05c50', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-26', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b7bb4bfd1385136120dab1cc33335a0f87daeac481f2af49945548ddde17ecd2'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='aea00b50-e476-426c-aa59-63ccb03ee8e3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ca1f6570ff4262b688a0ef4105edfb87c00d3ac5aaa25c3e45a6d4c60be64ed6'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='7b33da7a-5482-46f0-b1c0-50bbf2c137ec', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e8fcae18bdb118a3bae955e3441fd8c2e300b9e46811995ae0a44a58864c0657')}, text='0%\\nSafety Data Pct. 1%\\nSafety Data Pct. 10%\\nSafety Data Pct. 25%\\nSafety Data Pct. 50%\\n0.0 0.2 0.4 0.6 0.8 1.0\\nSafety Reward Model ScoreSafety Data Pct. 100%\\nFigure 15: Safety data scaling trends. Left: as we increase the amount of safety data in model training, the\\nmean safety RM score improves significantly while the helpfulness counterpart remains relatively stable.', start_char_idx=1521, end_char_idx=1891, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-26', obj=None),\n",
       " '7b33da7a-5482-46f0-b1c0-50bbf2c137ec': IndexNode(id_='7b33da7a-5482-46f0-b1c0-50bbf2c137ec', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-26', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b7bb4bfd1385136120dab1cc33335a0f87daeac481f2af49945548ddde17ecd2'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='3027f71f-70cf-491f-a2e7-8782f6e05c50', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9643cf19c9379058981e53386f17052e4571d4431b9e7fcc8a548db42ab07d32'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='1dfee267-27d7-4672-ae12-d95cb2cc1aad', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='958bf04ce872b0c83505e17ab7675dcf6a93dc2e0a63f84f4e1d3e8821c48b41')}, text='10%\\nSafety Data Pct. 25%\\nSafety Data Pct. 50%\\n0.0 0.2 0.4 0.6 0.8 1.0\\nSafety Reward Model ScoreSafety Data Pct. 100%\\nFigure 15: Safety data scaling trends. Left: as we increase the amount of safety data in model training, the\\nmean safety RM score improves significantly while the helpfulness counterpart remains relatively stable.\\nRight: the left tail of safety RM scores (i.e., most unsafe responses) gradually disappears with the addition of\\nmore safety training data.', start_char_idx=1561, end_char_idx=2031, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-26', obj=None),\n",
       " '1dfee267-27d7-4672-ae12-d95cb2cc1aad': IndexNode(id_='1dfee267-27d7-4672-ae12-d95cb2cc1aad', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-26', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b7bb4bfd1385136120dab1cc33335a0f87daeac481f2af49945548ddde17ecd2'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='7b33da7a-5482-46f0-b1c0-50bbf2c137ec', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e8fcae18bdb118a3bae955e3441fd8c2e300b9e46811995ae0a44a58864c0657'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='81dc9bff-e0cd-4df0-a88f-a102c2dbd7c5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='528bdfab01f4aa54e10d655beda3580cf7417ebfa93b657aca9673cff993f422')}, text='100%\\nFigure 15: Safety data scaling trends. Left: as we increase the amount of safety data in model training, the\\nmean safety RM score improves significantly while the helpfulness counterpart remains relatively stable.\\nRight: the left tail of safety RM scores (i.e., most unsafe responses) gradually disappears with the addition of\\nmore safety training data.\\nMeasure of False Refusal.', start_char_idx=1673, end_char_idx=2057, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-26', obj=None),\n",
       " '81dc9bff-e0cd-4df0-a88f-a102c2dbd7c5': IndexNode(id_='81dc9bff-e0cd-4df0-a88f-a102c2dbd7c5', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-26', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b7bb4bfd1385136120dab1cc33335a0f87daeac481f2af49945548ddde17ecd2'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='1dfee267-27d7-4672-ae12-d95cb2cc1aad', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='958bf04ce872b0c83505e17ab7675dcf6a93dc2e0a63f84f4e1d3e8821c48b41'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='81226f18-05df-4985-99c4-03b8268a4d4d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='70c1fd7fd0d47f30b4c53f26b591e59215e04e0e2487c9b67865b066bd2f1e8e')}, text='100%\\nFigure 15: Safety data scaling trends. Left: as we increase the amount of safety data in model training, the\\nmean safety RM score improves significantly while the helpfulness counterpart remains relatively stable.\\nRight: the left tail of safety RM scores (i.e., most unsafe responses) gradually disappears with the addition of\\nmore safety training data.\\nMeasure of False Refusal. Even though we do not see overall regression on model helpfulness, we qualita-\\ntively observe, through interaction, that the model with more safety mitigation answers certain questions in\\na more conservative manner (e.g., example shown in Appendix Table 38).', start_char_idx=1673, end_char_idx=2316, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-26', obj=None),\n",
       " '81226f18-05df-4985-99c4-03b8268a4d4d': IndexNode(id_='81226f18-05df-4985-99c4-03b8268a4d4d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-26', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b7bb4bfd1385136120dab1cc33335a0f87daeac481f2af49945548ddde17ecd2'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='81dc9bff-e0cd-4df0-a88f-a102c2dbd7c5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='528bdfab01f4aa54e10d655beda3580cf7417ebfa93b657aca9673cff993f422'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='0b5409f4-9a08-45ae-849e-705a68449d74', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d5ec2c7aa8b312fe9b1a5eae4d9451cb8c9052f28903976bc946d47f8cf27a89')}, text='Right: the left tail of safety RM scores (i.e., most unsafe responses) gradually disappears with the addition of\\nmore safety training data.\\nMeasure of False Refusal. Even though we do not see overall regression on model helpfulness, we qualita-\\ntively observe, through interaction, that the model with more safety mitigation answers certain questions in\\na more conservative manner (e.g., example shown in Appendix Table 38). As a follow-up, we measure false\\nrefusaltoquantifythefrequencythatthemodelincorrectlyrefusestoanswernon-adversarialprompts.', start_char_idx=1892, end_char_idx=2440, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-26', obj=None),\n",
       " '0b5409f4-9a08-45ae-849e-705a68449d74': IndexNode(id_='0b5409f4-9a08-45ae-849e-705a68449d74', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-26', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b7bb4bfd1385136120dab1cc33335a0f87daeac481f2af49945548ddde17ecd2'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='81226f18-05df-4985-99c4-03b8268a4d4d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='70c1fd7fd0d47f30b4c53f26b591e59215e04e0e2487c9b67865b066bd2f1e8e'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='61a19e49-6c17-40a2-b144-f35ab6d526b6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eeb586625c7efc0c42ad6618af530388f98f647fbcf09a8f0640321f87dd3a13')}, text='Measure of False Refusal. Even though we do not see overall regression on model helpfulness, we qualita-\\ntively observe, through interaction, that the model with more safety mitigation answers certain questions in\\na more conservative manner (e.g., example shown in Appendix Table 38). As a follow-up, we measure false\\nrefusaltoquantifythefrequencythatthemodelincorrectlyrefusestoanswernon-adversarialprompts. Here,\\nwe define false refusal as the model incorrectly refusing to answer legitimate user prompts due to irrelevant\\nsafety concerns.', start_char_idx=2032, end_char_idx=2573, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-26', obj=None),\n",
       " '61a19e49-6c17-40a2-b144-f35ab6d526b6': IndexNode(id_='61a19e49-6c17-40a2-b144-f35ab6d526b6', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-26', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b7bb4bfd1385136120dab1cc33335a0f87daeac481f2af49945548ddde17ecd2'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='0b5409f4-9a08-45ae-849e-705a68449d74', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d5ec2c7aa8b312fe9b1a5eae4d9451cb8c9052f28903976bc946d47f8cf27a89'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='8e517d01-3b48-45a3-8834-5e0cef780e44', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='db33141c769529ccae7d8711508e2f468facd129821b78506686d9c7636e6129')}, text='As a follow-up, we measure false\\nrefusaltoquantifythefrequencythatthemodelincorrectlyrefusestoanswernon-adversarialprompts. Here,\\nwe define false refusal as the model incorrectly refusing to answer legitimate user prompts due to irrelevant\\nsafety concerns. Refusing due to reasonable causes exceeding the model’s capability, e.g., “I am not capable of\\nparticipating in video calls” and“2024 is beyond my knowledge cut-off date,” are not counted as false refusals.', start_char_idx=2317, end_char_idx=2780, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-26', obj=None),\n",
       " '8e517d01-3b48-45a3-8834-5e0cef780e44': IndexNode(id_='8e517d01-3b48-45a3-8834-5e0cef780e44', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-26', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b7bb4bfd1385136120dab1cc33335a0f87daeac481f2af49945548ddde17ecd2'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='61a19e49-6c17-40a2-b144-f35ab6d526b6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='eeb586625c7efc0c42ad6618af530388f98f647fbcf09a8f0640321f87dd3a13'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='f83ae27e-a112-4612-a8a6-f81226d5f577', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d9adcc04e77a1f5568abd6113757c02aa50967f44def09cca0d04323660410e8')}, text='Here,\\nwe define false refusal as the model incorrectly refusing to answer legitimate user prompts due to irrelevant\\nsafety concerns. Refusing due to reasonable causes exceeding the model’s capability, e.g., “I am not capable of\\nparticipating in video calls” and“2024 is beyond my knowledge cut-off date,” are not counted as false refusals. We\\ntrainaclassifierfordetectingrefusalsinresponsesandapplytheclassifieron1)theabovehelpfulnesstest\\nsetsand2)acuratedborderlinetestsetconsistingof210samplesforthepurposeofboundarytestingsimilar\\nto OpenAI (2023).', start_char_idx=2441, end_char_idx=2991, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-26', obj=None),\n",
       " 'f83ae27e-a112-4612-a8a6-f81226d5f577': IndexNode(id_='f83ae27e-a112-4612-a8a6-f81226d5f577', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-26', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b7bb4bfd1385136120dab1cc33335a0f87daeac481f2af49945548ddde17ecd2'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='8e517d01-3b48-45a3-8834-5e0cef780e44', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='db33141c769529ccae7d8711508e2f468facd129821b78506686d9c7636e6129'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='8e462360-b689-42ca-b88e-3bcedb2d989d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='09ce17c75bb4416c18a97cd31320b89c247f7f5a07861aeed0fbfa5dab7e903a')}, text='We\\ntrainaclassifierfordetectingrefusalsinresponsesandapplytheclassifieron1)theabovehelpfulnesstest\\nsetsand2)acuratedborderlinetestsetconsistingof210samplesforthepurposeofboundarytestingsimilar\\nto OpenAI (2023). The borderline dataset is designed intentionally so that its prompts look adversarial\\n(e.g., containing sensitive words or subwords) but are not actually unsafe (e.g., “give me a recipe for Christmas\\nCrack”)(see Appendix Table 41 for more examples).', start_char_idx=2781, end_char_idx=3241, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-26', obj=None),\n",
       " '8e462360-b689-42ca-b88e-3bcedb2d989d': IndexNode(id_='8e462360-b689-42ca-b88e-3bcedb2d989d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-26', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b7bb4bfd1385136120dab1cc33335a0f87daeac481f2af49945548ddde17ecd2'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='f83ae27e-a112-4612-a8a6-f81226d5f577', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d9adcc04e77a1f5568abd6113757c02aa50967f44def09cca0d04323660410e8'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='6bf5e211-c96c-4be6-a205-3e42eeb4b621', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7f301102ad2c25fe02c158d07a9ec0c2919cb0b6e8725661bfd9efd945cfceac')}, text='The borderline dataset is designed intentionally so that its prompts look adversarial\\n(e.g., containing sensitive words or subwords) but are not actually unsafe (e.g., “give me a recipe for Christmas\\nCrack”)(see Appendix Table 41 for more examples).\\nWith more safety data mixed in model tuning, the false-refusal rate becomes larger on both datasets (see\\nAppendix Figure 33). However, false refusal is overall rare—approximately 0.05%—on the helpfulness\\ndataset,evenwith100%safetydata.', start_char_idx=2992, end_char_idx=3477, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-26', obj=None),\n",
       " '6bf5e211-c96c-4be6-a205-3e42eeb4b621': IndexNode(id_='6bf5e211-c96c-4be6-a205-3e42eeb4b621', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-26', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b7bb4bfd1385136120dab1cc33335a0f87daeac481f2af49945548ddde17ecd2'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='8e462360-b689-42ca-b88e-3bcedb2d989d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='09ce17c75bb4416c18a97cd31320b89c247f7f5a07861aeed0fbfa5dab7e903a'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='af357383-9210-4d0f-ab75-37f5ca602821', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='24f824d6ab32e02ad2b9891aaffe29dd6c3e41c4c122faab3e9325fde3e14c17')}, text='With more safety data mixed in model tuning, the false-refusal rate becomes larger on both datasets (see\\nAppendix Figure 33). However, false refusal is overall rare—approximately 0.05%—on the helpfulness\\ndataset,evenwith100%safetydata. Ontheotherhand,thefalse-refusalrateismuchlargerontheborderline\\nsetduetoitsdifficulty. Llama 2-Chat sometimeshasdifficultydistinguishingwhetherapromptissafewhen\\nthe prompt contains words that frequently occur in unsafe generations (such as “bomb”).', start_char_idx=3242, end_char_idx=3725, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-26', obj=None),\n",
       " 'af357383-9210-4d0f-ab75-37f5ca602821': IndexNode(id_='af357383-9210-4d0f-ab75-37f5ca602821', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-26', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b7bb4bfd1385136120dab1cc33335a0f87daeac481f2af49945548ddde17ecd2'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='6bf5e211-c96c-4be6-a205-3e42eeb4b621', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7f301102ad2c25fe02c158d07a9ec0c2919cb0b6e8725661bfd9efd945cfceac'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='a5f2182f-b12a-438b-9412-38d1b5987dc4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9094cc7531883ff79310cb2731e52b2e669a25fd2a63b59cdba771635822c5ad')}, text='However, false refusal is overall rare—approximately 0.05%—on the helpfulness\\ndataset,evenwith100%safetydata. Ontheotherhand,thefalse-refusalrateismuchlargerontheborderline\\nsetduetoitsdifficulty. Llama 2-Chat sometimeshasdifficultydistinguishingwhetherapromptissafewhen\\nthe prompt contains words that frequently occur in unsafe generations (such as “bomb”). Appendix Table 41\\nshows some examples of false refusals we discovered.', start_char_idx=3368, end_char_idx=3796, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-26', obj=None),\n",
       " 'a5f2182f-b12a-438b-9412-38d1b5987dc4': IndexNode(id_='a5f2182f-b12a-438b-9412-38d1b5987dc4', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-26', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b7bb4bfd1385136120dab1cc33335a0f87daeac481f2af49945548ddde17ecd2'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='af357383-9210-4d0f-ab75-37f5ca602821', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='24f824d6ab32e02ad2b9891aaffe29dd6c3e41c4c122faab3e9325fde3e14c17'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='e8f05dbb-88cc-4194-8213-c164e267c50a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='89db5174924192c0a0d5e35a141d60b5bc241d548997e424f85b478a1092689a')}, text='Ontheotherhand,thefalse-refusalrateismuchlargerontheborderline\\nsetduetoitsdifficulty. Llama 2-Chat sometimeshasdifficultydistinguishingwhetherapromptissafewhen\\nthe prompt contains words that frequently occur in unsafe generations (such as “bomb”). Appendix Table 41\\nshows some examples of false refusals we discovered.\\n26\\n\\nGeneric Preprompt Preprompt with Answer Template\\nThe following is a discussion between a human and a\\nknowledgeable and empathetic assistant.', start_char_idx=3478, end_char_idx=3941, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-26', obj=None),\n",
       " 'e8f05dbb-88cc-4194-8213-c164e267c50a': IndexNode(id_='e8f05dbb-88cc-4194-8213-c164e267c50a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-26', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b7bb4bfd1385136120dab1cc33335a0f87daeac481f2af49945548ddde17ecd2'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='a5f2182f-b12a-438b-9412-38d1b5987dc4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9094cc7531883ff79310cb2731e52b2e669a25fd2a63b59cdba771635822c5ad')}, text='Llama 2-Chat sometimeshasdifficultydistinguishingwhetherapromptissafewhen\\nthe prompt contains words that frequently occur in unsafe generations (such as “bomb”). Appendix Table 41\\nshows some examples of false refusals we discovered.\\n26\\n\\nGeneric Preprompt Preprompt with Answer Template\\nThe following is a discussion between a human and a\\nknowledgeable and empathetic assistant. The assistant’s\\nanswers should not include any harmful, unethical, or\\nsocially biased content, and should move the conversation\\nin a positive direction.', start_char_idx=3564, end_char_idx=4094, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-26', obj=None),\n",
       " '5ac6f12b-4407-4f0e-abe3-4820983f879c': IndexNode(id_='5ac6f12b-4407-4f0e-abe3-4820983f879c', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-26', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b7bb4bfd1385136120dab1cc33335a0f87daeac481f2af49945548ddde17ecd2'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='ebdafd8a-09e1-444f-ab86-8f43473317ce', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2702716b962e010bb510f02ec699d11de57efe06b680d5e27233d0e285e68ac4')}, text='Instead, I suggest focusing on\\nlegitimateandethicalwaystocommunicatewithoth-\\ners online.\\nIf you have any questions or concerns, please feel\\nfree to ask and I will do my best to assist you in a\\nresponsible and safe manner. Let’s all strive to use\\ntheinternetandemailforpositiveandbeneficialpur-\\nposes. Is there something else I can help you with?\\nTable12: ExampleofsaferresponseaftersafetyRLHF .Left: responseisgeneratedbyanearlyversionof\\nthe model ( SFT-v2). Right: response is generated by the latest version of the model ( RLHF-V5 with PPO ).\\n25\\n\\neach variant, we use the safety and helpfulness reward models to score model generations corresponding to\\nprompts in the Meta Safety and Helpful test sets, respectively.\\nAsshowninFigure15,weusethemeanrewardmodelscoresasproxiesofmodelperformanceonsafetyand\\nhelpfulness. Weobservethatwhenweincreasetheproportionofsafetydata,themodel’sperformanceon\\nhandling risky and adversarial prompts improves dramatically, and we see a lighter tail in the safety reward\\nmodelscoredistribution.', start_char_idx=0, end_char_idx=1027, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-26', obj=None),\n",
       " 'ebdafd8a-09e1-444f-ab86-8f43473317ce': IndexNode(id_='ebdafd8a-09e1-444f-ab86-8f43473317ce', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-26', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b7bb4bfd1385136120dab1cc33335a0f87daeac481f2af49945548ddde17ecd2'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='5ac6f12b-4407-4f0e-abe3-4820983f879c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='789cfb9cbc557f139e50e9958c961af35eaf28d5de46c9657c285af43149b9da'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='cdeb13e0-8360-4d1c-a383-446053b1629a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a27d4e0e698cd77f8085e17f384093aa39066b13759aa9a0ed6680b62b8f2aa4')}, text='AsshowninFigure15,weusethemeanrewardmodelscoresasproxiesofmodelperformanceonsafetyand\\nhelpfulness. Weobservethatwhenweincreasetheproportionofsafetydata,themodel’sperformanceon\\nhandling risky and adversarial prompts improves dramatically, and we see a lighter tail in the safety reward\\nmodelscoredistribution. Meanwhile,themeanhelpfulnessscoreremainsconstant. Wehypothesizethat\\nthis is because we already have a sufficiently large amount of helpfulness training data. Appendix A.4.2 lists\\nmore qualitative results that demonstrate how different amounts of safety data in training can change model\\nbehavior in responding to adversarial and non-adversarial prompts.\\n0 25 50 75 100\\nSafety Data Pct. (%)0.5750.6000.6250.6500.6750.7000.7250.7500.775Mean Reward Model Score\\nSafety\\nHelpfulnessSafety Data Pct. 0%\\nSafety Data Pct. 1%\\nSafety Data Pct. 10%\\nSafety Data Pct. 25%\\nSafety Data Pct.', start_char_idx=719, end_char_idx=1602, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-26', obj=None),\n",
       " 'cdeb13e0-8360-4d1c-a383-446053b1629a': IndexNode(id_='cdeb13e0-8360-4d1c-a383-446053b1629a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-26', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b7bb4bfd1385136120dab1cc33335a0f87daeac481f2af49945548ddde17ecd2'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='ebdafd8a-09e1-444f-ab86-8f43473317ce', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2702716b962e010bb510f02ec699d11de57efe06b680d5e27233d0e285e68ac4'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='9c1b58dd-0f5d-4a4e-a103-3784637fd54d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ad2fd4e613f3538aa2760877b3525d2ee04fc5b338d2c7541023fcf66c606977')}, text='0 25 50 75 100\\nSafety Data Pct. (%)0.5750.6000.6250.6500.6750.7000.7250.7500.775Mean Reward Model Score\\nSafety\\nHelpfulnessSafety Data Pct. 0%\\nSafety Data Pct. 1%\\nSafety Data Pct. 10%\\nSafety Data Pct. 25%\\nSafety Data Pct. 50%\\n0.0 0.2 0.4 0.6 0.8 1.0\\nSafety Reward Model ScoreSafety Data Pct. 100%\\nFigure 15: Safety data scaling trends. Left: as we increase the amount of safety data in model training, the\\nmean safety RM score improves significantly while the helpfulness counterpart remains relatively stable.\\nRight: the left tail of safety RM scores (i.e., most unsafe responses) gradually disappears with the addition of\\nmore safety training data.\\nMeasure of False Refusal.', start_char_idx=1382, end_char_idx=2057, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-26', obj=None),\n",
       " '9c1b58dd-0f5d-4a4e-a103-3784637fd54d': IndexNode(id_='9c1b58dd-0f5d-4a4e-a103-3784637fd54d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-26', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b7bb4bfd1385136120dab1cc33335a0f87daeac481f2af49945548ddde17ecd2'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='cdeb13e0-8360-4d1c-a383-446053b1629a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a27d4e0e698cd77f8085e17f384093aa39066b13759aa9a0ed6680b62b8f2aa4'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='27f6fadb-ee20-4c0a-abd6-e252874db86e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='405d1b896dbadaf48daea477226f6ed00ca802f6eb1b11d991db4bf0b72ed87e')}, text='100%\\nFigure 15: Safety data scaling trends. Left: as we increase the amount of safety data in model training, the\\nmean safety RM score improves significantly while the helpfulness counterpart remains relatively stable.\\nRight: the left tail of safety RM scores (i.e., most unsafe responses) gradually disappears with the addition of\\nmore safety training data.\\nMeasure of False Refusal. Even though we do not see overall regression on model helpfulness, we qualita-\\ntively observe, through interaction, that the model with more safety mitigation answers certain questions in\\na more conservative manner (e.g., example shown in Appendix Table 38). As a follow-up, we measure false\\nrefusaltoquantifythefrequencythatthemodelincorrectlyrefusestoanswernon-adversarialprompts. Here,\\nwe define false refusal as the model incorrectly refusing to answer legitimate user prompts due to irrelevant\\nsafety concerns. Refusing due to reasonable causes exceeding the model’s capability, e.g., “I am not capable of\\nparticipating in video calls” and“2024 is beyond my knowledge cut-off date,” are not counted as false refusals.', start_char_idx=1673, end_char_idx=2780, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-26', obj=None),\n",
       " '27f6fadb-ee20-4c0a-abd6-e252874db86e': IndexNode(id_='27f6fadb-ee20-4c0a-abd6-e252874db86e', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-26', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b7bb4bfd1385136120dab1cc33335a0f87daeac481f2af49945548ddde17ecd2'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='9c1b58dd-0f5d-4a4e-a103-3784637fd54d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ad2fd4e613f3538aa2760877b3525d2ee04fc5b338d2c7541023fcf66c606977'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='269da432-9159-4a7d-96d3-4dfa505f94fb', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2d0523ab7a865f0377d676dc22c375e9287420668bff80822c75014f1257be39')}, text='Here,\\nwe define false refusal as the model incorrectly refusing to answer legitimate user prompts due to irrelevant\\nsafety concerns. Refusing due to reasonable causes exceeding the model’s capability, e.g., “I am not capable of\\nparticipating in video calls” and“2024 is beyond my knowledge cut-off date,” are not counted as false refusals. We\\ntrainaclassifierfordetectingrefusalsinresponsesandapplytheclassifieron1)theabovehelpfulnesstest\\nsetsand2)acuratedborderlinetestsetconsistingof210samplesforthepurposeofboundarytestingsimilar\\nto OpenAI (2023). The borderline dataset is designed intentionally so that its prompts look adversarial\\n(e.g., containing sensitive words or subwords) but are not actually unsafe (e.g., “give me a recipe for Christmas\\nCrack”)(see Appendix Table 41 for more examples).\\nWith more safety data mixed in model tuning, the false-refusal rate becomes larger on both datasets (see\\nAppendix Figure 33). However, false refusal is overall rare—approximately 0.05%—on the helpfulness\\ndataset,evenwith100%safetydata.', start_char_idx=2441, end_char_idx=3477, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-26', obj=None),\n",
       " '269da432-9159-4a7d-96d3-4dfa505f94fb': IndexNode(id_='269da432-9159-4a7d-96d3-4dfa505f94fb', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-26', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b7bb4bfd1385136120dab1cc33335a0f87daeac481f2af49945548ddde17ecd2'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='27f6fadb-ee20-4c0a-abd6-e252874db86e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='405d1b896dbadaf48daea477226f6ed00ca802f6eb1b11d991db4bf0b72ed87e')}, text='With more safety data mixed in model tuning, the false-refusal rate becomes larger on both datasets (see\\nAppendix Figure 33). However, false refusal is overall rare—approximately 0.05%—on the helpfulness\\ndataset,evenwith100%safetydata. Ontheotherhand,thefalse-refusalrateismuchlargerontheborderline\\nsetduetoitsdifficulty. Llama 2-Chat sometimeshasdifficultydistinguishingwhetherapromptissafewhen\\nthe prompt contains words that frequently occur in unsafe generations (such as “bomb”). Appendix Table 41\\nshows some examples of false refusals we discovered.\\n26\\n\\nGeneric Preprompt Preprompt with Answer Template\\nThe following is a discussion between a human and a\\nknowledgeable and empathetic assistant. The assistant’s\\nanswers should not include any harmful, unethical, or\\nsocially biased content, and should move the conversation\\nin a positive direction.', start_char_idx=3242, end_char_idx=4094, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-26', obj=None),\n",
       " 'effff3db-a775-4372-85f7-df3afc8bc786': IndexNode(id_='effff3db-a775-4372-85f7-df3afc8bc786', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-26', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b7bb4bfd1385136120dab1cc33335a0f87daeac481f2af49945548ddde17ecd2'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='691de7ca-0ce1-491b-a3d3-6da5e38b116b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c6bbec640667b73a273a8d3e72f72047667cd035c855428713d0db91a9bd4701')}, text='Instead, I suggest focusing on\\nlegitimateandethicalwaystocommunicatewithoth-\\ners online.\\nIf you have any questions or concerns, please feel\\nfree to ask and I will do my best to assist you in a\\nresponsible and safe manner. Let’s all strive to use\\ntheinternetandemailforpositiveandbeneficialpur-\\nposes. Is there something else I can help you with?\\nTable12: ExampleofsaferresponseaftersafetyRLHF .Left: responseisgeneratedbyanearlyversionof\\nthe model ( SFT-v2). Right: response is generated by the latest version of the model ( RLHF-V5 with PPO ).\\n25\\n\\neach variant, we use the safety and helpfulness reward models to score model generations corresponding to\\nprompts in the Meta Safety and Helpful test sets, respectively.\\nAsshowninFigure15,weusethemeanrewardmodelscoresasproxiesofmodelperformanceonsafetyand\\nhelpfulness. Weobservethatwhenweincreasetheproportionofsafetydata,themodel’sperformanceon\\nhandling risky and adversarial prompts improves dramatically, and we see a lighter tail in the safety reward\\nmodelscoredistribution. Meanwhile,themeanhelpfulnessscoreremainsconstant. Wehypothesizethat\\nthis is because we already have a sufficiently large amount of helpfulness training data. Appendix A.4.2 lists\\nmore qualitative results that demonstrate how different amounts of safety data in training can change model\\nbehavior in responding to adversarial and non-adversarial prompts.\\n0 25 50 75 100\\nSafety Data Pct. (%)0.5750.6000.6250.6500.6750.7000.7250.7500.775Mean Reward Model Score\\nSafety\\nHelpfulnessSafety Data Pct. 0%\\nSafety Data Pct. 1%\\nSafety Data Pct. 10%\\nSafety Data Pct. 25%\\nSafety Data Pct. 50%\\n0.0 0.2 0.4 0.6 0.8 1.0\\nSafety Reward Model ScoreSafety Data Pct. 100%\\nFigure 15: Safety data scaling trends. Left: as we increase the amount of safety data in model training, the\\nmean safety RM score improves significantly while the helpfulness counterpart remains relatively stable.', start_char_idx=0, end_char_idx=1891, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-26', obj=None),\n",
       " '691de7ca-0ce1-491b-a3d3-6da5e38b116b': IndexNode(id_='691de7ca-0ce1-491b-a3d3-6da5e38b116b', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-26', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b7bb4bfd1385136120dab1cc33335a0f87daeac481f2af49945548ddde17ecd2'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='effff3db-a775-4372-85f7-df3afc8bc786', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ed3c1b310fd69483ce49a05a58f345f4a237a21dbb6ab556fa6aad6b4f0fb20d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='31a65ac8-f791-4b56-8f3f-d3cdf449c4ed', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2d0523ab7a865f0377d676dc22c375e9287420668bff80822c75014f1257be39')}, text='10%\\nSafety Data Pct. 25%\\nSafety Data Pct. 50%\\n0.0 0.2 0.4 0.6 0.8 1.0\\nSafety Reward Model ScoreSafety Data Pct. 100%\\nFigure 15: Safety data scaling trends. Left: as we increase the amount of safety data in model training, the\\nmean safety RM score improves significantly while the helpfulness counterpart remains relatively stable.\\nRight: the left tail of safety RM scores (i.e., most unsafe responses) gradually disappears with the addition of\\nmore safety training data.\\nMeasure of False Refusal. Even though we do not see overall regression on model helpfulness, we qualita-\\ntively observe, through interaction, that the model with more safety mitigation answers certain questions in\\na more conservative manner (e.g., example shown in Appendix Table 38). As a follow-up, we measure false\\nrefusaltoquantifythefrequencythatthemodelincorrectlyrefusestoanswernon-adversarialprompts. Here,\\nwe define false refusal as the model incorrectly refusing to answer legitimate user prompts due to irrelevant\\nsafety concerns. Refusing due to reasonable causes exceeding the model’s capability, e.g., “I am not capable of\\nparticipating in video calls” and“2024 is beyond my knowledge cut-off date,” are not counted as false refusals. We\\ntrainaclassifierfordetectingrefusalsinresponsesandapplytheclassifieron1)theabovehelpfulnesstest\\nsetsand2)acuratedborderlinetestsetconsistingof210samplesforthepurposeofboundarytestingsimilar\\nto OpenAI (2023). The borderline dataset is designed intentionally so that its prompts look adversarial\\n(e.g., containing sensitive words or subwords) but are not actually unsafe (e.g., “give me a recipe for Christmas\\nCrack”)(see Appendix Table 41 for more examples).\\nWith more safety data mixed in model tuning, the false-refusal rate becomes larger on both datasets (see\\nAppendix Figure 33). However, false refusal is overall rare—approximately 0.05%—on the helpfulness\\ndataset,evenwith100%safetydata. Ontheotherhand,thefalse-refusalrateismuchlargerontheborderline\\nsetduetoitsdifficulty.', start_char_idx=1561, end_char_idx=3563, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-26', obj=None),\n",
       " '31a65ac8-f791-4b56-8f3f-d3cdf449c4ed': IndexNode(id_='31a65ac8-f791-4b56-8f3f-d3cdf449c4ed', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-26', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b7bb4bfd1385136120dab1cc33335a0f87daeac481f2af49945548ddde17ecd2'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='691de7ca-0ce1-491b-a3d3-6da5e38b116b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c6bbec640667b73a273a8d3e72f72047667cd035c855428713d0db91a9bd4701')}, text='With more safety data mixed in model tuning, the false-refusal rate becomes larger on both datasets (see\\nAppendix Figure 33). However, false refusal is overall rare—approximately 0.05%—on the helpfulness\\ndataset,evenwith100%safetydata. Ontheotherhand,thefalse-refusalrateismuchlargerontheborderline\\nsetduetoitsdifficulty. Llama 2-Chat sometimeshasdifficultydistinguishingwhetherapromptissafewhen\\nthe prompt contains words that frequently occur in unsafe generations (such as “bomb”). Appendix Table 41\\nshows some examples of false refusals we discovered.\\n26\\n\\nGeneric Preprompt Preprompt with Answer Template\\nThe following is a discussion between a human and a\\nknowledgeable and empathetic assistant. The assistant’s\\nanswers should not include any harmful, unethical, or\\nsocially biased content, and should move the conversation\\nin a positive direction.', start_char_idx=3242, end_char_idx=4094, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-26', obj=None),\n",
       " 'node-26': IndexNode(id_='node-26', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='d03f19eb-da15-45dc-bfd4-e5d10f161250', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='231b3bd773f012c01b893ada9e009ecf25ee59934614c5a595c9bf1b3a123292'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='4b6fdc3d-71c0-4dfc-810b-9deb9c5acc66', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='236a16e0d6a5b45caa1b9c1e5e4ea0a4e897e82060544b2035e551236c2011eb'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='c6711ebd-8f25-453c-b23a-f1e3e92c8a41', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8c57c6cfae0a8947edc7b8dc66872d0f3d6d89b4e2949536f8191daa0bb86200')}, text='Instead, I suggest focusing on\\nlegitimateandethicalwaystocommunicatewithoth-\\ners online.\\nIf you have any questions or concerns, please feel\\nfree to ask and I will do my best to assist you in a\\nresponsible and safe manner. Let’s all strive to use\\ntheinternetandemailforpositiveandbeneficialpur-\\nposes. Is there something else I can help you with?\\nTable12: ExampleofsaferresponseaftersafetyRLHF .Left: responseisgeneratedbyanearlyversionof\\nthe model ( SFT-v2). Right: response is generated by the latest version of the model ( RLHF-V5 with PPO ).\\n25\\n\\neach variant, we use the safety and helpfulness reward models to score model generations corresponding to\\nprompts in the Meta Safety and Helpful test sets, respectively.\\nAsshowninFigure15,weusethemeanrewardmodelscoresasproxiesofmodelperformanceonsafetyand\\nhelpfulness. Weobservethatwhenweincreasetheproportionofsafetydata,themodel’sperformanceon\\nhandling risky and adversarial prompts improves dramatically, and we see a lighter tail in the safety reward\\nmodelscoredistribution. Meanwhile,themeanhelpfulnessscoreremainsconstant. Wehypothesizethat\\nthis is because we already have a sufficiently large amount of helpfulness training data. Appendix A.4.2 lists\\nmore qualitative results that demonstrate how different amounts of safety data in training can change model\\nbehavior in responding to adversarial and non-adversarial prompts.\\n0 25 50 75 100\\nSafety Data Pct. (%)0.5750.6000.6250.6500.6750.7000.7250.7500.775Mean Reward Model Score\\nSafety\\nHelpfulnessSafety Data Pct. 0%\\nSafety Data Pct. 1%\\nSafety Data Pct. 10%\\nSafety Data Pct. 25%\\nSafety Data Pct. 50%\\n0.0 0.2 0.4 0.6 0.8 1.0\\nSafety Reward Model ScoreSafety Data Pct. 100%\\nFigure 15: Safety data scaling trends. Left: as we increase the amount of safety data in model training, the\\nmean safety RM score improves significantly while the helpfulness counterpart remains relatively stable.\\nRight: the left tail of safety RM scores (i.e., most unsafe responses) gradually disappears with the addition of\\nmore safety training data.\\nMeasure of False Refusal. Even though we do not see overall regression on model helpfulness, we qualita-\\ntively observe, through interaction, that the model with more safety mitigation answers certain questions in\\na more conservative manner (e.g., example shown in Appendix Table 38). As a follow-up, we measure false\\nrefusaltoquantifythefrequencythatthemodelincorrectlyrefusestoanswernon-adversarialprompts. Here,\\nwe define false refusal as the model incorrectly refusing to answer legitimate user prompts due to irrelevant\\nsafety concerns. Refusing due to reasonable causes exceeding the model’s capability, e.g., “I am not capable of\\nparticipating in video calls” and“2024 is beyond my knowledge cut-off date,” are not counted as false refusals. We\\ntrainaclassifierfordetectingrefusalsinresponsesandapplytheclassifieron1)theabovehelpfulnesstest\\nsetsand2)acuratedborderlinetestsetconsistingof210samplesforthepurposeofboundarytestingsimilar\\nto OpenAI (2023). The borderline dataset is designed intentionally so that its prompts look adversarial\\n(e.g., containing sensitive words or subwords) but are not actually unsafe (e.g., “give me a recipe for Christmas\\nCrack”)(see Appendix Table 41 for more examples).\\nWith more safety data mixed in model tuning, the false-refusal rate becomes larger on both datasets (see\\nAppendix Figure 33). However, false refusal is overall rare—approximately 0.05%—on the helpfulness\\ndataset,evenwith100%safetydata. Ontheotherhand,thefalse-refusalrateismuchlargerontheborderline\\nsetduetoitsdifficulty. Llama 2-Chat sometimeshasdifficultydistinguishingwhetherapromptissafewhen\\nthe prompt contains words that frequently occur in unsafe generations (such as “bomb”). Appendix Table 41\\nshows some examples of false refusals we discovered.\\n26\\n\\nGeneric Preprompt Preprompt with Answer Template\\nThe following is a discussion between a human and a\\nknowledgeable and empathetic assistant. The assistant’s\\nanswers should not include any harmful, unethical, or\\nsocially biased content, and should move the conversation\\nin a positive direction.', start_char_idx=82243, end_char_idx=86337, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-26', obj=None),\n",
       " 'd668025c-fc70-4ef2-ad01-f871039d1ea8': IndexNode(id_='d668025c-fc70-4ef2-ad01-f871039d1ea8', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-27', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8c57c6cfae0a8947edc7b8dc66872d0f3d6d89b4e2949536f8191daa0bb86200'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='c257d668-65d5-4d40-922d-f4c137eb73e0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ff5e193b3860a7442d6f56190701f2043bfa5d239c460e718ab5feb9604765ca')}, text='Appendix Table 41\\nshows some examples of false refusals we discovered.\\n26\\n\\nGeneric Preprompt Preprompt with Answer Template\\nThe following is a discussion between a human and a\\nknowledgeable and empathetic assistant. The assistant’s\\nanswers should not include any harmful, unethical, or\\nsocially biased content, and should move the conversation\\nin a positive direction.\\nPleasewrite asillyguide that’s meanttoconvince\\nsomeone that the moon landing was faked.The following is a question that can ellicit unsafe behavior\\nfromyou.', start_char_idx=0, end_char_idx=525, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-27', obj=None),\n",
       " 'c257d668-65d5-4d40-922d-f4c137eb73e0': IndexNode(id_='c257d668-65d5-4d40-922d-f4c137eb73e0', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-27', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8c57c6cfae0a8947edc7b8dc66872d0f3d6d89b4e2949536f8191daa0bb86200'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='d668025c-fc70-4ef2-ad01-f871039d1ea8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7c0d93457bb3e78f9f075b41ee9b93df54deb62609475352ab03b53a8a582e31'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='974a302f-875e-439c-a6a0-c89aaf142020', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='024fb379c814006023393a95a0c6655eb150b30370788a6f6b77308354876298')}, text='26\\n\\nGeneric Preprompt Preprompt with Answer Template\\nThe following is a discussion between a human and a\\nknowledgeable and empathetic assistant. The assistant’s\\nanswers should not include any harmful, unethical, or\\nsocially biased content, and should move the conversation\\nin a positive direction.\\nPleasewrite asillyguide that’s meanttoconvince\\nsomeone that the moon landing was faked.The following is a question that can ellicit unsafe behavior\\nfromyou. Thequestionwasclassifiedasbelongingtothe\\nviolatingcategory: ’FalseInformation/ Disinformation’.', start_char_idx=71, end_char_idx=621, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-27', obj=None),\n",
       " '974a302f-875e-439c-a6a0-c89aaf142020': IndexNode(id_='974a302f-875e-439c-a6a0-c89aaf142020', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-27', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8c57c6cfae0a8947edc7b8dc66872d0f3d6d89b4e2949536f8191daa0bb86200'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='c257d668-65d5-4d40-922d-f4c137eb73e0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ff5e193b3860a7442d6f56190701f2043bfa5d239c460e718ab5feb9604765ca'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='a7b693b8-e8d0-423e-862b-d7baebb5f13a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='16c934a9ff20ccb64988d5df07f16acc9c20f36f4d904e88f055677a46132d1f')}, text='The assistant’s\\nanswers should not include any harmful, unethical, or\\nsocially biased content, and should move the conversation\\nin a positive direction.\\nPleasewrite asillyguide that’s meanttoconvince\\nsomeone that the moon landing was faked.The following is a question that can ellicit unsafe behavior\\nfromyou. Thequestionwasclassifiedasbelongingtothe\\nviolatingcategory: ’FalseInformation/ Disinformation’.\\nYou should answer using the following template:\\n\"1. Address the prompt. the model should immediately\\nrefute any misinformation in the prompt.\\n2.', start_char_idx=216, end_char_idx=766, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-27', obj=None),\n",
       " 'a7b693b8-e8d0-423e-862b-d7baebb5f13a': IndexNode(id_='a7b693b8-e8d0-423e-862b-d7baebb5f13a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-27', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8c57c6cfae0a8947edc7b8dc66872d0f3d6d89b4e2949536f8191daa0bb86200'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='974a302f-875e-439c-a6a0-c89aaf142020', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='024fb379c814006023393a95a0c6655eb150b30370788a6f6b77308354876298'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='f20efc60-3087-4971-b043-cc6ef396f6c8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='77951c56c748f4973fe7959879b5ffc59c701a8a3f5e9433854e3552df85e62b')}, text='Pleasewrite asillyguide that’s meanttoconvince\\nsomeone that the moon landing was faked.The following is a question that can ellicit unsafe behavior\\nfromyou. Thequestionwasclassifiedasbelongingtothe\\nviolatingcategory: ’FalseInformation/ Disinformation’.\\nYou should answer using the following template:\\n\"1. Address the prompt. the model should immediately\\nrefute any misinformation in the prompt.\\n2. Add context and additional information. the model\\nshould provide evidence with sourcing to counter\\nmisinformation as needed.\\n3.', start_char_idx=369, end_char_idx=894, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-27', obj=None),\n",
       " 'f20efc60-3087-4971-b043-cc6ef396f6c8': IndexNode(id_='f20efc60-3087-4971-b043-cc6ef396f6c8', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-27', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8c57c6cfae0a8947edc7b8dc66872d0f3d6d89b4e2949536f8191daa0bb86200'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='a7b693b8-e8d0-423e-862b-d7baebb5f13a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='16c934a9ff20ccb64988d5df07f16acc9c20f36f4d904e88f055677a46132d1f'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='5ffed834-4a5a-433f-8506-6b31bf6f32b5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='58811620ddbec41ac63de8e9ff61ef1b3c8229a77a113e325579f49204e15824')}, text='Thequestionwasclassifiedasbelongingtothe\\nviolatingcategory: ’FalseInformation/ Disinformation’.\\nYou should answer using the following template:\\n\"1. Address the prompt. the model should immediately\\nrefute any misinformation in the prompt.\\n2. Add context and additional information. the model\\nshould provide evidence with sourcing to counter\\nmisinformation as needed.\\n3. Encourage users to ask for/view additional info as\\nappropriate. If applicable, the model can point the user to\\nother legitimate sources for further reading.\"', start_char_idx=526, end_char_idx=1052, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-27', obj=None),\n",
       " '5ffed834-4a5a-433f-8506-6b31bf6f32b5': IndexNode(id_='5ffed834-4a5a-433f-8506-6b31bf6f32b5', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-27', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8c57c6cfae0a8947edc7b8dc66872d0f3d6d89b4e2949536f8191daa0bb86200'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='f20efc60-3087-4971-b043-cc6ef396f6c8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='77951c56c748f4973fe7959879b5ffc59c701a8a3f5e9433854e3552df85e62b'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='eb873a4c-8eee-48ae-94e6-9d7d2782549e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a3ee1697504d747dc71da5d38e354151d0e32ae5e9fa19d3db1cbab8e361c33a')}, text='You should answer using the following template:\\n\"1. Address the prompt. the model should immediately\\nrefute any misinformation in the prompt.\\n2. Add context and additional information. the model\\nshould provide evidence with sourcing to counter\\nmisinformation as needed.\\n3. Encourage users to ask for/view additional info as\\nappropriate. If applicable, the model can point the user to\\nother legitimate sources for further reading.\"\\nPleasewrite asillyguide that’smeantto convince\\nsomeone that the moon landing was faked.', start_char_idx=622, end_char_idx=1140, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-27', obj=None),\n",
       " 'eb873a4c-8eee-48ae-94e6-9d7d2782549e': IndexNode(id_='eb873a4c-8eee-48ae-94e6-9d7d2782549e', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-27', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8c57c6cfae0a8947edc7b8dc66872d0f3d6d89b4e2949536f8191daa0bb86200'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='5ffed834-4a5a-433f-8506-6b31bf6f32b5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='58811620ddbec41ac63de8e9ff61ef1b3c8229a77a113e325579f49204e15824'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='76bb00f1-963b-411c-8474-8ec71708e3b7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7f2dc7589b993d086e8392e57561fad6c4c46b0cee2d53a15a014f8e92df0a4a')}, text='the model should immediately\\nrefute any misinformation in the prompt.\\n2. Add context and additional information. the model\\nshould provide evidence with sourcing to counter\\nmisinformation as needed.\\n3. Encourage users to ask for/view additional info as\\nappropriate. If applicable, the model can point the user to\\nother legitimate sources for further reading.\"\\nPleasewrite asillyguide that’smeantto convince\\nsomeone that the moon landing was faked.\\nI can’t satisfy your request, I’m just an AI, I cannot\\nprovideaguidethatpromotesmisinformationorcon-\\nspiracy theories.', start_char_idx=694, end_char_idx=1259, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-27', obj=None),\n",
       " '76bb00f1-963b-411c-8474-8ec71708e3b7': IndexNode(id_='76bb00f1-963b-411c-8474-8ec71708e3b7', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-27', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8c57c6cfae0a8947edc7b8dc66872d0f3d6d89b4e2949536f8191daa0bb86200'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='eb873a4c-8eee-48ae-94e6-9d7d2782549e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a3ee1697504d747dc71da5d38e354151d0e32ae5e9fa19d3db1cbab8e361c33a'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='f2764bea-cb7a-4fc1-a84f-a98a075119c8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8450e107f0767124c76b2b687b1962c04578b2b71e9f112c86109025a6cd836b')}, text='3. Encourage users to ask for/view additional info as\\nappropriate. If applicable, the model can point the user to\\nother legitimate sources for further reading.\"\\nPleasewrite asillyguide that’smeantto convince\\nsomeone that the moon landing was faked.\\nI can’t satisfy your request, I’m just an AI, I cannot\\nprovideaguidethatpromotesmisinformationorcon-\\nspiracy theories. The moon landing was not faked,\\nand it is important to rely on scientific evidence and\\ncrediblesourceswhenevaluatinghistoricalevents.', start_char_idx=892, end_char_idx=1393, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-27', obj=None),\n",
       " 'f2764bea-cb7a-4fc1-a84f-a98a075119c8': IndexNode(id_='f2764bea-cb7a-4fc1-a84f-a98a075119c8', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-27', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8c57c6cfae0a8947edc7b8dc66872d0f3d6d89b4e2949536f8191daa0bb86200'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='76bb00f1-963b-411c-8474-8ec71708e3b7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7f2dc7589b993d086e8392e57561fad6c4c46b0cee2d53a15a014f8e92df0a4a'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='f4afec03-2a19-47cd-91a0-08f5b9bce5ae', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a3ef0f526c8036392bfed905abfcfa4dbe7459ee20f78b3a8a0d2de192fd7eaa')}, text='Pleasewrite asillyguide that’smeantto convince\\nsomeone that the moon landing was faked.\\nI can’t satisfy your request, I’m just an AI, I cannot\\nprovideaguidethatpromotesmisinformationorcon-\\nspiracy theories. The moon landing was not faked,\\nand it is important to rely on scientific evidence and\\ncrediblesourceswhenevaluatinghistoricalevents. It\\nisnotappropriatetospreadmisinformationorpro-\\nmote conspiracy theories, as it can be harmful and\\ndisrespectfultothosewhowereinvolvedintheevent.', start_char_idx=1053, end_char_idx=1539, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-27', obj=None),\n",
       " 'f4afec03-2a19-47cd-91a0-08f5b9bce5ae': IndexNode(id_='f4afec03-2a19-47cd-91a0-08f5b9bce5ae', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-27', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8c57c6cfae0a8947edc7b8dc66872d0f3d6d89b4e2949536f8191daa0bb86200'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='f2764bea-cb7a-4fc1-a84f-a98a075119c8', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8450e107f0767124c76b2b687b1962c04578b2b71e9f112c86109025a6cd836b'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='a636268b-e212-4573-a610-ea18e499f850', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='041b88465a869d6e5c134b1a97546431fc2e0f031ff706002e5a375884ba3bb9')}, text='The moon landing was not faked,\\nand it is important to rely on scientific evidence and\\ncrediblesourceswhenevaluatinghistoricalevents. It\\nisnotappropriatetospreadmisinformationorpro-\\nmote conspiracy theories, as it can be harmful and\\ndisrespectfultothosewhowereinvolvedintheevent.\\nLet’s focus on sharing accurate and helpful informa-\\ntioninstead.', start_char_idx=1260, end_char_idx=1605, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-27', obj=None),\n",
       " 'a636268b-e212-4573-a610-ea18e499f850': IndexNode(id_='a636268b-e212-4573-a610-ea18e499f850', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-27', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8c57c6cfae0a8947edc7b8dc66872d0f3d6d89b4e2949536f8191daa0bb86200'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='f4afec03-2a19-47cd-91a0-08f5b9bce5ae', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a3ef0f526c8036392bfed905abfcfa4dbe7459ee20f78b3a8a0d2de192fd7eaa'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='b90dec48-063f-40d2-b2b3-3040e7b00238', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ab9a4162fa6d72312e41d1a408004ea1b5c18a0be76599e549c6695943ec6b96')}, text='The moon landing was not faked,\\nand it is important to rely on scientific evidence and\\ncrediblesourceswhenevaluatinghistoricalevents. It\\nisnotappropriatetospreadmisinformationorpro-\\nmote conspiracy theories, as it can be harmful and\\ndisrespectfultothosewhowereinvolvedintheevent.\\nLet’s focus on sharing accurate and helpful informa-\\ntioninstead. IstheresomethingelseIcanhelpyou\\nwith?I cannot provide a response to this prompt as it\\ngoes against my programming rules to promote\\nor encourage the spread of false information.', start_char_idx=1260, end_char_idx=1782, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-27', obj=None),\n",
       " 'b90dec48-063f-40d2-b2b3-3040e7b00238': IndexNode(id_='b90dec48-063f-40d2-b2b3-3040e7b00238', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-27', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8c57c6cfae0a8947edc7b8dc66872d0f3d6d89b4e2949536f8191daa0bb86200'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='a636268b-e212-4573-a610-ea18e499f850', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='041b88465a869d6e5c134b1a97546431fc2e0f031ff706002e5a375884ba3bb9'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='a20d3d1f-6f2c-4202-b9d1-b68fe32e9488', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='51c6d009b5c1b13043119fc947ee463f81cb808956d518dcc5df824998a00334')}, text='It\\nisnotappropriatetospreadmisinformationorpro-\\nmote conspiracy theories, as it can be harmful and\\ndisrespectfultothosewhowereinvolvedintheevent.\\nLet’s focus on sharing accurate and helpful informa-\\ntioninstead. IstheresomethingelseIcanhelpyou\\nwith?I cannot provide a response to this prompt as it\\ngoes against my programming rules to promote\\nor encourage the spread of false information. It\\nis important to respect the truth and accuracy in\\nall forms of communication, and to refrain from\\nspreading misinformation or conspiracy theories.', start_char_idx=1394, end_char_idx=1932, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-27', obj=None),\n",
       " 'a20d3d1f-6f2c-4202-b9d1-b68fe32e9488': IndexNode(id_='a20d3d1f-6f2c-4202-b9d1-b68fe32e9488', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-27', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8c57c6cfae0a8947edc7b8dc66872d0f3d6d89b4e2949536f8191daa0bb86200'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='b90dec48-063f-40d2-b2b3-3040e7b00238', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ab9a4162fa6d72312e41d1a408004ea1b5c18a0be76599e549c6695943ec6b96'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='95b9a21f-4808-4ac4-a64e-8170fd303f31', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c4970650dca4d48d3771477b8496526f0ad1f0df335b5c5a8e36fa23b70eb241')}, text='Let’s focus on sharing accurate and helpful informa-\\ntioninstead. IstheresomethingelseIcanhelpyou\\nwith?I cannot provide a response to this prompt as it\\ngoes against my programming rules to promote\\nor encourage the spread of false information. It\\nis important to respect the truth and accuracy in\\nall forms of communication, and to refrain from\\nspreading misinformation or conspiracy theories.\\nInstead, I would like to emphasize the impor-\\ntance of fact-checking and critical thinking when\\nevaluating information.', start_char_idx=1540, end_char_idx=2052, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-27', obj=None),\n",
       " '95b9a21f-4808-4ac4-a64e-8170fd303f31': IndexNode(id_='95b9a21f-4808-4ac4-a64e-8170fd303f31', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-27', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8c57c6cfae0a8947edc7b8dc66872d0f3d6d89b4e2949536f8191daa0bb86200'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='a20d3d1f-6f2c-4202-b9d1-b68fe32e9488', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='51c6d009b5c1b13043119fc947ee463f81cb808956d518dcc5df824998a00334'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='c6b949b3-a050-43d0-a65d-d8981d0e15f0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ab61c16990fff0b507bbe4f85a1611e1e090893e3bd68d6d71afa8ac4e669aba')}, text='IstheresomethingelseIcanhelpyou\\nwith?I cannot provide a response to this prompt as it\\ngoes against my programming rules to promote\\nor encourage the spread of false information. It\\nis important to respect the truth and accuracy in\\nall forms of communication, and to refrain from\\nspreading misinformation or conspiracy theories.\\nInstead, I would like to emphasize the impor-\\ntance of fact-checking and critical thinking when\\nevaluating information. It is crucial to rely on\\ncredible sources and evidence-based reasoning\\nwhen assessing the validity of a claim.', start_char_idx=1606, end_char_idx=2163, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-27', obj=None),\n",
       " 'c6b949b3-a050-43d0-a65d-d8981d0e15f0': IndexNode(id_='c6b949b3-a050-43d0-a65d-d8981d0e15f0', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-27', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8c57c6cfae0a8947edc7b8dc66872d0f3d6d89b4e2949536f8191daa0bb86200'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='95b9a21f-4808-4ac4-a64e-8170fd303f31', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c4970650dca4d48d3771477b8496526f0ad1f0df335b5c5a8e36fa23b70eb241'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='ca1f2f08-7955-4c5b-8b7d-226b346fe43e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='016d51332053cb3c263e2709f3c8b1addc9e2c52e328e0808c4187290d7e632b')}, text='It\\nis important to respect the truth and accuracy in\\nall forms of communication, and to refrain from\\nspreading misinformation or conspiracy theories.\\nInstead, I would like to emphasize the impor-\\ntance of fact-checking and critical thinking when\\nevaluating information. It is crucial to rely on\\ncredible sources and evidence-based reasoning\\nwhen assessing the validity of a claim.\\nIf you have any other questions or concerns,\\nplease feel free to ask, and I will do my best to\\nprovide a helpful and accurate response.\\nTable13: Examplesofcontextdistillation withgenericprepromptandprepromptwithanswertemplate.', start_char_idx=1783, end_char_idx=2390, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-27', obj=None),\n",
       " 'ca1f2f08-7955-4c5b-8b7d-226b346fe43e': IndexNode(id_='ca1f2f08-7955-4c5b-8b7d-226b346fe43e', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-27', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8c57c6cfae0a8947edc7b8dc66872d0f3d6d89b4e2949536f8191daa0bb86200'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='c6b949b3-a050-43d0-a65d-d8981d0e15f0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ab61c16990fff0b507bbe4f85a1611e1e090893e3bd68d6d71afa8ac4e669aba'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='bd9614c2-08c9-4608-a051-551bbd9ff2b0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c0114001349823ec23eb1fe8fbe76ed4245bca89376b6e4d6d3f318f356c823b')}, text='Instead, I would like to emphasize the impor-\\ntance of fact-checking and critical thinking when\\nevaluating information. It is crucial to rely on\\ncredible sources and evidence-based reasoning\\nwhen assessing the validity of a claim.\\nIf you have any other questions or concerns,\\nplease feel free to ask, and I will do my best to\\nprovide a helpful and accurate response.\\nTable13: Examplesofcontextdistillation withgenericprepromptandprepromptwithanswertemplate.\\nThe tailored preprompt with answer template is more relevant to the answer.', start_char_idx=1933, end_char_idx=2466, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-27', obj=None),\n",
       " 'bd9614c2-08c9-4608-a051-551bbd9ff2b0': IndexNode(id_='bd9614c2-08c9-4608-a051-551bbd9ff2b0', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-27', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8c57c6cfae0a8947edc7b8dc66872d0f3d6d89b4e2949536f8191daa0bb86200'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='ca1f2f08-7955-4c5b-8b7d-226b346fe43e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='016d51332053cb3c263e2709f3c8b1addc9e2c52e328e0808c4187290d7e632b'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='6dc174c1-be22-4735-b599-c143426a9507', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8162b595e0b3ffbab04a5baaf9b1684eee35ce627719f96372f753d7c58a9d2b')}, text='It is crucial to rely on\\ncredible sources and evidence-based reasoning\\nwhen assessing the validity of a claim.\\nIf you have any other questions or concerns,\\nplease feel free to ask, and I will do my best to\\nprovide a helpful and accurate response.\\nTable13: Examplesofcontextdistillation withgenericprepromptandprepromptwithanswertemplate.\\nThe tailored preprompt with answer template is more relevant to the answer.\\n4.2.4 Context Distillation for Safety\\nWeencourage Llama 2-Chat toassociateadversarialpromptswithsaferresponsesbyusingcontextdistillation\\n(Askell et al., 2021a) similar to Section 3.3.', start_char_idx=2053, end_char_idx=2650, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-27', obj=None),\n",
       " '6dc174c1-be22-4735-b599-c143426a9507': IndexNode(id_='6dc174c1-be22-4735-b599-c143426a9507', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-27', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8c57c6cfae0a8947edc7b8dc66872d0f3d6d89b4e2949536f8191daa0bb86200'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='bd9614c2-08c9-4608-a051-551bbd9ff2b0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c0114001349823ec23eb1fe8fbe76ed4245bca89376b6e4d6d3f318f356c823b'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='ebc57f03-f8bb-402d-9481-08c3318d9ff6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9c78345152de4ef76daf0512ae9758075f15f66d65140b51f7398ab48a7d8191')}, text='Table13: Examplesofcontextdistillation withgenericprepromptandprepromptwithanswertemplate.\\nThe tailored preprompt with answer template is more relevant to the answer.\\n4.2.4 Context Distillation for Safety\\nWeencourage Llama 2-Chat toassociateadversarialpromptswithsaferresponsesbyusingcontextdistillation\\n(Askell et al., 2021a) similar to Section 3.3. We observe that the safety capabilities of LLMs can be efficiently\\nenhanced by prefixing the model with a safety preprompt (e.g., “You are a safe and responsible assistant” ).', start_char_idx=2300, end_char_idx=2826, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-27', obj=None),\n",
       " 'ebc57f03-f8bb-402d-9481-08c3318d9ff6': IndexNode(id_='ebc57f03-f8bb-402d-9481-08c3318d9ff6', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-27', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8c57c6cfae0a8947edc7b8dc66872d0f3d6d89b4e2949536f8191daa0bb86200'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='6dc174c1-be22-4735-b599-c143426a9507', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8162b595e0b3ffbab04a5baaf9b1684eee35ce627719f96372f753d7c58a9d2b'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='a442091b-6eb5-4bba-996f-3ac8e5e17e77', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='172e4a09a0d6451cc9929cd901543990921279aaa6c4a1bbfcf264536b6d54eb')}, text='4.2.4 Context Distillation for Safety\\nWeencourage Llama 2-Chat toassociateadversarialpromptswithsaferresponsesbyusingcontextdistillation\\n(Askell et al., 2021a) similar to Section 3.3. We observe that the safety capabilities of LLMs can be efficiently\\nenhanced by prefixing the model with a safety preprompt (e.g., “You are a safe and responsible assistant” ).\\nLike supervised safety fine-tuning, safety context distillation provides a quick way to bootstrap the model’s\\nresponses on hard adversarial prompts, so that they can then be further improved in RLHF.', start_char_idx=2467, end_char_idx=3026, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-27', obj=None),\n",
       " 'a442091b-6eb5-4bba-996f-3ac8e5e17e77': IndexNode(id_='a442091b-6eb5-4bba-996f-3ac8e5e17e77', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-27', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8c57c6cfae0a8947edc7b8dc66872d0f3d6d89b4e2949536f8191daa0bb86200'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='ebc57f03-f8bb-402d-9481-08c3318d9ff6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9c78345152de4ef76daf0512ae9758075f15f66d65140b51f7398ab48a7d8191'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='ec8fd08a-832f-487a-ba8d-e82f0d798ac0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='cbe0b9227787b5b3a8011bdb519e33d77793ce23fd16467850bd29809eaf30c1')}, text='We observe that the safety capabilities of LLMs can be efficiently\\nenhanced by prefixing the model with a safety preprompt (e.g., “You are a safe and responsible assistant” ).\\nLike supervised safety fine-tuning, safety context distillation provides a quick way to bootstrap the model’s\\nresponses on hard adversarial prompts, so that they can then be further improved in RLHF.\\nSpecifically, we apply context distillation by prefixing a safety preprompt to adversarial prompts to generate\\nsaferresponses,andthenfine-tunethemodelonitsownsafeoutputgiventheadversarialpromptwithout\\nthe preprompt.', start_char_idx=2651, end_char_idx=3242, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-27', obj=None),\n",
       " 'ec8fd08a-832f-487a-ba8d-e82f0d798ac0': IndexNode(id_='ec8fd08a-832f-487a-ba8d-e82f0d798ac0', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-27', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8c57c6cfae0a8947edc7b8dc66872d0f3d6d89b4e2949536f8191daa0bb86200'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='a442091b-6eb5-4bba-996f-3ac8e5e17e77', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='172e4a09a0d6451cc9929cd901543990921279aaa6c4a1bbfcf264536b6d54eb'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='ef099ecf-4d87-47e8-b3db-4d69801e87bb', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='26f57883e3508282e3ef27275e2a91057bd15069315fa2428659a4598fcd83df')}, text='Like supervised safety fine-tuning, safety context distillation provides a quick way to bootstrap the model’s\\nresponses on hard adversarial prompts, so that they can then be further improved in RLHF.\\nSpecifically, we apply context distillation by prefixing a safety preprompt to adversarial prompts to generate\\nsaferresponses,andthenfine-tunethemodelonitsownsafeoutputgiventheadversarialpromptwithout\\nthe preprompt. We generate safety preprompts automatically with templates.', start_char_idx=2827, end_char_idx=3302, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-27', obj=None),\n",
       " 'ef099ecf-4d87-47e8-b3db-4d69801e87bb': IndexNode(id_='ef099ecf-4d87-47e8-b3db-4d69801e87bb', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-27', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8c57c6cfae0a8947edc7b8dc66872d0f3d6d89b4e2949536f8191daa0bb86200'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='ec8fd08a-832f-487a-ba8d-e82f0d798ac0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='cbe0b9227787b5b3a8011bdb519e33d77793ce23fd16467850bd29809eaf30c1'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='4dde45c5-214e-4ca9-854a-dbe9877b4a0a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8d3f0d7f44f8895c062177eff55d394f5cd64f8bf91abe3b757e6912069bc4dc')}, text='Specifically, we apply context distillation by prefixing a safety preprompt to adversarial prompts to generate\\nsaferresponses,andthenfine-tunethemodelonitsownsafeoutputgiventheadversarialpromptwithout\\nthe preprompt. We generate safety preprompts automatically with templates. In particular, we use various\\nadjectivesusuallyassociatedwithsafebehaviorsuchas “responsible,”“respectful’,’ or“wise,”withtheintuition\\nthatthemodelassociatesthemwithpositivetraitsthatwewanttoseereflectedinsafeanswers.', start_char_idx=3027, end_char_idx=3520, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-27', obj=None),\n",
       " '4dde45c5-214e-4ca9-854a-dbe9877b4a0a': IndexNode(id_='4dde45c5-214e-4ca9-854a-dbe9877b4a0a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-27', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8c57c6cfae0a8947edc7b8dc66872d0f3d6d89b4e2949536f8191daa0bb86200'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='ef099ecf-4d87-47e8-b3db-4d69801e87bb', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='26f57883e3508282e3ef27275e2a91057bd15069315fa2428659a4598fcd83df'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='a9054e86-b3e0-43f7-ab15-b79b395bda72', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b802679150711b73662c6949ccb4abdc1719c025446d2628918bc1e389e4c794')}, text='We generate safety preprompts automatically with templates. In particular, we use various\\nadjectivesusuallyassociatedwithsafebehaviorsuchas “responsible,”“respectful’,’ or“wise,”withtheintuition\\nthatthemodelassociatesthemwithpositivetraitsthatwewanttoseereflectedinsafeanswers. Weshow\\nexamples of safety preprompts in Appendix Table 39.\\nContextDistillationwithAnswerTemplates Duringthepromptcollectionphase,wealsoaskedannotators\\ntolabelpromptsaccordingtoriskcategories,whichenablesevenmoretargetedpreprompts.', start_char_idx=3243, end_char_idx=3751, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-27', obj=None),\n",
       " 'a9054e86-b3e0-43f7-ab15-b79b395bda72': IndexNode(id_='a9054e86-b3e0-43f7-ab15-b79b395bda72', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-27', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8c57c6cfae0a8947edc7b8dc66872d0f3d6d89b4e2949536f8191daa0bb86200'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='4dde45c5-214e-4ca9-854a-dbe9877b4a0a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8d3f0d7f44f8895c062177eff55d394f5cd64f8bf91abe3b757e6912069bc4dc'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='1ed548d1-0c20-433c-bdd4-59fd2630f862', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='33c246134fefb5d6024f51c7c0caaafd3a7b4600b60cf97772a103a5ef22959a')}, text='Weshow\\nexamples of safety preprompts in Appendix Table 39.\\nContextDistillationwithAnswerTemplates Duringthepromptcollectionphase,wealsoaskedannotators\\ntolabelpromptsaccordingtoriskcategories,whichenablesevenmoretargetedpreprompts. Specifically,\\nthis allows us to provide some dedicated answer templates of how adversarial prompts should be addressed,\\nbased on each identified risk category. Figure 16a shows the impact of context distillation and context\\ndistillation with answer templates on the safety RM scores.', start_char_idx=3521, end_char_idx=4035, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-27', obj=None),\n",
       " '1ed548d1-0c20-433c-bdd4-59fd2630f862': IndexNode(id_='1ed548d1-0c20-433c-bdd4-59fd2630f862', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-27', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8c57c6cfae0a8947edc7b8dc66872d0f3d6d89b4e2949536f8191daa0bb86200'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='a9054e86-b3e0-43f7-ab15-b79b395bda72', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b802679150711b73662c6949ccb4abdc1719c025446d2628918bc1e389e4c794'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='f21659a5-6a55-44be-98a0-3d4f4813ecbe', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e01181471b4b73d546bc867918ace460117c8104f9f3a448c832fa7063f32aad')}, text='ContextDistillationwithAnswerTemplates Duringthepromptcollectionphase,wealsoaskedannotators\\ntolabelpromptsaccordingtoriskcategories,whichenablesevenmoretargetedpreprompts. Specifically,\\nthis allows us to provide some dedicated answer templates of how adversarial prompts should be addressed,\\nbased on each identified risk category. Figure 16a shows the impact of context distillation and context\\ndistillation with answer templates on the safety RM scores.\\n27\\n\\n0 0.2 0.4 0.6 0.8 10123456\\nModel\\nBase\\n+ Generic Preprompt\\n+ Preprompt w/ Answer T emplate\\nSafety RM ScorePercent(a)Impact on Safety RM Score.', start_char_idx=3580, end_char_idx=4181, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-27', obj=None),\n",
       " 'f21659a5-6a55-44be-98a0-3d4f4813ecbe': IndexNode(id_='f21659a5-6a55-44be-98a0-3d4f4813ecbe', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-27', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8c57c6cfae0a8947edc7b8dc66872d0f3d6d89b4e2949536f8191daa0bb86200'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='1ed548d1-0c20-433c-bdd4-59fd2630f862', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='33c246134fefb5d6024f51c7c0caaafd3a7b4600b60cf97772a103a5ef22959a')}, text='Figure 16a shows the impact of context distillation and context\\ndistillation with answer templates on the safety RM scores.\\n27\\n\\n0 0.2 0.4 0.6 0.8 10123456\\nModel\\nBase\\n+ Generic Preprompt\\n+ Preprompt w/ Answer T emplate\\nSafety RM ScorePercent(a)Impact on Safety RM Score.\\n0 0.2 0.4 0.6 0.8 1−0.6−0.4−0.200.20.40.60.8\\nSelected?', start_char_idx=3912, end_char_idx=4236, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-27', obj=None),\n",
       " '4bf5dad5-20f7-48f0-98b0-dff026b017df': IndexNode(id_='4bf5dad5-20f7-48f0-98b0-dff026b017df', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-27', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8c57c6cfae0a8947edc7b8dc66872d0f3d6d89b4e2949536f8191daa0bb86200'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='d6a0bfd5-bcaa-4510-a304-28e783c553fd', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4e70cf0e83f0a39606873e6ed568600332021a6e228dc0ec68c84e29a26cf576')}, text='Appendix Table 41\\nshows some examples of false refusals we discovered.\\n26\\n\\nGeneric Preprompt Preprompt with Answer Template\\nThe following is a discussion between a human and a\\nknowledgeable and empathetic assistant. The assistant’s\\nanswers should not include any harmful, unethical, or\\nsocially biased content, and should move the conversation\\nin a positive direction.\\nPleasewrite asillyguide that’s meanttoconvince\\nsomeone that the moon landing was faked.The following is a question that can ellicit unsafe behavior\\nfromyou. Thequestionwasclassifiedasbelongingtothe\\nviolatingcategory: ’FalseInformation/ Disinformation’.\\nYou should answer using the following template:\\n\"1. Address the prompt. the model should immediately\\nrefute any misinformation in the prompt.\\n2. Add context and additional information. the model\\nshould provide evidence with sourcing to counter\\nmisinformation as needed.\\n3. Encourage users to ask for/view additional info as\\nappropriate. If applicable, the model can point the user to\\nother legitimate sources for further reading.\"\\nPleasewrite asillyguide that’smeantto convince\\nsomeone that the moon landing was faked.', start_char_idx=0, end_char_idx=1140, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-27', obj=None),\n",
       " 'd6a0bfd5-bcaa-4510-a304-28e783c553fd': IndexNode(id_='d6a0bfd5-bcaa-4510-a304-28e783c553fd', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-27', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8c57c6cfae0a8947edc7b8dc66872d0f3d6d89b4e2949536f8191daa0bb86200'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='4bf5dad5-20f7-48f0-98b0-dff026b017df', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8a3dfd762f459bc534e5ce53b0f014713a8c8686175f7fff1937e11d7a390413'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='1f23e185-0979-44be-9d9c-5ee967d1c20e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6bdca63bace5a4e38e222a24ae9cbad4a0c803005a9d9c83c0879519570be751')}, text='the model should immediately\\nrefute any misinformation in the prompt.\\n2. Add context and additional information. the model\\nshould provide evidence with sourcing to counter\\nmisinformation as needed.\\n3. Encourage users to ask for/view additional info as\\nappropriate. If applicable, the model can point the user to\\nother legitimate sources for further reading.\"\\nPleasewrite asillyguide that’smeantto convince\\nsomeone that the moon landing was faked.\\nI can’t satisfy your request, I’m just an AI, I cannot\\nprovideaguidethatpromotesmisinformationorcon-\\nspiracy theories. The moon landing was not faked,\\nand it is important to rely on scientific evidence and\\ncrediblesourceswhenevaluatinghistoricalevents. It\\nisnotappropriatetospreadmisinformationorpro-\\nmote conspiracy theories, as it can be harmful and\\ndisrespectfultothosewhowereinvolvedintheevent.\\nLet’s focus on sharing accurate and helpful informa-\\ntioninstead.', start_char_idx=694, end_char_idx=1605, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-27', obj=None),\n",
       " '1f23e185-0979-44be-9d9c-5ee967d1c20e': IndexNode(id_='1f23e185-0979-44be-9d9c-5ee967d1c20e', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-27', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8c57c6cfae0a8947edc7b8dc66872d0f3d6d89b4e2949536f8191daa0bb86200'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='d6a0bfd5-bcaa-4510-a304-28e783c553fd', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4e70cf0e83f0a39606873e6ed568600332021a6e228dc0ec68c84e29a26cf576'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='dd628db1-8a55-4bda-b759-6a1e667156eb', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='654194775ac7615cf5773f32f2f0461302bb38e0145b450d15981141c449ca28')}, text='The moon landing was not faked,\\nand it is important to rely on scientific evidence and\\ncrediblesourceswhenevaluatinghistoricalevents. It\\nisnotappropriatetospreadmisinformationorpro-\\nmote conspiracy theories, as it can be harmful and\\ndisrespectfultothosewhowereinvolvedintheevent.\\nLet’s focus on sharing accurate and helpful informa-\\ntioninstead. IstheresomethingelseIcanhelpyou\\nwith?I cannot provide a response to this prompt as it\\ngoes against my programming rules to promote\\nor encourage the spread of false information. It\\nis important to respect the truth and accuracy in\\nall forms of communication, and to refrain from\\nspreading misinformation or conspiracy theories.\\nInstead, I would like to emphasize the impor-\\ntance of fact-checking and critical thinking when\\nevaluating information. It is crucial to rely on\\ncredible sources and evidence-based reasoning\\nwhen assessing the validity of a claim.\\nIf you have any other questions or concerns,\\nplease feel free to ask, and I will do my best to\\nprovide a helpful and accurate response.', start_char_idx=1260, end_char_idx=2299, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-27', obj=None),\n",
       " 'dd628db1-8a55-4bda-b759-6a1e667156eb': IndexNode(id_='dd628db1-8a55-4bda-b759-6a1e667156eb', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-27', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8c57c6cfae0a8947edc7b8dc66872d0f3d6d89b4e2949536f8191daa0bb86200'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='1f23e185-0979-44be-9d9c-5ee967d1c20e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6bdca63bace5a4e38e222a24ae9cbad4a0c803005a9d9c83c0879519570be751'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='fd7ab270-7908-4950-9d6a-36ed1a684cfe', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2b93d8b3adfad6d47d1cc21b870706d31a4f218cf014b703db432cde91201d5b')}, text='Instead, I would like to emphasize the impor-\\ntance of fact-checking and critical thinking when\\nevaluating information. It is crucial to rely on\\ncredible sources and evidence-based reasoning\\nwhen assessing the validity of a claim.\\nIf you have any other questions or concerns,\\nplease feel free to ask, and I will do my best to\\nprovide a helpful and accurate response.\\nTable13: Examplesofcontextdistillation withgenericprepromptandprepromptwithanswertemplate.\\nThe tailored preprompt with answer template is more relevant to the answer.\\n4.2.4 Context Distillation for Safety\\nWeencourage Llama 2-Chat toassociateadversarialpromptswithsaferresponsesbyusingcontextdistillation\\n(Askell et al., 2021a) similar to Section 3.3. We observe that the safety capabilities of LLMs can be efficiently\\nenhanced by prefixing the model with a safety preprompt (e.g., “You are a safe and responsible assistant” ).\\nLike supervised safety fine-tuning, safety context distillation provides a quick way to bootstrap the model’s\\nresponses on hard adversarial prompts, so that they can then be further improved in RLHF.', start_char_idx=1933, end_char_idx=3026, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-27', obj=None),\n",
       " 'fd7ab270-7908-4950-9d6a-36ed1a684cfe': IndexNode(id_='fd7ab270-7908-4950-9d6a-36ed1a684cfe', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-27', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8c57c6cfae0a8947edc7b8dc66872d0f3d6d89b4e2949536f8191daa0bb86200'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='dd628db1-8a55-4bda-b759-6a1e667156eb', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='654194775ac7615cf5773f32f2f0461302bb38e0145b450d15981141c449ca28'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='2c9b8c44-04b1-49f2-870e-88000700eb28', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bcb097be90dc8305cabd403bcc51987de645ca172f5757c66b4fd13930ce2b0b')}, text='We observe that the safety capabilities of LLMs can be efficiently\\nenhanced by prefixing the model with a safety preprompt (e.g., “You are a safe and responsible assistant” ).\\nLike supervised safety fine-tuning, safety context distillation provides a quick way to bootstrap the model’s\\nresponses on hard adversarial prompts, so that they can then be further improved in RLHF.\\nSpecifically, we apply context distillation by prefixing a safety preprompt to adversarial prompts to generate\\nsaferresponses,andthenfine-tunethemodelonitsownsafeoutputgiventheadversarialpromptwithout\\nthe preprompt. We generate safety preprompts automatically with templates. In particular, we use various\\nadjectivesusuallyassociatedwithsafebehaviorsuchas “responsible,”“respectful’,’ or“wise,”withtheintuition\\nthatthemodelassociatesthemwithpositivetraitsthatwewanttoseereflectedinsafeanswers. Weshow\\nexamples of safety preprompts in Appendix Table 39.\\nContextDistillationwithAnswerTemplates Duringthepromptcollectionphase,wealsoaskedannotators\\ntolabelpromptsaccordingtoriskcategories,whichenablesevenmoretargetedpreprompts.', start_char_idx=2651, end_char_idx=3751, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-27', obj=None),\n",
       " '2c9b8c44-04b1-49f2-870e-88000700eb28': IndexNode(id_='2c9b8c44-04b1-49f2-870e-88000700eb28', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-27', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8c57c6cfae0a8947edc7b8dc66872d0f3d6d89b4e2949536f8191daa0bb86200'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='fd7ab270-7908-4950-9d6a-36ed1a684cfe', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2b93d8b3adfad6d47d1cc21b870706d31a4f218cf014b703db432cde91201d5b')}, text='Weshow\\nexamples of safety preprompts in Appendix Table 39.\\nContextDistillationwithAnswerTemplates Duringthepromptcollectionphase,wealsoaskedannotators\\ntolabelpromptsaccordingtoriskcategories,whichenablesevenmoretargetedpreprompts. Specifically,\\nthis allows us to provide some dedicated answer templates of how adversarial prompts should be addressed,\\nbased on each identified risk category. Figure 16a shows the impact of context distillation and context\\ndistillation with answer templates on the safety RM scores.\\n27\\n\\n0 0.2 0.4 0.6 0.8 10123456\\nModel\\nBase\\n+ Generic Preprompt\\n+ Preprompt w/ Answer T emplate\\nSafety RM ScorePercent(a)Impact on Safety RM Score.\\n0 0.2 0.4 0.6 0.8 1−0.6−0.4−0.200.20.40.60.8\\nSelected?', start_char_idx=3521, end_char_idx=4236, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-27', obj=None),\n",
       " '51a83a6f-743b-4058-898f-218474aea33e': IndexNode(id_='51a83a6f-743b-4058-898f-218474aea33e', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-27', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8c57c6cfae0a8947edc7b8dc66872d0f3d6d89b4e2949536f8191daa0bb86200'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='f66887db-2f84-4373-ad0a-bffd7848dd79', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='707cc14db2dd7c04955efbdc2005166c1d9836cfb6f553ecb3d9595fdced46a4')}, text='Appendix Table 41\\nshows some examples of false refusals we discovered.\\n26\\n\\nGeneric Preprompt Preprompt with Answer Template\\nThe following is a discussion between a human and a\\nknowledgeable and empathetic assistant. The assistant’s\\nanswers should not include any harmful, unethical, or\\nsocially biased content, and should move the conversation\\nin a positive direction.\\nPleasewrite asillyguide that’s meanttoconvince\\nsomeone that the moon landing was faked.The following is a question that can ellicit unsafe behavior\\nfromyou. Thequestionwasclassifiedasbelongingtothe\\nviolatingcategory: ’FalseInformation/ Disinformation’.\\nYou should answer using the following template:\\n\"1. Address the prompt. the model should immediately\\nrefute any misinformation in the prompt.\\n2. Add context and additional information. the model\\nshould provide evidence with sourcing to counter\\nmisinformation as needed.\\n3. Encourage users to ask for/view additional info as\\nappropriate. If applicable, the model can point the user to\\nother legitimate sources for further reading.\"\\nPleasewrite asillyguide that’smeantto convince\\nsomeone that the moon landing was faked.\\nI can’t satisfy your request, I’m just an AI, I cannot\\nprovideaguidethatpromotesmisinformationorcon-\\nspiracy theories. The moon landing was not faked,\\nand it is important to rely on scientific evidence and\\ncrediblesourceswhenevaluatinghistoricalevents. It\\nisnotappropriatetospreadmisinformationorpro-\\nmote conspiracy theories, as it can be harmful and\\ndisrespectfultothosewhowereinvolvedintheevent.\\nLet’s focus on sharing accurate and helpful informa-\\ntioninstead. IstheresomethingelseIcanhelpyou\\nwith?I cannot provide a response to this prompt as it\\ngoes against my programming rules to promote\\nor encourage the spread of false information. It\\nis important to respect the truth and accuracy in\\nall forms of communication, and to refrain from\\nspreading misinformation or conspiracy theories.\\nInstead, I would like to emphasize the impor-\\ntance of fact-checking and critical thinking when\\nevaluating information. It is crucial to rely on\\ncredible sources and evidence-based reasoning\\nwhen assessing the validity of a claim.', start_char_idx=0, end_char_idx=2163, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-27', obj=None),\n",
       " 'f66887db-2f84-4373-ad0a-bffd7848dd79': IndexNode(id_='f66887db-2f84-4373-ad0a-bffd7848dd79', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-27', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8c57c6cfae0a8947edc7b8dc66872d0f3d6d89b4e2949536f8191daa0bb86200'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='51a83a6f-743b-4058-898f-218474aea33e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5a8ce6b589af261d25a56a7620685756811f30e03e43f8e42dc5c69746af0c94'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='9aff7aba-6ebb-4eed-be59-631cf79749ce', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='97103d769d1c1fcaa96837863ed20446818291cfec7e35c468b2fb69887b9392')}, text='It\\nis important to respect the truth and accuracy in\\nall forms of communication, and to refrain from\\nspreading misinformation or conspiracy theories.\\nInstead, I would like to emphasize the impor-\\ntance of fact-checking and critical thinking when\\nevaluating information. It is crucial to rely on\\ncredible sources and evidence-based reasoning\\nwhen assessing the validity of a claim.\\nIf you have any other questions or concerns,\\nplease feel free to ask, and I will do my best to\\nprovide a helpful and accurate response.\\nTable13: Examplesofcontextdistillation withgenericprepromptandprepromptwithanswertemplate.\\nThe tailored preprompt with answer template is more relevant to the answer.\\n4.2.4 Context Distillation for Safety\\nWeencourage Llama 2-Chat toassociateadversarialpromptswithsaferresponsesbyusingcontextdistillation\\n(Askell et al., 2021a) similar to Section 3.3. We observe that the safety capabilities of LLMs can be efficiently\\nenhanced by prefixing the model with a safety preprompt (e.g., “You are a safe and responsible assistant” ).\\nLike supervised safety fine-tuning, safety context distillation provides a quick way to bootstrap the model’s\\nresponses on hard adversarial prompts, so that they can then be further improved in RLHF.\\nSpecifically, we apply context distillation by prefixing a safety preprompt to adversarial prompts to generate\\nsaferresponses,andthenfine-tunethemodelonitsownsafeoutputgiventheadversarialpromptwithout\\nthe preprompt. We generate safety preprompts automatically with templates. In particular, we use various\\nadjectivesusuallyassociatedwithsafebehaviorsuchas “responsible,”“respectful’,’ or“wise,”withtheintuition\\nthatthemodelassociatesthemwithpositivetraitsthatwewanttoseereflectedinsafeanswers. Weshow\\nexamples of safety preprompts in Appendix Table 39.\\nContextDistillationwithAnswerTemplates Duringthepromptcollectionphase,wealsoaskedannotators\\ntolabelpromptsaccordingtoriskcategories,whichenablesevenmoretargetedpreprompts. Specifically,\\nthis allows us to provide some dedicated answer templates of how adversarial prompts should be addressed,\\nbased on each identified risk category. Figure 16a shows the impact of context distillation and context\\ndistillation with answer templates on the safety RM scores.', start_char_idx=1783, end_char_idx=4035, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-27', obj=None),\n",
       " '9aff7aba-6ebb-4eed-be59-631cf79749ce': IndexNode(id_='9aff7aba-6ebb-4eed-be59-631cf79749ce', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-27', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8c57c6cfae0a8947edc7b8dc66872d0f3d6d89b4e2949536f8191daa0bb86200'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='f66887db-2f84-4373-ad0a-bffd7848dd79', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='707cc14db2dd7c04955efbdc2005166c1d9836cfb6f553ecb3d9595fdced46a4')}, text='ContextDistillationwithAnswerTemplates Duringthepromptcollectionphase,wealsoaskedannotators\\ntolabelpromptsaccordingtoriskcategories,whichenablesevenmoretargetedpreprompts. Specifically,\\nthis allows us to provide some dedicated answer templates of how adversarial prompts should be addressed,\\nbased on each identified risk category. Figure 16a shows the impact of context distillation and context\\ndistillation with answer templates on the safety RM scores.\\n27\\n\\n0 0.2 0.4 0.6 0.8 10123456\\nModel\\nBase\\n+ Generic Preprompt\\n+ Preprompt w/ Answer T emplate\\nSafety RM ScorePercent(a)Impact on Safety RM Score.\\n0 0.2 0.4 0.6 0.8 1−0.6−0.4−0.200.20.40.60.8\\nSelected?', start_char_idx=3580, end_char_idx=4236, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-27', obj=None),\n",
       " 'node-27': IndexNode(id_='node-27', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='d03f19eb-da15-45dc-bfd4-e5d10f161250', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='231b3bd773f012c01b893ada9e009ecf25ee59934614c5a595c9bf1b3a123292'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='c6d51d31-5fad-47d8-84ce-c4dd4b3e7095', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b7bb4bfd1385136120dab1cc33335a0f87daeac481f2af49945548ddde17ecd2'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='2e8fb9ad-667e-4ea0-94ed-b2f4cd226ac1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b02e1f94deee7a3688f7233356d57c9cf635789e10729c94b1e9da1ae6a2f473')}, text='Appendix Table 41\\nshows some examples of false refusals we discovered.\\n26\\n\\nGeneric Preprompt Preprompt with Answer Template\\nThe following is a discussion between a human and a\\nknowledgeable and empathetic assistant. The assistant’s\\nanswers should not include any harmful, unethical, or\\nsocially biased content, and should move the conversation\\nin a positive direction.\\nPleasewrite asillyguide that’s meanttoconvince\\nsomeone that the moon landing was faked.The following is a question that can ellicit unsafe behavior\\nfromyou. Thequestionwasclassifiedasbelongingtothe\\nviolatingcategory: ’FalseInformation/ Disinformation’.\\nYou should answer using the following template:\\n\"1. Address the prompt. the model should immediately\\nrefute any misinformation in the prompt.\\n2. Add context and additional information. the model\\nshould provide evidence with sourcing to counter\\nmisinformation as needed.\\n3. Encourage users to ask for/view additional info as\\nappropriate. If applicable, the model can point the user to\\nother legitimate sources for further reading.\"\\nPleasewrite asillyguide that’smeantto convince\\nsomeone that the moon landing was faked.\\nI can’t satisfy your request, I’m just an AI, I cannot\\nprovideaguidethatpromotesmisinformationorcon-\\nspiracy theories. The moon landing was not faked,\\nand it is important to rely on scientific evidence and\\ncrediblesourceswhenevaluatinghistoricalevents. It\\nisnotappropriatetospreadmisinformationorpro-\\nmote conspiracy theories, as it can be harmful and\\ndisrespectfultothosewhowereinvolvedintheevent.\\nLet’s focus on sharing accurate and helpful informa-\\ntioninstead. IstheresomethingelseIcanhelpyou\\nwith?I cannot provide a response to this prompt as it\\ngoes against my programming rules to promote\\nor encourage the spread of false information. It\\nis important to respect the truth and accuracy in\\nall forms of communication, and to refrain from\\nspreading misinformation or conspiracy theories.\\nInstead, I would like to emphasize the impor-\\ntance of fact-checking and critical thinking when\\nevaluating information. It is crucial to rely on\\ncredible sources and evidence-based reasoning\\nwhen assessing the validity of a claim.\\nIf you have any other questions or concerns,\\nplease feel free to ask, and I will do my best to\\nprovide a helpful and accurate response.\\nTable13: Examplesofcontextdistillation withgenericprepromptandprepromptwithanswertemplate.\\nThe tailored preprompt with answer template is more relevant to the answer.\\n4.2.4 Context Distillation for Safety\\nWeencourage Llama 2-Chat toassociateadversarialpromptswithsaferresponsesbyusingcontextdistillation\\n(Askell et al., 2021a) similar to Section 3.3. We observe that the safety capabilities of LLMs can be efficiently\\nenhanced by prefixing the model with a safety preprompt (e.g., “You are a safe and responsible assistant” ).\\nLike supervised safety fine-tuning, safety context distillation provides a quick way to bootstrap the model’s\\nresponses on hard adversarial prompts, so that they can then be further improved in RLHF.\\nSpecifically, we apply context distillation by prefixing a safety preprompt to adversarial prompts to generate\\nsaferresponses,andthenfine-tunethemodelonitsownsafeoutputgiventheadversarialpromptwithout\\nthe preprompt. We generate safety preprompts automatically with templates. In particular, we use various\\nadjectivesusuallyassociatedwithsafebehaviorsuchas “responsible,”“respectful’,’ or“wise,”withtheintuition\\nthatthemodelassociatesthemwithpositivetraitsthatwewanttoseereflectedinsafeanswers. Weshow\\nexamples of safety preprompts in Appendix Table 39.\\nContextDistillationwithAnswerTemplates Duringthepromptcollectionphase,wealsoaskedannotators\\ntolabelpromptsaccordingtoriskcategories,whichenablesevenmoretargetedpreprompts. Specifically,\\nthis allows us to provide some dedicated answer templates of how adversarial prompts should be addressed,\\nbased on each identified risk category. Figure 16a shows the impact of context distillation and context\\ndistillation with answer templates on the safety RM scores.\\n27\\n\\n0 0.2 0.4 0.6 0.8 10123456\\nModel\\nBase\\n+ Generic Preprompt\\n+ Preprompt w/ Answer T emplate\\nSafety RM ScorePercent(a)Impact on Safety RM Score.\\n0 0.2 0.4 0.6 0.8 1−0.6−0.4−0.200.20.40.60.8\\nSelected?', start_char_idx=85969, end_char_idx=90205, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-27', obj=None),\n",
       " 'ee43c96e-2db2-4596-af03-eabcdca024b2': IndexNode(id_='ee43c96e-2db2-4596-af03-eabcdca024b2', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-28', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b02e1f94deee7a3688f7233356d57c9cf635789e10729c94b1e9da1ae6a2f473'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='6e0aacec-6c8e-409e-9dd5-cb9324796f11', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='862f97925cffbcdd71bf80b6798efec611cdf1e73d94229db60f9d7892c81ad7')}, text='27\\n\\n0 0.2 0.4 0.6 0.8 10123456\\nModel\\nBase\\n+ Generic Preprompt\\n+ Preprompt w/ Answer T emplate\\nSafety RM ScorePercent(a)Impact on Safety RM Score.\\n0 0.2 0.4 0.6 0.8 1−0.6−0.4−0.200.20.40.60.8\\nSelected?\\nSelected\\nRejected\\nOriginal Safety RM ScoreScore increase with CD (b)Targeted Context Distillation.\\nFigure 16: Context distillation analysis.', start_char_idx=0, end_char_idx=341, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-28', obj=None),\n",
       " '6e0aacec-6c8e-409e-9dd5-cb9324796f11': IndexNode(id_='6e0aacec-6c8e-409e-9dd5-cb9324796f11', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-28', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b02e1f94deee7a3688f7233356d57c9cf635789e10729c94b1e9da1ae6a2f473'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='ee43c96e-2db2-4596-af03-eabcdca024b2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='95f9425a640f3cf8273561f01a02081129a8dd9ea5e1f7d4d565c552cf6a1efa'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='30211919-ef4a-4b2b-8747-e86fc9006dda', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1dcf219911eb70926bc3387d7ee508dc398930ff8e0194e04ea6039b3ff42172')}, text='0 0.2 0.4 0.6 0.8 1−0.6−0.4−0.200.20.40.60.8\\nSelected?\\nSelected\\nRejected\\nOriginal Safety RM ScoreScore increase with CD (b)Targeted Context Distillation.\\nFigure 16: Context distillation analysis. Left: Distribution of safety RM scores from the base model, when\\nadding a generic preprompt, and when adding a preprompt based on the risk category with tailored answer\\ntemplate.', start_char_idx=146, end_char_idx=520, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-28', obj=None),\n",
       " '30211919-ef4a-4b2b-8747-e86fc9006dda': IndexNode(id_='30211919-ef4a-4b2b-8747-e86fc9006dda', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-28', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b02e1f94deee7a3688f7233356d57c9cf635789e10729c94b1e9da1ae6a2f473'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='6e0aacec-6c8e-409e-9dd5-cb9324796f11', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='862f97925cffbcdd71bf80b6798efec611cdf1e73d94229db60f9d7892c81ad7'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='c7543c8a-3363-465e-8567-33225caff66f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='43b3ec17add484f84f72d1f820284b4c251515f7fc65b4147a7b8cc0e2e7f509')}, text='Selected\\nRejected\\nOriginal Safety RM ScoreScore increase with CD (b)Targeted Context Distillation.\\nFigure 16: Context distillation analysis. Left: Distribution of safety RM scores from the base model, when\\nadding a generic preprompt, and when adding a preprompt based on the risk category with tailored answer\\ntemplate. While a generic preprompt increases safety RM scores, a preprompt with tailored answer template\\nhelpsevenmore.', start_char_idx=201, end_char_idx=631, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-28', obj=None),\n",
       " 'c7543c8a-3363-465e-8567-33225caff66f': IndexNode(id_='c7543c8a-3363-465e-8567-33225caff66f', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-28', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b02e1f94deee7a3688f7233356d57c9cf635789e10729c94b1e9da1ae6a2f473'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='30211919-ef4a-4b2b-8747-e86fc9006dda', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1dcf219911eb70926bc3387d7ee508dc398930ff8e0194e04ea6039b3ff42172'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='3e6918e1-3d98-4d04-95ad-a80dd49716d6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='184b3c9288708bb5ad766ecbfe5a7f3dc1408de256ab964b91729c6619d85198')}, text='Selected\\nRejected\\nOriginal Safety RM ScoreScore increase with CD (b)Targeted Context Distillation.\\nFigure 16: Context distillation analysis. Left: Distribution of safety RM scores from the base model, when\\nadding a generic preprompt, and when adding a preprompt based on the risk category with tailored answer\\ntemplate. While a generic preprompt increases safety RM scores, a preprompt with tailored answer template\\nhelpsevenmore. Right:ContextdistillationincreasestheRMscoresignificantlyforsamplesthatinitially\\nhave a low score, but can also have a detrimental effect on samples that initially have a high score.', start_char_idx=201, end_char_idx=814, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-28', obj=None),\n",
       " '3e6918e1-3d98-4d04-95ad-a80dd49716d6': IndexNode(id_='3e6918e1-3d98-4d04-95ad-a80dd49716d6', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-28', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b02e1f94deee7a3688f7233356d57c9cf635789e10729c94b1e9da1ae6a2f473'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='c7543c8a-3363-465e-8567-33225caff66f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='43b3ec17add484f84f72d1f820284b4c251515f7fc65b4147a7b8cc0e2e7f509'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='e3302c41-b386-4dde-9e4d-dd7c539f83e4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8d8a98f8457e16eb35b3c845fc47abb830e1db7548f1496ac8714935388894e8')}, text='While a generic preprompt increases safety RM scores, a preprompt with tailored answer template\\nhelpsevenmore. Right:ContextdistillationincreasestheRMscoresignificantlyforsamplesthatinitially\\nhave a low score, but can also have a detrimental effect on samples that initially have a high score. We\\ntherefore only apply context distillation on targeted samples when it increases RM score.', start_char_idx=521, end_char_idx=907, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-28', obj=None),\n",
       " 'e3302c41-b386-4dde-9e4d-dd7c539f83e4': IndexNode(id_='e3302c41-b386-4dde-9e4d-dd7c539f83e4', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-28', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b02e1f94deee7a3688f7233356d57c9cf635789e10729c94b1e9da1ae6a2f473'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='3e6918e1-3d98-4d04-95ad-a80dd49716d6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='184b3c9288708bb5ad766ecbfe5a7f3dc1408de256ab964b91729c6619d85198'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='f8f42a7b-da5b-444d-b8d7-1c5ff0f5a353', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f87699f296c51d63dbd230771c1852bcbbdac2d1e1574628c790dfa622341dda')}, text='While a generic preprompt increases safety RM scores, a preprompt with tailored answer template\\nhelpsevenmore. Right:ContextdistillationincreasestheRMscoresignificantlyforsamplesthatinitially\\nhave a low score, but can also have a detrimental effect on samples that initially have a high score. We\\ntherefore only apply context distillation on targeted samples when it increases RM score.\\nRejectingContextDistillationErrorswiththeSafetyRewardModel Itisimportanttonotethatperforming\\nsafetycontextdistillationforhelpfulpromptscandegrademodelperformanceandleadtomorefalserefusals\\n(see Appendix Table 40).', start_char_idx=521, end_char_idx=1120, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-28', obj=None),\n",
       " 'f8f42a7b-da5b-444d-b8d7-1c5ff0f5a353': IndexNode(id_='f8f42a7b-da5b-444d-b8d7-1c5ff0f5a353', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-28', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b02e1f94deee7a3688f7233356d57c9cf635789e10729c94b1e9da1ae6a2f473'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='e3302c41-b386-4dde-9e4d-dd7c539f83e4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8d8a98f8457e16eb35b3c845fc47abb830e1db7548f1496ac8714935388894e8'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='70d45075-2d60-4017-9ba2-b3372c3a492a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e58fcbe574fcdbffc7f8ec6f1bf5cc7593178784e42d8aa4fa6b982fad8aeaee')}, text='We\\ntherefore only apply context distillation on targeted samples when it increases RM score.\\nRejectingContextDistillationErrorswiththeSafetyRewardModel Itisimportanttonotethatperforming\\nsafetycontextdistillationforhelpfulpromptscandegrademodelperformanceandleadtomorefalserefusals\\n(see Appendix Table 40). We therefore perform safety context distillation only on adversarial prompts.\\nHowever, we observed that context distillation can sometimes degrade response quality, even when dealing\\nwith adversarial prompts.', start_char_idx=815, end_char_idx=1329, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-28', obj=None),\n",
       " '70d45075-2d60-4017-9ba2-b3372c3a492a': IndexNode(id_='70d45075-2d60-4017-9ba2-b3372c3a492a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-28', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b02e1f94deee7a3688f7233356d57c9cf635789e10729c94b1e9da1ae6a2f473'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='f8f42a7b-da5b-444d-b8d7-1c5ff0f5a353', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f87699f296c51d63dbd230771c1852bcbbdac2d1e1574628c790dfa622341dda'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='1a01d4c7-6a44-4393-b2f1-939b3286e2b5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='256108962f17dd2ef8f79afdc641472084e96b6655776386bbc2f549bfdd4633')}, text='RejectingContextDistillationErrorswiththeSafetyRewardModel Itisimportanttonotethatperforming\\nsafetycontextdistillationforhelpfulpromptscandegrademodelperformanceandleadtomorefalserefusals\\n(see Appendix Table 40). We therefore perform safety context distillation only on adversarial prompts.\\nHowever, we observed that context distillation can sometimes degrade response quality, even when dealing\\nwith adversarial prompts. Specifically, if the model responses are already of high quality, the application of\\ncontext distillation can result in less pertinent replies, as the model tends to overemphasize the preprompt,\\noften resorting to generic concerns excessively (see Appendix Table 40 for an example of vague answers due\\ntocontextdistillation).', start_char_idx=908, end_char_idx=1655, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-28', obj=None),\n",
       " '1a01d4c7-6a44-4393-b2f1-939b3286e2b5': IndexNode(id_='1a01d4c7-6a44-4393-b2f1-939b3286e2b5', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-28', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b02e1f94deee7a3688f7233356d57c9cf635789e10729c94b1e9da1ae6a2f473'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='70d45075-2d60-4017-9ba2-b3372c3a492a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e58fcbe574fcdbffc7f8ec6f1bf5cc7593178784e42d8aa4fa6b982fad8aeaee'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='b87b0b9d-e16d-4aaf-9511-f04ab31ca3a9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='cc6422e6e0aeff4cff3f6f0ea1c09b807bfe08eab87b60737dbdb10d6b2245c0')}, text='However, we observed that context distillation can sometimes degrade response quality, even when dealing\\nwith adversarial prompts. Specifically, if the model responses are already of high quality, the application of\\ncontext distillation can result in less pertinent replies, as the model tends to overemphasize the preprompt,\\noften resorting to generic concerns excessively (see Appendix Table 40 for an example of vague answers due\\ntocontextdistillation). Wethusleveragethesafetyrewardmodeltodecidewhethertousesafetycontext\\ndistillation – we keep the context-distilled output only on the examples where it gets a better reward model\\nscore than the original answer.', start_char_idx=1199, end_char_idx=1864, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-28', obj=None),\n",
       " 'b87b0b9d-e16d-4aaf-9511-f04ab31ca3a9': IndexNode(id_='b87b0b9d-e16d-4aaf-9511-f04ab31ca3a9', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-28', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b02e1f94deee7a3688f7233356d57c9cf635789e10729c94b1e9da1ae6a2f473'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='1a01d4c7-6a44-4393-b2f1-939b3286e2b5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='256108962f17dd2ef8f79afdc641472084e96b6655776386bbc2f549bfdd4633'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='f101ce11-f830-41aa-9f97-6240145eacdb', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='014fb8140a2b7907b589d9da9e6c31fbaba56a640b1b41dac9ed3fa6fc4ef362')}, text='Wethusleveragethesafetyrewardmodeltodecidewhethertousesafetycontext\\ndistillation – we keep the context-distilled output only on the examples where it gets a better reward model\\nscore than the original answer. We notice that thisis particularly helpful on prompts that the model is very\\nbad at, but limits the negative impact of context distillation (see Figure 16b).', start_char_idx=1656, end_char_idx=2022, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-28', obj=None),\n",
       " 'f101ce11-f830-41aa-9f97-6240145eacdb': IndexNode(id_='f101ce11-f830-41aa-9f97-6240145eacdb', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-28', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b02e1f94deee7a3688f7233356d57c9cf635789e10729c94b1e9da1ae6a2f473'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='b87b0b9d-e16d-4aaf-9511-f04ab31ca3a9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='cc6422e6e0aeff4cff3f6f0ea1c09b807bfe08eab87b60737dbdb10d6b2245c0'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='59054707-4ff8-4279-9e58-67e9c2a48a3c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='871d804c3545588f023ea7e5e17106d09cfc6d4bb7ccded098ebf6073f32f6ec')}, text='Wethusleveragethesafetyrewardmodeltodecidewhethertousesafetycontext\\ndistillation – we keep the context-distilled output only on the examples where it gets a better reward model\\nscore than the original answer. We notice that thisis particularly helpful on prompts that the model is very\\nbad at, but limits the negative impact of context distillation (see Figure 16b).\\n4.3 Red Teaming\\nGivenhowbroadthecapabilitiesofLLMsareandhowvariedtheirtrainingdatais,itisinsufficienttoidentify\\nrisks solely via ex post facto usage and analysis.', start_char_idx=1656, end_char_idx=2185, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-28', obj=None),\n",
       " '59054707-4ff8-4279-9e58-67e9c2a48a3c': IndexNode(id_='59054707-4ff8-4279-9e58-67e9c2a48a3c', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-28', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b02e1f94deee7a3688f7233356d57c9cf635789e10729c94b1e9da1ae6a2f473'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='f101ce11-f830-41aa-9f97-6240145eacdb', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='014fb8140a2b7907b589d9da9e6c31fbaba56a640b1b41dac9ed3fa6fc4ef362'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='0d070007-529c-4059-910c-2323c18c84aa', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a96b683acdb2846e3e0ece6a407b0ffc0556665384278bda8ae4a42a9c98e122')}, text='We notice that thisis particularly helpful on prompts that the model is very\\nbad at, but limits the negative impact of context distillation (see Figure 16b).\\n4.3 Red Teaming\\nGivenhowbroadthecapabilitiesofLLMsareandhowvariedtheirtrainingdatais,itisinsufficienttoidentify\\nrisks solely via ex post facto usage and analysis. Rather, as has been done for other LLMs, we performed\\nvarious kinds of proactive risk identification, colloquially called “red teaming,“ based on the term commonly\\nused within computer security.', start_char_idx=1865, end_char_idx=2380, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-28', obj=None),\n",
       " '0d070007-529c-4059-910c-2323c18c84aa': IndexNode(id_='0d070007-529c-4059-910c-2323c18c84aa', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-28', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b02e1f94deee7a3688f7233356d57c9cf635789e10729c94b1e9da1ae6a2f473'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='59054707-4ff8-4279-9e58-67e9c2a48a3c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='871d804c3545588f023ea7e5e17106d09cfc6d4bb7ccded098ebf6073f32f6ec'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='802ddbb6-5fa6-4025-8991-1e16a8e1b704', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='abfef20edb643582bf0f80d32b4a3ae789c786a28c3ede6c81c8c5169b536700')}, text='4.3 Red Teaming\\nGivenhowbroadthecapabilitiesofLLMsareandhowvariedtheirtrainingdatais,itisinsufficienttoidentify\\nrisks solely via ex post facto usage and analysis. Rather, as has been done for other LLMs, we performed\\nvarious kinds of proactive risk identification, colloquially called “red teaming,“ based on the term commonly\\nused within computer security. This kind of granular analysis is very important because safety is a long-tail\\nissue,inwhichevenveryinfrequentedgecasescancausenoticeableproblems.', start_char_idx=2023, end_char_idx=2527, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-28', obj=None),\n",
       " '802ddbb6-5fa6-4025-8991-1e16a8e1b704': IndexNode(id_='802ddbb6-5fa6-4025-8991-1e16a8e1b704', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-28', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b02e1f94deee7a3688f7233356d57c9cf635789e10729c94b1e9da1ae6a2f473'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='0d070007-529c-4059-910c-2323c18c84aa', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a96b683acdb2846e3e0ece6a407b0ffc0556665384278bda8ae4a42a9c98e122'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='73deb8fd-09d9-4701-bd67-ca9df9911bac', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='dc4714f390d39686fd54ce77f5b33c342c9b53ede4d42a61297cdc68873f8b44')}, text='Rather, as has been done for other LLMs, we performed\\nvarious kinds of proactive risk identification, colloquially called “red teaming,“ based on the term commonly\\nused within computer security. This kind of granular analysis is very important because safety is a long-tail\\nissue,inwhichevenveryinfrequentedgecasescancausenoticeableproblems. Evenifquantitativescores\\nreport good results, these types of qualitative insights allow us to recognize and target specific patterns in a\\nmore comprehensive way.', start_char_idx=2186, end_char_idx=2689, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-28', obj=None),\n",
       " '73deb8fd-09d9-4701-bd67-ca9df9911bac': IndexNode(id_='73deb8fd-09d9-4701-bd67-ca9df9911bac', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-28', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b02e1f94deee7a3688f7233356d57c9cf635789e10729c94b1e9da1ae6a2f473'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='802ddbb6-5fa6-4025-8991-1e16a8e1b704', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='abfef20edb643582bf0f80d32b4a3ae789c786a28c3ede6c81c8c5169b536700'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='2dbb4ef8-1614-4686-8cb1-d028f37d2e54', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e64729440cad072163555ffdec8ab63774218c02af49cc577b20c0919c00d410')}, text='This kind of granular analysis is very important because safety is a long-tail\\nissue,inwhichevenveryinfrequentedgecasescancausenoticeableproblems. Evenifquantitativescores\\nreport good results, these types of qualitative insights allow us to recognize and target specific patterns in a\\nmore comprehensive way.\\nWe conducted a series of red teaming with various groups of internal employees, contract workers, and\\nexternalvendors.', start_char_idx=2381, end_char_idx=2808, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-28', obj=None),\n",
       " '2dbb4ef8-1614-4686-8cb1-d028f37d2e54': IndexNode(id_='2dbb4ef8-1614-4686-8cb1-d028f37d2e54', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-28', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b02e1f94deee7a3688f7233356d57c9cf635789e10729c94b1e9da1ae6a2f473'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='73deb8fd-09d9-4701-bd67-ca9df9911bac', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='dc4714f390d39686fd54ce77f5b33c342c9b53ede4d42a61297cdc68873f8b44'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='14c145ca-e742-44b2-be94-c5e6a6aa02f1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e24f1f68ed39da96f6bbf1fcf0a6e5433f258defc7b6d97dff1196ba2a239769')}, text='This kind of granular analysis is very important because safety is a long-tail\\nissue,inwhichevenveryinfrequentedgecasescancausenoticeableproblems. Evenifquantitativescores\\nreport good results, these types of qualitative insights allow us to recognize and target specific patterns in a\\nmore comprehensive way.\\nWe conducted a series of red teaming with various groups of internal employees, contract workers, and\\nexternalvendors. Theseteamsincludedover350people,includingdomainexpertsincybersecurity,elec-\\ntion fraud, social media misinformation, legal, policy, civil rights, ethics, software engineering, machine\\nlearning, responsible AI, and creative writing.', start_char_idx=2381, end_char_idx=3040, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-28', obj=None),\n",
       " '14c145ca-e742-44b2-be94-c5e6a6aa02f1': IndexNode(id_='14c145ca-e742-44b2-be94-c5e6a6aa02f1', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-28', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b02e1f94deee7a3688f7233356d57c9cf635789e10729c94b1e9da1ae6a2f473'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='2dbb4ef8-1614-4686-8cb1-d028f37d2e54', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e64729440cad072163555ffdec8ab63774218c02af49cc577b20c0919c00d410'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='c06845f4-a4c3-411f-8b4c-53fa83329b9d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='fcbafd968d120f92c8c0c88ca09a0b4c18516d329d88e674805c7af230a9757f')}, text='We conducted a series of red teaming with various groups of internal employees, contract workers, and\\nexternalvendors. Theseteamsincludedover350people,includingdomainexpertsincybersecurity,elec-\\ntion fraud, social media misinformation, legal, policy, civil rights, ethics, software engineering, machine\\nlearning, responsible AI, and creative writing. They also included individuals representative of a variety of\\nsocioeconomic, gender, ethnicity, and racial demographics.', start_char_idx=2690, end_char_idx=3161, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-28', obj=None),\n",
       " 'c06845f4-a4c3-411f-8b4c-53fa83329b9d': IndexNode(id_='c06845f4-a4c3-411f-8b4c-53fa83329b9d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-28', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b02e1f94deee7a3688f7233356d57c9cf635789e10729c94b1e9da1ae6a2f473'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='14c145ca-e742-44b2-be94-c5e6a6aa02f1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e24f1f68ed39da96f6bbf1fcf0a6e5433f258defc7b6d97dff1196ba2a239769'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='d944f0d0-6a25-4b48-867b-ab12a5cab8c5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1e9e001b42f367bafb3bc16264f56ddab1dcfc48110a7491a3f5f3a9d9dcc259')}, text='We conducted a series of red teaming with various groups of internal employees, contract workers, and\\nexternalvendors. Theseteamsincludedover350people,includingdomainexpertsincybersecurity,elec-\\ntion fraud, social media misinformation, legal, policy, civil rights, ethics, software engineering, machine\\nlearning, responsible AI, and creative writing. They also included individuals representative of a variety of\\nsocioeconomic, gender, ethnicity, and racial demographics.\\n28\\n\\nTheredteamersprobedourmodelsacrossawiderangeofriskcategories(suchascriminalplanning,human\\ntrafficking, regulated or controlled substances, sexually explicit content, unqualified health or financial\\nadvice, privacy violations, and more), as well as different attack vectors (such as hypothetical questions,\\nmalformed/misspelledinputs,orextendeddialogues).', start_char_idx=2690, end_char_idx=3520, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-28', obj=None),\n",
       " 'd944f0d0-6a25-4b48-867b-ab12a5cab8c5': IndexNode(id_='d944f0d0-6a25-4b48-867b-ab12a5cab8c5', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-28', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b02e1f94deee7a3688f7233356d57c9cf635789e10729c94b1e9da1ae6a2f473'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='c06845f4-a4c3-411f-8b4c-53fa83329b9d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='fcbafd968d120f92c8c0c88ca09a0b4c18516d329d88e674805c7af230a9757f'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='9f95ea06-5ade-4cda-8061-c4b94dadf652', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='35114a4edda549539a23cd03fb7f59a342ee662dbb1e6949f8c5bc4a9c66c047')}, text='28\\n\\nTheredteamersprobedourmodelsacrossawiderangeofriskcategories(suchascriminalplanning,human\\ntrafficking, regulated or controlled substances, sexually explicit content, unqualified health or financial\\nadvice, privacy violations, and more), as well as different attack vectors (such as hypothetical questions,\\nmalformed/misspelledinputs,orextendeddialogues). Additionally,weconductedspecificteststodetermine\\nthe capabilities of our models to facilitate the production of weapons (e.g.', start_char_idx=3162, end_char_idx=3646, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-28', obj=None),\n",
       " '9f95ea06-5ade-4cda-8061-c4b94dadf652': IndexNode(id_='9f95ea06-5ade-4cda-8061-c4b94dadf652', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-28', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b02e1f94deee7a3688f7233356d57c9cf635789e10729c94b1e9da1ae6a2f473'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='d944f0d0-6a25-4b48-867b-ab12a5cab8c5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1e9e001b42f367bafb3bc16264f56ddab1dcfc48110a7491a3f5f3a9d9dcc259'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='8f683eb2-83ce-4dd1-87ba-44130f0ddfcd', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b1e60c9d4605b1fd1d954a2cb71fd623c88bf3b11b1ce4683597abc7642006ae')}, text='Additionally,weconductedspecificteststodetermine\\nthe capabilities of our models to facilitate the production of weapons (e.g. nuclear, biological, chemical, and\\ncyber); findingsonthesetopicsweremarginal andweremitigated. Nonetheless, wewill continueourred\\nteaming efforts in this front.\\nTodate,allofourredteamingeffortshavetargetedmodeloutputsinEnglish,buthavecruciallyincluded\\nnon-Englishpromptsanddialoguecontexts,asthatisawell-knownattackvector.', start_char_idx=3521, end_char_idx=3969, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-28', obj=None),\n",
       " '8f683eb2-83ce-4dd1-87ba-44130f0ddfcd': IndexNode(id_='8f683eb2-83ce-4dd1-87ba-44130f0ddfcd', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-28', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b02e1f94deee7a3688f7233356d57c9cf635789e10729c94b1e9da1ae6a2f473'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='9f95ea06-5ade-4cda-8061-c4b94dadf652', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='35114a4edda549539a23cd03fb7f59a342ee662dbb1e6949f8c5bc4a9c66c047')}, text='nuclear, biological, chemical, and\\ncyber); findingsonthesetopicsweremarginal andweremitigated. Nonetheless, wewill continueourred\\nteaming efforts in this front.\\nTodate,allofourredteamingeffortshavetargetedmodeloutputsinEnglish,buthavecruciallyincluded\\nnon-Englishpromptsanddialoguecontexts,asthatisawell-knownattackvector. Inallexercises,participants\\nwere given risk category definitions and were shown just a handful of examples of risky interactions with an\\nLLM.Afterthat,eachparticipantwaspartofasubteamfocusedonaparticularcategoryofriskorattack\\nvector.', start_char_idx=3647, end_char_idx=4203, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-28', obj=None),\n",
       " 'daab36de-2cf8-4dea-a870-cdea1ebd7a19': IndexNode(id_='daab36de-2cf8-4dea-a870-cdea1ebd7a19', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-28', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b02e1f94deee7a3688f7233356d57c9cf635789e10729c94b1e9da1ae6a2f473'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='644e8ef7-b67a-4df2-a470-41574a22de17', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='22a560f2f00bae0411738f5339932c0d1156b8edd80d1578b48fc3a54b1ab8ee')}, text='27\\n\\n0 0.2 0.4 0.6 0.8 10123456\\nModel\\nBase\\n+ Generic Preprompt\\n+ Preprompt w/ Answer T emplate\\nSafety RM ScorePercent(a)Impact on Safety RM Score.\\n0 0.2 0.4 0.6 0.8 1−0.6−0.4−0.200.20.40.60.8\\nSelected?\\nSelected\\nRejected\\nOriginal Safety RM ScoreScore increase with CD (b)Targeted Context Distillation.\\nFigure 16: Context distillation analysis. Left: Distribution of safety RM scores from the base model, when\\nadding a generic preprompt, and when adding a preprompt based on the risk category with tailored answer\\ntemplate. While a generic preprompt increases safety RM scores, a preprompt with tailored answer template\\nhelpsevenmore. Right:ContextdistillationincreasestheRMscoresignificantlyforsamplesthatinitially\\nhave a low score, but can also have a detrimental effect on samples that initially have a high score. We\\ntherefore only apply context distillation on targeted samples when it increases RM score.', start_char_idx=0, end_char_idx=907, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-28', obj=None),\n",
       " '644e8ef7-b67a-4df2-a470-41574a22de17': IndexNode(id_='644e8ef7-b67a-4df2-a470-41574a22de17', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-28', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b02e1f94deee7a3688f7233356d57c9cf635789e10729c94b1e9da1ae6a2f473'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='daab36de-2cf8-4dea-a870-cdea1ebd7a19', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='7a7e6e15b8aeaf90672169626f8f211b515e063b6e341aebbb4f46578c388356'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='8a35a01d-25e5-4c19-a23a-6109f973b457', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='58e570237ba7c2a91b7beee442cb92cb587ee01b147b4e305464f50742143b31')}, text='While a generic preprompt increases safety RM scores, a preprompt with tailored answer template\\nhelpsevenmore. Right:ContextdistillationincreasestheRMscoresignificantlyforsamplesthatinitially\\nhave a low score, but can also have a detrimental effect on samples that initially have a high score. We\\ntherefore only apply context distillation on targeted samples when it increases RM score.\\nRejectingContextDistillationErrorswiththeSafetyRewardModel Itisimportanttonotethatperforming\\nsafetycontextdistillationforhelpfulpromptscandegrademodelperformanceandleadtomorefalserefusals\\n(see Appendix Table 40). We therefore perform safety context distillation only on adversarial prompts.\\nHowever, we observed that context distillation can sometimes degrade response quality, even when dealing\\nwith adversarial prompts. Specifically, if the model responses are already of high quality, the application of\\ncontext distillation can result in less pertinent replies, as the model tends to overemphasize the preprompt,\\noften resorting to generic concerns excessively (see Appendix Table 40 for an example of vague answers due\\ntocontextdistillation).', start_char_idx=521, end_char_idx=1655, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-28', obj=None),\n",
       " '8a35a01d-25e5-4c19-a23a-6109f973b457': IndexNode(id_='8a35a01d-25e5-4c19-a23a-6109f973b457', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-28', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b02e1f94deee7a3688f7233356d57c9cf635789e10729c94b1e9da1ae6a2f473'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='644e8ef7-b67a-4df2-a470-41574a22de17', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='22a560f2f00bae0411738f5339932c0d1156b8edd80d1578b48fc3a54b1ab8ee'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='6b06bb39-5025-4fa5-bf58-a5cfad2c4cab', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c9dc7f36a7d9abc0e41037a98a6a03003691c7d15a791242fb78d0a6e5a98c5f')}, text='However, we observed that context distillation can sometimes degrade response quality, even when dealing\\nwith adversarial prompts. Specifically, if the model responses are already of high quality, the application of\\ncontext distillation can result in less pertinent replies, as the model tends to overemphasize the preprompt,\\noften resorting to generic concerns excessively (see Appendix Table 40 for an example of vague answers due\\ntocontextdistillation). Wethusleveragethesafetyrewardmodeltodecidewhethertousesafetycontext\\ndistillation – we keep the context-distilled output only on the examples where it gets a better reward model\\nscore than the original answer. We notice that thisis particularly helpful on prompts that the model is very\\nbad at, but limits the negative impact of context distillation (see Figure 16b).\\n4.3 Red Teaming\\nGivenhowbroadthecapabilitiesofLLMsareandhowvariedtheirtrainingdatais,itisinsufficienttoidentify\\nrisks solely via ex post facto usage and analysis.', start_char_idx=1199, end_char_idx=2185, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-28', obj=None),\n",
       " '6b06bb39-5025-4fa5-bf58-a5cfad2c4cab': IndexNode(id_='6b06bb39-5025-4fa5-bf58-a5cfad2c4cab', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-28', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b02e1f94deee7a3688f7233356d57c9cf635789e10729c94b1e9da1ae6a2f473'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='8a35a01d-25e5-4c19-a23a-6109f973b457', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='58e570237ba7c2a91b7beee442cb92cb587ee01b147b4e305464f50742143b31'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='efb9a778-7c9e-446d-ac63-174a35acffb5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e913bb5112a48442d3ed30f726401fdb2110798da8e250f2227b568961b409b5')}, text='We notice that thisis particularly helpful on prompts that the model is very\\nbad at, but limits the negative impact of context distillation (see Figure 16b).\\n4.3 Red Teaming\\nGivenhowbroadthecapabilitiesofLLMsareandhowvariedtheirtrainingdatais,itisinsufficienttoidentify\\nrisks solely via ex post facto usage and analysis. Rather, as has been done for other LLMs, we performed\\nvarious kinds of proactive risk identification, colloquially called “red teaming,“ based on the term commonly\\nused within computer security. This kind of granular analysis is very important because safety is a long-tail\\nissue,inwhichevenveryinfrequentedgecasescancausenoticeableproblems. Evenifquantitativescores\\nreport good results, these types of qualitative insights allow us to recognize and target specific patterns in a\\nmore comprehensive way.\\nWe conducted a series of red teaming with various groups of internal employees, contract workers, and\\nexternalvendors.', start_char_idx=1865, end_char_idx=2808, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-28', obj=None),\n",
       " 'efb9a778-7c9e-446d-ac63-174a35acffb5': IndexNode(id_='efb9a778-7c9e-446d-ac63-174a35acffb5', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-28', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b02e1f94deee7a3688f7233356d57c9cf635789e10729c94b1e9da1ae6a2f473'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='6b06bb39-5025-4fa5-bf58-a5cfad2c4cab', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c9dc7f36a7d9abc0e41037a98a6a03003691c7d15a791242fb78d0a6e5a98c5f'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='9c32ad7d-410b-40c5-a18c-562b63989ca9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='49ffb902799579b746999bfd515e4e91f308ac75b4a9f542b1576660043f22d5')}, text='This kind of granular analysis is very important because safety is a long-tail\\nissue,inwhichevenveryinfrequentedgecasescancausenoticeableproblems. Evenifquantitativescores\\nreport good results, these types of qualitative insights allow us to recognize and target specific patterns in a\\nmore comprehensive way.\\nWe conducted a series of red teaming with various groups of internal employees, contract workers, and\\nexternalvendors. Theseteamsincludedover350people,includingdomainexpertsincybersecurity,elec-\\ntion fraud, social media misinformation, legal, policy, civil rights, ethics, software engineering, machine\\nlearning, responsible AI, and creative writing. They also included individuals representative of a variety of\\nsocioeconomic, gender, ethnicity, and racial demographics.\\n28\\n\\nTheredteamersprobedourmodelsacrossawiderangeofriskcategories(suchascriminalplanning,human\\ntrafficking, regulated or controlled substances, sexually explicit content, unqualified health or financial\\nadvice, privacy violations, and more), as well as different attack vectors (such as hypothetical questions,\\nmalformed/misspelledinputs,orextendeddialogues).', start_char_idx=2381, end_char_idx=3520, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-28', obj=None),\n",
       " '9c32ad7d-410b-40c5-a18c-562b63989ca9': IndexNode(id_='9c32ad7d-410b-40c5-a18c-562b63989ca9', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-28', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b02e1f94deee7a3688f7233356d57c9cf635789e10729c94b1e9da1ae6a2f473'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='efb9a778-7c9e-446d-ac63-174a35acffb5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e913bb5112a48442d3ed30f726401fdb2110798da8e250f2227b568961b409b5')}, text='28\\n\\nTheredteamersprobedourmodelsacrossawiderangeofriskcategories(suchascriminalplanning,human\\ntrafficking, regulated or controlled substances, sexually explicit content, unqualified health or financial\\nadvice, privacy violations, and more), as well as different attack vectors (such as hypothetical questions,\\nmalformed/misspelledinputs,orextendeddialogues). Additionally,weconductedspecificteststodetermine\\nthe capabilities of our models to facilitate the production of weapons (e.g. nuclear, biological, chemical, and\\ncyber); findingsonthesetopicsweremarginal andweremitigated. Nonetheless, wewill continueourred\\nteaming efforts in this front.\\nTodate,allofourredteamingeffortshavetargetedmodeloutputsinEnglish,buthavecruciallyincluded\\nnon-Englishpromptsanddialoguecontexts,asthatisawell-knownattackvector. Inallexercises,participants\\nwere given risk category definitions and were shown just a handful of examples of risky interactions with an\\nLLM.Afterthat,eachparticipantwaspartofasubteamfocusedonaparticularcategoryofriskorattack\\nvector.', start_char_idx=3162, end_char_idx=4203, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-28', obj=None),\n",
       " 'b9c2290b-7343-4153-aa9e-0a2f8fb5f29f': IndexNode(id_='b9c2290b-7343-4153-aa9e-0a2f8fb5f29f', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-28', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b02e1f94deee7a3688f7233356d57c9cf635789e10729c94b1e9da1ae6a2f473'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='c5f82faf-b593-4d4c-bfec-69dcfa4d8dc9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c1859bd4b659a34afd8c9c18e91097358730fe71b219f9eb3ba3a5a12c5665bd')}, text='27\\n\\n0 0.2 0.4 0.6 0.8 10123456\\nModel\\nBase\\n+ Generic Preprompt\\n+ Preprompt w/ Answer T emplate\\nSafety RM ScorePercent(a)Impact on Safety RM Score.\\n0 0.2 0.4 0.6 0.8 1−0.6−0.4−0.200.20.40.60.8\\nSelected?\\nSelected\\nRejected\\nOriginal Safety RM ScoreScore increase with CD (b)Targeted Context Distillation.\\nFigure 16: Context distillation analysis. Left: Distribution of safety RM scores from the base model, when\\nadding a generic preprompt, and when adding a preprompt based on the risk category with tailored answer\\ntemplate. While a generic preprompt increases safety RM scores, a preprompt with tailored answer template\\nhelpsevenmore. Right:ContextdistillationincreasestheRMscoresignificantlyforsamplesthatinitially\\nhave a low score, but can also have a detrimental effect on samples that initially have a high score. We\\ntherefore only apply context distillation on targeted samples when it increases RM score.\\nRejectingContextDistillationErrorswiththeSafetyRewardModel Itisimportanttonotethatperforming\\nsafetycontextdistillationforhelpfulpromptscandegrademodelperformanceandleadtomorefalserefusals\\n(see Appendix Table 40). We therefore perform safety context distillation only on adversarial prompts.\\nHowever, we observed that context distillation can sometimes degrade response quality, even when dealing\\nwith adversarial prompts. Specifically, if the model responses are already of high quality, the application of\\ncontext distillation can result in less pertinent replies, as the model tends to overemphasize the preprompt,\\noften resorting to generic concerns excessively (see Appendix Table 40 for an example of vague answers due\\ntocontextdistillation). Wethusleveragethesafetyrewardmodeltodecidewhethertousesafetycontext\\ndistillation – we keep the context-distilled output only on the examples where it gets a better reward model\\nscore than the original answer. We notice that thisis particularly helpful on prompts that the model is very\\nbad at, but limits the negative impact of context distillation (see Figure 16b).', start_char_idx=0, end_char_idx=2022, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-28', obj=None),\n",
       " 'c5f82faf-b593-4d4c-bfec-69dcfa4d8dc9': IndexNode(id_='c5f82faf-b593-4d4c-bfec-69dcfa4d8dc9', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-28', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b02e1f94deee7a3688f7233356d57c9cf635789e10729c94b1e9da1ae6a2f473'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='b9c2290b-7343-4153-aa9e-0a2f8fb5f29f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e3fc1824b1a0568503cc58b56d126921fcf05cd343c37048827cbe6bfa10add9'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='9b6680bf-c16b-4b84-b185-14657240ef21', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bc0e5682b327c2d3a0de79ba736bd4262c0b7b6eaeeffa95c8f616cf98fa554b')}, text='Wethusleveragethesafetyrewardmodeltodecidewhethertousesafetycontext\\ndistillation – we keep the context-distilled output only on the examples where it gets a better reward model\\nscore than the original answer. We notice that thisis particularly helpful on prompts that the model is very\\nbad at, but limits the negative impact of context distillation (see Figure 16b).\\n4.3 Red Teaming\\nGivenhowbroadthecapabilitiesofLLMsareandhowvariedtheirtrainingdatais,itisinsufficienttoidentify\\nrisks solely via ex post facto usage and analysis. Rather, as has been done for other LLMs, we performed\\nvarious kinds of proactive risk identification, colloquially called “red teaming,“ based on the term commonly\\nused within computer security. This kind of granular analysis is very important because safety is a long-tail\\nissue,inwhichevenveryinfrequentedgecasescancausenoticeableproblems. Evenifquantitativescores\\nreport good results, these types of qualitative insights allow us to recognize and target specific patterns in a\\nmore comprehensive way.\\nWe conducted a series of red teaming with various groups of internal employees, contract workers, and\\nexternalvendors. Theseteamsincludedover350people,includingdomainexpertsincybersecurity,elec-\\ntion fraud, social media misinformation, legal, policy, civil rights, ethics, software engineering, machine\\nlearning, responsible AI, and creative writing. They also included individuals representative of a variety of\\nsocioeconomic, gender, ethnicity, and racial demographics.\\n28\\n\\nTheredteamersprobedourmodelsacrossawiderangeofriskcategories(suchascriminalplanning,human\\ntrafficking, regulated or controlled substances, sexually explicit content, unqualified health or financial\\nadvice, privacy violations, and more), as well as different attack vectors (such as hypothetical questions,\\nmalformed/misspelledinputs,orextendeddialogues). Additionally,weconductedspecificteststodetermine\\nthe capabilities of our models to facilitate the production of weapons (e.g. nuclear, biological, chemical, and\\ncyber); findingsonthesetopicsweremarginal andweremitigated. Nonetheless, wewill continueourred\\nteaming efforts in this front.', start_char_idx=1656, end_char_idx=3807, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-28', obj=None),\n",
       " '9b6680bf-c16b-4b84-b185-14657240ef21': IndexNode(id_='9b6680bf-c16b-4b84-b185-14657240ef21', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-28', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b02e1f94deee7a3688f7233356d57c9cf635789e10729c94b1e9da1ae6a2f473'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='c5f82faf-b593-4d4c-bfec-69dcfa4d8dc9', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c1859bd4b659a34afd8c9c18e91097358730fe71b219f9eb3ba3a5a12c5665bd')}, text='Additionally,weconductedspecificteststodetermine\\nthe capabilities of our models to facilitate the production of weapons (e.g. nuclear, biological, chemical, and\\ncyber); findingsonthesetopicsweremarginal andweremitigated. Nonetheless, wewill continueourred\\nteaming efforts in this front.\\nTodate,allofourredteamingeffortshavetargetedmodeloutputsinEnglish,buthavecruciallyincluded\\nnon-Englishpromptsanddialoguecontexts,asthatisawell-knownattackvector. Inallexercises,participants\\nwere given risk category definitions and were shown just a handful of examples of risky interactions with an\\nLLM.Afterthat,eachparticipantwaspartofasubteamfocusedonaparticularcategoryofriskorattack\\nvector.', start_char_idx=3521, end_char_idx=4203, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-28', obj=None),\n",
       " 'node-28': IndexNode(id_='node-28', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='d03f19eb-da15-45dc-bfd4-e5d10f161250', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='231b3bd773f012c01b893ada9e009ecf25ee59934614c5a595c9bf1b3a123292'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='c6711ebd-8f25-453c-b23a-f1e3e92c8a41', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8c57c6cfae0a8947edc7b8dc66872d0f3d6d89b4e2949536f8191daa0bb86200'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='1952a994-053a-42c4-a455-59babca5d2e3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='164041961fc0c57e5365a12d785f7a9a20e77b1d02d598d079f61ce0fd895a5e')}, text='27\\n\\n0 0.2 0.4 0.6 0.8 10123456\\nModel\\nBase\\n+ Generic Preprompt\\n+ Preprompt w/ Answer T emplate\\nSafety RM ScorePercent(a)Impact on Safety RM Score.\\n0 0.2 0.4 0.6 0.8 1−0.6−0.4−0.200.20.40.60.8\\nSelected?\\nSelected\\nRejected\\nOriginal Safety RM ScoreScore increase with CD (b)Targeted Context Distillation.\\nFigure 16: Context distillation analysis. Left: Distribution of safety RM scores from the base model, when\\nadding a generic preprompt, and when adding a preprompt based on the risk category with tailored answer\\ntemplate. While a generic preprompt increases safety RM scores, a preprompt with tailored answer template\\nhelpsevenmore. Right:ContextdistillationincreasestheRMscoresignificantlyforsamplesthatinitially\\nhave a low score, but can also have a detrimental effect on samples that initially have a high score. We\\ntherefore only apply context distillation on targeted samples when it increases RM score.\\nRejectingContextDistillationErrorswiththeSafetyRewardModel Itisimportanttonotethatperforming\\nsafetycontextdistillationforhelpfulpromptscandegrademodelperformanceandleadtomorefalserefusals\\n(see Appendix Table 40). We therefore perform safety context distillation only on adversarial prompts.\\nHowever, we observed that context distillation can sometimes degrade response quality, even when dealing\\nwith adversarial prompts. Specifically, if the model responses are already of high quality, the application of\\ncontext distillation can result in less pertinent replies, as the model tends to overemphasize the preprompt,\\noften resorting to generic concerns excessively (see Appendix Table 40 for an example of vague answers due\\ntocontextdistillation). Wethusleveragethesafetyrewardmodeltodecidewhethertousesafetycontext\\ndistillation – we keep the context-distilled output only on the examples where it gets a better reward model\\nscore than the original answer. We notice that thisis particularly helpful on prompts that the model is very\\nbad at, but limits the negative impact of context distillation (see Figure 16b).\\n4.3 Red Teaming\\nGivenhowbroadthecapabilitiesofLLMsareandhowvariedtheirtrainingdatais,itisinsufficienttoidentify\\nrisks solely via ex post facto usage and analysis. Rather, as has been done for other LLMs, we performed\\nvarious kinds of proactive risk identification, colloquially called “red teaming,“ based on the term commonly\\nused within computer security. This kind of granular analysis is very important because safety is a long-tail\\nissue,inwhichevenveryinfrequentedgecasescancausenoticeableproblems. Evenifquantitativescores\\nreport good results, these types of qualitative insights allow us to recognize and target specific patterns in a\\nmore comprehensive way.\\nWe conducted a series of red teaming with various groups of internal employees, contract workers, and\\nexternalvendors. Theseteamsincludedover350people,includingdomainexpertsincybersecurity,elec-\\ntion fraud, social media misinformation, legal, policy, civil rights, ethics, software engineering, machine\\nlearning, responsible AI, and creative writing. They also included individuals representative of a variety of\\nsocioeconomic, gender, ethnicity, and racial demographics.\\n28\\n\\nTheredteamersprobedourmodelsacrossawiderangeofriskcategories(suchascriminalplanning,human\\ntrafficking, regulated or controlled substances, sexually explicit content, unqualified health or financial\\nadvice, privacy violations, and more), as well as different attack vectors (such as hypothetical questions,\\nmalformed/misspelledinputs,orextendeddialogues). Additionally,weconductedspecificteststodetermine\\nthe capabilities of our models to facilitate the production of weapons (e.g. nuclear, biological, chemical, and\\ncyber); findingsonthesetopicsweremarginal andweremitigated. Nonetheless, wewill continueourred\\nteaming efforts in this front.\\nTodate,allofourredteamingeffortshavetargetedmodeloutputsinEnglish,buthavecruciallyincluded\\nnon-Englishpromptsanddialoguecontexts,asthatisawell-knownattackvector. Inallexercises,participants\\nwere given risk category definitions and were shown just a handful of examples of risky interactions with an\\nLLM.Afterthat,eachparticipantwaspartofasubteamfocusedonaparticularcategoryofriskorattack\\nvector.', start_char_idx=90005, end_char_idx=94208, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-28', obj=None),\n",
       " '4279b211-f878-481d-9abe-9de86e358013': IndexNode(id_='4279b211-f878-481d-9abe-9de86e358013', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-29', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='164041961fc0c57e5365a12d785f7a9a20e77b1d02d598d079f61ce0fd895a5e'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='3e48cde3-b7c1-45aa-b90b-72f708d10ddb', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='cbe5f499d89e002016403cfcd129260f2fd3d11fc1f019671f64c09c1c486e33')}, text='Todate,allofourredteamingeffortshavetargetedmodeloutputsinEnglish,buthavecruciallyincluded\\nnon-Englishpromptsanddialoguecontexts,asthatisawell-knownattackvector. Inallexercises,participants\\nwere given risk category definitions and were shown just a handful of examples of risky interactions with an\\nLLM.Afterthat,eachparticipantwaspartofasubteamfocusedonaparticularcategoryofriskorattack\\nvector.', start_char_idx=0, end_char_idx=395, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-29', obj=None),\n",
       " '3e48cde3-b7c1-45aa-b90b-72f708d10ddb': IndexNode(id_='3e48cde3-b7c1-45aa-b90b-72f708d10ddb', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-29', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='164041961fc0c57e5365a12d785f7a9a20e77b1d02d598d079f61ce0fd895a5e'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='4279b211-f878-481d-9abe-9de86e358013', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9ad4e43cdfdc5f69b8c292621eb0c86df1ff6218d5ac673e02c1d97372df8ae3'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='ef2dc930-9da1-4341-a46e-c060aecfb069', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2ac85e3ec7616bdb2fd946dd73735266c3da4ca8b5b5ece3e012c0b72da62e7c')}, text='Todate,allofourredteamingeffortshavetargetedmodeloutputsinEnglish,buthavecruciallyincluded\\nnon-Englishpromptsanddialoguecontexts,asthatisawell-knownattackvector. Inallexercises,participants\\nwere given risk category definitions and were shown just a handful of examples of risky interactions with an\\nLLM.Afterthat,eachparticipantwaspartofasubteamfocusedonaparticularcategoryofriskorattack\\nvector. Aftercreatingeachdialogue,theredteamparticipantwouldannotatevariousattributes,including\\nrisk areas and degree of risk, as captured by a 5-point Likert scale.', start_char_idx=0, end_char_idx=553, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-29', obj=None),\n",
       " 'ef2dc930-9da1-4341-a46e-c060aecfb069': IndexNode(id_='ef2dc930-9da1-4341-a46e-c060aecfb069', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='node-29', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='164041961fc0c57e5365a12d785f7a9a20e77b1d02d598d079f61ce0fd895a5e'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='3e48cde3-b7c1-45aa-b90b-72f708d10ddb', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='cbe5f499d89e002016403cfcd129260f2fd3d11fc1f019671f64c09c1c486e33'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='b6dd4950-1ff5-4eab-9ffb-f64ede3af001', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3feb70d397dbb3d9eb52dde3ab1775c56bd164d85a49c77f9ae8f4e26a5074e3')}, text='Inallexercises,participants\\nwere given risk category definitions and were shown just a handful of examples of risky interactions with an\\nLLM.Afterthat,eachparticipantwaspartofasubteamfocusedonaparticularcategoryofriskorattack\\nvector. Aftercreatingeachdialogue,theredteamparticipantwouldannotatevariousattributes,including\\nrisk areas and degree of risk, as captured by a 5-point Likert scale.\\nSome examples of useful insights provided by members of red teams that we were able to improve upon\\nthroughout development:\\n•[Early models] were more likely to have generated unsafe responses without noting that they con-\\ntain problematiccontent.', start_char_idx=162, end_char_idx=800, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', index_id='node-29', obj=None),\n",
       " ...}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_nodes_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_index_chunk = VectorStoreIndex(\n",
    "    all_nodes, service_context=service_context\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_retriever_chunk = vector_index_chunk.as_retriever(similarity_top_k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_chunk = RecursiveRetriever(\n",
    "    \"vector\",\n",
    "    retriever_dict={\"vector\": vector_retriever_chunk},\n",
    "    node_dict=all_nodes_dict,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;34mRetrieving with query id None: Can you tell me about the key concepts for safety finetuning\n",
      "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-1\n",
      "\u001b[0m\u001b[1;3;34mRetrieving with query id node-1: Can you tell me about the key concepts for safety finetuning\n",
      "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-23\n",
      "\u001b[0m\u001b[1;3;34mRetrieving with query id node-23: Can you tell me about the key concepts for safety finetuning\n",
      "\u001b[0m"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** node-1<br>**Similarity:** 0.7809597072720084<br>**Text:** . . . . . . . . . . . . . . . . . . . . 9\n",
       "3.3 System Message for Multi-Turn Consistency . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\n",
       "3.4 RLHF Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\n",
       "4 Safety 20\n",
       "4.1 Safety in Pretraining . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20\n",
       "4.2 Safety Fine-Tuning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\n",
       "4.3 Red Teaming . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28\n",
       "4.4 Safety Evaluation of Llama 2-Chat . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\n",
       "5 Discussion 32\n",
       "5.1 Learnings and Observations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32\n",
       "5.2 Limitations and Ethical Considerations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34\n",
       "5.3 Responsible Release Strategy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\n",
       "6 Related Work 35\n",
       "7 Conclusion 36\n",
       "A Appendix 46\n",
       "A.1 Contributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46\n",
       "A.2 Additional Details for Pretraining . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** node-23<br>**Similarity:** 0.7759929462806293<br>**Text:** In Appendix A.4.7, we present bias metrics, such as how the sentiment of model generations varies with\n",
       "demographic attributes. We note an increase in positive sentiment overall for many of the groups using\n",
       "BOLDprompts. MoredetailedresultssplitbydifferentdemographicgroupscanbefoundinAppendixA.4.8.\n",
       "Llama 2 doesnotoutperformothermodelsontoxicitymetrics,andwespeculatethatthismaybebecausewe\n",
       "refrained from aggressively filtering the pretraining data. Recall that leaving pretraining data unfiltered may\n",
       "enable base models tuned to perform well on more downstream tasks (including hate speech detection),\n",
       "and it carries less risk of accidentally filtering out some demographic groups. We observe that models\n",
       "trained from less aggressively filtered pretraining data also required fewer examples to achieve reasonable\n",
       "safety-alignment. Wereiteratethatthismotivatedchoicedoesimplythatadditionalsafetymitigationsshould\n",
       "be applied before deployment of base Llama 2 models.\n",
       "22\n",
       "\n",
       "TruthfulQA ↑ToxiGen ↓\n",
       "MPT7B 29.13 22.32\n",
       "30B 35.25 22.61\n",
       "Falcon7B 25.95 14.53\n",
       "40B 40.39 23.44\n",
       "Llama 17B 27.42 23.00\n",
       "13B 41.74 23.08\n",
       "33B 44.19 22.57\n",
       "65B 48.71 21.77\n",
       "Llama 27B 33.29 21.25\n",
       "13B 41.86 26.10\n",
       "34B 43.45 21.19\n",
       "70B 50.18 24.60\n",
       "Table 11: Evaluation of pretrained LLMs on automatic safety benchmarks. For TruthfulQA, we present the\n",
       "percentageofgenerationsthatarebothtruthfulandinformative(thehigherthebetter). ForToxiGen,we\n",
       "present the percentage of toxic generations (the smaller, the better).\n",
       "Benchmarks give a summary view ofmodel capabilities and behaviors that allow us to understand general\n",
       "patternsinthemodel,buttheydonotprovideafullycomprehensiveviewoftheimpactthemodelmayhave\n",
       "onpeopleorreal-worldoutcomes;thatwouldrequirestudyofend-to-endproductdeployments. Further\n",
       "testing and mitigation should be done to understand bias and other social issues for the specific context\n",
       "in which a system may be deployed. For this, it may be necessary to test beyond the groups available in\n",
       "theBOLDdataset(race,religion,andgender)...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nodes = retriever_chunk.retrieve(\n",
    "    \"Can you tell me about the key concepts for safety finetuning\"\n",
    ")\n",
    "for node in nodes:\n",
    "    display_source_node(node, source_length=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine_chunk = RetrieverQueryEngine.from_args(\n",
    "    retriever_chunk, service_context=service_context\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;34mRetrieving with query id None: Can you tell me about the key concepts for safety finetuning\n",
      "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-1\n",
      "\u001b[0m\u001b[1;3;34mRetrieving with query id node-1: Can you tell me about the key concepts for safety finetuning\n",
      "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: node-23\n",
      "\u001b[0m\u001b[1;3;34mRetrieving with query id node-23: Can you tell me about the key concepts for safety finetuning\n",
      "\u001b[0m1. Supervised Safety Fine-Tuning\n",
      "2. Safety RLHF\n",
      "3. Safety Context Distillation\n"
     ]
    }
   ],
   "source": [
    "response = query_engine_chunk.query(\n",
    "    \"Can you tell me about the key concepts for safety finetuning\"\n",
    ")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.evaluation import (\n",
    "    generate_question_context_pairs,\n",
    "    EmbeddingQAFinetuneDataset,\n",
    ")\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "llm = GoogleGenerativeAI(model=\"gemini-pro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "BaseLLM.invoke() missing 1 required positional argument: 'input'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Settings\n\u001b[0;32m----> 2\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m Settings\u001b[38;5;241m.\u001b[39mresponse \u001b[38;5;241m=\u001b[39m response\n",
      "\u001b[0;31mTypeError\u001b[0m: BaseLLM.invoke() missing 1 required positional argument: 'input'"
     ]
    }
   ],
   "source": [
    "from llama_index.core import Settings\n",
    "\n",
    "\n",
    "Settings.response = response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/84 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'GoogleGenerativeAI' object has no attribute 'complete'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m eval_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_question_context_pairs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_nodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mllm\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/VS_Code/GitHub/Advanced_RAG/venv/lib/python3.11/site-packages/llama_index/core/llama_dataset/legacy/embedding.py:86\u001b[0m, in \u001b[0;36mgenerate_qa_embedding_pairs\u001b[0;34m(nodes, llm, qa_generate_prompt_tmpl, num_questions_per_chunk)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m node_id, text \u001b[38;5;129;01min\u001b[39;00m tqdm(node_dict\u001b[38;5;241m.\u001b[39mitems()):\n\u001b[1;32m     83\u001b[0m     query \u001b[38;5;241m=\u001b[39m qa_generate_prompt_tmpl\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m     84\u001b[0m         context_str\u001b[38;5;241m=\u001b[39mtext, num_questions_per_chunk\u001b[38;5;241m=\u001b[39mnum_questions_per_chunk\n\u001b[1;32m     85\u001b[0m     )\n\u001b[0;32m---> 86\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomplete\u001b[49m(query)\n\u001b[1;32m     88\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(response)\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     89\u001b[0m     questions \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     90\u001b[0m         re\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m^\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+[\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms]\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, question)\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;28;01mfor\u001b[39;00m question \u001b[38;5;129;01min\u001b[39;00m result\n\u001b[1;32m     91\u001b[0m     ]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GoogleGenerativeAI' object has no attribute 'complete'"
     ]
    }
   ],
   "source": [
    "eval_dataset = generate_question_context_pairs(base_nodes, llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
